{
  "version": "1.0",
  "updated_at": "2025-10-22T20:19:52.193339",
  "files": {
    "ui\\app.py": {
      "file_path": "ui\\app.py",
      "sha256": "e823eda1ef09b3583749a7cbb914a63d4216c8b99cfea2a4a69523da91d00902",
      "mtime": 1760708281.0978136,
      "size_bytes": 21039,
      "language": "python",
      "chunk_count": 17,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.039311",
      "status": "completed"
    },
    "db\\__init__.py": {
      "file_path": "db\\__init__.py",
      "sha256": "571752226de1f4e6315ece8454bf478fba65f68d0f4b1699fec70b4349240679",
      "mtime": 1760777607.7765794,
      "size_bytes": 307,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.039835",
      "status": "completed"
    },
    "features\\__init__.py": {
      "file_path": "features\\__init__.py",
      "sha256": "b780bcd1560497635612d3b61b8ed10bd1391f6c9c43fd68e900394255d91dd4",
      "mtime": 1760707910.578414,
      "size_bytes": 615,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.039835",
      "status": "completed"
    },
    "features\\code_generator\\__init__.py": {
      "file_path": "features\\code_generator\\__init__.py",
      "sha256": "38119c9797c1620ce54fa2f16d302d1875e7cb09817dbf1c500308265a8234dd",
      "mtime": 1760679926.8950346,
      "size_bytes": 75,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\context_resolver\\__init__.py": {
      "file_path": "features\\context_resolver\\__init__.py",
      "sha256": "08c0d232e08e968aeb6d5388f96568f210ed1911807906eece8fe8347b49ca03",
      "mtime": 1760679926.8965425,
      "size_bytes": 71,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\data_injector\\__init__.py": {
      "file_path": "features\\data_injector\\__init__.py",
      "sha256": "c13ce757421fd986bae6de0d57a01dfb7f0bf3baf04a5159a16c4d32b304cb9e",
      "mtime": 1760679926.8990908,
      "size_bytes": 63,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\doc_generator\\__init__.py": {
      "file_path": "features\\doc_generator\\__init__.py",
      "sha256": "d7dd9a8e3fb15d22326e08c60704adb4ecdd4e275b1a21465953f1f738f619b1",
      "mtime": 1760707910.5794282,
      "size_bytes": 85,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\doc_orchestrator\\__init__.py": {
      "file_path": "features\\doc_orchestrator\\__init__.py",
      "sha256": "68ea4f4655f04c29d21318c4986092dc4fa8ec0525045ebfae6def8ebfdc5dd7",
      "mtime": 1760707910.5809464,
      "size_bytes": 91,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\doc_publisher\\__init__.py": {
      "file_path": "features\\doc_publisher\\__init__.py",
      "sha256": "2494cd7dc60821f1869dccb560c4f68ecbbb6f28e4cbeff1a7e824a749cf5a6d",
      "mtime": 1760679926.901088,
      "size_bytes": 83,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.040849",
      "status": "completed"
    },
    "features\\issue_analyzer\\__init__.py": {
      "file_path": "features\\issue_analyzer\\__init__.py",
      "sha256": "198ccb924ad517b4e8158b9845053e840face49fe0d81e226f3a0c9b16be0689",
      "mtime": 1760679926.902605,
      "size_bytes": 67,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.041859",
      "status": "completed"
    },
    "features\\test_orchestrator\\__init__.py": {
      "file_path": "features\\test_orchestrator\\__init__.py",
      "sha256": "e33080af9382bb80f02db2405a700b33e302a72413c4d01f78df4340f3f4c878",
      "mtime": 1760679926.9046147,
      "size_bytes": 75,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.041859",
      "status": "completed"
    },
    "interfaces\\__init__.py": {
      "file_path": "interfaces\\__init__.py",
      "sha256": "a556d63c53361da8aae4851594e90daf059d84ac27d958e980203d007c57381c",
      "mtime": 1760679926.905617,
      "size_bytes": 99,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.043862",
      "status": "completed"
    },
    "interfaces\\api\\__init__.py": {
      "file_path": "interfaces\\api\\__init__.py",
      "sha256": "b35a4398ed2d49fed7f52396c8ed57edce006c1b4a7ec13fda80437bca9836de",
      "mtime": 1761083779.1659095,
      "size_bytes": 21,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.043862",
      "status": "completed"
    },
    "observability\\__init__.py": {
      "file_path": "observability\\__init__.py",
      "sha256": "cebd4ce46a4aac774b2c8655c9995db7c0ac331673487fe7bf5f4ea6b31ad7c4",
      "mtime": 1760679926.9090047,
      "size_bytes": 108,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.044848",
      "status": "completed"
    },
    "orchestration\\__init__.py": {
      "file_path": "orchestration\\__init__.py",
      "sha256": "769884b598cabf8ce380748439f2205ba6970e844e11a6b2380b20dc4eaa2ef9",
      "mtime": 1760777607.8237402,
      "size_bytes": 674,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.044848",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\__init__.py": {
      "file_path": "orchestration\\cloud_providers\\__init__.py",
      "sha256": "63fbc36e1c9447d413a5a430423c73084560fab4e982a1dd88610881754a0d4f",
      "mtime": 1761127274.635042,
      "size_bytes": 504,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.046367",
      "status": "completed"
    },
    "orchestration\\commit_workflow\\__init__.py": {
      "file_path": "orchestration\\commit_workflow\\__init__.py",
      "sha256": "012b180be6af38ece2fb71163fe0bfb90472e2162e4f7d159046db494a07d2fc",
      "mtime": 1761046693.0575442,
      "size_bytes": 703,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.048892",
      "status": "completed"
    },
    "orchestration\\context_enricher\\__init__.py": {
      "file_path": "orchestration\\context_enricher\\__init__.py",
      "sha256": "6bfea69092351cd86102979f687ccea33e1d9f72f8732826a6c93160bb3cf2d3",
      "mtime": 1760777607.8247423,
      "size_bytes": 187,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.050900",
      "status": "completed"
    },
    "orchestration\\context_manager\\__init__.py": {
      "file_path": "orchestration\\context_manager\\__init__.py",
      "sha256": "eddb53a02df19cd4f2bec967f61143c1246c0f3f6ebc4704aa99f4d965a62ecc",
      "mtime": 1760897642.5211356,
      "size_bytes": 417,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.050900",
      "status": "completed"
    },
    "orchestration\\github_llm\\__init__.py": {
      "file_path": "orchestration\\github_llm\\__init__.py",
      "sha256": "52aa0e5233f32ac03f90d04deab2594a679d4209a73df339e48826e9ebe8fc88",
      "mtime": 1760897642.5231476,
      "size_bytes": 365,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.052413",
      "status": "completed"
    },
    "orchestration\\langgraph_agent\\__init__.py": {
      "file_path": "orchestration\\langgraph_agent\\__init__.py",
      "sha256": "383a994af79c91cb1e8676ae2d574607e875156758f8c9974e54981a32d5e281",
      "mtime": 1760777607.8341,
      "size_bytes": 182,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.053425",
      "status": "completed"
    },
    "orchestration\\message_parser\\__init__.py": {
      "file_path": "orchestration\\message_parser\\__init__.py",
      "sha256": "edab4536833e51e2a64ebc61df31b80b3a95079382416b7def98d3326fe25830",
      "mtime": 1761046693.0606048,
      "size_bytes": 269,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.053425",
      "status": "completed"
    },
    "orchestration\\prompt_builder\\__init__.py": {
      "file_path": "orchestration\\prompt_builder\\__init__.py",
      "sha256": "bfafc48fb6c7f7778f4b6e1bdbdb90ed00e6a1a247b01f7621346638baff2c0f",
      "mtime": 1760777607.8411431,
      "size_bytes": 179,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.053425",
      "status": "completed"
    },
    "orchestration\\shared\\__init__.py": {
      "file_path": "orchestration\\shared\\__init__.py",
      "sha256": "165530bcaa88e3281f653824c1937296552c97d2774bebb3d705538368970e5e",
      "mtime": 1760777607.8421514,
      "size_bytes": 59,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.054423",
      "status": "completed"
    },
    "orchestration\\summary_layer\\__init__.py": {
      "file_path": "orchestration\\summary_layer\\__init__.py",
      "sha256": "96fa39f471de69e9f799a3f2dabb1f6c24c9167c43d0e5d62852188cd5600d76",
      "mtime": 1760897642.5273075,
      "size_bytes": 317,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.054423",
      "status": "completed"
    },
    "orchestration\\tests\\__init__.py": {
      "file_path": "orchestration\\tests\\__init__.py",
      "sha256": "a268b0ac6865796173d8ccbde5a8f25321de342405f38fa5b255e79e2fb019a8",
      "mtime": 1760777607.845325,
      "size_bytes": 33,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\__init__.py": {
      "file_path": "orchestration\\voice_assistant\\__init__.py",
      "sha256": "23c36bf77b2e887fe3455bef11689e858ef53a130e4ffc5d3fbd1a14de59305b",
      "mtime": 1761046693.0636127,
      "size_bytes": 638,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "shared\\__init__.py": {
      "file_path": "shared\\__init__.py",
      "sha256": "bc5087222f288aded94c7b65fce318e25443eaf996632caf65b5d9b8307d55ce",
      "mtime": 1760679926.9122274,
      "size_bytes": 100,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "shared\\azure_services\\__init__.py": {
      "file_path": "shared\\azure_services\\__init__.py",
      "sha256": "70eba7957ea21d58cdfddc49ea9dd5b31e3064c340b8b83578264e6bf8bc1b80",
      "mtime": 1761079877.9079337,
      "size_bytes": 665,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "shared\\clients\\__init__.py": {
      "file_path": "shared\\clients\\__init__.py",
      "sha256": "405fdce3c80a4d5886795e5c642877910576418f503ae979bded1fcb65af47fb",
      "mtime": 1760777607.8533661,
      "size_bytes": 182,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "shared\\llm_providers\\__init__.py": {
      "file_path": "shared\\llm_providers\\__init__.py",
      "sha256": "a93d44320846a8b0c35a78d086316f29c23fa224d2a95b8eb49475496a068444",
      "mtime": 1761031286.2445705,
      "size_bytes": 323,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.055426",
      "status": "completed"
    },
    "shared\\routing\\__init__.py": {
      "file_path": "shared\\routing\\__init__.py",
      "sha256": "7aea846f9249a6dfec0710f3b326432f19542777650b497f6fff9c65cf76a437",
      "mtime": 1761127253.387488,
      "size_bytes": 209,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.056425",
      "status": "completed"
    },
    "shared\\services\\__init__.py": {
      "file_path": "shared\\services\\__init__.py",
      "sha256": "e15cf3853b94c24b05d3dce387fd8a9f2300be4364de2e135102dab2daac7684",
      "mtime": 1760777607.8639326,
      "size_bytes": 325,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.056425",
      "status": "completed"
    },
    "shared\\tests\\__init__.py": {
      "file_path": "shared\\tests\\__init__.py",
      "sha256": "4359d85ca57094b1e57aaf35cee4444b366ae615a1b4fa7df079231a56502d37",
      "mtime": 1761033753.1876853,
      "size_bytes": 46,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.056425",
      "status": "completed"
    },
    "shared\\vector_db\\__init__.py": {
      "file_path": "shared\\vector_db\\__init__.py",
      "sha256": "aa012492cdf671d5115cf6993c1743158acef92cdb9c4f975f8e0f8dca49bda3",
      "mtime": 1760897642.542003,
      "size_bytes": 496,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.056425",
      "status": "completed"
    },
    "ui\\__init__.py": {
      "file_path": "ui\\__init__.py",
      "sha256": "66eff897458ebe84bd40437c18f99ce7cd04a7731d7ddfef2d3a4aea5e3a034b",
      "mtime": 1760679926.923277,
      "size_bytes": 49,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.056425",
      "status": "completed"
    },
    "code-intelligence\\parsers\\__init__.py": {
      "file_path": "code-intelligence\\parsers\\__init__.py",
      "sha256": "4d06f1fcface6c4b719f900d1011bb54628d146a79d8fbbcfaa54e8350350745",
      "mtime": 1761142664.460797,
      "size_bytes": 4988,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.057421",
      "status": "completed"
    },
    "main.py": {
      "file_path": "main.py",
      "sha256": "adb1f28a53cfd307f1b41e48dc189ee2e2a2040faf653051f3657eb0e8976854",
      "mtime": 1761046693.0565498,
      "size_bytes": 3631,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.058944",
      "status": "completed"
    },
    "frontend\\src\\utils\\logger.ts": {
      "file_path": "frontend\\src\\utils\\logger.ts",
      "sha256": "91926b8a3a8710dbcc094804758fdf2dbb8ba65317267bd7e682c77f851c233a",
      "mtime": 1760897642.5154674,
      "size_bytes": 3653,
      "language": "typescript",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.061482",
      "status": "completed"
    },
    "shared\\logger.py": {
      "file_path": "shared\\logger.py",
      "sha256": "de16d24844ca45378b104065125dded211139c0ea05cd9decf7ab1a02dea3e78",
      "mtime": 1760897625.3204446,
      "size_bytes": 9619,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.064022",
      "status": "completed"
    },
    "shared\\llm_providers\\base.py": {
      "file_path": "shared\\llm_providers\\base.py",
      "sha256": "4d8bbee4f8ac901672eed3f13caf51b189dc939a5072e22cd7b31ceaf1c4f49f",
      "mtime": 1761031286.246149,
      "size_bytes": 1342,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.067022",
      "status": "completed"
    },
    "shared\\services\\base.py": {
      "file_path": "shared\\services\\base.py",
      "sha256": "64eb24d5c97f8c1d94ea4ac8e030336ffdbdfc15093971b9d0aa06dba293f04d",
      "mtime": 1760777607.8649268,
      "size_bytes": 2530,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.068050",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\templates\\base.py": {
      "file_path": "orchestration\\cloud_providers\\templates\\base.py",
      "sha256": "d59d6a4f36958ca7652df2c6a0dd05a58b690ac4422299b86cff0f45f342e027",
      "mtime": 1761127274.6411698,
      "size_bytes": 7409,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.069555",
      "status": "completed"
    },
    "shared\\vector_db\\base.py": {
      "file_path": "shared\\vector_db\\base.py",
      "sha256": "2f6e74e2d065120fecdc17517268066f7dbd0598ed2b631b7fa5f63772c3f103",
      "mtime": 1760897642.5429907,
      "size_bytes": 2603,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.070069",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\implementations\\__init__.py": {
      "file_path": "orchestration\\cloud_providers\\implementations\\__init__.py",
      "sha256": "b9130b22443a17a8cca554dc43a5cf6ebed13f64ac7779eb11f7dfad776e6eae",
      "mtime": 1761127274.637852,
      "size_bytes": 32,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.071087",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\templates\\__init__.py": {
      "file_path": "orchestration\\cloud_providers\\templates\\__init__.py",
      "sha256": "853b2e31a15f36b9b2f68cb46dfe69d5e9124e7eab96e6a26670c5805ddcca8d",
      "mtime": 1761127274.6411698,
      "size_bytes": 36,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.071087",
      "status": "completed"
    },
    "orchestration\\context_enricher\\implementations\\__init__.py": {
      "file_path": "orchestration\\context_enricher\\implementations\\__init__.py",
      "sha256": "76a0a677a4a260f0e2b995a97a1cca6721f6a7a388bfd139e982f5ec48e5fce8",
      "mtime": 1760777607.8292823,
      "size_bytes": 40,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.071087",
      "status": "completed"
    },
    "orchestration\\langgraph_agent\\implementations\\__init__.py": {
      "file_path": "orchestration\\langgraph_agent\\implementations\\__init__.py",
      "sha256": "e59a39f19bb9eb4271dd4c8a0fe33f4264b8a3bc79627e0b83faa00e88de0b56",
      "mtime": 1760777607.835101,
      "size_bytes": 39,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.071087",
      "status": "completed"
    },
    "orchestration\\message_parser\\extractors\\__init__.py": {
      "file_path": "orchestration\\message_parser\\extractors\\__init__.py",
      "sha256": "23f914f6219e4bc26832b25c511b15d1f4403c5008c1b710f5d8e269053dcd06",
      "mtime": 1760897642.5231476,
      "size_bytes": 665,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.072076",
      "status": "completed"
    },
    "orchestration\\message_parser\\implementations\\__init__.py": {
      "file_path": "orchestration\\message_parser\\implementations\\__init__.py",
      "sha256": "bb3cb5f113d82165fae8f9eb8b07119c1ccdf16e276dc01421c39b489e28fe33",
      "mtime": 1760777607.8396082,
      "size_bytes": 38,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.072076",
      "status": "completed"
    },
    "orchestration\\prompt_builder\\implementations\\__init__.py": {
      "file_path": "orchestration\\prompt_builder\\implementations\\__init__.py",
      "sha256": "cae95a6153d43adcf5d903edfd886153e19d7092a51ee180f183d2d4b74e937e",
      "mtime": 1760777607.8411431,
      "size_bytes": 38,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.072076",
      "status": "completed"
    },
    "shared\\clients\\wrappers\\__init__.py": {
      "file_path": "shared\\clients\\wrappers\\__init__.py",
      "sha256": "f1242c04c8a16622fc660c679577ef38d4247e5aa30d1b23b2a72ed7faccaec1",
      "mtime": 1760897642.5334184,
      "size_bytes": 200,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.072076",
      "status": "completed"
    },
    "shared\\services\\integrations\\__init__.py": {
      "file_path": "shared\\services\\integrations\\__init__.py",
      "sha256": "3bdc0b00880384d29b77b107a6f1f714093cc957e25eead3f59deba30b611b9b",
      "mtime": 1761131276.8668966,
      "size_bytes": 470,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.073464",
      "status": "completed"
    },
    "shared\\vector_db\\providers\\__init__.py": {
      "file_path": "shared\\vector_db\\providers\\__init__.py",
      "sha256": "bd0ae2b16c455fe7b77c902034ccf2c02e70177e23be7932333cf566abf9b22f",
      "mtime": 1760897642.5480075,
      "size_bytes": 197,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.073464",
      "status": "completed"
    },
    "shared\\vector_db\\services\\__init__.py": {
      "file_path": "shared\\vector_db\\services\\__init__.py",
      "sha256": "1397a021ee5e6d8b29ce81a293f96189a916e33ff559f3cf86fd8e0827ce8647",
      "mtime": 1761144251.4585128,
      "size_bytes": 294,
      "language": null,
      "chunk_count": 0,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.073973",
      "status": "completed"
    },
    "db\\repo.py": {
      "file_path": "db\\repo.py",
      "sha256": "ebbda58e400b6227eb174e8d22786d8dbe9476cf62e1b9a015d33e1d41492328",
      "mtime": 1760777607.7786777,
      "size_bytes": 4698,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.074986",
      "status": "completed"
    },
    "features\\code_generator\\service.py": {
      "file_path": "features\\code_generator\\service.py",
      "sha256": "0a3ae24ddcc5935ce9ec378029e02cae2d861e1bde54a42f2f60ab09e82aa1c6",
      "mtime": 1760679926.8950346,
      "size_bytes": 971,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.076978",
      "status": "completed"
    },
    "features\\data_injector\\service.py": {
      "file_path": "features\\data_injector\\service.py",
      "sha256": "238fe1f9123c8da7fbc51ebbff9233b3fe2ecd4323ed88815e0b1cebff5fdac0",
      "mtime": 1760679926.9000883,
      "size_bytes": 2922,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.077994",
      "status": "completed"
    },
    "features\\doc_publisher\\service.py": {
      "file_path": "features\\doc_publisher\\service.py",
      "sha256": "a08096cd90f04fb7341028edf1a303bd3e2ea70d49004fd0e1bf4c7cade38d58",
      "mtime": 1761054155.39616,
      "size_bytes": 1544,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.077994",
      "status": "completed"
    },
    "features\\issue_analyzer\\service.py": {
      "file_path": "features\\issue_analyzer\\service.py",
      "sha256": "3d6ffdbb19cfbcf611950ca26c2d539554db14e4eabb9a4ca2ecd49e37e8a204",
      "mtime": 1760679926.9036179,
      "size_bytes": 1869,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.079526",
      "status": "completed"
    },
    "features\\test_orchestrator\\service.py": {
      "file_path": "features\\test_orchestrator\\service.py",
      "sha256": "be63213adb14326a0e5b88790d696bceb0d10187fd8d15aaa0aed474d35fd886",
      "mtime": 1760679926.905617,
      "size_bytes": 1213,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.081539",
      "status": "completed"
    },
    "features\\context_resolver\\service.py": {
      "file_path": "features\\context_resolver\\service.py",
      "sha256": "ff069946628c0c0b532748cc2f0d4ee1099f352751b0a3975284e9fea0af014a",
      "mtime": 1760679926.8990908,
      "size_bytes": 9558,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.084051",
      "status": "completed"
    },
    "features\\doc_generator\\service.py": {
      "file_path": "features\\doc_generator\\service.py",
      "sha256": "8ce18c1eef95521cc6771ba8b09843962a9555b9370df5c998adddf36cbb3eca",
      "mtime": 1761055302.1295648,
      "size_bytes": 11320,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.085060",
      "status": "completed"
    },
    "features\\doc_orchestrator\\service.py": {
      "file_path": "features\\doc_orchestrator\\service.py",
      "sha256": "38e3910bfc70a9d2db414ef779ff10b39c7ed55c8cf8a4c2f3dd2f51b9924c2a",
      "mtime": 1761133728.5302522,
      "size_bytes": 15119,
      "language": "python",
      "chunk_count": 12,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.086058",
      "status": "completed"
    },
    "features\\context_resolver\\model.py": {
      "file_path": "features\\context_resolver\\model.py",
      "sha256": "a0238c52290837014e0b890f6f28f78e3fc7f649b3707c873490e64d6a7a334b",
      "mtime": 1760679926.8980727,
      "size_bytes": 1100,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.087057",
      "status": "completed"
    },
    "frontend\\src\\types\\api.ts": {
      "file_path": "frontend\\src\\types\\api.ts",
      "sha256": "bf6e6f593c4368e08609fc3f2302f0ac6ab0f824d8d4a65250ed8a4152a574c1",
      "mtime": 1760777607.8166997,
      "size_bytes": 2727,
      "language": "typescript",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.087562",
      "status": "completed"
    },
    "frontend\\src\\services\\api.ts": {
      "file_path": "frontend\\src\\services\\api.ts",
      "sha256": "7fe593c13d0c51ef862c4bc3a57fd10e70859b667f1ffd3986d9bc61d77c4645",
      "mtime": 1761046693.0535436,
      "size_bytes": 3589,
      "language": "typescript",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.089084",
      "status": "completed"
    },
    "shared\\config.py": {
      "file_path": "shared\\config.py",
      "sha256": "e0b1dbdb61570f0010da2c1a9877be828628dbe97a4e49b60de6883bd65c0582",
      "mtime": 1761144706.019318,
      "size_bytes": 6590,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.090092",
      "status": "completed"
    },
    "code-intelligence\\cli.py": {
      "file_path": "code-intelligence\\cli.py",
      "sha256": "426cdb5ea0fc241d7b7f0b030980f958d3f4c8d938d7107f6752631f8e64b7e1",
      "mtime": 1761156235.6587284,
      "size_bytes": 1097,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.091098",
      "status": "completed"
    },
    "db\\models.py": {
      "file_path": "db\\models.py",
      "sha256": "10aeed0cb77e3b73d4f071996a43d580cea644fd4193d15e43c6c7624380cd54",
      "mtime": 1760777607.7786777,
      "size_bytes": 2845,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.092110",
      "status": "completed"
    },
    "orchestration\\context_manager\\models.py": {
      "file_path": "orchestration\\context_manager\\models.py",
      "sha256": "8ce18f4effb4f7573472e36db52e8d86db6f46c1dc9da950d77ee641ff9a28ac",
      "mtime": 1760897642.5231476,
      "size_bytes": 2846,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.093100",
      "status": "completed"
    },
    "shared\\llm.py": {
      "file_path": "shared\\llm.py",
      "sha256": "493d67ecceabd7f584afa7e1a958d90166b92c8050460a8cd512e856c0052815",
      "mtime": 1761123619.394322,
      "size_bytes": 4155,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.094097",
      "status": "completed"
    },
    "shared\\models.py": {
      "file_path": "shared\\models.py",
      "sha256": "383cbe23f13804b1caa7c7d32e6a184a9d9875ecac643d7bba92575838b9c7d8",
      "mtime": 1760679926.9201794,
      "size_bytes": 2243,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.094097",
      "status": "completed"
    },
    "orchestration\\github_llm\\models.py": {
      "file_path": "orchestration\\github_llm\\models.py",
      "sha256": "8590066cb2c5567d9377c148a83447a444c0b736211f4a51ac35a820df3c2f9c",
      "mtime": 1760897642.5231476,
      "size_bytes": 1426,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.094097",
      "status": "completed"
    },
    "orchestration\\shared\\models.py": {
      "file_path": "orchestration\\shared\\models.py",
      "sha256": "cc122ba8a347604f03279643a62c29c8a8b10ef33dbb180d1e2fee425cdbd6f1",
      "mtime": 1760777607.8436587,
      "size_bytes": 3093,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.094097",
      "status": "completed"
    },
    "frontend\\src\\main.tsx": {
      "file_path": "frontend\\src\\main.tsx",
      "sha256": "c130e78ded8dd9ee2ca60b3503fee26e35d437525a846cb3a2585bb31b3ca3be",
      "mtime": 1760777607.8116877,
      "size_bytes": 246,
      "language": "text",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.094097",
      "status": "completed"
    },
    "interfaces\\api\\core.py": {
      "file_path": "interfaces\\api\\core.py",
      "sha256": "418d1697a6eeb99a3e8a4000db1b2ee6f174e0dc707b6447fae708589f3dbd69",
      "mtime": 1761083779.4501233,
      "size_bytes": 3226,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.095605",
      "status": "completed"
    },
    "code-intelligence\\orchestrator.py": {
      "file_path": "code-intelligence\\orchestrator.py",
      "sha256": "37067743cb99f6ca93a90bb72e10fec3563e97bf53aff4e9df6bf613faaf68a5",
      "mtime": 1761147305.4738853,
      "size_bytes": 14215,
      "language": "python",
      "chunk_count": 10,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.095605",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\orchestrator.py": {
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "sha256": "2f5df21ea390061dd6e05599cd186d403b27e468f00e77d78611bd353eac7e47",
      "mtime": 1761131276.8623545,
      "size_bytes": 14656,
      "language": "python",
      "chunk_count": 12,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.096649",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\factory.py": {
      "file_path": "orchestration\\cloud_providers\\factory.py",
      "sha256": "ead887c9e2fc3f6bc5d270fb84d90d9e1686c9ceea1e8d117193249e268e06fd",
      "mtime": 1761132622.86857,
      "size_bytes": 8785,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.097665",
      "status": "completed"
    },
    "shared\\llm_providers\\factory.py": {
      "file_path": "shared\\llm_providers\\factory.py",
      "sha256": "ddb3247d30ef91e8465e9181c28ad714a6e82c5a835b572a47d77a632e27c6df",
      "mtime": 1761133727.6863952,
      "size_bytes": 8433,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.099181",
      "status": "completed"
    },
    "shared\\vector_db\\factory.py": {
      "file_path": "shared\\vector_db\\factory.py",
      "sha256": "c91f993146d25465c430615beecb6ced3ae8b4dee973ad0513f995db93bb7534",
      "mtime": 1760897642.5475001,
      "size_bytes": 1990,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.100748",
      "status": "completed"
    },
    "shared\\services\\manager.py": {
      "file_path": "shared\\services\\manager.py",
      "sha256": "8043a2a1e008c91d2de41344c17189ed09503a747c27110d7c55ee7e35bd7e30",
      "mtime": 1761131276.867892,
      "size_bytes": 7051,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.101774",
      "status": "completed"
    },
    "orchestration\\message_parser\\implementations\\parser.py": {
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "sha256": "9fcd2346b4542f0ac1726d2fc771fed93d060130260f670ba23dba6e25dcf2a0",
      "mtime": 1760897642.5273075,
      "size_bytes": 5950,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.102752",
      "status": "completed"
    },
    "frontend\\src\\App.tsx": {
      "file_path": "frontend\\src\\App.tsx",
      "sha256": "0dbcef3bcbe7a25a716816f156fb71e9c356894668ace6bf0caef5c4bda16e51",
      "mtime": 1760897642.5115266,
      "size_bytes": 1684,
      "language": "text",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.103796",
      "status": "completed"
    },
    "frontend\\src\\types\\integrations.ts": {
      "file_path": "frontend\\src\\types\\integrations.ts",
      "sha256": "5b9970d0ce37d2d6ffd4557065dbca2629f236fd812cc85deb4511e5bd1d2abe",
      "mtime": 1760777607.8166997,
      "size_bytes": 2652,
      "language": "typescript",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.103796",
      "status": "completed"
    },
    "observability\\metrics.py": {
      "file_path": "observability\\metrics.py",
      "sha256": "3ffb264198cc4cb83256088e62a34a0de63753224566b30a40c2b43635ba7191",
      "mtime": 1760679926.9090047,
      "size_bytes": 2009,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.104799",
      "status": "completed"
    },
    "orchestration\\langgraph_agent\\implementations\\agent.py": {
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "sha256": "2ab9a470a745b155d08e41ca81aaafa4e7e70dff69deb94f59d1dffb5a18b02d",
      "mtime": 1761133727.9979498,
      "size_bytes": 11100,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.105143",
      "status": "completed"
    },
    "orchestration\\shared\\interfaces.py": {
      "file_path": "orchestration\\shared\\interfaces.py",
      "sha256": "cd986e8c8c3dad22121637d08bfe2cc09e145bef98af24e15d510a5dc52fa53f",
      "mtime": 1760777607.8431516,
      "size_bytes": 2802,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.106149",
      "status": "completed"
    },
    "orchestration\\commit_workflow\\templates.py": {
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "sha256": "5d2cd5dc9f9f5daad240be644408d81efe9da2408bf9658fd3b1e3ca0d46a15f",
      "mtime": 1761046693.0599701,
      "size_bytes": 8625,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.106149",
      "status": "completed"
    },
    "shared\\clients\\github_client.py": {
      "file_path": "shared\\clients\\github_client.py",
      "sha256": "f90869ab1beed373c1cec20547d741337eece085a820977fd1926857ea5b76e3",
      "mtime": 1761074756.9258146,
      "size_bytes": 18378,
      "language": "python",
      "chunk_count": 15,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.107269",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\registry.py": {
      "file_path": "orchestration\\cloud_providers\\registry.py",
      "sha256": "a9697b696345e5abd468b2d45b1f591c1b5673e093c2bf6e94856df94c7308d7",
      "mtime": 1761131276.8623545,
      "size_bytes": 886,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.107734",
      "status": "completed"
    },
    "code-intelligence\\parsers\\base_parser.py": {
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "sha256": "2a96ab2ba831a30355d0e352116d815c1c10eb0684aeb863f31eb15a0301c72b",
      "mtime": 1761157433.326032,
      "size_bytes": 9839,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.107982",
      "status": "completed"
    },
    "orchestration\\context_enricher\\implementations\\enricher.py": {
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "sha256": "480e2f61b24b2030fe9115bcc7cc67a43669b5979ba6f5af89289637ca90009c",
      "mtime": 1760777607.8312194,
      "size_bytes": 11441,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.107982",
      "status": "completed"
    },
    "orchestration\\prompt_builder\\implementations\\builder.py": {
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "sha256": "cee2bb600b71963861de398e46fc5da004061f9a4f6c7bd372b31686889bfa43",
      "mtime": 1760777607.8411431,
      "size_bytes": 8759,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.108987",
      "status": "completed"
    },
    "shared\\services\\integrations\\azure_services.py": {
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "sha256": "2e3dfc5e1529ba9542a4c495b26f490cc5dd57cd5c9c933aa9ad6395fb3e74c7",
      "mtime": 1761131276.867892,
      "size_bytes": 6819,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.108987",
      "status": "completed"
    },
    "code-intelligence\\parsers\\fallback_parser.py": {
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "sha256": "e2c483c834d5d88ce730091b5fcc98fc126d77dec95ba8691b1af4e0895c0fac",
      "mtime": 1761157433.385239,
      "size_bytes": 6678,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.109997",
      "status": "completed"
    },
    "shared\\llm_providers\\resilient_orchestrator.py": {
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "sha256": "df834d8f80e200c5ad2976812ad2e67a852e74604781b03bb6e040a00389762d",
      "mtime": 1761046693.0711281,
      "size_bytes": 10246,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.109997",
      "status": "completed"
    },
    "shared\\vector_db\\embedding_service.py": {
      "file_path": "shared\\vector_db\\embedding_service.py",
      "sha256": "bf5ae1d49da0d9823d1907f2025fb711c89b212aec624affc3c499d24fb68873",
      "mtime": 1761143421.5884206,
      "size_bytes": 18905,
      "language": "python",
      "chunk_count": 15,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.109997",
      "status": "completed"
    },
    "code-intelligence\\embed_repo.py": {
      "file_path": "code-intelligence\\embed_repo.py",
      "sha256": "a96bccae6296d86dae0f595035b45e4e48df89b186a7c66ef5ec696cafda542b",
      "mtime": 1761148241.292935,
      "size_bytes": 18997,
      "language": "python",
      "chunk_count": 15,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.111506",
      "status": "completed"
    },
    "code-intelligence\\enhanced_summarizer.py": {
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "sha256": "c9715be455e0c8438a418e41c0331cdced448694faa72d44060001adfe60dd6b",
      "mtime": 1761156361.488255,
      "size_bytes": 22607,
      "language": "python",
      "chunk_count": 18,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.112124",
      "status": "completed"
    },
    "code-intelligence\\rate_limiter.py": {
      "file_path": "code-intelligence\\rate_limiter.py",
      "sha256": "da2b4e5c6b74e65db077aba5ae9b48c35a24f2fdbb46dee0b3ff41634aaa17d7",
      "mtime": 1761147305.5432339,
      "size_bytes": 13482,
      "language": "python",
      "chunk_count": 11,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.113282",
      "status": "completed"
    },
    "code-intelligence\\repo_state.py": {
      "file_path": "code-intelligence\\repo_state.py",
      "sha256": "e6a23febe40dfb00f00bedc8a9f237d34b07b5888651c6e5fcdabc099af7cae4",
      "mtime": 1761147556.2759416,
      "size_bytes": 10390,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.115833",
      "status": "completed"
    },
    "orchestration\\summary_layer\\beautifier.py": {
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "sha256": "3f987b9850933d23b9043816db01a5a65b5eb719f5208715397a43422b67c5d2",
      "mtime": 1761046693.0626132,
      "size_bytes": 10430,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.117834",
      "status": "completed"
    },
    "shared\\azure_services\\speech_service.py": {
      "file_path": "shared\\azure_services\\speech_service.py",
      "sha256": "5b09dbff01973ce998d46bb87f1586f546d73fb500a2a200db7982ed8a5283e4",
      "mtime": 1761079847.7959118,
      "size_bytes": 5366,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.119897",
      "status": "completed"
    },
    "shared\\azure_services\\translation_service.py": {
      "file_path": "shared\\azure_services\\translation_service.py",
      "sha256": "8901d54a2b9c01a99030688c9ef8ba436df493a63bddb421cd83a2cf32c52fdc",
      "mtime": 1761083087.387532,
      "size_bytes": 8020,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.122132",
      "status": "completed"
    },
    "shared\\clients\\jira_client.py": {
      "file_path": "shared\\clients\\jira_client.py",
      "sha256": "e31af93237806c225007686ac8f858cd7cf5f066867e2a59a593bc5fc5d9efa8",
      "mtime": 1761133728.0690906,
      "size_bytes": 7334,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.122132",
      "status": "completed"
    },
    "shared\\clients\\wrappers\\github_wrapper.py": {
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "sha256": "49669bc839b47b3ee760495fe46cc7eed66c7d1a56cbe68e60aa779fb4c72005",
      "mtime": 1761054584.2572162,
      "size_bytes": 5602,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.124142",
      "status": "completed"
    },
    "code-intelligence\\change_planner.py": {
      "file_path": "code-intelligence\\change_planner.py",
      "sha256": "0e0b35eb96eba39f018205769ace4bac0f764c7e4292e13d5361545339e7d6da",
      "mtime": 1761142664.457625,
      "size_bytes": 9040,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.125142",
      "status": "completed"
    },
    "code-intelligence\\vector_store.py": {
      "file_path": "code-intelligence\\vector_store.py",
      "sha256": "c6393926b1a8efa79cff431809f0525c3993e28b391c181de1f146f01ef4dedf",
      "mtime": 1761142664.4663959,
      "size_bytes": 9639,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.125142",
      "status": "completed"
    },
    "features\\context_resolver\\domain.py": {
      "file_path": "features\\context_resolver\\domain.py",
      "sha256": "47b4ad28935b96f60623962ee42b13f3025c550abb8f632c6e3ddfb7966532cf",
      "mtime": 1760679926.8965425,
      "size_bytes": 2651,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.126161",
      "status": "completed"
    },
    "frontend\\src\\components\\Layout\\Header.tsx": {
      "file_path": "frontend\\src\\components\\Layout\\Header.tsx",
      "sha256": "b2501d8dca6c5564a0c5b6824f8884e3763cf485b7b10c59b895ba3a90743b26",
      "mtime": 1760777607.7958944,
      "size_bytes": 1649,
      "language": "text",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.126161",
      "status": "completed"
    },
    "shared\\azure_services\\azure_ai_manager.py": {
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "sha256": "146cf57267117ef530a045ca9593e9b51156b5f8f638c329a294153039b1e059",
      "mtime": 1761083293.7150567,
      "size_bytes": 13457,
      "language": "python",
      "chunk_count": 11,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.127140",
      "status": "completed"
    },
    "shared\\azure_services\\model_deployment_service.py": {
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "sha256": "8ed667c30c602b123bfda241af89492c9f9f0a66ee8eb5a7f430537507b8b664",
      "mtime": 1761147825.8844218,
      "size_bytes": 12507,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.128218",
      "status": "completed"
    },
    "shared\\llm_providers\\together_provider.py": {
      "file_path": "shared\\llm_providers\\together_provider.py",
      "sha256": "b40fda6c50d4c3a5b66c2d288782b315881932a05248fa218dc6d297e0e2c5fe",
      "mtime": 1761133727.7620864,
      "size_bytes": 6537,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.128733",
      "status": "completed"
    },
    "features\\context_resolver\\dto.py": {
      "file_path": "features\\context_resolver\\dto.py",
      "sha256": "284b22cce356f215dad9658263521919350d537bfbafe2f4956d69151601f2d8",
      "mtime": 1760679926.8965425,
      "size_bytes": 558,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.128733",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\IntegrationsHub.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "sha256": "d506648c14db9e0a3bbcd1d66a3f87acb7896de72b8a4faf207c362a32d75f9d",
      "mtime": 1760777607.8021483,
      "size_bytes": 25821,
      "language": "text",
      "chunk_count": 21,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.130344",
      "status": "completed"
    },
    "frontend\\src\\components\\Shared\\ThinkingProcess.tsx": {
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "sha256": "740759d38530e9fbdd0b059fc76aada723bdcb44854c0a1e7d493c1b68b8c2e9",
      "mtime": 1760897642.5136707,
      "size_bytes": 8015,
      "language": "text",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.131942",
      "status": "completed"
    },
    "interfaces\\vector_db_api.py": {
      "file_path": "interfaces\\vector_db_api.py",
      "sha256": "0549f1b760480caba584b53a3f9ee36e90a60a53c1be831443980979c9486843",
      "mtime": 1761144250.5427554,
      "size_bytes": 34190,
      "language": "python",
      "chunk_count": 27,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.133662",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\implementations\\azure_provider.py": {
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "sha256": "de85df800ab56282dbd78d4825ac185a401a0ddbb0e9d474b948e5213f48650a",
      "mtime": 1761131276.8598402,
      "size_bytes": 7588,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.134209",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\implementations\\together_provider.py": {
      "file_path": "orchestration\\cloud_providers\\implementations\\together_provider.py",
      "sha256": "e87546873d196cce2ec41b2a5862bcfeec880b5b79025cdda4756784c3b42cf7",
      "mtime": 1761131276.8608415,
      "size_bytes": 3059,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.134751",
      "status": "completed"
    },
    "orchestration\\facade.py": {
      "file_path": "orchestration\\facade.py",
      "sha256": "d0749ef731b3a4f017576c9cb35a7ee5a1e40854ebe9c074f446b320f9332583",
      "mtime": 1760777607.833098,
      "size_bytes": 10313,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.135847",
      "status": "completed"
    },
    "orchestration\\message_parser\\extractors\\repository_registry.py": {
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "sha256": "c501776e4398f3385562e10a0a378d8fbd6cb1bec06a3e2bbb68e002002c9608",
      "mtime": 1760897642.5267358,
      "size_bytes": 9818,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.137076",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\intent_classifier.py": {
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "sha256": "dec5d55002c236a2c97cca3f6d2dd71f1fea822dfbe862988876dadf6e168e4e",
      "mtime": 1761046693.0636127,
      "size_bytes": 6043,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.138702",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\session_manager.py": {
      "file_path": "orchestration\\voice_assistant\\session_manager.py",
      "sha256": "683c416955d023285d97275a4e7a1139d8966ffcb11cef81576cd9e4a09038bd",
      "mtime": 1761046693.065118,
      "size_bytes": 5219,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.139247",
      "status": "completed"
    },
    "shared\\clients\\confluence_client.py": {
      "file_path": "shared\\clients\\confluence_client.py",
      "sha256": "539464f7e2db7e567004da068f5cce388eace874bf2e2d2e342c95e101e7abb7",
      "mtime": 1761054855.3438022,
      "size_bytes": 17606,
      "language": "python",
      "chunk_count": 14,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140208",
      "status": "completed"
    },
    "shared\\clients\\grafana_client.py": {
      "file_path": "shared\\clients\\grafana_client.py",
      "sha256": "c9ecb29a306ceaa52553ff6b11ffac80653d58f6a7aa3feb3bb3bc4638d1f85a",
      "mtime": 1760679926.9137776,
      "size_bytes": 4619,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140544",
      "status": "completed"
    },
    "shared\\llm_providers\\azure_provider.py": {
      "file_path": "shared\\llm_providers\\azure_provider.py",
      "sha256": "aee045086e7a82c79c3a4490345a18d5ea113cffa9bc88dd812e7e2ed77aa730",
      "mtime": 1761031286.2451367,
      "size_bytes": 5183,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140833",
      "status": "completed"
    },
    "shared\\routing\\intent_classifier.py": {
      "file_path": "shared\\routing\\intent_classifier.py",
      "sha256": "193a34e514a9fe767b2634e608ee436026e6624e3f176ae960c59dc5814c72aa",
      "mtime": 1761123619.7958715,
      "size_bytes": 5345,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140833",
      "status": "completed"
    },
    "shared\\services\\integrations\\confluence_service.py": {
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "sha256": "3fe74469e172839390f6dd63a6a485db75a77d2ffb3c96686f238014cf2befdc",
      "mtime": 1761049877.007458,
      "size_bytes": 5988,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140833",
      "status": "completed"
    },
    "shared\\services\\integrations\\github_service.py": {
      "file_path": "shared\\services\\integrations\\github_service.py",
      "sha256": "c263b31a2e5e1d828022fbb48ff0e3710120b9810bc8af31d2b191b782fc84ba",
      "mtime": 1761049876.8929005,
      "size_bytes": 7059,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.140833",
      "status": "completed"
    },
    "shared\\vector_db\\services\\vector_query_service.py": {
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "sha256": "7449837b863ab03097e7f7d90686e79e14574a4c6bc037dc40b613fafa0007db",
      "mtime": 1760897642.557796,
      "size_bytes": 6166,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "frontend\\src\\components\\Layout\\Sidebar.tsx": {
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "sha256": "d1e9db020ce6801692770734395a75c4f8c5ddd0fc744e3926d60a8e94eeb803",
      "mtime": 1760777607.7968836,
      "size_bytes": 7546,
      "language": "text",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "interfaces\\http_api.py": {
      "file_path": "interfaces\\http_api.py",
      "sha256": "48b3f8d54940992881b2092c3b3c1ffd0324f13735405f0aa89ef7caed5402d2",
      "mtime": 1761142664.467484,
      "size_bytes": 3182,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "orchestration\\commit_workflow\\approval_system.py": {
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "sha256": "af93b266209562bd4733a16604692042b83deab99fe3d7a801b6634c63782ede",
      "mtime": 1761046693.0585446,
      "size_bytes": 7733,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "orchestration\\commit_workflow\\github_operations.py": {
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "sha256": "8c79a02dcbc17c797b4f2e5185f0a12c5bd8fa3b4bc86eebed12218472bac9db",
      "mtime": 1761046693.0585446,
      "size_bytes": 10919,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "orchestration\\context_manager\\context_extractor.py": {
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "sha256": "f8dcd31f97f102bc72601b52ac70454c7060e2fbbb06151afaba526365ddd164",
      "mtime": 1760897642.5211356,
      "size_bytes": 8095,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.141841",
      "status": "completed"
    },
    "orchestration\\context_manager\\context_manager.py": {
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "sha256": "fc1a4b2a737e03e51f59710ae538265151fbbef6dfa7e57e668d8fc1f3707358",
      "mtime": 1760897642.522151,
      "size_bytes": 6718,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.143346",
      "status": "completed"
    },
    "orchestration\\github_llm\\query_orchestrator.py": {
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "sha256": "c09fb81aa2c86d0b2a7ca1fcab36e47dabf59ae32d7871b789dbbfc3663540d4",
      "mtime": 1760897642.5231476,
      "size_bytes": 12137,
      "language": "python",
      "chunk_count": 10,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.143346",
      "status": "completed"
    },
    "orchestration\\message_parser\\extractors\\github_extractor.py": {
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "sha256": "5e21e4d7821a79b6d76a0d78764756cf460ec05908c5618a8f797f850c1b450b",
      "mtime": 1760897642.5250916,
      "size_bytes": 19642,
      "language": "python",
      "chunk_count": 16,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.144356",
      "status": "completed"
    },
    "orchestration\\summary_layer\\formatters.py": {
      "file_path": "orchestration\\summary_layer\\formatters.py",
      "sha256": "f8f65b687e95b1abc10c4906f38f7e2c39b2cec78f0f1d2f90a1f1a9eadb2514",
      "mtime": 1760897642.5278473,
      "size_bytes": 2209,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.144356",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\response_formatter.py": {
      "file_path": "orchestration\\voice_assistant\\response_formatter.py",
      "sha256": "2aa6fe860d7884ead6fbac9b5e5048eec95f7f36962300386844667b73c62a4b",
      "mtime": 1761046693.065118,
      "size_bytes": 5306,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.145903",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\voice_orchestrator.py": {
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "sha256": "2dc227c79301594cc35ba0b09bef65ca111d19b5133e2828b428406bdfa7300a",
      "mtime": 1761074756.9225442,
      "size_bytes": 14934,
      "language": "python",
      "chunk_count": 12,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.146439",
      "status": "completed"
    },
    "shared\\secrets.py": {
      "file_path": "shared\\secrets.py",
      "sha256": "89adc184102a74c52f319fe5327f4009b81da9511936f256b70223f514e18807",
      "mtime": 1760679926.9220767,
      "size_bytes": 2470,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.148972",
      "status": "completed"
    },
    "shared\\services\\integrations\\mongodb_service.py": {
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "sha256": "457d468910c7b0ffb0fad0ccc5619b014c9cec38eb2153f10fbd09c5ead8ac20",
      "mtime": 1760777607.8674495,
      "size_bytes": 6321,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.151983",
      "status": "completed"
    },
    "shared\\services\\llm_wrapper.py": {
      "file_path": "shared\\services\\llm_wrapper.py",
      "sha256": "46db157a4a719b7f21026e1114b1de03f6d884902b752710ba8307d57ca1e8ea",
      "mtime": 1761128636.4429624,
      "size_bytes": 4134,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.151983",
      "status": "completed"
    },
    "shared\\thinking_process.py": {
      "file_path": "shared\\thinking_process.py",
      "sha256": "d4de85430caff991ac137fad890baffa664f17320d56d658e41943df06e396c2",
      "mtime": 1760777607.8694496,
      "size_bytes": 7086,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.152983",
      "status": "completed"
    },
    "shared\\vector_db\\providers\\chromadb_provider.py": {
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "sha256": "9fabafd733f9eaaa96da113b7f68184b0825dc710a27ee1d1157fa96c37dbf0f",
      "mtime": 1760897642.5488315,
      "size_bytes": 7486,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.152983",
      "status": "completed"
    },
    "shared\\vector_db\\providers\\in_memory_provider.py": {
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "sha256": "b87e8c1a3ed042317406edfd6e67b5b4dad191637f059303b3e6444dcb5bbd17",
      "mtime": 1760897642.5488315,
      "size_bytes": 5866,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.154004",
      "status": "completed"
    },
    "code-intelligence\\logging_config.py": {
      "file_path": "code-intelligence\\logging_config.py",
      "sha256": "3538146e3d5139f478ecb003eb3cdfc431cb44ae0a656a3e29ecb45982c4fa68",
      "mtime": 1761157432.853969,
      "size_bytes": 6629,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.154980",
      "status": "completed"
    },
    "code-intelligence\\parsers\\cpp_parser.py": {
      "file_path": "code-intelligence\\parsers\\cpp_parser.py",
      "sha256": "14c167b50d41aaef2dc670c75bf8a9772dd8fedb7529189e2068e274ecffb62b",
      "mtime": 1761142664.4613233,
      "size_bytes": 739,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.154980",
      "status": "completed"
    },
    "code-intelligence\\parsers\\dart_parser.py": {
      "file_path": "code-intelligence\\parsers\\dart_parser.py",
      "sha256": "6989f1251b3395c288d820182904a961980473eddc44335f8c955001498fd73a",
      "mtime": 1761142664.4613233,
      "size_bytes": 700,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.154980",
      "status": "completed"
    },
    "code-intelligence\\parsers\\java_parser.py": {
      "file_path": "code-intelligence\\parsers\\java_parser.py",
      "sha256": "420611bcfa174316c1129dc2885dda515ebeb8cb0924debb2bb00329440881f3",
      "mtime": 1761142664.461842,
      "size_bytes": 696,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.154980",
      "status": "completed"
    },
    "code-intelligence\\parsers\\js_parser.py": {
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "sha256": "3e2b9aab5ccda6cc3c2feed9d68b11c7d63d286284b8fd41e1028fe9799f9cb7",
      "mtime": 1761157433.1013875,
      "size_bytes": 5988,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.155981",
      "status": "completed"
    },
    "code-intelligence\\parsers\\kotlin_parser.py": {
      "file_path": "code-intelligence\\parsers\\kotlin_parser.py",
      "sha256": "65244af9c4769b801392ed51bce2bb02d95706b3049a1602eaec53650a3e7638",
      "mtime": 1761142664.4628756,
      "size_bytes": 712,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.155981",
      "status": "completed"
    },
    "code-intelligence\\parsers\\python_parser.py": {
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "sha256": "1bf4870c710d92bda92c6b9858bc7429a698194c1b08dae0760410449eed30bd",
      "mtime": 1761157432.9517167,
      "size_bytes": 6734,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.156982",
      "status": "completed"
    },
    "code-intelligence\\summary_templates.py": {
      "file_path": "code-intelligence\\summary_templates.py",
      "sha256": "aef0e7ba1d1856709cc7d87d078fed109f1a9a37131a113f3cb78db075b10f8b",
      "mtime": 1761143702.3037071,
      "size_bytes": 6921,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.157981",
      "status": "completed"
    },
    "frontend\\src\\api\\servicesClient.ts": {
      "file_path": "frontend\\src\\api\\servicesClient.ts",
      "sha256": "e7288f00f455eb067794a906d9aa574e2a485b6e16b5682f6b0903ae14980b30",
      "mtime": 1760777607.7928717,
      "size_bytes": 2251,
      "language": "typescript",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.157981",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "sha256": "2a7f9a8044e4d9d623839a340b1bef066b10839bd9d209d5ad196b16c5a078a6",
      "mtime": 1760777607.7994163,
      "size_bytes": 16881,
      "language": "text",
      "chunk_count": 14,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.159492",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\LLMTestPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "sha256": "cc1ab4f6478ec576102df39ed02b5792155527af97c3b8578bdb4bfc5f84fb6e",
      "mtime": 1761131276.853194,
      "size_bytes": 26261,
      "language": "text",
      "chunk_count": 21,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.160498",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "sha256": "9d361fe79027d9c3f7af5bcf8320108f2e7390b1c2584f25707ddd30c87a6856",
      "mtime": 1761046693.0510283,
      "size_bytes": 18226,
      "language": "text",
      "chunk_count": 14,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.161499",
      "status": "completed"
    },
    "frontend\\src\\components\\Shared\\ApprovalDialog.tsx": {
      "file_path": "frontend\\src\\components\\Shared\\ApprovalDialog.tsx",
      "sha256": "91c3ba16bc55e29eed788abae43c132c7b45c5ab01b185d800eb3da4cc4120fa",
      "mtime": 1761046693.0525339,
      "size_bytes": 4951,
      "language": "text",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.161499",
      "status": "completed"
    },
    "frontend\\src\\components\\Shared\\LogViewer.tsx": {
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "sha256": "e6026650d3ab6ca5e4d08a5615bbc8005591c5f14de98a792f855213e23d44ff",
      "mtime": 1760897642.5131524,
      "size_bytes": 7091,
      "language": "text",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.162847",
      "status": "completed"
    },
    "frontend\\src\\components\\Shared\\ProviderSettings.tsx": {
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "sha256": "625583b363f7029493f31f795fcc8979f8235570b31955a5f5ce27e22756b310",
      "mtime": 1761131276.853749,
      "size_bytes": 8265,
      "language": "text",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.163369",
      "status": "completed"
    },
    "frontend\\src\\config\\serviceRegistry.ts": {
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "sha256": "8c0027bcd93e18cfb3adc5da6120c4f036cf79d140cfc720de01f108adcad9b9",
      "mtime": 1761131276.856695,
      "size_bytes": 20613,
      "language": "typescript",
      "chunk_count": 16,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.163918",
      "status": "completed"
    },
    "interfaces\\api\\analysis_endpoints.py": {
      "file_path": "interfaces\\api\\analysis_endpoints.py",
      "sha256": "ad57d006d33428adb33f968ca101833b73a167594e90894b7932d53f0c01e181",
      "mtime": 1761083780.5954547,
      "size_bytes": 4543,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.164939",
      "status": "completed"
    },
    "interfaces\\api\\basic_endpoints.py": {
      "file_path": "interfaces\\api\\basic_endpoints.py",
      "sha256": "c56cf3f8ab253c8cf6991d703c4401a357765e00e6f5e61033fcb7a4e284a301",
      "mtime": 1761083780.9292676,
      "size_bytes": 2024,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.165930",
      "status": "completed"
    },
    "interfaces\\api\\chat_endpoints.py": {
      "file_path": "interfaces\\api\\chat_endpoints.py",
      "sha256": "82dde95565b03f99f1f5d32e6207b65ec08eb67ec49139ca742be74f7b217cd4",
      "mtime": 1761083780.7500434,
      "size_bytes": 4648,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.166934",
      "status": "completed"
    },
    "interfaces\\api\\commit_endpoints.py": {
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "sha256": "57b4b48c11b4e0e532ba73c65edf567bb67b3d2a27c78b0542ee5bd53e4aea24",
      "mtime": 1761083780.8258646,
      "size_bytes": 10683,
      "language": "python",
      "chunk_count": 8,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.167904",
      "status": "completed"
    },
    "interfaces\\api\\doc_endpoints.py": {
      "file_path": "interfaces\\api\\doc_endpoints.py",
      "sha256": "17ad1084af6d86b1486aca173bb0991c990c732dcdc20f8b843a9970eff68072",
      "mtime": 1761083780.5068843,
      "size_bytes": 4523,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.167904",
      "status": "completed"
    },
    "interfaces\\api\\llm_endpoints.py": {
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "sha256": "b5488e97a41b32765e791b5596cd7ad4a9d9f16133e33fd10466acb69f063266",
      "mtime": 1761134598.5920262,
      "size_bytes": 14327,
      "language": "python",
      "chunk_count": 12,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.168911",
      "status": "completed"
    },
    "interfaces\\api\\voice_endpoints.py": {
      "file_path": "interfaces\\api\\voice_endpoints.py",
      "sha256": "605fbc57f1b4ac3627eb839d147f8d988f2d3e45ca8740696a14f44ef750df3c",
      "mtime": 1761083780.8754725,
      "size_bytes": 4982,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.168911",
      "status": "completed"
    },
    "interfaces\\code_intelligence_api.py": {
      "file_path": "interfaces\\code_intelligence_api.py",
      "sha256": "59f8c11d48b2a8ee1815e8d72be2c0ba0a3db935d5af1d44623cf1c73ae36d9a",
      "mtime": 1761142664.4669006,
      "size_bytes": 21184,
      "language": "python",
      "chunk_count": 17,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.170831",
      "status": "completed"
    },
    "interfaces\\services_api.py": {
      "file_path": "interfaces\\services_api.py",
      "sha256": "929b432eb25094ab05f2c039ac5fac590aae10c4f0b7f0221ad5dfb9c81e2e13",
      "mtime": 1761131276.857831,
      "size_bytes": 5616,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.170831",
      "status": "completed"
    },
    "interfaces\\teams_bot.py": {
      "file_path": "interfaces\\teams_bot.py",
      "sha256": "d7cfb3006518d632bfd6ff5f7968a69bc1e83aa7383e45aa3623860cd3a3b1b9",
      "mtime": 1760679926.907468,
      "size_bytes": 3806,
      "language": "python",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.172381",
      "status": "completed"
    },
    "interfaces\\translation_api.py": {
      "file_path": "interfaces\\translation_api.py",
      "sha256": "f8421a38b70b2dfe56565204d993c20671683009ec74eab466c328114980785d",
      "mtime": 1761074756.9203157,
      "size_bytes": 5257,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.172381",
      "status": "completed"
    },
    "interfaces\\unified_ai_api.py": {
      "file_path": "interfaces\\unified_ai_api.py",
      "sha256": "a542828abe4e3bb6dbcfd9ecd1d9832446bdb5c5617441946bcc568759a8c463",
      "mtime": 1761131276.857831,
      "size_bytes": 11742,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.173388",
      "status": "completed"
    },
    "observability\\tracing.py": {
      "file_path": "observability\\tracing.py",
      "sha256": "0fc3ad35ff850f69609796dc990d13e6785defbe549792a43f34ada43f11e70c",
      "mtime": 1760679926.910006,
      "size_bytes": 945,
      "language": "python",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.173388",
      "status": "completed"
    },
    "orchestration\\cloud_providers\\implementations\\openai_provider.py": {
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "sha256": "5284d23acead456ec4601c22b6ca6e5408ac706820df689926886a0a14ed1e92",
      "mtime": 1761146344.9684484,
      "size_bytes": 6343,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.174387",
      "status": "completed"
    },
    "orchestration\\commit_workflow\\langgraph_router.py": {
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "sha256": "0b36601e256a7c4492aed8b7cacde528f044f2fa88bacbe393605958ffb519c1",
      "mtime": 1761046693.0585446,
      "size_bytes": 11422,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.175387",
      "status": "completed"
    },
    "orchestration\\message_parser\\extractors\\github_repo_loader.py": {
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "sha256": "28a4e4be1730f1c08c69f4f659f298d9131861c0e08e6a97ea2867027d1ddcd8",
      "mtime": 1760897642.526186,
      "size_bytes": 8999,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.175387",
      "status": "completed"
    },
    "orchestration\\shared\\connection_factory.py": {
      "file_path": "orchestration\\shared\\connection_factory.py",
      "sha256": "0c003f5e6b82799c65b893e11f45636dd0e50409adcef885f0eddbf08431f290",
      "mtime": 1761046693.0616138,
      "size_bytes": 13180,
      "language": "python",
      "chunk_count": 11,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.176387",
      "status": "completed"
    },
    "orchestration\\streaming_wrapper.py": {
      "file_path": "orchestration\\streaming_wrapper.py",
      "sha256": "8973ab8b119742932a5ed39d3b48ca24ebfca52a83587866c379429995e58cb0",
      "mtime": 1760777607.8436587,
      "size_bytes": 11837,
      "language": "python",
      "chunk_count": 10,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.176387",
      "status": "completed"
    },
    "orchestration\\summary_layer\\response_cleaner.py": {
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "sha256": "da7f3576d3cf3d7c9b41dc338089ac2b0eb107812b1f9fdf920e6c4e49d9b32b",
      "mtime": 1760897642.5283966,
      "size_bytes": 8198,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.177408",
      "status": "completed"
    },
    "orchestration\\voice_assistant\\azure_voice_adapter.py": {
      "file_path": "orchestration\\voice_assistant\\azure_voice_adapter.py",
      "sha256": "d80da2c69f62bbdbc03e8775b1e6ebcf4027bd414f9c27928fb6a73369e0194d",
      "mtime": 1761074756.921952,
      "size_bytes": 4894,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.177408",
      "status": "completed"
    },
    "shared\\azure_services\\azure_config_validator.py": {
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "sha256": "378545773fc260a07119e27b281e9bfbb53bb4728ebd2425ba54058f8e080b54",
      "mtime": 1761083293.7956061,
      "size_bytes": 10406,
      "language": "python",
      "chunk_count": 9,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.178917",
      "status": "completed"
    },
    "shared\\clients\\wrappers\\confluence_wrapper.py": {
      "file_path": "shared\\clients\\wrappers\\confluence_wrapper.py",
      "sha256": "dfd787a02f7549b8f342d5fc000705576ea6fea01af79430fe18d77e53e18493",
      "mtime": 1761135880.672984,
      "size_bytes": 4651,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.179924",
      "status": "completed"
    },
    "shared\\clients\\wrappers\\jira_wrapper.py": {
      "file_path": "shared\\clients\\wrappers\\jira_wrapper.py",
      "sha256": "bbe54d339da2a1d89ccd2a3d7b63b9f15775ffebbf480f6ec400c2ff857e5cc7",
      "mtime": 1761135880.7220056,
      "size_bytes": 4521,
      "language": "python",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.179924",
      "status": "completed"
    },
    "shared\\routing\\input_router.py": {
      "file_path": "shared\\routing\\input_router.py",
      "sha256": "5aa8bb774f67222daaf76c2827cb3aeee5abde619a876b380c291c714d7387ed",
      "mtime": 1761123619.709917,
      "size_bytes": 5653,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.181168",
      "status": "completed"
    },
    "shared\\utils\\github_query_detector.py": {
      "file_path": "shared\\utils\\github_query_detector.py",
      "sha256": "c3cf35a6ed1270d49e0052ec53e5d20f7537408e538f68c93e4806d4e958a444",
      "mtime": 1760897642.5397694,
      "size_bytes": 6864,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.182166",
      "status": "completed"
    },
    "shared\\utils\\language_detector.py": {
      "file_path": "shared\\utils\\language_detector.py",
      "sha256": "1db2a6ff77a34abba3e04b99d143f64151e4971839b4935e6de92bac9cc5563c",
      "mtime": 1761046693.0732026,
      "size_bytes": 6106,
      "language": "python",
      "chunk_count": 5,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.182764",
      "status": "completed"
    },
    "shared\\vector_db\\providers\\qdrant_provider.py": {
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "sha256": "a367717f0b24e9732ee8f2a6592b2917059795c608877b519e375e38de812965",
      "mtime": 1761046693.0742073,
      "size_bytes": 13025,
      "language": "python",
      "chunk_count": 11,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.183779",
      "status": "completed"
    },
    "ui\\api_client.py": {
      "file_path": "ui\\api_client.py",
      "sha256": "82dae8b834829fcf601c4ce08335e33a3c14173c47b60ffe81df9a9a2672d9b4",
      "mtime": 1760707910.5870092,
      "size_bytes": 7935,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.184783",
      "status": "completed"
    },
    "code-intelligence\\examples\\UserController.java": {
      "file_path": "code-intelligence\\examples\\UserController.java",
      "sha256": "4664e378eebd15ac98ab80fb8d4849644006946b51fb84da35546f759b01582b",
      "mtime": 1761142664.4586723,
      "size_bytes": 3107,
      "language": "java",
      "chunk_count": 3,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.185773",
      "status": "completed"
    },
    "code-intelligence\\examples\\sample_code.py": {
      "file_path": "code-intelligence\\examples\\sample_code.py",
      "sha256": "a00fdbaf327210d30cc6c6b96f0cf85e5b06f7263b653421a4346c01bb063b10",
      "mtime": 1761142664.4602304,
      "size_bytes": 2720,
      "language": "python",
      "chunk_count": 2,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.185773",
      "status": "completed"
    },
    "frontend\\postcss.config.js": {
      "file_path": "frontend\\postcss.config.js",
      "sha256": "374f669f08b18e67d0a7264fa45b71228017e604fe7f6db8a5c1bd5ba27e5c98",
      "mtime": 1760777607.791324,
      "size_bytes": 86,
      "language": "javascript",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.186773",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "sha256": "202229819a870a0dbe3003adeac623ba3e6af586d4189caa2bac34b25414b237",
      "mtime": 1760777607.7968836,
      "size_bytes": 7082,
      "language": "text",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.186773",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx",
      "sha256": "9bc3ccd1d8d7ede0b559a6b11ed615f4798c66cd8945f3884bddb48f264fef97",
      "mtime": 1760777607.79993,
      "size_bytes": 4848,
      "language": "text",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.187771",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx",
      "sha256": "126b834d53cbf338631652e46fcc3a1ec1706f1ddb06fc0b1e70502469e6cabc",
      "mtime": 1760777607.800592,
      "size_bytes": 4251,
      "language": "text",
      "chunk_count": 4,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.187771",
      "status": "completed"
    },
    "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx": {
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "sha256": "5d1f08440af2773bbe7f075fc033c9c19f1ba4117e70d3e467e80c5e5e4f4808",
      "mtime": 1761131276.852121,
      "size_bytes": 12193,
      "language": "text",
      "chunk_count": 10,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.188769",
      "status": "completed"
    },
    "frontend\\src\\components\\Shared\\BackendActivityStream.tsx": {
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "sha256": "c5bb8fe36153e8b24aa5c44b8a2f3ae4cc64eba30d42bb55ee9cf6304fe7e3ce",
      "mtime": 1760777607.806486,
      "size_bytes": 8597,
      "language": "text",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.189813",
      "status": "completed"
    },
    "frontend\\src\\vite-env.d.ts": {
      "file_path": "frontend\\src\\vite-env.d.ts",
      "sha256": "557791e30c70750f303bd0d820ef0176fb2d5c9399bbf237d5d77d638c24a288",
      "mtime": 1760777607.817701,
      "size_bytes": 207,
      "language": "typescript",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.189813",
      "status": "completed"
    },
    "frontend\\tailwind.config.js": {
      "file_path": "frontend\\tailwind.config.js",
      "sha256": "b07b9cd8e9453106975003eb26aee769e4469c1cc2f9579f9f808d1ec9ddcd91",
      "mtime": 1760777607.8192205,
      "size_bytes": 527,
      "language": "javascript",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.190795",
      "status": "completed"
    },
    "frontend\\vite.config.ts": {
      "file_path": "frontend\\vite.config.ts",
      "sha256": "90318afe6a7c958d16f9d4b5fa3de21ba67b04aae64c186c365f5f11f32466dd",
      "mtime": 1761074756.9148257,
      "size_bytes": 479,
      "language": "typescript",
      "chunk_count": 1,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.190795",
      "status": "completed"
    },
    "orchestration\\example_usage.py": {
      "file_path": "orchestration\\example_usage.py",
      "sha256": "9d08bb69a5e8cc2b36ca744c2c9171890e07a7f19107f7b7bd1ccf6deaca5cd8",
      "mtime": 1760777607.832086,
      "size_bytes": 7860,
      "language": "python",
      "chunk_count": 6,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.190795",
      "status": "completed"
    },
    "orchestration\\summary_layer\\azure_enhanced_summarizer.py": {
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "sha256": "1248de43335b999172ea4e024eb45d643da5fcba960443e8aec3273754d45422",
      "mtime": 1761074756.9208775,
      "size_bytes": 8458,
      "language": "python",
      "chunk_count": 7,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.192322",
      "status": "completed"
    },
    "shared\\vector_db\\services\\repository_indexer.deprecated.py": {
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "sha256": "2d7c0f51722c60861af43655c93245efcc3843c246089f8fa54e536526f0a8fa",
      "mtime": 1761144251.5530338,
      "size_bytes": 14511,
      "language": "python",
      "chunk_count": 11,
      "embedding_ids": [],
      "summary_cached": false,
      "last_embedded": "2025-10-22T20:19:52.193339",
      "status": "completed"
    }
  },
  "chunks": {
    "app.py:chunk_0": {
      "chunk_id": "app.py:chunk_0",
      "file_path": "ui\\app.py",
      "chunk_hash": "5316d96e099f2e6fcc1202dbe08c7a294126458ec8b1a4b85ff41a603aea5885",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code implements a Streamlit-based web UI for testing and interacting with an AI Development Agent backend API. It provides a multi-tab interface to test various AI-related services such as LLM providers, GitHub, Jira, and more.\n\n2. **Technical Details**:  \n- Uses Streamlit for rapid UI development with interactive widgets (tabs, columns, selectbox, checkbox, text_area).  \n- Instantiates an `APIClient` to communicate with backend services via HTTP or RPC (details abstracted in `api_client`).  \n- Checks API health status on load and displays success or error messages accordingly.  \n- Organizes UI into multiple tabs representing different functional areas of the AI Dev Agent.  \n- Uses layout components like columns to arrange controls and inputs neatly.\n\n3. **Business Logic**:  \nEnables developers, testers, or product managers to validate and experiment with AI-powered development tools and integrations (LLM providers, code analysis, documentation orchestration, etc.) through a unified interface. This helps ensure backend services are operational and meet functional requirements before deployment or integration.\n\n4. **Dependencies**:  \n- `streamlit`: For building the interactive web UI.  \n- `api_client` (custom module): Provides the `APIClient` class to interact with backend APIs.  \n- `json`: Standard library for JSON handling (imported but usage not shown in snippet).\n\n5. **Configuration**:  \n- Streamlit page configuration is set",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:16.772568",
      "status": "summarized"
    },
    "app.py:chunk_2": {
      "chunk_id": "app.py:chunk_2",
      "file_path": "ui\\app.py",
      "chunk_hash": "73f634f9db943c1129caf37f82afd38d7ec07fbcc699e310c34fba5e8d926742",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis snippet is part of a Streamlit-based UI that allows users to input a prompt and test a Large Language Model (LLM) by displaying the user message and showing detailed status updates about the LLM testing process.\n\n2. **Technical Details**:  \n- Uses Streamlit components such as `st.button`, `st.container`, `st.markdown`, `st.status`, and `st.expander` to create an interactive chat-like interface.  \n- Dynamically renders HTML-styled user message bubbles within the Streamlit app.  \n- Implements a stepwise status display with expandable sections to show detailed progress (e.g., provider selection).  \n- Conditional logic based on the selected provider to display relevant model and API information.\n\n3. **Business Logic**:  \nEnables users (likely developers or testers) to interactively test different LLM providers and models, facilitating evaluation and comparison of AI models for integration into business applications such as chatbots, content generation, or customer support automation.\n\n4. **Dependencies**:  \n- Streamlit (`st`), a Python library for building web apps for machine learning and data science.  \n- The code references an LLM provider named \"together\" and a model \"Llama-3.3-70B-Instruct-Turbo,\" implying integration with Together AI's OpenAI-compatible API.\n\n5. **Configuration**:  \n- Variables like `prompt`, `show_details`, and `provider` are used",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:21.369431",
      "status": "summarized"
    },
    "app.py:chunk_4": {
      "chunk_id": "app.py:chunk_4",
      "file_path": "ui\\app.py",
      "chunk_hash": "d3f0c3f69621abe1e8e075375db2f03de8eb3d05243242dd98e40b14ccf3e043",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Streamlit-based UI application that interacts with various Large Language Model (LLM) providers, sending prompts to an API endpoint and displaying the response along with metadata such as response time and success status.\n\n2. **Technical Details**:  \n- Uses Streamlit (`st`) for UI rendering, including expandable sections (`st.expander`) and formatted text (`st.write`, `st.code`).  \n- Measures API call duration using `time.time()` before and after the request.  \n- Calls an API client method `test_llm(prompt, provider)` to send the prompt and receive a response.  \n- Conditional UI logic to display provider-specific information (e.g., GPT-4 on Azure, fallback options).  \n- Uses dictionary access with `.get()` to safely extract response fields.\n\n3. **Business Logic**:  \nEnables users to test and compare responses from different LLM providers (e.g., Azure OpenAI, Together AI) by sending prompts and viewing response times and success status. This supports decision-making on which LLM provider to use based on performance and availability.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components.  \n- A custom or external `api_client` module/class that handles API requests to the backend LLM service.  \n- Python standard library `time` module for timing.\n\n5. **Configuration**:  \n- The code references conditional logic based on whether Azure Open",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:29.153835",
      "status": "summarized"
    },
    "app.py:chunk_6": {
      "chunk_id": "app.py:chunk_6",
      "file_path": "ui\\app.py",
      "chunk_hash": "c50348a090ed31d17457531c3b802793517e8ba3922be083b81e420b4566f2cd",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis snippet is part of a Streamlit-based UI application that interacts with a language model API to generate AI responses based on user prompts, displaying response metadata and status updates in the web interface.\n\n2. **Technical Details**:  \n- Uses Streamlit (`st`) for UI rendering, including spinners, markdown, and warning messages.  \n- Calls an asynchronous or synchronous API client method `test_llm(prompt, provider)` to get AI-generated results.  \n- Extracts and displays metadata such as response length, provider used, fallback usage, and token consumption from the API response dictionary.  \n- Uses timing functions (`time.time()`) to measure request duration.  \n- Updates UI status indicators dynamically based on operation progress and completion.\n\n3. **Business Logic**:  \nEnables users to input prompts and receive AI-generated text responses, while providing transparency on the underlying AI provider, token usage (cost proxy), and fallback mechanisms. This supports business needs for AI-driven content generation with operational insights.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components.  \n- A custom or external `api_client` module that provides the `test_llm` method to interact with language model providers.  \n- Python standard library `time` module for measuring elapsed time.\n\n5. **Configuration**:  \nNot explicitly shown in the snippet, but likely involves:  \n- Configuration of `api_client` with API keys, provider selection, or endpoint",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:34.008819",
      "status": "summarized"
    },
    "app.py:chunk_8": {
      "chunk_id": "app.py:chunk_8",
      "file_path": "ui\\app.py",
      "chunk_hash": "29719661da19d079a46d66ada3beae913b34055b414c0b74469a61f4ea0d99fe",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a Streamlit web application UI that displays the response from an AI assistant provider, showing the response content, performance metrics, and error messages if any occur during the interaction.\n\n2. **Technical Details**:  \n- Uses Streamlit (`st`) for UI rendering, including markdown, columns, captions, and expandable sections.  \n- Dynamically formats HTML content with inline styles for success and error messages.  \n- Utilizes a three-column layout to display provider name, response time, and status.  \n- Conditional rendering based on the presence of a successful response or an error in the `result` dictionary.  \n- Supports an expandable JSON view for detailed error information.\n\n3. **Business Logic**:  \nFacilitates user interaction with an AI assistant by presenting the AI-generated response and relevant metadata, enabling users to quickly assess the quality and performance of the AI service. It also provides detailed error diagnostics to troubleshoot issues, enhancing user trust and support efficiency.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and layout.  \n- Presumably, an AI provider API or service that returns a `result` dictionary containing keys like `\"response\"`, `\"error\"`, and performance metrics such as `duration`.\n\n5. **Configuration**:  \n- The variable `provider` indicates the AI service provider name, likely set elsewhere in the app.  \n- `show_details` flag controls whether detailed error",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:38.983577",
      "status": "summarized"
    },
    "app.py:chunk_10": {
      "chunk_id": "app.py:chunk_10",
      "file_path": "ui\\app.py",
      "chunk_hash": "4248374fa1449cc6d4547871ab82d911c9b48b25e186a6247fc5b178287a9aac",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code provides a Streamlit-based UI for testing integrations with GitHub and Jira by fetching and displaying open issues from specified repositories or Jira projects.\n\n2. **Technical Details**:  \n- Uses Streamlit widgets (`text_input`, `button`, `spinner`, `success`, `error`, `warning`, `json`) to build an interactive web interface.  \n- Captures user input for GitHub repository (`owner/repo`) and Jira project key.  \n- On button click, calls corresponding API client methods (`api_client.test_github` and `api_client.test_jira`) to fetch issue data.  \n- Displays results dynamically, including counts and JSON-formatted issue details.  \n- Uses conditional logic to handle empty inputs and API response success/failure.\n\n3. **Business Logic**:  \nEnables users (likely developers or project managers) to quickly verify connectivity and data retrieval from GitHub and Jira issue trackers, facilitating integration testing and validation of project issue data.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and user interaction.  \n- `api_client` module/object responsible for communicating with GitHub and Jira APIs (not shown in snippet).  \n- Underlying GitHub and Jira REST APIs accessed via `api_client`.\n\n5. **Configuration**:  \n- User inputs repository and project key at runtime; no explicit environment variables or config files shown here.  \n- Presumably, `api_client` is pre",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:43.612249",
      "status": "summarized"
    },
    "app.py:chunk_12": {
      "chunk_id": "app.py:chunk_12",
      "file_path": "ui\\app.py",
      "chunk_hash": "3f01b92b3b60f4ec03af360029eb7b80f0453af5ba407db8925ef11af6d58f1c",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a Streamlit web application UI that provides interactive tabs for testing integrations with external services: Confluence and Grafana. It allows users to input parameters, trigger API calls, and view results or errors directly in the UI.\n\n2. **Technical Details**:  \n- Utilizes Streamlit components such as `st.header()`, `st.text_input()`, `st.button()`, `st.spinner()`, `st.success()`, `st.error()`, `st.warning()`, and `st.json()` to build an interactive web interface.  \n- Uses conditional logic to validate user input (e.g., checking if `space_key` is provided).  \n- Calls methods on an `api_client` object (`test_confluence(space_key)` and `test_grafana()`) to perform backend API requests.  \n- Displays results dynamically based on the success or failure of API calls, including JSON output for detailed data.\n\n3. **Business Logic**:  \nEnables users (likely developers or system administrators) to verify the connectivity and data retrieval from Confluence spaces and Grafana alert systems. This helps ensure that integrations are correctly configured and operational, facilitating monitoring and documentation workflows.\n\n4. **Dependencies**:  \n- Streamlit (`st`), a Python library for building interactive web apps.  \n- An external `api_client` module or object responsible for communicating with Confluence and Grafana APIs.  \n- Under",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:48.133823",
      "status": "summarized"
    },
    "app.py:chunk_14": {
      "chunk_id": "app.py:chunk_14",
      "file_path": "ui\\app.py",
      "chunk_hash": "20367f96d98759b225fbc57710c3d28c63563ba3f8c1324c854d60cb1170cef1",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a Streamlit-based UI application that provides interactive testing interfaces for backend services, specifically for resolving issue context from various sources (GitHub, Jira, Grafana) and for code analysis testing.\n\n2. **Technical Details**:  \n- Utilizes Streamlit's tabbed interface (`tabs`) and layout components (`columns`) to organize input fields and display results.  \n- Collects user inputs such as issue ID, source type, and repository name.  \n- On button click, it calls an API client method `test_context_resolver` asynchronously (wrapped in a spinner for UX) to fetch context resolution results.  \n- Displays JSON-formatted results or error messages using Streamlit's `st.json`, `st.success`, `st.error`, and `st.warning` components.\n\n3. **Business Logic**:  \nEnables users (likely developers or support engineers) to validate and troubleshoot the context resolution of issues across different platforms, improving the accuracy and efficiency of issue tracking and triage workflows.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and interaction.  \n- An external `api_client` module or service that exposes the `test_context_resolver` method to interact with backend APIs.\n\n5. **Configuration**:  \n- UI keys for Streamlit widgets (e.g., `\"context_issue_id\"`, `\"context_source\"`, `\"context_repo\"`, `\"test_context\"`)",
      "embedding_id": null,
      "created_at": "2025-10-22T18:24:57.950580",
      "status": "summarized"
    },
    "app.py:chunk_16": {
      "chunk_id": "app.py:chunk_16",
      "file_path": "ui\\app.py",
      "chunk_hash": "6e718e529e49cb2e82971e48d416a2cef444be1401fe5f07232eb70d0fdfebbc",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a Streamlit-based UI application that provides interactive tools for analyzing Python code snippets and generating test cases for given functions. It allows users to input code and context, then calls an external API to perform code analysis or test generation.\n\n2. **Technical Details**:  \n- Utilizes Streamlit components such as `text_area`, `selectbox`, `button`, `columns`, and `tabs` to create a responsive web interface.  \n- The code analysis section accepts a code snippet and contextual information, then triggers an asynchronous API call (`api_client.test_code_analysis`) to analyze the code.  \n- The test generation section allows input of code and selection of a programming language to generate tests accordingly.  \n- Uses JSON to display structured analysis results.  \n- UI layout is organized using columns and tabs for better user experience.\n\n3. **Business Logic**:  \nThe application targets developers or QA engineers in software development environments, particularly those working on e-commerce or similar domains, to automate and streamline code review and test generation processes. This reduces manual effort and improves code quality and coverage.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and interaction.  \n- An external API client (`api_client`) responsible for backend code analysis and test generation services.  \n- Implicitly depends on JSON handling for displaying results.\n\n5. **Configuration**:  \n- UI elements have configurable keys for state management (`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:01.818820",
      "status": "summarized"
    },
    "app.py:chunk_18": {
      "chunk_id": "app.py:chunk_18",
      "file_path": "ui\\app.py",
      "chunk_hash": "46b84934f05b5fbf1b880364d79168b04c6b2c1bf820ea3a0cbd38a0db784a4e",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Streamlit web application UI that enables users to generate automated tests from code snippets and orchestrate AI-driven documentation workflows for GitHub repositories, including optional publishing and ticket creation.\n\n2. **Technical Details**:  \n- Utilizes Streamlit UI components such as `st.button`, `st.spinner`, `st.code`, `st.text_area`, `st.columns`, and `st.header` to create an interactive web interface.  \n- Invokes an external API client method `api_client.test_generate_tests(test_code, language)` to generate test code based on user input.  \n- Implements a multi-step documentation workflow described via markdown, guiding users through AI-powered documentation generation, GitHub commits, Confluence publishing, and Jira ticket creation.  \n- Uses a tabbed interface (`tabs[8]`) to organize the documentation orchestrator UI section.\n\n3. **Business Logic**:  \n- Automates the generation of test cases to improve code quality and reduce manual testing effort.  \n- Provides a streamlined, AI-assisted documentation process that integrates with common developer tools (GitHub, Confluence, Jira), enhancing developer productivity and ensuring up-to-date project documentation.  \n- Supports natural language prompts to simplify user interaction with complex documentation tasks.\n\n4. **Dependencies**:  \n- Streamlit (`st`), a Python library for building interactive web apps.  \n- An external `api_client` module/service responsible for generating tests and likely other AI",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:08.066810",
      "status": "summarized"
    },
    "app.py:chunk_20": {
      "chunk_id": "app.py:chunk_20",
      "file_path": "ui\\app.py",
      "chunk_hash": "b17320c9a745c21cd82b2613911c546838eff3866624f60fa048ac80a08e9b82",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a user interface section within a Streamlit app that collects user inputs related to GitHub repository settings and publishing options for generated documentation.\n\n2. **Technical Details**:  \n- Utilizes Streamlit UI components such as `subheader`, `text_input`, `number_input`, and `checkbox` to create an interactive form.  \n- Organizes inputs into two columns (`col1` and `col2` implied by context) for GitHub settings and publishing options respectively.  \n- Uses conditional disabling of input fields based on checkbox states (e.g., disabling Confluence and Jira inputs unless their respective checkboxes are checked).  \n- Captures user inputs as variables for further processing downstream.\n\n3. **Business Logic**:  \nEnables users to configure parameters for analyzing a GitHub repository (e.g., specifying which repo, how many files to analyze, commit path and message) and optionally publish the generated documentation to Confluence or create a Jira ticket. This supports automation of documentation workflows and integration with enterprise collaboration tools.\n\n4. **Dependencies**:  \n- Streamlit (`st`), a Python library for building interactive web apps.  \n- Implicit dependencies on GitHub, Confluence, and Jira APIs/services for subsequent operations (not shown in this snippet).\n\n5. **Configuration**:  \n- User-configured inputs via the UI serve as runtime configuration.  \n- No explicit environment variables or config files are referenced here,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:12.147362",
      "status": "summarized"
    },
    "app.py:chunk_22": {
      "chunk_id": "app.py:chunk_22",
      "file_path": "ui\\app.py",
      "chunk_hash": "347adc4ac2137d5f5fbe46a7fc63a2b0e6579d5cb602af4486b86b07fc2a6fc7",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Streamlit UI that triggers a documentation orchestration workflow when a user clicks the \"Generate & Orchestrate Docs\" button. It validates user inputs and then calls an API client method to generate documentation, optionally publishing it to Confluence and creating Jira tickets.\n\n2. **Technical Details**:  \n- Uses Streamlit's button widget with a callback pattern to initiate actions.  \n- Sequential input validation with conditional checks to ensure required fields are provided before proceeding.  \n- Uses a context manager (`st.spinner`) to display a loading indicator during the asynchronous orchestration process.  \n- Calls `api_client.orchestrate_docs` with multiple parameters, some conditionally passed based on user input.  \n- Parameters include strings, booleans, and optional values, demonstrating flexible API usage.\n\n3. **Business Logic**:  \nEnables users to automate the generation and orchestration of project documentation from a code repository, with optional publishing to Confluence spaces and creation of Jira tickets. This streamlines documentation workflows and integrates with common enterprise collaboration tools.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and user interaction.  \n- An external `api_client` module or service that exposes the `orchestrate_docs` method to handle the backend orchestration logic.  \n- Integration points with Atlassian Confluence and Jira (implied by parameters like `confluence_space_key` and `jira_project`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:16.365442",
      "status": "summarized"
    },
    "app.py:chunk_24": {
      "chunk_id": "app.py:chunk_24",
      "file_path": "ui\\app.py",
      "chunk_hash": "fd07c7d1564f95c63d173a3844194687b4ba939162da92f45467fc857fe37355",
      "chunk_index": 24,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a Streamlit web application UI that displays the results of a documentation orchestration workflow, showing the status of each step and the generated documentation to the user.\n\n2. **Technical Details**:  \n- Uses Streamlit (`st`) for UI rendering, including columns (`st.columns`), metrics (`st.metric`), success messages (`st.success`), and expandable sections (`st.expander`).  \n- Extracts workflow step statuses from a dictionary (`workflow_summary`) returned in the `result` object.  \n- Conditional logic determines the display text for each workflow step based on substring presence (e.g., `\"completed\" in workflow.get(\"step_1_generate\", \"\")`).  \n- Displays generated documentation in markdown format inside an expandable UI panel.\n\n3. **Business Logic**:  \n- Provides users with a clear, stepwise summary of a multi-step documentation orchestration process, which likely involves generating, committing, publishing, and creating related artifacts (e.g., GitHub commits, Confluence pages, Jira tickets).  \n- Helps stakeholders verify the success or failure of each step in the documentation pipeline, improving transparency and traceability.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and layout.  \n- The `result` dictionary presumably comes from an internal orchestration service or function that handles documentation generation and integration with external systems like GitHub, Confluence, and Jira.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:21.235367",
      "status": "summarized"
    },
    "app.py:chunk_26": {
      "chunk_id": "app.py:chunk_26",
      "file_path": "ui\\app.py",
      "chunk_hash": "ab8dd78a9d0eb009d198a64b086de6063dd42948b52ae1dee4e98c715acd4f73",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Streamlit-based UI that displays detailed analysis results, including files analyzed, GitHub commits, Confluence pages, and Jira tickets, in expandable sections for user-friendly visualization.\n\n2. **Technical Details**:  \n- Uses Streamlit (`st`) components such as `expander`, `write`, `json`, and `success` to render interactive UI elements.  \n- Retrieves data from a dictionary `result` with keys like `files_analyzed`, `github_commit`, `confluence_page`, and `jira_ticket`.  \n- Conditional rendering is employed to only show sections if corresponding data exists.  \n- Data structures involved are primarily Python dictionaries and lists, with JSON visualization for nested data.\n\n3. **Business Logic**:  \nThe code supports a business workflow that involves analyzing code repositories or projects and then tracking related artifacts such as commits, documentation pages, and issue tickets. It provides stakeholders with a consolidated view of the analysis outputs and their linkage to development and documentation tools.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI rendering.  \n- Implicitly depends on upstream processes or services that generate the `result` dictionary containing analysis and integration data.\n\n5. **Configuration**:  \n- No explicit configuration or environment variables are shown in this snippet.  \n- Assumes `result` is populated externally, possibly from API calls or data processing pipelines configured elsewhere.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:27.428075",
      "status": "summarized"
    },
    "app.py:chunk_28": {
      "chunk_id": "app.py:chunk_28",
      "file_path": "ui\\app.py",
      "chunk_hash": "79f53a8319153f39d025aa086e755d6e10c9e39f5be0694bca9b1b740ce0506d",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis snippet is part of a Streamlit-based UI application that facilitates interaction with an issue tracking and workflow system. It displays results of ticket creation and workflow summaries, and provides a form interface for executing a full issue analysis workflow with options to create pull requests and publish documentation.\n\n2. **Technical Details**:  \n- Uses Streamlit UI components such as `st.success`, `st.error`, `st.json`, `st.expander`, `st.header`, `st.columns`, `st.text_input`, `st.selectbox`, and `st.checkbox` to build an interactive web interface.  \n- Organizes UI into tabs and columns for better layout and user experience.  \n- Displays JSON data structures (`ticket`, `workflow`, `workflow_summary`) for detailed insights.  \n- Conditional rendering based on the presence of success or error results.\n\n3. **Business Logic**:  \n- Supports a workflow that creates and manages issue tickets (likely in Jira or similar systems) and analyzes issues end-to-end.  \n- Enables users to input issue identifiers, select data sources (GitHub, Jira, Grafana), and specify repositories.  \n- Provides options to automate downstream tasks such as creating pull requests and publishing documentation to Confluence, streamlining the software development lifecycle and documentation process.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI rendering.  \n- Implicit dependencies on external issue tracking and source control systems (GitHub, Jira, Grafana",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:31.569127",
      "status": "summarized"
    },
    "app.py:chunk_30": {
      "chunk_id": "app.py:chunk_30",
      "file_path": "ui\\app.py",
      "chunk_hash": "92421bad5a287f208aee30b98c8ca2bce0a93307898c3cb1332185b36f40397f",
      "chunk_index": 30,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Streamlit UI that triggers a full analysis workflow on a specified issue when a button is clicked, then displays the analysis results, generated fixes, and optionally a created pull request link.\n\n2. **Technical Details**:  \n- Uses Streamlit components (`st.button`, `st.spinner`, `st.success`, `st.expander`, `st.json`, `st.write`) to create an interactive web UI.  \n- Calls an external API client method `analyze_issue` with parameters collected from the UI inputs.  \n- Conditional UI rendering based on the presence of results (e.g., showing JSON analysis, fixes count, PR URL).  \n- Uses a spinner to indicate processing state during the asynchronous operation.\n\n3. **Business Logic**:  \nEnables users (likely developers or analysts) to run a comprehensive analysis on a software issue, generate automated fixes, and optionally create a pull request and publish documentation to Confluence, streamlining the software maintenance and documentation process.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI components and interaction.  \n- `api_client` module or object that provides the `analyze_issue` method, presumably interfacing with backend services or analysis engines.\n\n5. **Configuration**:  \n- UI state variables such as `full_issue_id`, `full_source`, `full_repository`, `create_pr`, `publish_docs`, and `confluence_space` are expected to be",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:38.629898",
      "status": "summarized"
    },
    "app.py:chunk_32": {
      "chunk_id": "app.py:chunk_32",
      "file_path": "ui\\app.py",
      "chunk_hash": "0f0802c437f24e13565700036965919148a7b8041ac5df85e6b300618af75bb2",
      "chunk_index": 32,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet is part of a Streamlit-based UI that displays the outcome of an operation related to publishing documentation for a given issue ID. It provides user feedback indicating success, error, or prompts for missing input.\n\n2. **Technical Details**:  \n- Uses conditional checks on a dictionary `result` to determine if a documentation page URL is present.  \n- Utilizes Streamlit's UI components (`st.success`, `st.error`, `st.warning`, `st.markdown`, `st.caption`) to render messages and UI separators.  \n- The code snippet is likely inside an event handler or callback responding to user input (issue ID).\n\n3. **Business Logic**:  \nEnables users to input an issue ID and receive automated feedback on whether the related documentation was successfully published or if an error occurred, facilitating streamlined bug fixing and documentation publishing workflows.\n\n4. **Dependencies**:  \n- Streamlit (`st`) for UI rendering and user interaction.  \n- The `result` dictionary presumably comes from an internal function or external API that processes the issue and attempts documentation publication.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet. Configuration likely exists elsewhere to manage API endpoints or authentication for the documentation publishing process.\n\n6. **Error Handling**:  \n- Handles missing or invalid issue ID input by showing a warning message.  \n- Displays error messages from the `result` dictionary, defaulting to \"Unknown error",
      "embedding_id": null,
      "created_at": "2025-10-22T18:25:42.900674",
      "status": "summarized"
    },
    "__init__.py:chunk_0": {
      "chunk_id": "__init__.py:chunk_0",
      "file_path": "orchestration\\__init__.py",
      "chunk_hash": "44ff67d28e4410b42c5145f80c32eb56ab9a6e54ff66b00298390f8dd5e8ce10",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines the orchestration layer for an AI Development Agent, organizing modular components that parse user messages, enrich context from external sources, build prompts, and coordinate task execution with a language model.\n\n2. **Technical Details**  \n- Implements a modular architecture separating concerns into message parsing, context enrichment, prompt building, and agent task execution.  \n- Uses data models (`ParsedMessage`, `EnrichedContext`, `PromptTemplate`, `AgentTask`) to represent structured information flowing through the pipeline.  \n- The `__all__` declaration explicitly exports these models for controlled package interface exposure.\n\n3. **Business Logic**  \nEnables an AI agent to understand and act upon user inputs by extracting references (e.g., URLs, tickets), enriching these with relevant data from tools like GitHub, Jira, and Confluence, and generating context-aware prompts to automate development-related tasks, thereby improving developer productivity and collaboration.\n\n4. **Dependencies**  \n- Internal module: `orchestration.shared.models` providing core data structures.  \n- External services implied (not directly shown here): GitHub, Jira, Confluence APIs for context enrichment.\n\n5. **Configuration**  \nNo explicit configuration or environment variables are defined in this snippet; configuration likely resides in other parts of the package or external config files to manage API credentials and service endpoints.\n\n6. **Error Handling**  \nNo error handling is present in this initialization code; error management is expected to be implemented within the individual",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:02.037418",
      "status": "summarized"
    },
    "__init__.py:chunk_2": {
      "chunk_id": "__init__.py:chunk_2",
      "file_path": "code-intelligence\\parsers\\__init__.py",
      "chunk_hash": "19f71b37f156dd2fc833053f5c3a741203bd1de9651fe41dd35014dbf750caf2",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `code-intelligence\\parsers\\__init__.py`**\n\n1. **Purpose**  \n   This code handles errors related to the dynamic import and registration of language-specific parsers within a code intelligence system. Its goal is to ensure that the system can continue functioning even if some language parsers fail to load due to missing dependencies or other import issues.\n\n2. **Exception Types**  \n   - Specifically catches `ImportError` exceptions, which occur if the parser module or its dependencies are not available in the runtime environment.\n\n3. **Recovery Strategy**  \n   - Upon catching an `ImportError`, the system logs a warning but does not halt execution.  \n   - It proceeds to attempt loading other parsers sequentially, allowing partial functionality rather than complete failure.  \n   - There is no retry mechanism; the code attempts each parser import once during initialization.\n\n4. **Logging**  \n   - Uses `logger.warning` to record each failed parser import, including the exception message for diagnostic purposes.  \n   - Logs an informational message (`logger.info`) after all parsers are processed, indicating how many parsers were successfully registered.  \n   - This logging supports monitoring and troubleshooting parser availability issues.\n\n5. **User Impact**  \n   - End users may experience reduced language support if certain parsers fail to load, potentially limiting code intelligence features (e.g., syntax highlighting, code analysis) for those languages.  \n   - However, the system remains operational",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:13.320568",
      "status": "summarized"
    },
    "__init__.py:chunk_4": {
      "chunk_id": "__init__.py:chunk_4",
      "file_path": "code-intelligence\\parsers\\__init__.py",
      "chunk_hash": "dc9adc5ff8a128fca13ece165120ce5c3ebcf30f07882394acf11ca64769a933",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code manages the registration and retrieval of language-specific parsers for source code files, enabling parsing of files based on their extensions. It provides a mechanism to select the appropriate parser or fallback to a generic parser when no specific parser is available.\n\n2. **Technical Details**:  \n- Uses dictionaries (`self._parsers` and `self._extension_map`) to map languages to parser instances and file extensions to languages, respectively.  \n- Registers parsers by associating them with language identifiers and their file extensions (converted to lowercase for consistency).  \n- Retrieves parsers by extracting the file extension from a given file path and looking up the corresponding parser; falls back to a generic parser if none is found.  \n- Uses logging (`logger.debug`) to trace parser registration and fallback events.  \n- Likely uses a base class or interface `BaseParser` for parser instances, ensuring a consistent API.\n\n3. **Business Logic**:  \nSupports a code intelligence platform or tool that needs to parse source code files of various programming languages. By mapping file extensions to parsers, it automates the selection of the correct parser, facilitating language-aware code analysis, indexing, or transformation.\n\n4. **Dependencies**:  \n- `Path` from Python\u2019s `pathlib` module for file path and extension handling.  \n- A logging framework (likely Python\u2019s standard `logging` module) for debug messages.  \n- Custom classes/interfaces such as `Base",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:22.004793",
      "status": "summarized"
    },
    "__init__.py:chunk_6": {
      "chunk_id": "__init__.py:chunk_6",
      "file_path": "code-intelligence\\parsers\\__init__.py",
      "chunk_hash": "23a4a2c1b3df29bad25fee1481d2c91ea4b0b1c5548b57774d6e84b5fabdcfc5",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines part of a parser registry system that manages and delegates source file parsing to appropriate language-specific parsers based on file extensions. It provides utilities to check supported file types and retrieve parsers dynamically.\n\n2. **Technical Details**:  \n- Uses a registry pattern (`ParserRegistry`) to map file extensions and programming languages to parser instances.  \n- Maintains internal dictionaries `_extension_map` and `_parsers` to associate file extensions with parsers and languages.  \n- Uses Python\u2019s `Path` from `pathlib` to extract file extensions in a platform-independent way.  \n- Provides methods to get supported extensions, languages, and to check if a file is supported.  \n- The `parse_file` method dynamically selects the correct parser and invokes its `parse_file` method, returning a list of `CodeChunk` objects representing parsed code segments.\n\n3. **Business Logic**:  \nEnables a modular and extensible system for analyzing source code files of various languages and formats, facilitating code intelligence features such as syntax analysis, code indexing, or transformation in a multi-language environment.\n\n4. **Dependencies**:  \n- Python standard library: `pathlib.Path` for file path manipulation.  \n- Custom classes/types: `ParserRegistry`, `BaseParser`, `CodeChunk` (likely defined elsewhere in the same package).  \n- No external third-party libraries are explicitly referenced in this snippet.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:26.155406",
      "status": "summarized"
    },
    "main.py:chunk_0": {
      "chunk_id": "main.py:chunk_0",
      "file_path": "main.py",
      "chunk_hash": "fa00b7cf2defd690404ea59d57eb97801ec92c8fc9482f32b5a363f7c2eed3f3",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code initializes logging and verifies the presence of a `.env` configuration file at application startup, logging key configuration settings for a service that likely involves LLM (Large Language Model) integration and vector database usage.\n\n2. **Technical Details**  \n- Uses Python\u2019s built-in `logging` module configured dynamically based on a log level from `settings`.  \n- Checks for the existence of a `.env` file using `pathlib.Path`.  \n- Logs configuration details without exposing sensitive information (e.g., API keys are masked).  \n- Imports asynchronous context management and SQLAlchemy engine creation, indicating potential async resource management and database interaction elsewhere in the application.  \n- Modular design with separation of concerns: HTTP API, vector DB initialization, observability metrics, and database models are imported from separate modules.\n\n3. **Business Logic**  \nEnsures that the application environment is correctly set up before running, which is critical for services relying on external LLM providers and vector databases. This verification step helps prevent misconfiguration that could lead to runtime failures or degraded service quality.\n\n4. **Dependencies**  \n- `uvicorn`: ASGI server for running the HTTP API.  \n- `logging`: Standard Python logging for observability.  \n- `os` and `pathlib`: For environment and file system operations.  \n- `contextlib.asynccontextmanager`: For managing asynchronous context lifecycles (likely used elsewhere).  \n- `sqlalchemy`: For ORM and database engine",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:34.904291",
      "status": "summarized"
    },
    "main.py:chunk_2": {
      "chunk_id": "main.py:chunk_2",
      "file_path": "main.py",
      "chunk_hash": "e3246fe4f8577b243892212ae4d48b963e39d20b21023459cd7fed94a19e89b7",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet logs the current application configuration status and initializes a database connection by creating the necessary schema tables.\n\n2. **Technical Details**:  \n- Uses structured logging to report configuration values and their presence/absence.  \n- Checks for critical missing configuration keys and logs warnings accordingly.  \n- Initializes a SQL database using SQLAlchemy\u2019s `create_engine` and `Base.metadata.create_all` to create tables based on ORM models.  \n- Returns the database engine instance if successful, or `None` if initialization fails.\n\n3. **Business Logic**:  \nEnsures that essential configuration parameters (like API keys and tokens) are present before the application proceeds, preventing runtime failures due to missing credentials. It also sets up the database schema required for the application\u2019s data persistence layer.\n\n4. **Dependencies**:  \n- `logger`: Presumably a configured logging instance (e.g., Python\u2019s `logging` module).  \n- `settings`: A configuration object or module providing application settings such as API keys, database URLs, host/port, and logging level.  \n- `create_engine` and `Base` from SQLAlchemy for database connectivity and ORM schema management.\n\n5. **Configuration**:  \n- `settings.github_token`: GitHub API token.  \n- `settings.github_org`: GitHub organization name.  \n- `settings.database_url`: Database connection string (e.g., `postgresql://user:pass@host/db`).  \n- `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:42.754002",
      "status": "summarized"
    },
    "main.py:chunk_4": {
      "chunk_id": "main.py:chunk_4",
      "file_path": "main.py",
      "chunk_hash": "8d73d93739a0c9b64ebcafb5720573cffd084f0fea6fa7a559a43b7a44d535d2",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines an asynchronous web service that initializes essential components (environment, database, vector DB) on startup and exposes a `/metrics` endpoint to provide application metrics.\n\n2. **Technical Details**:  \n- Uses an `asynccontextmanager` to manage the application's lifespan, ensuring proper startup and shutdown sequences.  \n- Initialization steps include environment verification, database setup, and asynchronous vector database initialization.  \n- The web server is run using `uvicorn` with dynamic configuration for host, port, reload mode, and log level.  \n- The `/metrics` endpoint is an asynchronous GET handler returning metrics data, presumably in a format compatible with monitoring tools.\n\n3. **Business Logic**:  \nThe service appears to be part of an AI development agent platform that requires persistent storage and vector search capabilities. It supports operational monitoring through metrics exposure, enabling observability and performance tracking for AI development workflows.\n\n4. **Dependencies**:  \n- `uvicorn` for ASGI server hosting.  \n- `asynccontextmanager` from `contextlib` for lifespan management.  \n- Custom modules or functions: `verify_env_loaded()`, `init_database()`, `initialize_vector_db()`, `metrics.get_metrics()`.  \n- `settings` module/object for configuration parameters.  \n- `logger` for structured logging.\n\n5. **Configuration**:  \n- Environment variables or config files are loaded and verified via `verify_env_loaded()`.  \n- `settings`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:26:52.265146",
      "status": "summarized"
    },
    "logger.ts:chunk_0": {
      "chunk_id": "logger.ts:chunk_0",
      "file_path": "frontend\\src\\utils\\logger.ts",
      "chunk_hash": "f8c42d1e9d3ac530316d57e58769f52ceab37e019208127529ef0c14f71a6171",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis TypeScript module implements a client-side logging utility using Zustand for state management, enabling structured logging with different severity levels, categorization, and in-memory storage of log entries.\n\n2. **Technical Details**  \n- Uses Zustand, a lightweight state management library, to create a global log store (`useLogStore`).  \n- Defines a `LogEntry` interface capturing log metadata: unique `id`, `timestamp`, `level`, `category`, `message`, and optional `data`.  \n- Maintains an array of logs (`logs`) with a maximum capacity (`maxLogs` = 1000). When the limit is exceeded, the oldest log is removed (FIFO behavior).  \n- Provides methods to add logs (`addLog`), clear all logs (`clearLogs`), and filter logs by category or level (`getLogsByCategory`, `getLogsByLevel`).  \n- Logs are also output to the browser console with appropriate console methods (`console.debug`, `console.info`, etc.) based on log level, including a formatted prefix with the category.\n\n3. **Business Logic**  \nThis utility addresses the need for consistent, categorized, and level-based logging in a frontend application, facilitating debugging, monitoring, and auditing of client-side events and errors. It helps developers and support teams trace issues and understand application behavior in production or development environments.\n\n4. **Dependencies**  \n- `zustand`: For reactive state management of the log store.  \n- Native browser",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:00.656686",
      "status": "summarized"
    },
    "logger.ts:chunk_2": {
      "chunk_id": "logger.ts:chunk_2",
      "file_path": "frontend\\src\\utils\\logger.ts",
      "chunk_hash": "08deb81e3fcfaf24c783a971e9a8c60b5af9e9dfb641b1cf0f19f538a8c2424a",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis TypeScript code implements a structured logging utility for a frontend application, enabling categorized and leveled logging with support for storing, filtering, and tracking log entries.\n\n2. **Technical Details**:  \n- Uses a centralized log store (likely via a state management hook `useLogStore`) to maintain an array of log entries.  \n- Supports multiple log levels (`debug`, `info`, `warn`, `error`, `success`) with corresponding console methods (`console.warn`, `console.error`, `console.log`).  \n- Logs are categorized by a string category, allowing filtering by category or level.  \n- The `Logger` class encapsulates logging functionality per category, providing instance methods for each log level that delegate to the store.  \n- Includes a `track` method (partially shown) designed to wrap asynchronous operations, presumably for timing or error tracking.  \n- Provides utility functions to clear logs and retrieve logs filtered by category or level.\n\n3. **Business Logic**:  \nFacilitates consistent and categorized logging across the frontend application to aid in debugging, monitoring, and operational visibility. The ability to filter logs by category or level supports targeted troubleshooting and analytics.\n\n4. **Dependencies**:  \n- Relies on a state management solution exposing `useLogStore` with `get` and `set` methods (likely Zustand or similar).  \n- Uses standard browser console APIs for output (`console.warn`, `console.error`, `console.log`).",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:09.104080",
      "status": "summarized"
    },
    "logger.ts:chunk_4": {
      "chunk_id": "logger.ts:chunk_4",
      "file_path": "frontend\\src\\utils\\logger.ts",
      "chunk_hash": "08ef53d47f513f2dd00812f6486ecda0f919ac75554b9d2ba1dce5b2dd2782ed",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis TypeScript code provides a structured logging utility designed to measure and log the execution duration of asynchronous operations, capturing success and failure states with contextual metadata.\n\n2. **Technical Details**:  \n- Uses a `Logger` class (implied from context) with methods like `info()`, `success()`, and `error()` to log messages at different severity levels.  \n- Wraps asynchronous function calls (`fn()`) with timing logic using `Date.now()` to calculate operation duration.  \n- Implements a try-catch block to handle both successful and failed executions, logging accordingly.  \n- Factory function `createLogger` instantiates loggers scoped by category for modular logging.  \n- Exports a `logger` object containing pre-configured logger instances for various application domains (e.g., Chat, Voice, API).\n\n3. **Business Logic**:  \nEnables detailed operational monitoring and diagnostics by logging the start, success, failure, and duration of key asynchronous business operations. This supports performance tracking, error auditing, and system observability critical for maintaining service reliability and user experience.\n\n4. **Dependencies**:  \n- Relies on a `Logger` class (not fully shown) that provides logging methods.  \n- No explicit external libraries are imported in the snippet; likely depends on standard TypeScript/JavaScript runtime and possibly a logging backend integrated within the `Logger` class.\n\n5. **Configuration**:  \n- Uses environment variables `operation`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:17.370019",
      "status": "summarized"
    },
    "logger.py:chunk_0": {
      "chunk_id": "logger.py:chunk_0",
      "file_path": "shared\\logger.py",
      "chunk_hash": "3c83849e75c23d6ab1aad398b92556ec3881e44ccf0fcfc7215d0a418ea3edf0",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module provides a centralized, structured logging utility tailored for an AI development agent application. It enhances log messages with contextual information such as request and user identifiers, timestamps, and supports structured data for better traceability and analysis.\n\n2. **Technical Details**:  \n- Uses Python\u2019s built-in `logging` module with a custom `StructuredFormatter` subclass to format log records.  \n- Incorporates `contextvars.ContextVar` to maintain and inject contextual information (e.g., `request_id`, `user_id`) into logs across asynchronous or concurrent execution flows.  \n- Adds ISO8601 UTC timestamps to each log entry.  \n- Supports attaching arbitrary structured data to log records for richer logging semantics.  \n- Imports standard libraries like `json`, `time`, `uuid` for potential use in generating or formatting log-related data.  \n- Uses type hints and standard Python idioms for clarity and maintainability.\n\n3. **Business Logic**:  \nEnables consistent, enriched logging across the AI Dev Agent system to facilitate debugging, monitoring, and auditing of user requests and interactions with large language models (LLMs). This helps in tracking request lifecycles, user actions, and performance metrics critical for operational insights and compliance.\n\n4. **Dependencies**:  \n- Python standard library modules: `logging`, `sys`, `json`, `time`, `uuid`, `datetime`, `contextvars`, `functools`, `typing`.  \n- No external third",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:22.005941",
      "status": "summarized"
    },
    "logger.py:chunk_2": {
      "chunk_id": "logger.py:chunk_2",
      "file_path": "shared\\logger.py",
      "chunk_hash": "6d168c60cb9779c89f6a03a6a15347a4f992d241b0bf18283b8e47fd3b6cf1b6",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines a centralized logging utility class `AppLogger` that supports structured logging with enriched contextual information, enabling consistent and readable log output across an application.\n\n2. **Technical Details**:  \n- Uses Python\u2019s built-in `logging` module to create and manage loggers.  \n- Implements a custom log formatter `StructuredFormatter` (partially shown) that formats log messages with structured JSON data and a specific log message template including timestamp, logger name, log level, request ID, and message.  \n- The `AppLogger` class encapsulates logger setup and provides convenience methods (`info`, `error`, `warning`) to log messages at different severity levels, optionally including additional structured data via keyword arguments.  \n- Logger handlers are configured to output to standard output (`sys.stdout`) using a stream handler.\n\n3. **Business Logic**:  \nFacilitates consistent, structured logging across an application, which is critical for monitoring, debugging, and auditing in production environments. The inclusion of structured data (e.g., request IDs) helps correlate logs with business transactions or user requests, improving traceability and operational insight.\n\n4. **Dependencies**:  \n- Python standard libraries: `logging`, `json`, `sys`.  \n- A custom `StructuredFormatter` class (not fully shown) that extends or customizes log message formatting.\n\n5. **Configuration**:  \n- Logger name is passed during `AppLogger` instantiation to differentiate log",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:29.520760",
      "status": "summarized"
    },
    "logger.py:chunk_4": {
      "chunk_id": "logger.py:chunk_4",
      "file_path": "shared\\logger.py",
      "chunk_hash": "932318eb1381fe07eca30288d3d80c0bbc4c6e5c55d114c014dd78dfd498c24c",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a structured logging utility that extends standard logging capabilities by supporting additional contextual and structured data for log entries, particularly focusing on method calls and LLM (Large Language Model) requests.\n\n2. **Technical Details**:  \n- Implements wrapper methods (`debug`, `info`, `warning`) around Python\u2019s built-in `logging` module to add structured data via the `extra` parameter.  \n- Uses a private `_log` method to centralize logging logic, injecting structured data under the key `'structured_data'`.  \n- Provides specialized logging methods such as `log_method_call` to capture method invocation details (method name, argument counts, keyword argument keys, and execution duration).  \n- Partial implementation of `log_llm_request` suggests logging of LLM request metadata (provider, model, prompt, temperature).  \n- Uses Python type hints and optional parameters for clarity and flexibility.\n\n3. **Business Logic**:  \nEnables enhanced observability and debugging by capturing detailed, structured logs of application behavior, especially method executions and interactions with LLM services. This supports monitoring, troubleshooting, and auditing in business-critical workflows involving AI models and complex method calls.\n\n4. **Dependencies**:  \n- Python standard library `logging` module.  \n- `typing` module for type annotations (`Dict`, `Any`, `Optional`).  \n- Presumably a configured `self.logger` instance of `logging.Logger` (not shown in snippet).",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:39.565827",
      "status": "summarized"
    },
    "logger.py:chunk_6": {
      "chunk_id": "logger.py:chunk_6",
      "file_path": "shared\\logger.py",
      "chunk_hash": "5f83c606b8d57d53b7e6be5cfc5594d3ac596b59aacb448e7340aba992223087",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides logging functionality specifically tailored for interactions with Large Language Models (LLMs). It logs both requests sent to LLM providers and their corresponding responses, including metadata such as prompt length, response length, duration, and errors.\n\n2. **Technical Details**:  \n- Uses structured logging by assembling dictionaries of relevant metadata (`data`) to pass as keyword arguments to logging methods (`self.info`, `self.error`).  \n- Truncates long strings (prompts and responses) to 100 characters for preview purposes to keep logs concise.  \n- Rounds duration metrics to two decimal places for readability.  \n- Optional parameters like `temperature` and `tokens` are conditionally included in logs if provided.  \n- The code snippet appears to be part of a class that extends or wraps a logger with custom methods for LLM-specific events.\n\n3. **Business Logic**:  \nEnables detailed observability into LLM usage within an application, helping developers and operators monitor request/response cycles, measure latency, track token usage, and quickly identify errors from different LLM providers. This supports debugging, performance tuning, and SLA compliance in AI-driven products.\n\n4. **Dependencies**:  \n- Implicitly depends on a logging framework (likely Python\u2019s built-in `logging` module or a wrapper around it) providing `info` and `error` methods.  \n- Uses Python standard types like `Optional`, `Dict`, and `Any`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:44.269466",
      "status": "summarized"
    },
    "logger.py:chunk_8": {
      "chunk_id": "logger.py:chunk_8",
      "file_path": "shared\\logger.py",
      "chunk_hash": "12e690d8594bc8d2dba1bbb1080c98f00ad7045863c996e7abb1adf00ad52f88",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code defines logging utility methods within a logger class to standardize and enrich logs related to API requests, GitHub operations, and database operations, including contextual metadata and performance metrics.\n\n2. **Technical Details**:  \n- Uses typed method signatures with `Optional` and `Dict` from `typing` for clarity and type safety.  \n- Constructs dictionaries to hold structured log data, conditionally including fields like `status_code` and `duration_ms`.  \n- Uses emoji prefixes (\"\u2705\", \"\u274c\", \"\ud83d\udce6\") in log messages to visually indicate success/failure or operation type.  \n- Calls a presumed `self.info()` method to emit logs, passing both a formatted message string and keyword arguments for structured logging.  \n- Rounds duration metrics to two decimal places for readability.\n\n3. **Business Logic**:  \n- Provides consistent, enriched logging for critical business operations: API calls, GitHub repository interactions, and database queries.  \n- Enables monitoring and troubleshooting by capturing HTTP methods, paths, response statuses, operation names, repository names, database tables, and operation durations.  \n- Helps track success/failure rates and performance metrics, supporting operational visibility and reliability.\n\n4. **Dependencies**:  \n- Relies on Python standard typing module (`Dict`, `Any`, `Optional`).  \n- Depends on a logging framework or base class providing `self.info()` method (not shown in snippet).  \n- No explicit external libraries or services",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:52.331837",
      "status": "summarized"
    },
    "logger.py:chunk_10": {
      "chunk_id": "logger.py:chunk_10",
      "file_path": "shared\\logger.py",
      "chunk_hash": "bb79612919a6b91c25ff7f156eb4bd5e426c8ffa4e8432318badcc3255276b41",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides a logging utility focused on structured and automated logging of method calls, including entry, exit, duration, and exceptions, primarily for asynchronous functions.\n\n2. **Technical Details**:  \n- Defines a decorator `log_method` that wraps asynchronous functions to log their invocation lifecycle.  \n- Uses `time.time()` to measure execution duration in milliseconds.  \n- Employs `functools.wraps` to preserve the wrapped function\u2019s metadata.  \n- Uses a custom `AppLogger` class (presumably extending standard logging) to output logs with contextual data such as method name, arguments, and execution time.  \n- The decorator supports optional injection of a logger instance or creates one based on the function\u2019s module name.\n\n3. **Business Logic**:  \nEnables consistent and detailed logging of asynchronous method executions, which is critical for monitoring, debugging, and auditing business operations that involve database or service calls, improving observability and operational insight.\n\n4. **Dependencies**:  \n- Python standard libraries: `time`, `functools` (for `wraps`), `typing` (for `Callable`, `Optional`).  \n- Custom module/class: `AppLogger` (not fully shown but central to logging functionality).\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet. Logger instantiation is dynamic based on the module name, implying possible external configuration within `AppLogger`.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T18:27:59.463517",
      "status": "summarized"
    },
    "logger.py:chunk_12": {
      "chunk_id": "logger.py:chunk_12",
      "file_path": "shared\\logger.py",
      "chunk_hash": "09b4079b1910a692cc6482ed9111b4aca4296c653221b0c50049489da8049afa",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides a decorator-based logging utility to automatically log entry, exit, execution duration, and errors for synchronous functions, enhancing observability and debugging capabilities.\n\n2. **Technical Details**:  \n- Uses Python decorators (`@wraps`) to wrap target functions.  \n- Measures execution time using `time.time()` before and after function calls to calculate duration in milliseconds.  \n- Logs method entry and exit points with debug-level messages.  \n- On successful execution, logs method call details including arguments and duration.  \n- On exceptions, logs error details with the exception message and duration, then re-raises the exception.  \n- Differentiates between synchronous and asynchronous function wrappers (though async wrapper code is not fully shown here).  \n- Uses a `logger` instance, lazily initialized via `get_logger(func.__module__)`.\n\n3. **Business Logic**:  \nFacilitates consistent and detailed logging of method executions across the application, which is critical for monitoring, troubleshooting, and auditing business operations and workflows.\n\n4. **Dependencies**:  \n- Python standard library modules: `asyncio` (imported but not fully shown in use), `time` (implied usage), `functools.wraps`.  \n- A custom or external `get_logger` function and a `logger` object with methods like `debug()`, `error()`, and `log_method_call()`.\n\n5. **Configuration**:  \nNo explicit environment",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:06.102394",
      "status": "summarized"
    },
    "logger.py:chunk_14": {
      "chunk_id": "logger.py:chunk_14",
      "file_path": "shared\\logger.py",
      "chunk_hash": "40ec040c5489272ed59f3081694d33d0a8ec7d28d909d49946ba23627d70d71f",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a logging utility designed to manage and enrich log entries with contextual information such as request IDs and user IDs, supporting both synchronous and asynchronous function logging.\n\n2. **Technical Details**:  \n- Uses context variables (`request_id_var`, `user_id_var`) to store per-request contextual data in an asynchronous-safe manner.  \n- Provides functions to set (`set_request_context`) and clear (`clear_request_context`) these context variables.  \n- Generates a new UUID as a fallback request ID if none is provided.  \n- Implements a decorator pattern (partially shown) that wraps functions differently depending on whether they are coroutine functions (async) or synchronous, enabling seamless logging integration.  \n- Instantiates a default logger named `\"ai_dev_agent\"` via a `get_logger` function (not shown here).\n\n3. **Business Logic**:  \nEnhances logging with request and user context to improve traceability and debugging in applications, particularly useful in distributed systems or services where correlating logs to specific requests or users is critical for monitoring, auditing, and troubleshooting.\n\n4. **Dependencies**:  \n- Python standard library modules: `asyncio` (for coroutine detection), `uuid` (for generating unique IDs), and `contextvars` (implied for context variable management).  \n- A custom or external `get_logger` function/module to create logger instances.\n\n5. **Configuration**:  \nNo explicit environment variables or config files",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:24.570894",
      "status": "summarized"
    },
    "base.py:chunk_0": {
      "chunk_id": "base.py:chunk_0",
      "file_path": "shared\\services\\base.py",
      "chunk_hash": "d76dcd5cf9e2c298ea860b0f14caf6bea793ab94c547cc4344421b4405bcc601",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a foundational abstract base class and related types for integrating with external services in a standardized way. It provides a common interface and configuration model for service connection management.\n\n2. **Technical Details**:  \n- Uses Python's `abc` module to define an abstract base class (`BaseService`) enforcing implementation of asynchronous `connect` and `disconnect` methods.  \n- Employs `Enum` (`ServiceStatus`) to represent service connection states.  \n- Uses Pydantic's `BaseModel` (`ServiceConfig`) for structured, type-validated service configuration including service metadata and dynamic config dictionary.  \n- Maintains internal state such as connection status, last error message, last connection timestamp, and an optional client instance.  \n- Logging is initialized via a shared logger utility.\n\n3. **Business Logic**:  \nProvides a reusable, consistent framework for managing connections to various external services (e.g., APIs, databases, messaging systems). This abstraction allows business applications to integrate multiple service types with uniform lifecycle management, status tracking, and error reporting.\n\n4. **Dependencies**:  \n- Python standard libraries: `abc`, `enum`, `datetime`, `typing`  \n- Third-party: `pydantic` for data validation and settings management  \n- Internal module: `shared.logger` for logging\n\n5. **Configuration**:  \n- Service configuration is encapsulated in `ServiceConfig` with fields for service name, type, enabled flag, and",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:38.432081",
      "status": "summarized"
    },
    "base.py:chunk_2": {
      "chunk_id": "base.py:chunk_2",
      "file_path": "shared\\services\\base.py",
      "chunk_hash": "b14da148fbc39849bd860a685244b27627e99266fb98f2d82da642c0ee7a1396",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines an abstract base class for asynchronous service integrations, providing a standardized interface to test connectivity, execute service-specific actions, retrieve capabilities, and track service status.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to support non-blocking I/O operations.  \n- Defines an abstract method `execute` with the `@abstractmethod` decorator, enforcing subclasses to implement service-specific logic.  \n- Maintains internal state with attributes like `status`, `last_error`, and `last_connected`.  \n- Uses Python standard data structures such as dictionaries (`Dict[str, Any]`) and lists (`List[str]`) for method inputs and outputs.  \n- Implements helper methods `_set_connected` and `_set_error` to update service status and log errors.  \n- Uses ISO 8601 formatting for timestamps (`datetime.isoformat()`).\n\n3. **Business Logic**:  \nProvides a reusable, consistent framework for integrating with various external or internal services, enabling health checks, action execution, capability discovery, and status monitoring. This abstraction helps in managing service reliability and error tracking in a scalable way.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous method definitions (implied).  \n- `abc` module for `@abstractmethod` decorator (implied).  \n- `datetime` module for timestamping connection events.  \n- `logger` for error logging (likely a configured logging instance).  \n- `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:48.400250",
      "status": "summarized"
    },
    "base.py:chunk_4": {
      "chunk_id": "base.py:chunk_4",
      "file_path": "orchestration\\cloud_providers\\templates\\base.py",
      "chunk_hash": "c604dfa0ededb6e7071afa898be1f3ecc18005ceaf99ebba9c748fcf78cc43b5",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines abstract base classes for cloud provider integrations, specifically focusing on general provider capabilities and Speech-to-Text (STT) services. It establishes a contract for implementing providers to support capability checks, health monitoring, and asynchronous audio transcription.\n\n2. **Technical Details**:  \n- Uses Python's `abc` module to define abstract base classes (`ABC`) and abstract methods (`@abstractmethod`), enforcing implementation in subclasses.  \n- Defines asynchronous methods (`async def`) for operations that likely involve I/O-bound tasks such as network calls (e.g., `health_check`, `transcribe`).  \n- Employs type hinting with complex return types (`List[ProviderCapability]`, `Dict[str, Any]`, `STTResult`) to improve code clarity and static analysis.  \n- Implements a capability pattern where providers declare supported features via `get_capabilities()` and can be queried via `supports_capability()`.\n\n3. **Business Logic**:  \n- Provides a standardized interface for integrating multiple cloud providers, enabling the orchestration layer to interact with different services uniformly.  \n- Facilitates speech-to-text transcription workflows by abstracting the transcription process, allowing the business to support multiple STT providers interchangeably.  \n- Supports health checks to monitor provider service availability, critical for maintaining system reliability and failover strategies.\n\n4. **Dependencies**:  \n- Python standard library modules: `abc` for abstract base classes, `typing` for type annotations",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:55.024886",
      "status": "summarized"
    },
    "base.py:chunk_6": {
      "chunk_id": "base.py:chunk_6",
      "file_path": "orchestration\\cloud_providers\\templates\\base.py",
      "chunk_hash": "0d71d7b99b852e3ecbd074d68f7972891ac9b8e8186ba7d10871553e583025d1",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code defines abstract base classes (ABCs) for cloud-based speech and translation services, specifically for Text-to-Speech (TTS) and Translation providers. It establishes a standardized interface for implementing various cloud provider integrations.\n\n2. **Technical Details**:  \n- Uses Python's `abc` module to define abstract base classes and enforce implementation of key methods in subclasses.  \n- Asynchronous programming with `async def` for potentially I/O-bound operations like network calls (e.g., `synthesize` and `translate` methods).  \n- Method signatures include optional parameters with default values to support flexible provider implementations.  \n- Return types like `TTSResult` and `TranslationResult` suggest structured data objects encapsulating results and metadata.  \n- The `is_available` method provides a synchronous health check interface for service availability.\n\n3. **Business Logic**:  \nThese abstractions enable the orchestration layer of an application to interact uniformly with multiple cloud providers offering speech synthesis and translation services. This supports business needs such as multilingual content delivery, voice-enabled applications, and accessibility features without coupling to a specific vendor.\n\n4. **Dependencies**:  \n- Python standard library modules: `abc` for abstract base classes, `typing` for type hints (`Optional`).  \n- Custom or external data types: `TTSResult` and `TranslationResult` (likely defined elsewhere in the codebase).  \n- Implicit dependency on asynchronous event loop for async methods.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:28:59.752123",
      "status": "summarized"
    },
    "base.py:chunk_8": {
      "chunk_id": "base.py:chunk_8",
      "file_path": "orchestration\\cloud_providers\\templates\\base.py",
      "chunk_hash": "8764c0f9ae777fb83d24970460e0149594fb5c0aaf968e7570a8e76cdb2de6c7",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code defines abstract base classes for cloud-based language services, specifically for translation and large language model (LLM) providers. It establishes a standardized interface for implementing translation and chat completion functionalities asynchronously.\n\n2. **Technical Details**:  \n- Uses Python's `ABC` (Abstract Base Class) module to enforce implementation of key methods in subclasses.  \n- Defines asynchronous abstract methods (`async def`) for operations like language detection, translation, and chat completions, enabling non-blocking I/O operations.  \n- Method signatures include parameters for controlling behavior such as source language, temperature for sampling, max tokens, and streaming options.  \n- Returns structured result types (`TranslationResult`, `LLMResult`) encapsulating output and metadata.  \n- Uses type hints (`Dict[str, Any]`, `List[Dict[str, str]]`) for clarity and static analysis.\n\n3. **Business Logic**:  \nProvides a pluggable framework for integrating multiple cloud-based language services (translation and LLM chat) in a consistent manner. This abstraction supports business needs such as multilingual content processing, automated translation, and conversational AI, enabling easy swapping or addition of providers without changing business logic.\n\n4. **Dependencies**:  \n- Python standard library: `abc` for abstract classes, `typing` for type hints.  \n- Presumably depends on external implementations of `TranslationResult` and `LLMResult` data structures (not shown).  \n- Underlying cloud provider",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:07.543480",
      "status": "summarized"
    },
    "base.py:chunk_10": {
      "chunk_id": "base.py:chunk_10",
      "file_path": "orchestration\\cloud_providers\\templates\\base.py",
      "chunk_hash": "8a5b5a809daecf5ec17bc9339a4ff1a16b853bc5fce34d4a7ec3d5dee26133a3",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines an abstract base class interface for interacting with Large Language Model (LLM) services, specifying methods for generating text embeddings, checking service availability, and retrieving model metadata.\n\n2. **Technical Details**:  \n- Uses Python's `abc` module to declare abstract methods and properties, enforcing implementation in subclasses.  \n- Defines asynchronous method `generate_embedding` to support non-blocking calls, likely for I/O-bound operations such as network requests to LLM APIs.  \n- Returns embeddings as a list of floats, a common data structure for vector representations in NLP.  \n- Includes synchronous method `is_available` to check service health/status.  \n- Uses a property decorator for `model_name` to expose model metadata cleanly.\n\n3. **Business Logic**:  \nProvides a standardized interface for integrating various LLM providers into an orchestration system, enabling consistent embedding generation and model management across different cloud or service backends. This abstraction supports business needs around AI-driven text processing, semantic search, or content generation.\n\n4. **Dependencies**:  \n- Python standard library: `abc` for abstract base classes, `typing` for type hints (`Optional`, `List`).  \n- Implied dependency on asynchronous frameworks or event loops (e.g., `asyncio`) for async method execution.  \n- No direct external LLM SDKs or APIs are referenced here; these would be implemented in subclasses.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:12.144432",
      "status": "summarized"
    },
    "repo.py:chunk_0": {
      "chunk_id": "repo.py:chunk_0",
      "file_path": "db\\repo.py",
      "chunk_hash": "e1a8c9edcdfb3ada96df71f55219687be35e96fd03b3e7fc502fc7c687bc2168",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a repository class `IssueRepository` that provides an abstraction layer for CRUD operations on `Issue` entities within a database, facilitating issue management in an application.\n\n2. **Technical Details**:  \n- Uses SQLAlchemy ORM `Session` for database interactions.  \n- Implements the Repository design pattern to encapsulate data access logic.  \n- Supports creation, retrieval (by external ID or internal ID), bulk retrieval with pagination (skip, limit), and partial update (status) of `Issue` objects.  \n- Uses Python typing hints for method signatures (`List`, `Optional`).  \n- The `create` method supports flexible attribute assignment via `**kwargs`.\n\n3. **Business Logic**:  \nEnables managing issues (likely bug reports, tickets, or tasks) by creating new issues, retrieving existing ones, listing multiple issues with pagination, and updating issue status. This supports workflows such as issue tracking, prioritization, and resolution in a software or operational context.\n\n4. **Dependencies**:  \n- `sqlalchemy.orm.Session` for ORM database session management.  \n- Python standard libraries: `typing` for type annotations, `datetime` (imported but unused in this snippet).  \n- Local module `.models` providing ORM models: `Issue`, `Analysis`, `Fix`, `ChatConversation`, `ChatMessage`.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. The database session (`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:19.083071",
      "status": "summarized"
    },
    "repo.py:chunk_2": {
      "chunk_id": "repo.py:chunk_2",
      "file_path": "db\\repo.py",
      "chunk_hash": "497a83166a4dae9fe086927ff53912e070a2ac1e385664e63baac0e97af914ee",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines a repository class `AnalysisRepository` responsible for managing database operations related to `Analysis` and associated `Fix` entities, including creation, retrieval, and adding fixes to analyses.\n\n2. **Technical Details**:  \n- Uses the Repository design pattern to abstract database operations.  \n- Relies on SQLAlchemy ORM for database interaction (`Session` object for transactions).  \n- Implements CRUD-like methods: `create` for inserting new `Analysis` records, `get_by_issue` for querying analyses by issue ID, and `add_fix` for adding fix records linked to an analysis.  \n- Uses Python's `**kwargs` to allow flexible attribute passing during object creation.  \n- Commits transactions immediately after adding or modifying records and refreshes objects to sync with DB state.\n\n3. **Business Logic**:  \nSupports a system that tracks issues and their analyses, including root cause identification and confidence scoring. It also manages fixes related to these analyses, enabling traceability from issue to analysis to fix, which is critical for debugging, quality assurance, and continuous improvement workflows.\n\n4. **Dependencies**:  \n- SQLAlchemy ORM (`Session`, `query`, `add`, `commit`, `refresh`) for database operations.  \n- Python standard library `datetime` (implied from partial code) for timestamping updates.  \n- Domain models/entities `Analysis` and `Fix` (imported elsewhere) representing database tables.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:27.054380",
      "status": "summarized"
    },
    "repo.py:chunk_4": {
      "chunk_id": "repo.py:chunk_4",
      "file_path": "db\\repo.py",
      "chunk_hash": "f8a7ab5be3be3b30fad51a5fa068ccd01cf5a66c96835e085b78b7ffd7bd0ad3",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines a `ChatRepository` class that provides database operations for managing chat conversations and messages, including creating conversations, retrieving conversations, listing conversations, and adding messages.\n\n2. **Technical Details**:  \n- Uses SQLAlchemy ORM for database interactions via a `Session` object (`self.db`).  \n- Implements CRUD-like methods for `ChatConversation` and `ChatMessage` entities.  \n- Uses query filtering, ordering, pagination (`offset` and `limit`), and session methods like `add()`, `commit()`, and `refresh()` to persist and retrieve data.  \n- Data structures involved are ORM model instances (`ChatConversation`, `ChatMessage`).  \n- The repository pattern is used to abstract database operations behind a class interface.\n\n3. **Business Logic**:  \nEnables the backend system to manage chat conversations and their messages, supporting features such as creating new conversations, retrieving specific conversations by ID, listing recent conversations with pagination, and adding messages to conversations. This supports chat or messaging functionality in an application.\n\n4. **Dependencies**:  \n- SQLAlchemy ORM (`Session` class for DB session management).  \n- Presumably, `ChatConversation` and `ChatMessage` ORM models defined elsewhere in the codebase.  \n- Python standard typing module for type hints (`Optional`, `List`).\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in this snippet.  \n- Database connection and session",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:33.271520",
      "status": "summarized"
    },
    "repo.py:chunk_6": {
      "chunk_id": "repo.py:chunk_6",
      "file_path": "db\\repo.py",
      "chunk_hash": "9e48d89510651c33238a2e85bde3895b64768f1a61fedea4d515420d3c1c8e23",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a repository layer managing chat conversations and messages in a database. It provides functionality to update conversation timestamps, retrieve messages for a conversation, and delete conversations.\n\n2. **Technical Details**:  \n- Uses an ORM (likely SQLAlchemy) for database interactions.  \n- Implements CRUD operations: updating a conversation's timestamp, querying messages filtered by conversation ID and ordered by creation time, and deleting a conversation entity.  \n- Uses session methods like `commit()` and `refresh()` to persist and synchronize state with the database.  \n- Data structures involved include ORM model instances (`ChatMessage`, `Conversation`) and lists of messages.\n\n3. **Business Logic**:  \n- Keeps conversation metadata current by updating the `updated_at` timestamp whenever a new message is handled.  \n- Retrieves all messages for a given conversation in chronological order to support chat history display.  \n- Allows deletion of entire conversations, supporting user or system-driven cleanup or privacy requirements.\n\n4. **Dependencies**:  \n- SQLAlchemy ORM for database session management and querying.  \n- Python standard library's `datetime` module for timestamping.  \n- Presumably, custom ORM models `ChatMessage` and `Conversation` defined elsewhere in the codebase.\n\n5. **Configuration**:  \n- Database connection and session configuration are external to this snippet, likely set up in the repository or application initialization code.  \n- No explicit environment variables or config files referenced here.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:29:42.400268",
      "status": "summarized"
    },
    "service.py:chunk_0": {
      "chunk_id": "service.py:chunk_0",
      "file_path": "features\\doc_publisher\\service.py",
      "chunk_hash": "74b92a5473158e74a9fe54200a188bffd2bba6ae4987d803b9a28c52f01df333",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis asynchronous Python function generates and publishes detailed issue analysis documentation to a Confluence space, enhancing the content using a language model before creating the Confluence page.\n\n2. **Technical Details**  \n- Constructs a Markdown-formatted documentation string summarizing issue analysis details such as root cause, affected components, and suggested fixes.  \n- Iterates over a list of suggested fixes to append structured sections including file paths, explanations, and code snippets.  \n- Uses an asynchronous call to an LLM client (`llm_client.generate_documentation`) to enhance or reformat the documentation content specifically for Confluence.  \n- Utilizes an asynchronous Confluence client (`ConfluenceClient.create_page`) to create a new page in the specified Confluence space, optionally under a parent page.  \n- Employs Python\u2019s `logging` module for informational logging.\n\n3. **Business Logic**  \nAutomates the creation and publication of technical documentation related to issue analyses, facilitating knowledge sharing and collaboration within engineering teams by integrating with Confluence, a widely used enterprise wiki platform.\n\n4. **Dependencies**  \n- `shared.models`: Provides data models `AnalysisResult` and `DocumentationPage`.  \n- `shared.clients.confluence_client.ConfluenceClient`: Client to interact with Confluence REST API asynchronously.  \n- `shared.llm.llm_client`: Client to interact with a language model service for content generation/enhancement.  \n- Python standard libraries: `typing.Optional` for type hints, `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:20.442942",
      "status": "summarized"
    },
    "service.py:chunk_2": {
      "chunk_id": "service.py:chunk_2",
      "file_path": "features\\doc_publisher\\service.py",
      "chunk_hash": "2d15a11382d9a9c17fafdc0eb64424dc0c34fb0778f74574d6784bc2de7bd1c7",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet logs the successful publication of documentation to a Confluence page and asynchronously adds specific labels (\"ai-analysis\", \"auto-generated\") to that page, then returns the page identifier.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to interact with the Confluence client, indicating non-blocking I/O operations.  \n- Logging is performed via a standard logger to record the publishing event.  \n- The method likely resides within an async function that handles documentation publishing workflows.\n\n3. **Business Logic**:  \n- Automates the tagging of newly published documentation pages with relevant labels to facilitate categorization, searchability, and tracking of AI-generated content within Confluence.  \n- Supports governance and content management policies by marking auto-generated documents distinctly.\n\n4. **Dependencies**:  \n- `confluence_client`: An asynchronous client interface to interact with the Confluence API for page management and labeling.  \n- `logger`: A logging utility, probably Python\u2019s standard `logging` module or a configured wrapper.\n\n5. **Configuration**:  \n- Likely depends on environment variables or configuration files for Confluence API credentials, endpoint URLs, and logging settings (not shown in snippet).  \n- Label names are hardcoded here but could be configurable in a broader context.\n\n6. **Error Handling**:  \n- No explicit error handling is shown in this snippet; exceptions from `confluence_client.add_labels` or logging would propagate to the caller",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:24.703256",
      "status": "summarized"
    },
    "service.py:chunk_4": {
      "chunk_id": "service.py:chunk_4",
      "file_path": "features\\data_injector\\service.py",
      "chunk_hash": "951568387dd48faf61a440bd012daffa734292a215877e11e0bbdbe9f484c3e2",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet asynchronously fetches data from a GitHub source using an injector service based on provided repository and issue number parameters, returning the data along with its source type.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to perform non-blocking data injection.  \n- Retrieves parameters from a `kwargs` dictionary with default fallbacks (`''` for repository, `0` for issue number).  \n- Implements a simple conditional to handle different source types, defaulting to an error log and empty data if the source type is unknown.  \n- Returns a dictionary containing the source type and the fetched data.\n\n3. **Business Logic**:  \nEnables integration with GitHub to dynamically inject or retrieve issue-related data, likely for use in features such as issue tracking, reporting, or automated workflows within a larger application.\n\n4. **Dependencies**:  \n- An `injector` object or module with an asynchronous method `inject_github_data`.  \n- A `logger` for error logging.  \n- Implicitly depends on an asynchronous runtime (e.g., `asyncio`).\n\n5. **Configuration**:  \n- Source type is expected to be provided externally (likely as a function argument or context).  \n- Repository and issue number are passed via `kwargs`.  \n- No explicit environment variables or config files are referenced in this snippet.\n\n6. **Error Handling**:  \n- Logs an error when an unknown `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:10.743011",
      "status": "summarized"
    },
    "service.py:chunk_6": {
      "chunk_id": "service.py:chunk_6",
      "file_path": "features\\context_resolver\\service.py",
      "chunk_hash": "0af17b6da6b3b77103d5de571a90a11acad4279e80bd311c529554d6e1ec72a5",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method `_fetch_related_issues` retrieves a list of related issues from external issue tracking sources (specifically GitHub and Jira) based on the context provided. It aims to find and return issues related to a given issue for enhanced issue tracking and resolution.\n\n2. **Technical Details**:  \n- The method accepts a `Context` object containing metadata about the current issue.  \n- It checks the source type (`SourceType.GITHUB` or `SourceType.JIRA`) to determine which external API to query.  \n- For GitHub, it constructs a search query using the repository full name and the first word of the issue title, then fetches up to 5 issues sorted in descending order.  \n- It filters out the current issue by comparing issue numbers and appends related issues with a fixed similarity score (0.7) into a list of dictionaries.  \n- Uses asynchronous programming (`async def`) to allow non-blocking IO operations.  \n- Exception handling is implemented to catch and log any failures during the GitHub API call.\n\n3. **Business Logic**:  \nThe method supports the business need to automatically identify and suggest related issues from external issue trackers, improving issue triage, reducing duplication, and enhancing developer productivity by linking contextually relevant issues.\n\n4. **Dependencies**:  \n- `github_client.client.search_issues`: An external GitHub API client used to search issues.  \n- `SourceType`:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:32.263801",
      "status": "summarized"
    },
    "service.py:chunk_8": {
      "chunk_id": "service.py:chunk_8",
      "file_path": "features\\context_resolver\\service.py",
      "chunk_hash": "8f0742b2435a53e268d5909fb89b6578ff76eeb503341471877c2a90097e7142",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a service that fetches related context information for a given issue, specifically retrieving related Jira issues and relevant code snippets from a GitHub repository based on the issue's title.\n\n2. **Technical Details**:  \n- Constructs a Jira Query Language (JQL) string to search for issues containing the first word of the issue title, excluding the current issue by key.  \n- Uses Jira client\u2019s `search_issues` method to retrieve up to 5 related issues.  \n- Iterates over the returned issues to build a list of dictionaries containing issue metadata (id, title, similarity score, source).  \n- Implements asynchronous method `_fetch_code_context` which queries GitHub\u2019s code search API using keywords extracted from the issue title (up to 3 keywords).  \n- Limits code search results to 3 items per keyword and filters by repository and Python language.  \n- Uses nested try-except blocks to handle potential failures in external API calls.\n\n3. **Business Logic**:  \nThe code supports a feature that enriches an issue\u2019s context by linking it to related Jira issues and relevant code snippets from a specified GitHub repository. This helps developers quickly understand related work and relevant code, improving issue resolution efficiency.\n\n4. **Dependencies**:  \n- `jira_client`: A Jira API client used to perform issue searches.  \n- `github_client`: A GitHub API client used to perform code searches.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:40.886326",
      "status": "summarized"
    },
    "service.py:chunk_10": {
      "chunk_id": "service.py:chunk_10",
      "file_path": "features\\context_resolver\\service.py",
      "chunk_hash": "04cce2892325e931c7f7b7f15940754630aa13dc06f0fe2ecedaeccc852a8d33",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet retrieves and processes code snippets from a GitHub repository based on a search keyword, extracting up to the first 50 lines of relevant Python files to provide contextual code examples. If no code snippets are found, it falls back to using a textual description as context.\n\n2. **Technical Details**:  \n- Uses the `github_client` to fetch file content from a repository.  \n- Splits file content into lines and extracts a snippet limited to the first 50 lines.  \n- Constructs a dictionary representing each snippet with metadata: file path, code snippet, line range, and language.  \n- Implements nested exception handling: an inner try-except around file content fetching and an outer try-except around the overall code context fetching loop.  \n- Uses a list (`code_snippets`) to accumulate multiple snippet dictionaries.  \n- Employs a `break` statement to stop searching after the first successful snippet per keyword.\n\n3. **Business Logic**:  \nThe code supports a feature that provides developers or users with relevant code context from a repository to assist in understanding or debugging. It enhances user experience by automatically fetching and presenting concise, relevant code excerpts or fallback textual descriptions when code is unavailable.\n\n4. **Dependencies**:  \n- `github_client`: a service or client module responsible for interacting with GitHub APIs to fetch file contents.  \n- `logger`: a logging utility for debug and warning messages.  \n- Implicitly depends",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:45.076937",
      "status": "summarized"
    },
    "service.py:chunk_12": {
      "chunk_id": "service.py:chunk_12",
      "file_path": "features\\context_resolver\\service.py",
      "chunk_hash": "a3af34a6a1544874f76d9d11ccded95a4d93f9cf85c701db6d2140172926b366",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code asynchronously fetches contextual logs and metrics related to an issue or event, extracting error-related log entries from a textual description and retrieving alert metrics from an external monitoring service.\n\n2. **Technical Details**:  \n- Uses asynchronous Python (`async def`) for non-blocking I/O operations.  \n- Implements simple keyword matching on a lowercased issue description to identify error-related logs.  \n- Constructs log entries as dictionaries with timestamp, level, message, source, and metadata fields.  \n- Initializes a metrics dictionary with default values and conditionally updates it based on data fetched from an external Grafana client.  \n- Uses try-except blocks to handle potential exceptions during external API calls.\n\n3. **Business Logic**:  \nThe code supports incident/context resolution by extracting relevant error logs from issue descriptions and by providing real-time alert metrics to help diagnose and prioritize issues based on system health indicators like error rates and active alerts.\n\n4. **Dependencies**:  \n- `Context` data structure (likely a domain model representing an issue or event).  \n- `self.grafana_client` which is an asynchronous client interfacing with Grafana\u2019s API to fetch alert data.  \n- Python\u2019s async/await syntax for asynchronous operations.\n\n5. **Configuration**:  \n- The presence of `self.grafana_client.api_key` suggests configuration via API keys, likely set through environment variables or configuration files to authenticate with Grafana.  \n- Time range for",
      "embedding_id": null,
      "created_at": "2025-10-22T18:30:51.935273",
      "status": "summarized"
    },
    "service.py:chunk_14": {
      "chunk_id": "service.py:chunk_14",
      "file_path": "features\\doc_generator\\service.py",
      "chunk_hash": "8f986bb77a9cb2c57204f3fb0973e690fb03fc5922f6a3e6ba43641a4a2f2cbe",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis Python code asynchronously generates documentation for a code repository based on a given prompt, optionally commits the generated documentation to GitHub, and returns a structured result encapsulating the success status, generated content, and metadata.\n\n2. **Technical Details**:  \n- The function `generate_documentation` is asynchronous (`async def`), enabling non-blocking I/O operations, likely for network calls such as GitHub commits or external API requests.  \n- It processes input parameters including a prompt, repository name, file limits, output format, and a flag to commit changes.  \n- The code uses structured result objects (`DocumentationResult`) to encapsulate outputs, including success flags, documentation content, analyzed files, repository info, commit results, and metadata.  \n- Logging is employed to record success or failure events, including commit URLs on success.  \n- Exception handling is implemented with a broad `except Exception` clause to catch and log any errors during the documentation generation or commit process.\n\n3. **Business Logic**:  \nThis code automates the generation and management of code documentation, addressing the business need for maintaining up-to-date, consistent documentation in software repositories. By optionally committing documentation directly to GitHub, it streamlines developer workflows and improves documentation accuracy and availability.\n\n4. **Dependencies**:  \n- Likely depends on GitHub API clients or SDKs to perform commits (`github_commit_result` suggests interaction with GitHub).  \n- Uses a logging framework (`logger",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:07.891441",
      "status": "summarized"
    },
    "service.py:chunk_16": {
      "chunk_id": "service.py:chunk_16",
      "file_path": "features\\doc_generator\\service.py",
      "chunk_hash": "3466b871dbd0da0ee376d54715b38457b6e87f318672f88e39008c2ab3d42431",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python function generates documentation based on a natural language prompt, optionally analyzing a specified number of files from a given repository, formatting the output, and optionally committing the generated documentation to a GitHub repository.\n\n2. **Technical Details**:  \n- Uses an asynchronous call (`await service.generate(request)`) to handle potentially long-running documentation generation.  \n- Encapsulates input parameters into a `DocumentationRequest` data structure, promoting clean separation of concerns and easier testing.  \n- Utilizes a service class `DocGeneratorService` that likely implements the core logic for parsing the prompt, analyzing source files, generating documentation, and handling GitHub commits.  \n- Supports multiple output formats (e.g., markdown, HTML) via a `format` parameter, indicating extensibility in output rendering.\n\n3. **Business Logic**:  \nAutomates the creation of technical documentation from natural language descriptions, reducing manual effort for developers and improving documentation quality and consistency. The optional GitHub commit feature streamlines integration into existing development workflows and documentation repositories.\n\n4. **Dependencies**:  \n- `DocGeneratorService` and `DocumentationRequest` classes/modules, presumably part of the same codebase or internal libraries.  \n- GitHub API or SDK (implied by the commit functionality).  \n- Python async features (`async/await`).  \n- Optional: Markdown or HTML rendering libraries depending on output format.\n\n5. **Configuration**:  \n- Parameters such as `repository",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:16.904738",
      "status": "summarized"
    },
    "service.py:chunk_18": {
      "chunk_id": "service.py:chunk_18",
      "file_path": "features\\doc_orchestrator\\service.py",
      "chunk_hash": "8a273edb08bddded554d247eb1452e520dbefc18a69982ab305131fd929e83bc",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a documentation orchestration workflow that manages the creation of a Jira ticket as one of its steps, logs the outcome, and returns a structured result indicating the success of the overall process.\n\n2. **Technical Details**:  \n- Uses a `thinking` object to track workflow steps with methods like `complete_step`, `fail_step`, `skip_step`, and `add_step`.  \n- Maintains a `workflow_summary` dictionary to record the status of the Jira ticket creation step.  \n- Logs key events using a `logger` for audit and debugging purposes.  \n- Returns a `DocOrchestrationResult` data structure encapsulating the final outcome, including documentation details, files analyzed, repository info, GitHub commit, and Confluence page references.  \n- Uses conditional branching to handle whether Jira ticket creation was requested, succeeded, or failed.\n\n3. **Business Logic**:  \nThe code automates part of a documentation workflow by optionally creating a Jira ticket to track documentation tasks. It ensures that the ticket creation step is properly recorded and reported, supporting traceability and process transparency in documentation management.\n\n4. **Dependencies**:  \n- A `thinking` workflow orchestration or state-tracking object (likely custom or from an internal framework).  \n- A `logger` for logging events (probably Python\u2019s standard logging module or a wrapper).  \n- `datetime` module for timestamping workflow completion.  \n- `DocOr",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:24.112150",
      "status": "summarized"
    },
    "service.py:chunk_20": {
      "chunk_id": "service.py:chunk_20",
      "file_path": "features\\doc_orchestrator\\service.py",
      "chunk_hash": "7b3c2f1efbc8f20c9e8eb250159d93d8877c72979c8cfc51ebb399250b4c463f",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis Python code defines an asynchronous function `orchestrate_documentation` that manages an end-to-end workflow for generating, committing, and optionally publishing documentation based on a natural language prompt. It integrates with source code repositories, Confluence, and Jira to automate documentation tasks.\n\n2. **Technical Details**:  \n- The function uses asynchronous programming (`async def`) to handle potentially long-running I/O operations efficiently.  \n- It accepts multiple parameters controlling the workflow, such as repository details, commit options, and integration flags for Confluence and Jira.  \n- The function returns a `DocOrchestrationResult` object encapsulating the success status, error messages, workflow metadata, and a serialized `thinking` object that likely tracks internal state or timing.  \n- Exception handling is implemented with a broad `try-except` block that logs errors and updates the workflow summary and timing information before returning a failure result.\n\n3. **Business Logic**:  \nThe code automates the documentation process for software projects by:  \n- Generating documentation from a natural language prompt.  \n- Committing generated docs to a GitHub repository.  \n- Optionally publishing the documentation to Confluence spaces.  \n- Optionally creating Jira tickets to track documentation tasks.  \nThis streamlines documentation efforts, reduces manual overhead, and integrates documentation updates into existing development and project management workflows.\n\n4. **Dependencies**:  \n- Likely depends on asynchronous Python libraries (e.g., `async",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:34.676298",
      "status": "summarized"
    },
    "service.py:chunk_22": {
      "chunk_id": "service.py:chunk_22",
      "file_path": "features\\doc_orchestrator\\service.py",
      "chunk_hash": "f0cbcb4e89ffaae0657bb9edfd2d7d742e051e2a5dacfd8e3bdbaa1319a9e5dc",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python function orchestrates a documentation workflow by analyzing code files, optionally committing generated documentation to GitHub, publishing it to Confluence, and creating Jira tickets as needed. It returns a comprehensive result of the entire documentation orchestration process.\n\n2. **Technical Details**:  \n- Uses an instance of `DocOrchestrator` to manage the workflow.  \n- Constructs a `DocOrchestrationRequest` data object encapsulating all input parameters and configuration settings.  \n- Supports asynchronous execution (`await orchestrator.orchestrate(request)`) to handle potentially long-running I/O operations such as network calls to GitHub, Confluence, and Jira APIs.  \n- Employs defaulting logic for Confluence and Jira parameters by falling back to global `settings` if explicit values are not provided.\n\n3. **Business Logic**:  \nAutomates the generation and distribution of project documentation to multiple platforms (GitHub repos, Confluence spaces) and integrates with issue tracking (Jira), streamlining the documentation lifecycle and ensuring up-to-date, accessible project information for stakeholders.\n\n4. **Dependencies**:  \n- `DocOrchestrator` and `DocOrchestrationRequest` classes (likely internal modules or services).  \n- External services/APIs: GitHub (for commits), Confluence (for publishing pages), Jira (for ticket creation).  \n- `settings` module or object providing default configuration values.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:43.096036",
      "status": "summarized"
    },
    "model.py:chunk_0": {
      "chunk_id": "model.py:chunk_0",
      "file_path": "features\\context_resolver\\model.py",
      "chunk_hash": "9002543e45c21a052679553d544261b876660b89302bb6e8d10cf5e071c5e1e8",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a set of data models representing the structure of context-related information for issue tracking and enrichment within a software development or incident management system.\n\n2. **Technical Details**:  \n- Utilizes Python type annotations and `BaseModel` inheritance (likely from Pydantic or a similar library) for data validation and serialization.  \n- Defines multiple data classes (`ContextRequest`, `RelatedIssue`, `CodeContext`, `LogEntry`, `EnrichedContextModel`) to encapsulate various aspects of issue context such as related issues, code snippets, logs, and metadata.  \n- Uses default mutable arguments (`{}` and `[]`) which is a known anti-pattern and could lead to shared state bugs.  \n- Includes datetime handling with default enrichment timestamp set to current UTC time at model instantiation.\n\n3. **Business Logic**:  \n- Supports the enrichment and resolution of issues by aggregating contextual data from multiple sources (code, logs, related issues).  \n- Enables filtering and querying of issue context to improve debugging, triage, and root cause analysis processes in software maintenance or incident response workflows.\n\n4. **Dependencies**:  \n- `typing` module for type hints.  \n- `datetime` for timestamp management.  \n- `shared.models` module providing `BaseModel`, `SourceType`, and `SeverityLevel` which likely define base validation, issue source enumeration, and severity classification.\n\n5. **Configuration**:  \n- No explicit environment",
      "embedding_id": null,
      "created_at": "2025-10-22T18:31:49.719210",
      "status": "summarized"
    },
    "api.ts:chunk_0": {
      "chunk_id": "api.ts:chunk_0",
      "file_path": "frontend\\src\\services\\api.ts",
      "chunk_hash": "686dba5003aa5f54f6d0a142aadc64d4f17b326b4b1b133e28035eca61626bfa",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis TypeScript code defines an `ApiClient` class that acts as a wrapper around HTTP requests to a backend API, providing typed methods to interact with various service endpoints such as health checks, service info retrieval, and testing large language models (LLMs).\n\n2. **Technical Details**:  \n- Uses the Axios HTTP client (`AxiosInstance`) to manage API requests.  \n- Implements a class-based design pattern encapsulating API calls as asynchronous methods returning typed promises.  \n- Utilizes TypeScript generics and interfaces/types imported from a shared `../types/api` module to enforce strong typing on request payloads and responses.  \n- Dynamically sets the base URL depending on the environment (development vs production).  \n- Supports optional parameters and default values in methods (e.g., `testLLM` method).  \n- Uses RESTful HTTP verbs (`GET`, `POST`) to interact with backend endpoints.\n\n3. **Business Logic**:  \nThe `ApiClient` facilitates communication between the frontend and backend services for a product that likely involves AI/ML capabilities (e.g., LLM testing), service monitoring (health checks), and integration with various platforms (GitHub, Jira, Confluence, Grafana). It abstracts API details from UI components, enabling seamless data fetching and interaction with backend features critical for product functionality.\n\n4. **Dependencies**:  \n- `axios`: For HTTP request handling.  \n- `../types/api`: Provides TypeScript type",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:16.893756",
      "status": "summarized"
    },
    "api.ts:chunk_2": {
      "chunk_id": "api.ts:chunk_2",
      "file_path": "frontend\\src\\services\\api.ts",
      "chunk_hash": "8a3400432ac80125e94d009518b8f8435f9e99cf4a8c71fefa40fc11385d5031",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis TypeScript code defines a service class with asynchronous methods to interact with backend API endpoints for testing integrations with third-party tools (GitHub, Jira, Confluence, Grafana), performing data analysis, and orchestrating documentation workflows.\n\n2. **Technical Details**:  \n- Uses `async/await` syntax for asynchronous HTTP POST requests.  \n- Employs generic typing with Axios-like HTTP client (`this.client.post<T>`) to strongly type API responses.  \n- Encodes URL parameters (e.g., `repository` in `testGitHub`) to ensure safe HTTP requests.  \n- Methods return the `data` property from HTTP responses, abstracting away raw HTTP details.  \n- The code snippet suggests a class-based design pattern encapsulating API interaction logic.\n\n3. **Business Logic**:  \n- Facilitates integration testing with external services (GitHub, Jira, Confluence, Grafana) to verify connectivity or configuration correctness.  \n- Supports analytical processing by sending requests to an analysis endpoint, likely for data insights or processing.  \n- Enables orchestration of documentation generation or management workflows, streamlining content creation or update processes.\n\n4. **Dependencies**:  \n- Presumably depends on an HTTP client library such as Axios (`this.client.post` usage).  \n- Relies on backend REST API endpoints (`/api/test/github`, `/api/analyze`, etc.) to perform operations.  \n- Uses TypeScript interfaces/types (`GitHubTestResponse",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:23.369848",
      "status": "summarized"
    },
    "api.ts:chunk_4": {
      "chunk_id": "api.ts:chunk_4",
      "file_path": "frontend\\src\\services\\api.ts",
      "chunk_hash": "a923510e2d7fbf5c591613c80a33c3ca03f17acacc13a2b8eb4e1ea72db41933",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis TypeScript code defines an API client service for interacting with backend endpoints related to commit management, including parsing commit intents, approving or rejecting commits, and retrieving pending commit approvals.\n\n2. **Technical Details**:  \n- The class (presumably `ApiClient`, though the class declaration is not shown) uses asynchronous methods with `async/await` to handle HTTP POST and GET requests via `this.client`, which is likely an HTTP client instance (e.g., Axios).  \n- Data is sent and received as JSON objects.  \n- Methods accept parameters relevant to commit operations and return the response data directly.  \n- The `files` parameter in `parseCommitIntent` is a dictionary (`Record<string, string>`) mapping filenames to their contents.\n\n3. **Business Logic**:  \n- Supports a workflow for commit intent analysis, enabling automated or assisted parsing of commit messages and associated files to understand developer intent.  \n- Facilitates a commit approval process where commits can be approved or rejected with optional updated templates or rejection reasons, supporting code review or compliance workflows.  \n- Provides retrieval of pending approvals to enable UI or other services to display or process commits awaiting approval.\n\n4. **Dependencies**:  \n- An HTTP client instance (`this.client`) is used to make API calls; likely Axios or a similar library.  \n- Backend API endpoints under `/api/commit/*` are required to be available and conform to the expected request/response contracts.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:29.502233",
      "status": "summarized"
    },
    "config.py:chunk_0": {
      "chunk_id": "config.py:chunk_0",
      "file_path": "shared\\config.py",
      "chunk_hash": "5da0c78b8f885ac37e21187d844ac9f3aa55b8e1551599571cf7b6d77368eecc",
      "chunk_index": 0,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis Python module defines a configuration class `Settings` using Pydantic's `BaseSettings` to manage and validate environment-based configuration settings for integrating with Azure and Together AI services, primarily for large language model (LLM) providers.\n\n2. **Technical Details**  \n- Utilizes Pydantic's `BaseSettings` for declarative settings management with environment variable support.  \n- Uses `SettingsConfigDict` to specify environment file loading (`.env`), encoding, case insensitivity, and ignoring extra fields.  \n- Defines optional typed attributes for various credentials and configuration parameters related to Azure and Together AI LLM providers.  \n- Supports default values and optional fields to allow flexible configuration.  \n- No explicit methods; relies on Pydantic's built-in validation and parsing.\n\n3. **Business Logic**  \nEnables seamless configuration and switching between multiple LLM providers (Azure OpenAI and Together AI) by centralizing credentials and deployment settings. This supports business needs for AI-driven applications that require flexible backend LLM integrations, including fallback mechanisms and auto-detection of providers.\n\n4. **Dependencies**  \n- `pydantic_settings` (Pydantic v2+ settings management) for environment-based configuration parsing and validation.  \n- Python standard `typing` module for type annotations (`Optional`, `List`).\n\n5. **Configuration**  \n- Reads from a `.env` file with UTF-8 encoding.  \n- Environment variables",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:36.959201",
      "status": "summarized"
    },
    "config.py:chunk_2": {
      "chunk_id": "config.py:chunk_2",
      "file_path": "shared\\config.py",
      "chunk_hash": "451bae04b293b07d2e213219904387021df3c10ce169b9a96e32efdad0736dde",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines configuration parameters for integrating with Azure OpenAI services, specifically for managing API versions, deployment names, batching behavior, and provider selection for chat and embedding functionalities.\n\n2. **Technical Details**:  \n- Uses Python type hints with `Optional` to indicate nullable configuration values.  \n- Configuration variables are declared as module-level constants, likely to be imported and used elsewhere.  \n- Parameters include string identifiers for Azure deployment names and API versions, as well as numeric values for batching control (batch size and delay).  \n- Provider selection is controlled via string flags to route requests to different backend providers (\"azure\", \"together\", or \"auto\").\n\n3. **Business Logic**:  \nEnables flexible and centralized configuration of Azure OpenAI model deployments and API versions to support AI-powered features such as chat completions and embeddings. This supports business needs for scalable, multi-provider AI services with fine-grained control over which models and APIs are used for different tasks.\n\n4. **Dependencies**:  \n- Implicit dependency on Azure OpenAI services (Azure AI Foundry deployments).  \n- Uses Python's `Optional` type hint from the `typing` module (not shown but implied).  \n- No direct external libraries or modules are imported in this snippet.\n\n5. **Configuration**:  \n- Parameters are likely set via environment variables or configuration files external to this snippet.  \n- Key settings include API versions, deployment names for various Azure models, batch size",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:43.764998",
      "status": "summarized"
    },
    "config.py:chunk_4": {
      "chunk_id": "config.py:chunk_4",
      "file_path": "shared\\config.py",
      "chunk_hash": "6aa88503759d4802710e07d8c014ce5b186c8648026acad718212102151105ba",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a configuration schema using optional typed variables for various integration and feature toggles, centralizing application settings related to third-party services, language support, and database connectivity.\n\n2. **Technical Details**:  \n- Uses Python type hints with `Optional` to indicate that configuration values may be `None` if unset.  \n- Configuration parameters are grouped by service or feature (e.g., GitHub, Jira, Confluence, Grafana, Vector DB).  \n- Values are expected to be loaded from environment variables or external config files (implied by comments).  \n- No explicit functions or classes are defined; this is a declarative config module.\n\n3. **Business Logic**:  \n- Enables integration with multiple external platforms (GitHub, Jira, Confluence, Grafana) to support collaborative workflows, issue tracking, documentation, and monitoring.  \n- Supports multilingual capabilities and language detection to enhance user experience across different locales.  \n- Provides vector database configuration for advanced data retrieval or AI-related features, with fallback mechanisms to ensure robustness.  \n- Centralizes sensitive credentials and connection details to facilitate secure and maintainable deployment.\n\n4. **Dependencies**:  \n- Implicitly depends on environment management tools or libraries (e.g., `python-dotenv`) to populate these variables from `.env` files or environment variables.  \n- Integrations imply dependencies on external APIs for GitHub, Jira, Confluence, Grafana, and Q",
      "embedding_id": null,
      "created_at": "2025-10-22T18:32:53.248914",
      "status": "summarized"
    },
    "config.py:chunk_6": {
      "chunk_id": "config.py:chunk_6",
      "file_path": "shared\\config.py",
      "chunk_hash": "5c49bf63003f1ddeba239a9be1a7a221dc06a5b05599592898d4b885f2ca8192",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a configuration schema for an application that integrates voice assistant capabilities and speech services from multiple providers such as OpenAI and Azure. It centralizes various optional configuration parameters related to app hosting, logging, voice processing, and cloud service credentials.\n\n2. **Technical Details**:  \n- Uses Python type hinting with `Optional` to indicate that configuration fields may be `None` if not set.  \n- The code is structured as a set of configuration variables, likely intended to be part of a class or module-level constants (though the snippet does not show the enclosing class or structure).  \n- No algorithms or complex data structures are present; it is a straightforward declaration of configuration parameters.  \n- The parameters are grouped logically by service or feature (e.g., voice assistant settings, OpenAI, Azure Speech, Azure Translation).\n\n3. **Business Logic**:  \n- Supports a voice assistant application that requires speech-to-text (STT), text-to-speech (TTS), and translation capabilities.  \n- Enables switching between different cloud providers (OpenAI, Azure, Google) for voice services, allowing flexibility and potentially cost optimization or feature selection.  \n- Facilitates deployment configuration such as app host, port, and logging level to adapt to different environments (development, staging, production).\n\n4. **Dependencies**:  \n- Implicit dependencies on external cloud services: OpenAI API, Azure Speech Services, and Azure Translation Services.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:02.185817",
      "status": "summarized"
    },
    "config.py:chunk_8": {
      "chunk_id": "config.py:chunk_8",
      "file_path": "shared\\config.py",
      "chunk_hash": "e1194299b45a5374b7a190536fa109543d2f5fe4e47924291c70c9cf61f31367",
      "chunk_index": 8,
      "summary": "**Summary of `shared\\config.py`**\n\n1. **Purpose**  \nThis code defines configuration properties and helper methods for managing application settings related to Azure AI translation services and environment-specific behavior.\n\n2. **Technical Details**  \n- Uses Python properties (`@property`) to provide computed configuration values dynamically, such as `port`, `is_production`, and `supported_languages_list`.  \n- Parses environment variables (e.g., `PORT`) with fallback defaults.  \n- Handles optional configuration values using `Optional` type hints (likely from `typing`).  \n- Converts comma-separated strings into lists for supported languages.  \n- Contains placeholders for Azure Translator and Azure AI Services keys and endpoints.  \n- Includes a partially shown method `get_with_default` intended to retrieve configuration fields with default values.\n\n3. **Business Logic**  \nSupports configuration management for an application that integrates with Azure AI translation services, enabling features like automatic translation and multi-language support. It also distinguishes between production and development environments to adapt behavior accordingly.\n\n4. **Dependencies**  \n- Standard Python library: `os` for environment variable access.  \n- Likely uses `typing.Optional` and `List` (not explicitly imported in snippet).  \n- Azure AI services implied by configuration keys but no direct SDK usage shown here.\n\n5. **Configuration**  \n- Environment variables: `PORT` for server port.  \n- Configuration fields for Azure Translator and Azure AI Services keys, endpoints, and region.  \n- Translation settings such as",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:16.326086",
      "status": "summarized"
    },
    "config.py:chunk_10": {
      "chunk_id": "config.py:chunk_10",
      "file_path": "shared\\config.py",
      "chunk_hash": "56ce12d01f4d071d94f41eb1a4879aaf19f6bc970ecab9181e0023f0b3ca32ed",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet defines a method to retrieve the value of a specified attribute from an object, returning a default value if the attribute is not set or is `None`. It also instantiates a `Settings` object, presumably to manage application configuration.\n\n2. **Technical Details**:  \n- Uses Python's built-in `getattr` function to dynamically access an attribute by name.  \n- Implements a simple fallback mechanism returning `default_value` if the attribute is missing or `None`.  \n- The `Settings` class (not shown) is instantiated as a singleton-like global object named `settings`.\n\n3. **Business Logic**:  \nProvides a flexible way to access configuration or settings fields with safe defaults, ensuring the application can operate with fallback values when explicit configuration is absent.\n\n4. **Dependencies**:  \nNo external libraries or modules are explicitly imported or used in this snippet. The `Settings` class must be defined elsewhere in the codebase.\n\n5. **Configuration**:  \nRelies on the `Settings` class for configuration management, which may internally load environment variables, config files, or other sources (not visible here).\n\n6. **Error Handling**:  \nNo explicit error handling is implemented; the use of `getattr` with a default value prevents `AttributeError` exceptions when the field is missing.\n\n7. **API/Interface**:  \n- The method (unnamed in the snippet) provides a public interface to get a",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:20.072568",
      "status": "summarized"
    },
    "cli.py:chunk_0": {
      "chunk_id": "cli.py:chunk_0",
      "file_path": "code-intelligence\\cli.py",
      "chunk_hash": "5433c5a489d28d2d8eda501267ddf380099670a7cf5bdcb54323c3bd07b0d97c",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis script serves as a command-line interface (CLI) wrapper to invoke the main functionality of the `code_intelligence.orchestrator` module, ensuring it is executed from the repository root rather than from within the `code-intelligence` directory.\n\n2. **Technical Details**  \n- Uses Python's `pathlib.Path` to determine the current working directory and script location.  \n- Implements a directory check to prevent running the CLI from an incorrect location.  \n- Modifies `sys.path` at runtime to include the parent directory, enabling relative imports of the `code_intelligence` package.  \n- Delegates execution to the `main()` function imported from `code_intelligence.orchestrator`.  \n- Uses a standard Python CLI entry point idiom (`if __name__ == \"__main__\":`).\n\n3. **Business Logic**  \nEnsures that the code intelligence embedding or orchestration commands are run in the correct context (repository root), preventing misconfiguration or path-related errors that could disrupt code analysis or embedding workflows.\n\n4. **Dependencies**  \n- Standard Python libraries: `sys`, `os`, `pathlib`  \n- Internal module: `code_intelligence.orchestrator` (specifically its `main` function)\n\n5. **Configuration**  \nNo explicit environment variables or config files are referenced in this script. Configuration is implicit in the directory structure and command-line usage context.\n\n6. **Error Handling**  \n- Detects and handles",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:28.670404",
      "status": "summarized"
    },
    "models.py:chunk_0": {
      "chunk_id": "models.py:chunk_0",
      "file_path": "orchestration\\context_manager\\models.py",
      "chunk_hash": "6fb500f5356ded3fc176f9d4327a9224c54c698eafd93702f3f1668a7c83e99f",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines data models for managing and structuring conversational context related to software repositories, files, code entities, and discussion topics. It provides a typed schema to capture and track various contextual elements during conversations.\n\n2. **Technical Details**:  \n- Uses Python `Enum` to define a fixed set of context types (`ContextType`).  \n- Utilizes `pydantic.BaseModel` for data validation, serialization, and type enforcement in the `ConversationContext` class.  \n- Employs optional fields and default factories for lists to ensure safe defaults and avoid mutable default arguments.  \n- The data model captures multiple context dimensions such as repositories, files, code entities, topics, and features as lists of strings.\n\n3. **Business Logic**:  \nEnables an orchestration or conversational system to maintain structured context about software development discussions. This supports features like context-aware assistance, tracking of relevant repositories or code components, and improved understanding of user intents in developer workflows.\n\n4. **Dependencies**:  \n- `enum` (standard library) for enumerations.  \n- `typing` (standard library) for type hints.  \n- `pydantic` for data modeling, validation, and serialization.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced or required by this code snippet.\n\n6. **Error Handling**:  \nRelies on `pydantic`'s built-in validation to handle type errors and data inconsist",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:53.291219",
      "status": "summarized"
    },
    "models.py:chunk_2": {
      "chunk_id": "models.py:chunk_2",
      "file_path": "orchestration\\context_manager\\models.py",
      "chunk_hash": "ff031e129fa4dc10b34739d6c7b1c251560997371d9f8654d2043cb258fcb35c",
      "chunk_index": 2,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis Python code defines part of a data model for managing conversational context within an orchestration system, focusing on tracking repository, file, and code entity contexts alongside conversation metadata.\n\n2. **Technical Details**  \n- Utilizes Python `dataclasses` or Pydantic `BaseModel` (implied by `Field` usage) for structured data modeling.  \n- Contains typed attributes such as lists (`tasks`, `files_mentioned`, `code_entities`, `topics`) and optional strings (`last_query_type`).  \n- Implements boolean helper methods (`has_repository_context`, `has_file_context`, `has_code_context`) to check presence of specific context elements.  \n- Provides a method `get_context_summary` that constructs a concise, human-readable string summarizing the current conversational context by aggregating repository, files, and topics information.  \n- Uses default factories for mutable defaults (e.g., `tasks: List[str] = Field(default_factory=list)`), preventing common Python mutable default argument pitfalls.\n\n3. **Business Logic**  \nThe model supports tracking and summarizing the state of a conversation related to software repositories, files, and code entities, enabling an orchestration system to maintain context awareness during multi-turn interactions. This is critical for systems that automate or assist in code review, issue tracking, or developer collaboration workflows.\n\n4. **Dependencies**  \n- Likely depends on Pydantic (`BaseModel`, `Field`) for data validation and serialization",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:59.929620",
      "status": "summarized"
    },
    "models.py:chunk_4": {
      "chunk_id": "models.py:chunk_4",
      "file_path": "db\\models.py",
      "chunk_hash": "4f774aebcd64da8ad01c989964cce3b8afa8b2578018ff6f4cee66f2be0de042",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet defines part of a SQLAlchemy ORM model representing a message entity in a chat application, including its content, duration, creation timestamp, and its relationship to a conversation.\n\n2. **Technical Details**:  \n- Uses SQLAlchemy's `Column` to define database table columns with types `Text`, `Float`, and `DateTime`.  \n- The `created_at` column uses a default factory `datetime.utcnow` to timestamp message creation.  \n- Defines a bidirectional ORM relationship with the `ChatConversation` model via `relationship()` and `back_populates`, enabling easy navigation between messages and their parent conversation.\n\n3. **Business Logic**:  \nSupports storing and retrieving chat messages with metadata such as message content, optional duration (possibly for audio/video messages), and creation time, facilitating conversation threading and message history in a chat or messaging system.\n\n4. **Dependencies**:  \n- SQLAlchemy ORM for database modeling and relationships.  \n- Python's `datetime` module for timestamping.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet; database connection and ORM setup would be configured elsewhere in the application.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this code fragment; database-level constraints (e.g., nullable fields) implicitly enforce data integrity.\n\n7. **API/Interface**:  \nThis is a data model class fragment; it does not expose public methods or",
      "embedding_id": null,
      "created_at": "2025-10-22T18:33:47.046537",
      "status": "summarized"
    },
    "llm.py:chunk_0": {
      "chunk_id": "llm.py:chunk_0",
      "file_path": "shared\\llm.py",
      "chunk_hash": "5fb851509ad76bc673e1d68239e922e14487bb8a9c37625a6ddcea0902782113",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a unified Large Language Model (LLM) client class that abstracts interaction with multiple LLM providers, enabling seamless switching and fallback between providers like Together AI and Azure OpenAI.\n\n2. **Technical Details**  \n- Implements a factory pattern via the `get_llm_client` function to instantiate the appropriate LLM provider client based on configuration or auto-detection.  \n- Uses dependency injection for provider-specific parameters (e.g., Azure endpoint, API keys).  \n- Encapsulates provider logic behind a common interface (`BaseLLMProvider`), promoting polymorphism and extensibility.  \n- Logging is used to trace initialization steps and provider selection.\n\n3. **Business Logic**  \nEnables the application to flexibly integrate with different LLM service providers, ensuring high availability and provider choice based on configuration or environment. This supports business needs for robust AI-powered features without being locked into a single vendor.\n\n4. **Dependencies**  \n- Python standard libraries: `typing` for type hints, `logging` for diagnostics.  \n- Internal modules:  \n  - `.config` for application settings (e.g., provider choice, API keys).  \n  - `.llm_providers` which contains the factory method `get_llm_client` and base provider interface `BaseLLMProvider`.\n\n5. **Configuration**  \n- `settings.llm_provider`: Preferred LLM provider or \"auto\" for automatic detection.  \n- Azure-specific settings:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:05.950337",
      "status": "summarized"
    },
    "llm.py:chunk_2": {
      "chunk_id": "llm.py:chunk_2",
      "file_path": "shared\\llm.py",
      "chunk_hash": "01fa46acd694cf0088f4310f03a2b461c70152b518499004d2d97376718288c2",
      "chunk_index": 2,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages failures during the initialization of a Large Language Model (LLM) client, specifically addressing configuration issues and unexpected exceptions that may arise when setting up the LLM provider.\n\n2. **Exception Types**:  \n   - `ValueError`: Captures configuration-related errors, such as missing or invalid provider settings.  \n   - `Exception`: Catches all other unforeseen errors during initialization.\n\n3. **Recovery Strategy**:  \n   Upon encountering an error, the code sets the `self.provider` attribute to `None` to indicate that the LLM client is not available. It then re-raises the exception to propagate the error up the call stack, allowing higher-level components to handle or log it further. There is no automatic retry mechanism implemented here.\n\n4. **Logging**:  \n   - Successful initialization logs an info-level message confirming the LLM client is ready and specifies the active provider.  \n   - Configuration errors and other exceptions are logged at the error level with clear, descriptive messages prefixed by \"\u274c\" to highlight failure states.  \n   - Additional logging occurs if the `chat_completion` method is called without an initialized provider, warning that the operation cannot proceed.\n\n5. **User Impact**:  \n   If initialization fails, the LLM provider is unavailable (`self.provider` is `None`), causing subsequent calls to `chat_completion` to fail gracefully by returning `None` and logging",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:11.838407",
      "status": "summarized"
    },
    "llm.py:chunk_4": {
      "chunk_id": "llm.py:chunk_4",
      "file_path": "shared\\llm.py",
      "chunk_hash": "1e1d410f4162c81cdf76cabba512e370449fd4d2e7794936d3d1a8455dc44e85",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods within a class to interact with a configured Large Language Model (LLM) provider for various code-related tasks such as code analysis, test generation, and documentation generation.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running I/O operations with the LLM provider.  \n- Methods act as wrappers that delegate calls to the underlying `self.provider` object, which implements the actual LLM interaction logic.  \n- Input parameters include code snippets, context, task descriptions, programming language, and documentation type, enabling flexible usage.  \n- Returns are typically optional, indicating that the method may return `None` if the provider is not initialized.\n\n3. **Business Logic**:  \n- Automates software development lifecycle tasks by leveraging AI-powered LLMs to analyze code, generate tests, and produce documentation.  \n- Helps improve developer productivity and code quality by integrating AI-driven insights and automation into development workflows.\n\n4. **Dependencies**:  \n- Relies on an external LLM provider abstraction (`self.provider`) which is expected to implement methods like `chat_completion`, `analyze_code`, `generate_tests`, and `generate_documentation`.  \n- Uses a `logger` for error logging, implying a logging framework is configured elsewhere in the application.\n\n5. **Configuration**:  \n- The LLM provider instance (`self.provider`) must be initialized and configured prior to calling these methods",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:17.033424",
      "status": "summarized"
    },
    "llm.py:chunk_6": {
      "chunk_id": "llm.py:chunk_6",
      "file_path": "shared\\llm.py",
      "chunk_hash": "d7706c53c1fed179fc6a900c383b3c1d6c029c316ef38a5d08027e52837604bf",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet is part of an asynchronous method that generates documentation using a language model (LLM) provider. It checks if the LLM provider is initialized and, if so, delegates the documentation generation task to it.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to call the `generate_documentation` method on the LLM provider, enabling non-blocking I/O operations.  \n- Implements a guard clause to verify the presence of the `provider` before proceeding.  \n- The `LLMClient` instance (`llm_client`) is created at the module level, likely serving as a singleton or shared client for LLM interactions.\n\n3. **Business Logic**:  \nFacilitates automated generation of documentation content, which can improve developer productivity, maintain consistency in documentation, and reduce manual effort in creating technical or user-facing documents.\n\n4. **Dependencies**:  \n- An external or internal `provider` object that implements `generate_documentation`.  \n- A `logger` for error logging (likely from Python\u2019s standard `logging` module or a custom logger).  \n- The asynchronous environment (e.g., `asyncio`) to support `await`.\n\n5. **Configuration**:  \n- The `provider` must be initialized/configured elsewhere in the application before this method is called.  \n- No explicit environment variables or config files are shown here, but the provider initialization likely depends on configuration settings such as API keys",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:20.986424",
      "status": "summarized"
    },
    "main.tsx:chunk_0": {
      "chunk_id": "main.tsx:chunk_0",
      "file_path": "frontend\\src\\main.tsx",
      "chunk_hash": "abe0edc1f91f5d414bbfb8f335f8871b4bf4edf07a861ab225e368a8319cdb6b",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code initializes and renders the root React application component (`App`) into the DOM element with the ID `root`. It sets up the React application entry point for the frontend.\n\n2. **Technical Details**:  \n- Uses React 18's `ReactDOM.createRoot` API to create a root for concurrent rendering.  \n- Wraps the `App` component inside `React.StrictMode` to enable additional checks and warnings during development.  \n- Imports global CSS styles from `index.css`.  \n- No complex algorithms or data structures are involved; this is a bootstrap file for the React app.\n\n3. **Business Logic**:  \nThis file itself does not contain business logic but serves as the foundational entry point to load the entire frontend application, which presumably implements the business logic in the `App` component and its children.\n\n4. **Dependencies**:  \n- `react` and `react-dom` libraries for building and rendering the UI.  \n- Local modules: `./App.tsx` (main application component) and `./index.css` (global styles).\n\n5. **Configuration**:  \n- No environment variables or external configuration are referenced or used in this file.  \n- The DOM element with ID `root` must exist in the hosting HTML file for the app to mount correctly.\n\n6. **Error Handling**:  \n- No explicit error handling is implemented in this snippet.  \n- The non-null assertion operator (`!`) assumes the",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:29.236618",
      "status": "summarized"
    },
    "core.py:chunk_0": {
      "chunk_id": "core.py:chunk_0",
      "file_path": "interfaces\\api\\core.py",
      "chunk_hash": "2c025d0604f23636efdef8f8a4a1e753ff1d272e300666887d3cb9d39d684bad",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines the core configuration and shared dependencies for a FastAPI-based web API, including database session management, middleware setup, and application instantiation.\n\n2. **Technical Details**  \n- Uses SQLAlchemy ORM for database connectivity and session management with a session factory pattern (`SessionLocal`).  \n- Implements a dependency generator function `get_db()` to provide database sessions to API endpoints, ensuring proper session lifecycle management (open/close).  \n- Creates a FastAPI application instance with metadata (title, description, version).  \n- Configures CORS middleware to allow cross-origin requests from any origin, supporting credentials and all HTTP methods.  \n- Uses Python standard libraries (`uuid`, `time`, `datetime`, `pathlib`) likely for internal utilities or future extensions.  \n- Logging is integrated via a shared logger module with context management functions for request tracing.\n\n3. **Business Logic**  \nSupports an AI-powered development agent API aimed at automating bug fixing and code analysis by providing a stable, scalable backend foundation with database access and cross-origin support for frontend or external integrations.\n\n4. **Dependencies**  \n- FastAPI for API framework and middleware.  \n- SQLAlchemy for ORM and database connection pooling.  \n- `shared.logger` for structured logging with request context.  \n- `shared.config` for centralized configuration management (e.g., database URL).  \n- Standard Python libraries for utility functions.\n\n5. **Configuration**  \n- Database connection URL is injected via `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:36.270808",
      "status": "summarized"
    },
    "core.py:chunk_2": {
      "chunk_id": "core.py:chunk_2",
      "file_path": "interfaces\\api\\core.py",
      "chunk_hash": "1091baae967a94f1fb1024c732126e88bf29bd9998d20e0db9fc147ce65f037e",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines an HTTP middleware for a web application that logs incoming HTTP requests and their processing duration, capturing both successful responses and exceptions.\n\n2. **Technical Details**:  \n- Implements an asynchronous middleware function (`log_requests`) using the decorator pattern to intercept all HTTP requests.  \n- Uses timing (`time.time()`) to measure request processing duration in milliseconds.  \n- Extracts request metadata such as HTTP method, URL path, and client host for contextual logging.  \n- Logs request start, successful completion with status code and duration, and errors with exception details.  \n- Utilizes a custom logger with methods like `info()`, `log_api_request()`, and `error()` for structured logging.\n\n3. **Business Logic**:  \nEnables detailed request-level logging to support monitoring, debugging, and auditing of API usage, which is critical for operational visibility and troubleshooting in production environments.\n\n4. **Dependencies**:  \n- `Request` object from an ASGI framework (likely FastAPI or Starlette).  \n- `time` module for timing.  \n- A custom `logger` module or instance with specialized logging methods.  \n- `set_request_context()` function to enrich logs with contextual information (e.g., request ID, user info).\n\n5. **Configuration**:  \n- CORS headers are configured elsewhere (indicated by `allow_headers=[\"*\"]` snippet).  \n- No explicit environment variables or config files shown in this snippet,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:43.508604",
      "status": "summarized"
    },
    "core.py:chunk_4": {
      "chunk_id": "core.py:chunk_4",
      "file_path": "interfaces\\api\\core.py",
      "chunk_hash": "f2c2bfab08d50d14bcf0d7e0f0d93a89eb783f83801937cf1836984c1233975f",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet configures a web application to serve static frontend assets by mounting a directory containing compiled frontend files. It ensures that the static files are served from a specific path if the directory exists, and performs cleanup of request context after request handling.\n\n2. **Technical Details**:  \n- Uses Python's `pathlib.Path` to construct and verify the existence of the frontend distribution directory.  \n- Uses a conditional check to verify the presence and type (directory) of the static assets folder.  \n- Mounts static files to the web application under the `/assets` route using `StaticFiles` (likely from Starlette or FastAPI).  \n- Employs logging to inform about the mounting process or warn if the directory is missing.  \n- Contains a `finally` block that calls `clear_request_context()`, ensuring cleanup regardless of exceptions.  \n- The snippet is part of a larger function that returns the configured `app` instance.\n\n3. **Business Logic**:  \nEnables the backend API to serve frontend static assets, facilitating a full-stack deployment where the backend serves both API endpoints and frontend resources. This integration simplifies deployment and hosting by consolidating frontend and backend delivery.\n\n4. **Dependencies**:  \n- `pathlib.Path` for filesystem path manipulations.  \n- `StaticFiles` from a web framework such as Starlette or FastAPI for serving static content.  \n- A logger instance for logging informational and warning messages.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:50.184748",
      "status": "summarized"
    },
    "orchestrator.py:chunk_1": {
      "chunk_id": "orchestrator.py:chunk_1",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "a28910b4b59cd79f7981b2947061597b3922bcb121ef0931e4ef4a99df00be60",
      "chunk_index": 1,
      "summary": "1. **Purpose**  \nThis code defines a `CodeIntelligenceOrchestrator` class that serves as the main coordinator for various code intelligence operations such as embedding repository code into a vector database, summarizing code, analyzing changes, and performing health checks.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) for potentially long-running operations like embedding code.  \n- Encapsulates repository path resolution and settings loading in the constructor.  \n- Employs structured logging for observability (`logger.info`).  \n- Likely interacts with a vector database (e.g., Qdrant) for storing embeddings, indicated by the `collection_name` parameter.  \n- Uses type hints (`Optional[int]`, `Dict[str, Any]`) for clarity and static analysis.  \n- The class acts as a fa\u00e7ade pattern, providing a unified interface to multiple underlying code intelligence functionalities.\n\n3. **Business Logic**  \nEnables automated processing and analysis of source code repositories to facilitate advanced developer tooling such as semantic search, code summarization, and impact analysis. This supports business goals around improving developer productivity, code quality, and faster onboarding.\n\n4. **Dependencies**  \n- `logging_config.setup_logging` for configuring logging.  \n- Python standard libraries: `logging`, `pathlib.Path` (implied by `Path(repo_path)` usage).  \n- External vector database client (implied, e.g., Qdrant) for embedding storage.  \n- `settings` module or object",
      "embedding_id": null,
      "created_at": "2025-10-22T18:34:55.920387",
      "status": "summarized"
    },
    "orchestrator.py:chunk_3": {
      "chunk_id": "orchestrator.py:chunk_3",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "96b15f7433c791b8321cd8294d3e37f811aa84c96d1f255fe5701043963d79c4",
      "chunk_index": 3,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an orchestrator module responsible for managing a repository embedding pipeline and generating enhanced summaries of code files asynchronously.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O-bound operations without blocking.  \n- Instantiates an `EmbeddingOrchestrator` to run incremental embedding of repository files, supporting parameters like `max_files` and `force_reindex`.  \n- Implements a method `generate_summaries` that initializes components such as `RepoState` (likely representing the current state of the repository), a `RateLimitController` (to manage API or resource usage limits), and an `EnhancedCodeSummarizer` to produce code summaries.  \n- Uses structured logging for observability.  \n- The `generate_summaries` method includes a placeholder for batch processing, indicating future scalability improvements.\n\n3. **Business Logic**  \nThe code supports a business need to analyze and summarize code repositories efficiently, enabling enhanced code intelligence features such as embedding code for search or analysis and generating human-readable summaries. This can improve developer productivity, code review processes, and automated documentation.\n\n4. **Dependencies**  \n- Custom modules/classes: `EmbeddingOrchestrator`, `RepoState`, `RateLimitController`, `EnhancedCodeSummarizer`.  \n- Standard Python libraries: `asyncio` (implied by async usage), `logging`.  \n- No explicit external third-party libraries are shown in",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:06.216309",
      "status": "summarized"
    },
    "orchestrator.py:chunk_5": {
      "chunk_id": "orchestrator.py:chunk_5",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "4f9274ba5d0018d1d689cf3a563cfa96fe1cb6a0e812f2fdea991670e5b4ccfa",
      "chunk_index": 5,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method `analyze_changes` analyzes changes in a code repository by identifying changed files relative to a Git reference and calculating file priorities to guide further processing or review.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for potentially non-blocking operations.  \n- Utilizes a `ChangePlanner` class instance to obtain changed files and prioritize them.  \n- Recursively scans the repository directory for Python files (`*.py`) using `Path.rglob`.  \n- Converts file paths to relative strings before prioritization.  \n- Optionally displays priority information via a helper method `_display_priorities`.  \n- Returns a dictionary summarizing the number of changed files and priority data.\n\n3. **Business Logic**:  \nThe method supports a business need to efficiently identify and prioritize code changes in a repository, enabling focused code reviews, testing, or deployment strategies based on file importance and recent modifications.\n\n4. **Dependencies**:  \n- `ChangePlanner` class (likely a custom module/class responsible for Git diff and prioritization logic).  \n- `self.repo_path` as a `Path` object representing the repository root.  \n- `logger` for informational logging.  \n- Python standard libraries: `pathlib` for file operations, `asyncio` for async support.\n\n5. **Configuration**:  \n- `base_ref` parameter allows configuration of the Git reference point (default `\"HEAD\"`).  \n- `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:17.461692",
      "status": "summarized"
    },
    "orchestrator.py:chunk_7": {
      "chunk_id": "orchestrator.py:chunk_7",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "557ff68496dcef4afded00d2e64e195024ca3a26d0dd47efda0a8f6e90076a0a",
      "chunk_index": 7,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method `health_check` performs health status verification for multiple core services\u2014embedding service, vector store, and language model (LLM) service\u2014used in a code intelligence orchestration context.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking health checks.  \n- Instantiates service clients (`EmbeddingService`, `VectorStore`) to query their health status.  \n- Uses a dictionary to aggregate boolean health statuses for each service component.  \n- Employs try-except blocks for fault isolation per service check.  \n- Logging is used extensively for operational observability.\n\n3. **Business Logic**:  \nEnsures that critical AI infrastructure components (embedding generation, vector storage, and LLM inference) are operational before processing code intelligence tasks, thereby maintaining system reliability and early detection of service outages.\n\n4. **Dependencies**:  \n- `EmbeddingService` and `VectorStore` classes, likely custom or from internal SDKs, responsible for embedding generation and vector data management.  \n- A logger instance for info and error logging.  \n- Asyncio or an async-compatible runtime to support asynchronous calls.\n\n5. **Configuration**:  \n- The `EmbeddingService` is instantiated with a `\"provider\"` parameter set to `\"auto\"`, implying some form of dynamic provider selection or configuration.  \n- The `VectorStore` is configured with a collection name `\"health_check_test\"` and embedding dimension fetched from",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:26.484290",
      "status": "summarized"
    },
    "orchestrator.py:chunk_9": {
      "chunk_id": "orchestrator.py:chunk_9",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "987d95ffd0c7a865ecbce2a2c8ce2d9e80b23a4651b8800ad1c2a7b2c145af99",
      "chunk_index": 9,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a health check and reporting utility within an orchestrator module. It verifies the connectivity/status of backend services (vector store and LLM service) and displays a prioritized list of files with metadata such as change status and entry point designation.\n\n2. **Technical Details**:  \n- Uses try-except blocks to attempt health checks on services, logging success or failure.  \n- Maintains a `health` dictionary to track the status of each service.  \n- The `_display_priorities` method organizes a list of priority objects into a dictionary keyed by priority level, then prints a formatted summary showing the top 20 priority items, grouped by priority, and limited to 5 files per priority group.  \n- Uses simple data structures: dictionary (`health`, `by_priority`), list slicing (`priorities[:20]`), and sorting (`sorted(by_priority.keys())`).  \n- Logging is used for status reporting.\n\n3. **Business Logic**:  \n- Ensures critical backend components (vector store and LLM service) are operational before proceeding with further orchestration tasks.  \n- Provides visibility into file processing priorities, helping stakeholders understand which files are most critical or recently changed, aiding in resource allocation or debugging.\n\n4. **Dependencies**:  \n- Assumes a `logger` object for logging (likely from Python\u2019s `logging` module or a custom wrapper).  \n- Relies on external services: a vector store and",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:33.666358",
      "status": "summarized"
    },
    "orchestrator.py:chunk_11": {
      "chunk_id": "orchestrator.py:chunk_11",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "a0757239a12205ed0a5a6849e2581ce6088f0335f2f5081b88f8637c64858b1a",
      "chunk_index": 11,
      "summary": "1. **Purpose**  \nThis Python code defines asynchronous command handlers for a code intelligence orchestrator tool, specifically to embed code repositories, generate summaries of code files, and (partially shown) analyze code. It facilitates processing and summarizing code repositories for insights.\n\n2. **Technical Details**  \n- Uses asynchronous functions (`async def`) to handle potentially long-running I/O-bound operations without blocking.  \n- Instantiates a `CodeIntelligenceOrchestrator` class with a repository path to perform operations.  \n- Calls orchestrator methods like `embed_repository` and `generate_summaries` with parameters such as collection names, file limits, and force flags.  \n- Prints formatted statistics and results to the console, including counts and success rates.  \n- Uses Python dictionaries to receive and display operation statistics.\n\n3. **Business Logic**  \nThe code supports automating the embedding and summarization of code repositories, enabling developers or organizations to generate searchable vector embeddings and summaries of codebases. This supports improved code search, understanding, and maintenance workflows.\n\n4. **Dependencies**  \n- Relies on a `CodeIntelligenceOrchestrator` class (likely defined elsewhere in the project) that encapsulates the core embedding and summarization logic.  \n- Uses Python\u2019s built-in `print` function for output.  \n- Uses Python\u2019s `asyncio` framework for asynchronous execution.\n\n5. **Configuration**  \n- Command arguments (`args`) provide configuration such as repository path (`repo`),",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:41.147407",
      "status": "summarized"
    },
    "orchestrator.py:chunk_13": {
      "chunk_id": "orchestrator.py:chunk_13",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "c967d6155b5682ec8cd74d71d32525db1bf191b17d0a5422ac2b910c8054740d",
      "chunk_index": 13,
      "summary": "1. **Purpose**  \nThis Python code provides asynchronous command handlers for a code intelligence orchestrator tool, enabling analysis of code changes, health checks of underlying services, and running integration tests.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to perform potentially long-running operations without blocking.  \n- Instantiates a `CodeIntelligenceOrchestrator` class with a repository path to perform operations.  \n- The `analyze_changes` method analyzes code changes relative to a base reference and returns a dictionary with changed and total file counts.  \n- The `health_check` method returns a dictionary of service health statuses, which are aggregated and displayed with status icons.  \n- The `cmd_test` function dynamically imports and runs an asynchronous test pipeline, handling exceptions gracefully.  \n- Uses formatted printing with Unicode icons for user-friendly CLI output.\n\n3. **Business Logic**  \nThe code supports a developer or DevOps workflow by:  \n- Analyzing code changes to prioritize or understand impact in a repository.  \n- Providing health status of code intelligence services to ensure system reliability.  \n- Running integration tests to validate system correctness before deployment or further processing.\n\n4. **Dependencies**  \n- `CodeIntelligenceOrchestrator` class (likely internal or from the same project).  \n- `test_pipeline` module providing an asynchronous `main` function for integration tests.  \n- Standard Python libraries: `sys` (for exit), `logging` (implied by `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:48.763066",
      "status": "summarized"
    },
    "orchestrator.py:chunk_15": {
      "chunk_id": "orchestrator.py:chunk_15",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "1e341ed96ec97ef8cbdb7bb2731cd334581b6c23f60ba0cf59c7370d0a820414",
      "chunk_index": 15,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet defines the command-line interface (CLI) entry point for a code intelligence orchestration tool that manages code embedding, summarization, analysis, health checks, and testing workflows.\n\n2. **Technical Details**:  \n- Uses Python\u2019s `argparse` module to create a CLI parser with subcommands and global options.  \n- Provides detailed help text and usage examples via the `epilog` parameter.  \n- Supports logging configuration through `--log-level` and `--log-file` arguments.  \n- The design follows a command routing pattern, where different commands (e.g., `embed`, `summarize`, `analyze`) trigger different processing flows (not shown in this snippet).\n\n3. **Business Logic**:  \nEnables developers or automated systems to perform unified orchestration of code intelligence tasks such as embedding source code for search or analysis, generating summaries, analyzing code changes, performing health checks, and running tests. This supports improving code quality, maintainability, and developer productivity.\n\n4. **Dependencies**:  \n- Python standard library: `argparse` for CLI parsing.  \n- No external libraries or services are referenced in this snippet.\n\n5. **Configuration**:  \n- CLI options for logging level (`quiet`, `normal`, `verbose`, `debug`) and optional log file path.  \n- No environment variables or config files are referenced here, but the CLI design suggests extensibility for configuration.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T18:35:56.952552",
      "status": "summarized"
    },
    "orchestrator.py:chunk_17": {
      "chunk_id": "orchestrator.py:chunk_17",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "8d740e3e1660612b5a65e0d3f406a0d2fcfa335dc79e8ec4d3a39fb1bee12801",
      "chunk_index": 17,
      "summary": "1. **Purpose**:  \nThis code defines a command-line interface (CLI) parser for an orchestration tool that manages code intelligence workflows, including embedding code repositories into a vector database, generating code summaries, and analyzing repository changes.\n\n2. **Technical Details**:  \n- Uses Python's `argparse` module to create a hierarchical CLI with subcommands (`embed`, `summarize`, `analyze`).  \n- Each subcommand supports specific arguments such as repository path, file selection, collection names, and flags for forcing operations.  \n- The design follows the Command design pattern by encapsulating different operations as distinct commands with their own parameters.\n\n3. **Business Logic**:  \nEnables developers or automated systems to perform advanced code intelligence tasks:  \n- Embedding source code into a vector database for semantic search or similarity analysis.  \n- Generating summaries of code files to improve understanding or documentation.  \n- Analyzing changes in a repository to detect modifications or regressions.  \nThis supports business goals around improving developer productivity, code quality, and automated code analysis.\n\n4. **Dependencies**:  \n- Python standard library: `argparse` for CLI parsing.  \n- Implied dependencies (not shown here) likely include:  \n  - A vector database client (e.g., Qdrant) for embedding storage.  \n  - Git or a git wrapper for repository analysis.  \n  - Possibly NLP or embedding libraries for code summarization.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:01.511005",
      "status": "summarized"
    },
    "orchestrator.py:chunk_19": {
      "chunk_id": "orchestrator.py:chunk_19",
      "file_path": "code-intelligence\\orchestrator.py",
      "chunk_hash": "27625825fb35d67fda26b47cf89e57389057a13639cddd22054385532fad3a72",
      "chunk_index": 19,
      "summary": "**Summary of `code-intelligence\\orchestrator.py`**\n\n1. **Purpose**  \nThis script serves as a command-line interface (CLI) orchestrator for a code intelligence tool, enabling users to run various commands such as embedding, summarizing, analyzing code, checking system health, and running integration tests.\n\n2. **Technical Details**  \n- Uses Python\u2019s `argparse` module to define subcommands and parse CLI arguments.  \n- Implements a command dispatch pattern via a dictionary (`command_map`) mapping command names to asynchronous handler functions (`cmd_embed`, `cmd_summarize`, etc.).  \n- Uses `asyncio.run()` to execute asynchronous command handlers, indicating that command implementations are asynchronous.  \n- Logging is configured dynamically based on CLI arguments (`log_level`, `log_file`).  \n- The CLI gracefully handles missing commands by printing help and exiting.\n\n3. **Business Logic**  \nThe code orchestrates various code intelligence operations that support software development workflows, such as:  \n- Generating embeddings for code (likely for search or ML models).  \n- Summarizing codebases or components.  \n- Analyzing code for insights or metrics.  \n- Checking system or service health to ensure operational readiness.  \n- Running integration tests to validate system components.  \nThis supports developer productivity, code quality assurance, and system reliability.\n\n4. **Dependencies**  \n- Python standard library: `argparse`, `asyncio`, `sys` (implied).  \n- Custom",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:11.782644",
      "status": "summarized"
    },
    "orchestrator.py:chunk_0": {
      "chunk_id": "orchestrator.py:chunk_0",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "995c63bccc9f51e5343a614ac098dd0e06aac0f1cc99a6371612a2596cb6e1f3",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration/cloud_providers/orchestrator.py`**\n\n1. **Purpose**  \n   This module implements a centralized cloud orchestration manager that routes AI workflow requests (e.g., speech-to-text, text-to-speech, translation, large language models) to appropriate cloud providers. It supports automatic fallback mechanisms and health tracking to ensure reliable, provider-agnostic execution of AI services.\n\n2. **Technical Details**  \n   - Uses a factory design pattern (`ProviderFactory`) to instantiate provider-specific clients dynamically.  \n   - Maintains a health status dictionary (`_health_status`) keyed by provider names to track operational status and possibly influence fallback decisions.  \n   - Supports asynchronous operations (e.g., `async def speech_to_text`) for non-blocking I/O with cloud providers.  \n   - Implements provider preference and fallback chains via helper functions (`get_provider_preference`, `get_fallback_chain`) to determine routing logic.  \n   - Uses typed data structures and result wrappers (`STTResult`, `TTSResult`, etc.) to standardize responses across heterogeneous providers.\n\n3. **Business Logic**  \n   Enables enterprises to integrate multiple cloud AI providers seamlessly, abstracting away provider-specific APIs and failures. This ensures high availability and flexibility in deploying AI workflows such as speech recognition, synthesis, translation, and language modeling, critical for applications requiring robust multi-cloud AI capabilities.\n\n4. **Dependencies**  \n   - Internal modules:  \n     - `.factory` for provider",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:18.641417",
      "status": "summarized"
    },
    "orchestrator.py:chunk_2": {
      "chunk_id": "orchestrator.py:chunk_2",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "0b1368be32ac405535225467237625ae01c5c03495a696a8f4cbe5f9cff0c687",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a method that transcribes audio data into text by sequentially attempting multiple speech-to-text (STT) providers until one successfully processes the input or all fail.\n\n2. **Technical Details**:  \n- Implements a fallback chain pattern where a prioritized list of STT providers is tried in order.  \n- Uses a factory design pattern (`self.factory.create_provider`) to instantiate provider instances dynamically based on the provider name and capability.  \n- Logs each attempt for traceability and debugging.  \n- Checks provider availability before usage (`provider.is_available()`).  \n- Collects errors from failed attempts to potentially raise a comprehensive exception if all providers fail.\n\n3. **Business Logic**:  \nEnables robust and flexible audio transcription by leveraging multiple STT providers, improving reliability and accuracy. It supports forced use of a preferred provider or automatic fallback to a configured chain, ensuring transcription service continuity in case of provider outages or limitations.\n\n4. **Dependencies**:  \n- `ProviderCapability` enum or constant defining capabilities like `SPEECH_TO_TEXT`.  \n- `STTProvider` interface or base class representing speech-to-text providers.  \n- A factory class responsible for creating provider instances (`self.factory.create_provider`).  \n- Logging module for info-level logs.  \n- Possibly a configuration module or function `get_fallback_chain` to retrieve the ordered list of providers.\n\n5. **Configuration**:  \n- Provider chain order is configurable",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:28.803689",
      "status": "summarized"
    },
    "orchestrator.py:chunk_4": {
      "chunk_id": "orchestrator.py:chunk_4",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "df85bcf1f58fad3b0d1573708cda44e026ded47560be258fd1e62641a31a32a5",
      "chunk_index": 4,
      "summary": "**Summary of Error Handling Code in `orchestration\\cloud_providers\\orchestrator.py`**\n\n1. **Purpose**  \n   This code handles errors occurring during the invocation of multiple speech-to-text (STT) cloud providers. It manages failures such as provider unavailability, runtime exceptions during transcription, and missing metadata in the transcription results.\n\n2. **Exception Types**  \n   The code uses a broad `except Exception as e` clause, catching all exceptions derived from Python\u2019s base `Exception` class. No specific exception types are targeted, allowing it to catch any runtime error during the asynchronous transcription call.\n\n3. **Recovery Strategy**  \n   - If a provider is not available (implied by a preceding check, not shown here), it logs a warning and continues to the next provider without raising an error.  \n   - Upon encountering an exception during transcription, the error is logged and appended to an `errors` list, then the loop continues to try the next provider.  \n   - This retry-over-multiple-providers approach ensures that a failure in one provider does not stop the overall transcription process.  \n   - Only if all providers fail does the code raise a `RuntimeError` with a summary of all collected errors.\n\n4. **Logging**  \n   - Warnings are logged when a provider is unavailable or when a transcription attempt fails, including the exception message.  \n   - Successful transcriptions are logged at the info level with the provider name and duration in milliseconds",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:36.495791",
      "status": "summarized"
    },
    "orchestrator.py:chunk_6": {
      "chunk_id": "orchestrator.py:chunk_6",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "4ad448aaf4cd2148d928a5b3a1a6b21a7ee4b628b06933cb611e8ce139957601",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous method `text_to_speech` converts input text into speech audio by leveraging multiple cloud TTS providers, selecting the best available one based on a fallback chain or a preferred provider override.\n\n2. **Technical Details**:  \n- Uses an asynchronous function to support non-blocking I/O operations.  \n- Implements a provider fallback chain pattern: tries a prioritized list of TTS providers sequentially until one succeeds.  \n- Uses a factory design pattern (`self.factory.create_provider`) to instantiate provider-specific TTS clients dynamically.  \n- Logs each step for traceability and debugging.  \n- Returns a `TTSResult` object encapsulating audio data and metadata.  \n\n3. **Business Logic**:  \nEnables robust and flexible text-to-speech conversion by abstracting multiple cloud providers, ensuring high availability and quality by falling back to alternative providers if the preferred or primary provider fails. This supports applications requiring reliable speech synthesis, such as voice assistants, accessibility tools, or multimedia content generation.\n\n4. **Dependencies**:  \n- `ProviderCapability` enum or constant to specify capability type (TEXT_TO_SPEECH).  \n- `get_fallback_chain` function to retrieve provider priority list.  \n- `self.factory` which likely depends on a provider factory module/class to create TTS provider instances.  \n- `TTSProvider` interface or base class defining the provider contract.  \n- `TTSResult` data structure to encapsulate",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:46.730633",
      "status": "summarized"
    },
    "orchestrator.py:chunk_8": {
      "chunk_id": "orchestrator.py:chunk_8",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "07f5f350137342422894390a52b3b868cb2d56210333a14876d3dd86b52fd80f",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet attempts to synthesize text-to-speech (TTS) audio using a specified cloud provider. It checks provider availability, measures synthesis duration, enriches the result with metadata, and handles errors gracefully.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to call the provider's `synthesize` method, enabling non-blocking I/O operations.  \n- Measures execution time with `time.time()` before and after synthesis to calculate duration in milliseconds.  \n- Uses a loop (implied by `continue`) to iterate over multiple providers until one succeeds.  \n- Enriches the result object by adding a `duration_ms` attribute and updating a metadata dictionary with the provider name.  \n- Logging is used extensively for tracing success, warnings, and errors.\n\n3. **Business Logic**:  \nThe code supports a multi-provider TTS orchestration strategy, ensuring high availability and fallback mechanisms for generating speech audio from text. This improves reliability and user experience by trying alternative providers if one is unavailable or fails.\n\n4. **Dependencies**:  \n- An external or internal `provider` object implementing `is_available()` and asynchronous `synthesize()` methods.  \n- Python standard libraries: `time` for timing, and a `logger` for logging messages.  \n- The snippet implies an asynchronous runtime environment (e.g., `asyncio`).\n\n5. **Configuration**:  \n- Provider-specific configurations such",
      "embedding_id": null,
      "created_at": "2025-10-22T18:36:55.772783",
      "status": "summarized"
    },
    "orchestrator.py:chunk_10": {
      "chunk_id": "orchestrator.py:chunk_10",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "fa70e9a62e5eb91c489437e8751c0fd7c7d93a822b65b487a93a9e62dc3ced16",
      "chunk_index": 10,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles errors occurring during text translation attempts via multiple cloud providers. It ensures that if one or more providers fail to translate the text, the system tries alternative providers before ultimately failing.\n\n2. **Exception Types**:  \n   The snippet does not explicitly show which specific exceptions are caught during provider calls. However, it raises a `RuntimeError` if all translation providers fail, aggregating error messages from each failed attempt.\n\n3. **Recovery Strategy**:  \n   The method attempts translation using a prioritized chain of providers: either a user-specified preferred provider or a fallback chain determined by capability. It collects errors from each failed provider and only raises an exception after exhausting all options, effectively retrying with alternative providers.\n\n4. **Logging**:  \n   The code logs the provider chain used for the translation request (`logger.info`), which aids in monitoring which providers are being attempted. Although not shown, it is implied that errors from each provider are collected, potentially logged elsewhere.\n\n5. **User Impact**:  \n   If all providers fail, the user receives a `RuntimeError` indicating that translation was unsuccessful, including a summary of all provider errors. This prevents silent failures and informs the user or calling system of the failure cause.\n\n6. **Fallback**:  \n   The fallback mechanism involves trying multiple providers in sequence until one succeeds. If a preferred provider is specified, it is tried first, overriding the default fallback chain.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:05.512082",
      "status": "summarized"
    },
    "orchestrator.py:chunk_12": {
      "chunk_id": "orchestrator.py:chunk_12",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "c6913ee9d9dadfb6787fe406858b92bbb2f38688d145c40636d73848e4594c36",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code iterates over a sequence of translation providers to attempt translating a given text. It tries each provider in order until a successful translation is achieved, measuring and logging the duration of each attempt.\n\n2. **Technical Details**:  \n- Uses an asynchronous call (`await provider.translate(...)`) to perform translation, enabling non-blocking I/O operations.  \n- Implements a factory design pattern (`self.factory.create_provider`) to instantiate translation provider objects dynamically based on provider names and capabilities.  \n- Uses a loop to chain through multiple providers, checking availability before attempting translation.  \n- Measures execution time for each translation attempt in milliseconds and annotates the result with metadata including the provider name and duration.\n\n3. **Business Logic**:  \nThe code addresses the business need for a resilient, multi-provider translation orchestration system. It ensures high availability and fallback by sequentially trying multiple translation services until one succeeds, improving translation reliability and coverage.\n\n4. **Dependencies**:  \n- `TranslationProvider` interface or base class defining `is_available()` and `translate()` methods.  \n- `self.factory` module or class responsible for creating provider instances.  \n- `logger` for structured logging of events and warnings.  \n- Python standard libraries: `time` for measuring durations, `asyncio` for asynchronous operations.\n\n5. **Configuration**:  \n- The `chain` variable (list of provider names) likely comes from a configuration source dictating provider priority/order.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:13.032410",
      "status": "summarized"
    },
    "orchestrator.py:chunk_14": {
      "chunk_id": "orchestrator.py:chunk_14",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "b82709ff3c65b94c59505c368436af40c08df7d966489e873ccc52b5717bf2e7",
      "chunk_index": 14,
      "summary": "**Summary of Error Handling in `orchestration/cloud_providers/orchestrator.py`**\n\n1. **Purpose**  \n   The error handling code manages failures occurring during calls to multiple translation or LLM providers within an orchestration layer. It ensures that if one provider fails, the system attempts others, aggregating errors until either a successful response is obtained or all providers fail.\n\n2. **Exception Types**  \n   - Catches all exceptions via a broad `except Exception as e` clause.  \n   - No specific exception subclasses are targeted, implying a generic catch-all approach to handle any runtime error during provider invocation.\n\n3. **Recovery Strategy**  \n   - Implements a retry/failover mechanism by iterating over multiple providers.  \n   - On exception, logs the error, appends the error message to a list, and continues to the next provider.  \n   - Only raises a `RuntimeError` after all providers have failed, including a concatenated summary of all error messages.\n\n4. **Logging**  \n   - Uses `logger.warning` to log each provider failure with a clear, prefixed message including the provider name and error details.  \n   - Logs include a visual indicator (`\u274c`) to highlight failure events, aiding monitoring and troubleshooting.\n\n5. **User Impact**  \n   - End users experience a failure only if all providers fail, resulting in a `RuntimeError` with a detailed error summary.  \n   - Partial failures are transparent to users as the system",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:17.789523",
      "status": "summarized"
    },
    "orchestrator.py:chunk_16": {
      "chunk_id": "orchestrator.py:chunk_16",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "ae613856104f0b6a59088392ee66e8338805975775afa8a0df9bcd4106695173",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet orchestrates chat completion requests by selecting an appropriate large language model (LLM) provider from a prioritized chain and invoking its chat API, returning the first successful response.\n\n2. **Technical Details**:  \n- Uses a provider chain selection mechanism: either a single preferred provider or a fallback chain based on the requested capability.  \n- Iterates over providers sequentially, attempting to create and use each provider until one succeeds.  \n- Employs a factory design pattern (`self.factory.create_provider`) to instantiate provider objects dynamically by name and capability.  \n- Measures and records the duration of each chat completion call in milliseconds.  \n- Uses asynchronous programming (`await`) to handle potentially long-running I/O-bound chat completion calls.  \n- Logs key events and warnings for observability.\n\n3. **Business Logic**:  \nEnables resilient and flexible integration with multiple LLM providers to fulfill chat completion requests, ensuring high availability and fallback options if the preferred provider is unavailable or fails. This supports business continuity and optimizes user experience by transparently switching providers.\n\n4. **Dependencies**:  \n- `LLMProvider` interface or base class representing chat providers.  \n- `self.factory` module or class responsible for creating provider instances.  \n- `logger` for structured logging.  \n- `time` module for performance measurement.  \n- Asynchronous runtime (e.g., `asyncio`) to support `await`.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:22.060845",
      "status": "summarized"
    },
    "orchestrator.py:chunk_18": {
      "chunk_id": "orchestrator.py:chunk_18",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "414bdcc22d78cf8b1fb3f0d17595cb4cee9933e0c72d3b4defa0d65e4971aa25",
      "chunk_index": 18,
      "summary": "**Summary of Error Handling Code in `orchestration\\cloud_providers\\orchestrator.py`:**\n\n1. **Purpose**:  \n   The code handles errors occurring during attempts to obtain chat completions from multiple LLM (Large Language Model) providers. It ensures that if one provider fails, the system tries the next provider in the list until a successful response is obtained or all providers fail.\n\n2. **Exception Types**:  \n   The code uses a broad `except Exception as e` clause, meaning it catches all exceptions derived from Python\u2019s base `Exception` class. This includes network errors, API failures, timeouts, or any unexpected runtime errors during provider interaction.\n\n3. **Recovery Strategy**:  \n   Upon catching an exception from a provider, the error message is appended to an `errors` list, a warning is logged, and the loop continues to try the next provider. This retry-across-providers approach allows the system to recover by falling back to alternative providers rather than failing immediately.\n\n4. **Logging**:  \n   - Successful completions are logged at the info level with a checkmark and timing information (`Chat completion successful with {provider_name} ({duration_ms}ms)`).\n   - Failures are logged at the warning level with a cross mark and the error message (`{provider_name} failed: {e}`).\n   This logging strategy supports monitoring provider reliability and performance, aiding in troubleshooting and operational awareness.\n\n5. **User Impact**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:32.754951",
      "status": "summarized"
    },
    "orchestrator.py:chunk_20": {
      "chunk_id": "orchestrator.py:chunk_20",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "580bd93718c4262180eb4d282df47ea8560f450122ed9ba56ff84254d9da84f6",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a cloud provider orchestrator that gathers and reports the status of various AI service providers based on their capabilities (e.g., LLM chat, embedding). It collects available providers, their fallback chains, and configuration status to facilitate provider selection and failover.\n\n2. **Technical Details**:  \n- Iterates over an enumeration `ProviderCapability` to retrieve available providers and their fallback chains.  \n- Uses a factory pattern (`self.factory`) to abstract provider instantiation and configuration detection.  \n- Builds a nested dictionary `status` that maps capabilities to provider info and providers to their configuration and supported capabilities.  \n- Checks provider configuration by detecting API keys or endpoints dynamically (`_auto_detect_config`).  \n- Uses lists and dictionaries as primary data structures for organizing provider metadata.\n\n3. **Business Logic**:  \nEnables dynamic orchestration of multiple AI cloud providers by assessing their availability and configuration status. This supports business requirements for high availability, provider redundancy, and capability-based routing of AI requests (e.g., choosing the best provider for chat or embeddings).\n\n4. **Dependencies**:  \n- `ProviderCapability`: an enum defining AI service capabilities.  \n- `self.factory`: a factory object responsible for provider management and configuration detection.  \n- Functions like `get_provider_preference` and `get_fallback_chain` for preference and fallback logic.  \n- Likely depends on environment or external config for provider credentials.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:43.341270",
      "status": "summarized"
    },
    "orchestrator.py:chunk_22": {
      "chunk_id": "orchestrator.py:chunk_22",
      "file_path": "orchestration\\cloud_providers\\orchestrator.py",
      "chunk_hash": "2d84a5d93efa51bd025f8d2fdb3046c3f4737931c7e1992d2a0fefc24e573c76",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet is part of a cloud orchestration module that collects and aggregates the capabilities of various cloud providers, updating a status dictionary with each provider's configuration state and capabilities.\n\n2. **Technical Details**:  \n- Uses a nested dictionary (`status`) to store provider-specific information, including a list of capabilities.  \n- Iterates over providers and appends capability values to the corresponding list.  \n- Employs a try-except block to catch any exceptions during capability retrieval or processing, marking the provider as not configured and recording the error message.  \n- Instantiates a singleton-like `CloudOrchestrator` object at the end for use elsewhere.\n\n3. **Business Logic**:  \nEnables a centralized system to monitor and report the configuration status and supported features of multiple cloud providers, facilitating multi-cloud management and decision-making.\n\n4. **Dependencies**:  \n- Relies on a `CloudOrchestrator` class (not shown) which likely encapsulates provider interactions.  \n- Uses `capability.value`, implying an Enum or similar construct for capabilities.\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown in this snippet.  \n- Configuration likely handled within the `CloudOrchestrator` class or external settings.\n\n6. **Error Handling**:  \n- Catches all exceptions generically (`Exception as e`).  \n- On error, marks the provider as `\"configured\": False` and stores the error message under",
      "embedding_id": null,
      "created_at": "2025-10-22T18:37:52.310074",
      "status": "summarized"
    },
    "factory.py:chunk_0": {
      "chunk_id": "factory.py:chunk_0",
      "file_path": "orchestration\\cloud_providers\\factory.py",
      "chunk_hash": "c28c657c050a33f1fb2641ea6112d8b9983779129b4e432804af668a86c66c76",
      "chunk_index": 0,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis code implements a factory pattern to create and manage instances of various cloud provider classes (e.g., Azure, Together AI, OpenAI) based on configuration and requested capabilities. It centralizes provider instantiation and supports extensibility by allowing dynamic registration of new providers.\n\n2. **Technical Details**  \n- Uses a class-level registry (`_provider_registry`) mapping provider names (strings) to their corresponding provider classes.  \n- Maintains a cache (`_instances`) of instantiated providers to avoid redundant object creation.  \n- Provides class methods `register_provider` to add new providers and `create_provider` (partially shown) to instantiate or retrieve existing provider instances.  \n- Employs type hints extensively for clarity and type safety, including custom types like `ProviderCapability`.  \n- Uses the factory design pattern to abstract provider creation logic and enable easy extension.\n\n3. **Business Logic**  \nEnables the orchestration layer of an application to seamlessly switch between or fallback among multiple cloud AI providers for services such as speech-to-text (STT), text-to-speech (TTS), translation, and large language models (LLM). This supports business needs for flexibility, redundancy, and cost optimization by allowing dynamic provider selection based on capability and configuration.\n\n4. **Dependencies**  \n- Internal modules:  \n  - `shared.config.settings` for application configuration management.  \n  - `shared.logger.get_logger` for standardized logging.  \n  - `.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:38:00.123486",
      "status": "summarized"
    },
    "factory.py:chunk_2": {
      "chunk_id": "factory.py:chunk_2",
      "file_path": "orchestration\\cloud_providers\\factory.py",
      "chunk_hash": "8ded80759437449e53efaabddd24298b50a8d9064409d732398766ee51602753",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `orchestration\\cloud_providers\\factory.py`**\n\n1. **Purpose**  \n   This code segment handles errors related to the creation of cloud provider instances based on requested capabilities. Specifically, it ensures that only registered providers are instantiated and that the requested capability is supported. It prevents invalid provider names from proceeding further in the orchestration flow.\n\n2. **Exception Types**  \n   - Raises a `ValueError` explicitly when:  \n     - The requested `provider_name` is not found in the internal `_provider_registry`.  \n     - (Implied) If the provider does not support the requested capability, though that check is not shown in this snippet, the docstring mentions it as a possible cause for `ValueError`.\n\n3. **Recovery Strategy**  \n   - There is no retry mechanism or error recovery within this snippet.  \n   - The method fails fast by raising an exception if the provider is not registered, preventing downstream errors.  \n   - If no explicit `config` is provided, it attempts to auto-detect configuration from environment variables (`_auto_detect_config`), which acts as a fallback to avoid configuration errors.\n\n4. **Logging**  \n   - Uses debug-level logging to indicate when a cached provider instance is reused (`logger.debug`).  \n   - No explicit error logging is shown for the `ValueError` raised; it is expected that the caller handles or logs the exception.\n\n5. **User Impact**  \n   - If",
      "embedding_id": null,
      "created_at": "2025-10-22T18:38:11.208641",
      "status": "summarized"
    },
    "factory.py:chunk_4": {
      "chunk_id": "factory.py:chunk_4",
      "file_path": "orchestration\\cloud_providers\\factory.py",
      "chunk_hash": "a6e36e8392686a6df13f5d88e34edf8c0360ddc8128457cf5e13ef0aafedcf42",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a factory class responsible for creating and managing instances of cloud provider clients based on given configurations and capabilities. It includes logic to auto-detect provider configurations from environment variables for seamless initialization.\n\n2. **Technical Details**:  \n- Implements a factory design pattern to instantiate provider classes dynamically.  \n- Uses a class-level cache (`cls._instances`) keyed by a combination of provider name and capability to reuse existing instances and avoid redundant creations.  \n- The `_auto_detect_config` method reads environment-based settings to build a `ProviderConfig` object tailored for the specified provider (example shown for Azure).  \n- Uses structured configuration objects (`ProviderConfig`) to encapsulate provider-specific settings.  \n- Logging is used to track instance creation events.\n\n3. **Business Logic**:  \nEnables dynamic and efficient provisioning of cloud provider clients (e.g., Azure) with appropriate configurations, facilitating multi-cloud orchestration and capability-specific operations (like speech or translation services). This supports business needs for flexible, scalable integration with various cloud AI services without manual config management.\n\n4. **Dependencies**:  \n- `ProviderConfig` class or data structure (likely a custom or domain-specific class).  \n- `settings` module or object that holds environment variables or configuration values (possibly from a config management system or environment).  \n- `logger` for logging informational messages.  \n- `provider_class` which is dynamically instantiated, presumably imported or defined elsewhere.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:38:21.652242",
      "status": "summarized"
    },
    "factory.py:chunk_6": {
      "chunk_id": "factory.py:chunk_6",
      "file_path": "shared\\llm_providers\\factory.py",
      "chunk_hash": "b9a305197d01d53f786bae0d87a643c633ecd600cda6d83e2117cced5965827f",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a factory method responsible for selecting and instantiating a Large Language Model (LLM) provider based on configured credentials. It verifies which LLM providers (Azure OpenAI or Together AI) are configured and raises an error if none are available.\n\n2. **Technical Details**:  \n- Uses a detection method (`LLMFactory.detect_configured_providers`) to check the presence of required credentials for each provider.  \n- Maintains a dictionary (`configured`) with boolean flags indicating whether each provider is configured.  \n- Counts the number of configured providers by summing boolean values.  \n- Implements conditional logic to handle the case when no providers are configured.  \n- Uses structured logging (`logger.error`) to report configuration errors.\n\n3. **Business Logic**:  \nEnsures that the application has access to at least one LLM provider before proceeding, preventing runtime failures due to missing API credentials. This validation step is critical for applications relying on external AI services for natural language processing or generation tasks.\n\n4. **Dependencies**:  \n- `LLMFactory` class/module with a static or class method `detect_configured_providers`.  \n- `logger` for logging error messages.  \n- External LLM services: Azure OpenAI and Together AI (implied by the keys and endpoints).\n\n5. **Configuration**:  \n- Azure OpenAI: requires `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:00.423921",
      "status": "summarized"
    },
    "factory.py:chunk_8": {
      "chunk_id": "factory.py:chunk_8",
      "file_path": "shared\\llm_providers\\factory.py",
      "chunk_hash": "8d31f9c6d3a05b5f1a177d579e88f05f8e119d9a985fd6436d4f680d80482850",
      "chunk_index": 8,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This code segment handles configuration and availability errors related to initializing LLM (Large Language Model) providers\u2014specifically Azure OpenAI and Together AI. It ensures that the selected provider(s) are properly configured and available before use.\n\n2. **Exception Types**:  \n   - Raises `ValueError` with descriptive messages when:  \n     - No providers are configured (implied by the initial raise not shown fully here).  \n     - A single configured provider (Azure or Together AI) is not available (likely due to invalid credentials or connectivity issues).\n\n3. **Recovery Strategy**:  \n   - No automatic retries are implemented.  \n   - The code performs availability checks (`provider.is_available()`) immediately after instantiation.  \n   - If the provider is unavailable, it raises an exception to halt further processing, signaling a configuration or credential issue that must be fixed manually.  \n   - When both providers are configured, it enables a \"smart fallback\" mechanism (not shown in this snippet), implying a strategy to switch providers if one fails.\n\n4. **Logging**:  \n   - Uses `logger.info` to record the configuration state and chosen provider path, including:  \n     - When only Azure is configured and used exclusively.  \n     - When only Together AI is configured and used exclusively.  \n     - When both providers are configured and fallback is enabled.  \n   - Error conditions raise exceptions but do not explicitly log errors here;",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:07.120341",
      "status": "summarized"
    },
    "factory.py:chunk_10": {
      "chunk_id": "factory.py:chunk_10",
      "file_path": "shared\\llm_providers\\factory.py",
      "chunk_hash": "17eeca915b629d68c584bdb8692594704c4b8b982d01f2faaf0969611aca6384",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code snippet determines and instantiates a primary and fallback large language model (LLM) provider based on a specified provider type or auto-detection logic, enabling seamless switching between Azure OpenAI and Together AI services.\n\n2. **Technical Details**:  \n- Uses conditional logic to select the primary provider either explicitly or via auto-detection (prefers Azure if configured).  \n- Instantiates provider objects (`AzureOpenAIProvider` and `TogetherAIProvider`) with relevant configuration parameters.  \n- Implements a fallback mechanism by pairing the primary provider with an alternative provider.  \n- Checks provider availability through a method call (`is_available()`) before proceeding.\n\n3. **Business Logic**:  \nEnsures high availability and flexibility in accessing LLM services by automatically selecting the best available provider and providing a fallback option. This supports business continuity and optimizes resource usage depending on configuration and service availability.\n\n4. **Dependencies**:  \n- Custom provider classes: `AzureOpenAIProvider`, `TogetherAIProvider`.  \n- Logging module (`logger`) for informational output.  \n- External LLM services: Azure OpenAI and Together AI APIs.\n\n5. **Configuration**:  \n- Azure-related settings: `azure_endpoint`, `azure_api_key`, `azure_deployment`, `azure_api_version`.  \n- Together AI settings: `together_api_key`, `together_model`.  \n- A boolean flag `azure_configured` indicating if Azure credentials/configuration are present",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:13.693136",
      "status": "summarized"
    },
    "factory.py:chunk_12": {
      "chunk_id": "factory.py:chunk_12",
      "file_path": "orchestration\\cloud_providers\\factory.py",
      "chunk_hash": "a0bd6a7e1b7bc1de4b5e630dce145208f4bc8e9ba93df456cea2000589f1c3c6",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code determines and returns an ordered list of preferred cloud providers based on a given capability (such as LLM chat, speech-to-text, etc.) and a user or system preference. It acts as a provider selection mechanism within a cloud orchestration context.\n\n2. **Technical Details**:  \n- Uses conditional branching (`if-elif-else`) to map combinations of `capability` and `preference` to prioritized lists of provider strings.  \n- The `capability` is matched against enumerated types (`ProviderCapability`), and `preference` is a string indicating user or system preference.  \n- Returns a list of provider identifiers (strings) ordered by priority for fallback or selection logic downstream.\n\n3. **Business Logic**:  \n- Supports multi-cloud provider orchestration by selecting the best provider(s) for a given AI-related capability (e.g., large language model chat, speech-to-text).  \n- Implements fallback ordering to ensure service continuity if the preferred provider is unavailable.  \n- Encodes business rules about provider preference and capability support, enabling flexible provider usage based on customer or system preferences.\n\n4. **Dependencies**:  \n- Relies on an external enumeration or class `ProviderCapability` which defines the capabilities like `LLM_CHAT`, `SPEECH_TO_TEXT`, etc.  \n- No direct external libraries or APIs are called in this snippet, but it is part of a larger orchestration system that likely integrates with",
      "embedding_id": null,
      "created_at": "2025-10-22T18:38:55.451597",
      "status": "summarized"
    },
    "manager.py:chunk_0": {
      "chunk_id": "manager.py:chunk_0",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "656957c635c6f6d641eff95a1b6ee566909d91e5a2a17c90aed37f4069ce35aa",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `ServiceManager` class responsible for managing the lifecycle, connection pooling, and integration with large language model (LLM) services for various backend services in an application.\n\n2. **Technical Details**:  \n- Uses a dictionary `_services` keyed by service names to store instances of `BaseService`.  \n- Implements lazy initialization for the `ServiceLLMWrapper` to avoid startup failures related to LLM service availability.  \n- Maintains a `_connection_pool` dictionary mapping service names to timestamps (`datetime`) to track connection usage or expiry.  \n- Uses asynchronous method `register_service` to add new services, indicating potential I/O or network operations during registration.  \n- Employs structured logging via a shared logger instance for monitoring and debugging.\n\n3. **Business Logic**:  \nThe `ServiceManager` centralizes management of multiple backend services, ensuring efficient connection reuse and lifecycle control. It also integrates with an LLM wrapper to enable AI-powered interactions or augmentations, supporting business needs such as automated responses, intelligent service orchestration, or enhanced data processing.\n\n4. **Dependencies**:  \n- Python standard libraries: `typing` (for type hints), `datetime` (for time tracking).  \n- Internal modules:  \n  - `.base` providing `BaseService`, `ServiceConfig`, and `ServiceStatus` abstractions.  \n  - `.llm_wrapper` providing `ServiceLLMWrapper` and `LLMService",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:18.486654",
      "status": "summarized"
    },
    "manager.py:chunk_2": {
      "chunk_id": "manager.py:chunk_2",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "b3fafcb0a3b20209873c6918296f58c3f8efed6b080d25517f08060924d290e4",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a service manager class responsible for registering, connecting, and disconnecting various services asynchronously within an application.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self._services`) to store service instances keyed by their names.  \n- Maintains a connection pool (`self._connection_pool`) with timestamps to track active connections.  \n- Employs asynchronous programming (`async def`) to handle potentially long-running service connection/disconnection operations without blocking.  \n- Logging is used extensively for monitoring service registration and connection lifecycle events.  \n- Exception handling wraps service operations to catch and log errors, and to update service error states via a `_set_error` method on the service object.\n\n3. **Business Logic**:  \nEnables dynamic management of backend or external services by allowing the application to register services, establish connections, and disconnect from them as needed. This supports modularity and flexibility in integrating multiple service providers or microservices, improving maintainability and operational control.\n\n4. **Dependencies**:  \n- Uses Python\u2019s built-in `logging` module (implied by `logger`).  \n- Relies on asynchronous features from `asyncio` or similar async frameworks (implied by `async def` and `await`).  \n- Services are expected to implement `connect()` and `_set_error()` methods, indicating a service interface or base class dependency.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:24.860157",
      "status": "summarized"
    },
    "manager.py:chunk_4": {
      "chunk_id": "manager.py:chunk_4",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "f4f42be930e53077dbcc5bb56afbfc0ceea3b8a3d1488e7141b4584432ee9f6c",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous service manager responsible for managing connections to various services and executing actions on them, optionally enhanced by a Large Language Model (LLM).\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running I/O operations without blocking.  \n- Maintains a `_connection_pool` dictionary to track active service connections keyed by service name.  \n- Uses a `_services` dictionary to store service instances.  \n- Implements a method `execute_with_llm` that ensures a service is connected before executing an action, optionally enhancing the action parameters using an LLM wrapper.  \n- Employs a try-except block to catch and log exceptions during service disconnection and action execution.  \n- Uses a status check (`service.status != ServiceStatus.CONNECTED`) to verify connection state before proceeding.\n\n3. **Business Logic**:  \nEnables reliable interaction with external or internal services by managing their connection lifecycle and augmenting service actions with AI-driven enhancements (via LLM), improving the quality or intelligence of service responses.\n\n4. **Dependencies**:  \n- Assumes existence of:  \n  - `service.disconnect()` and `service.status` properties/methods.  \n  - `ServiceStatus` enum or class for connection states.  \n  - A logging mechanism (`logger`).  \n  - An LLM wrapper accessible via `_get_llm_wrapper()`.  \n- Likely",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:32.539819",
      "status": "summarized"
    },
    "manager.py:chunk_6": {
      "chunk_id": "manager.py:chunk_6",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "67a1ec3138e943938cc4a5713b541a10c488ba36c152625313c4fbc4122b05ba",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet enhances and executes a service action by optionally leveraging a Large Language Model (LLM) wrapper to improve query parameters and interpret the service response, thereby enriching the interaction with AI-driven insights.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially long-running I/O operations without blocking.  \n- Constructs an `LLMServiceContext` data structure encapsulating service metadata, action, input parameters, and capabilities for interaction with the LLM wrapper.  \n- Applies a two-step LLM integration pattern: first to enhance the input query parameters (`enhance_query`), then optionally to interpret the service response (`interpret_response`).  \n- Uses dictionary operations to update parameters and embed LLM-generated insights into the result.  \n- Logging is used to track when enhancements occur.\n\n3. **Business Logic**:  \nThe code aims to improve the quality and relevance of service actions by augmenting input parameters and interpreting outputs through AI, which can lead to smarter, context-aware service execution. This is useful in scenarios where dynamic query refinement and response understanding add business value, such as personalized recommendations, automated decision-making, or complex data retrieval.\n\n4. **Dependencies**:  \n- An asynchronous `service` object exposing `get_capabilities()` and `execute()` methods.  \n- An `llm_wrapper` object providing `enhance_query()` and `interpret_response()` asynchronous methods.  \n- `LLMServiceContext`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:41.057702",
      "status": "summarized"
    },
    "manager.py:chunk_8": {
      "chunk_id": "manager.py:chunk_8",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "d217e6450c87cc26fb74cebbe48613ef0d8abfb48c25dfecfb76d37014b8119c",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a service manager responsible for executing service actions, handling errors (including enhanced analysis via an LLM), retrieving statuses of all registered services, and cleaning up stale connections.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially I/O-bound operations without blocking.  \n- Maintains a dictionary `_services` mapping service names to service instances.  \n- Implements error handling with logging and optional integration with a large language model (LLM) wrapper for enhanced error analysis.  \n- Uses Python standard libraries such as `datetime` and `timedelta` for time-based operations (e.g., identifying stale connections).  \n- Returns structured dictionaries indicating success or failure of operations, including detailed error analysis when available.\n\n3. **Business Logic**:  \n- Facilitates centralized management and monitoring of multiple backend services by providing status aggregation and cleanup of unused resources.  \n- Enhances operational reliability by analyzing errors with an LLM, potentially improving troubleshooting and reducing downtime.  \n- Helps maintain system health by cleaning up stale connections, preventing resource leaks or performance degradation.\n\n4. **Dependencies**:  \n- `logger` for error logging (likely Python\u2019s `logging` module or a configured logger).  \n- `llm_wrapper` for large language model-based error analysis (an external or internal AI service wrapper).  \n- Python standard libraries: `datetime`, `timedelta`, `asyncio` (",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:47.603882",
      "status": "summarized"
    },
    "manager.py:chunk_10": {
      "chunk_id": "manager.py:chunk_10",
      "file_path": "shared\\services\\manager.py",
      "chunk_hash": "505cac8270a3a381bb212af90338f735a896fe79acbd6b01f2ecdb273574ba4b",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a service manager responsible for maintaining and managing connections to various services, including cleaning up stale connections and providing access to registered services.\n\n2. **Technical Details**:  \n- Uses a dictionary `_connection_pool` to track service connections with their last used timestamps.  \n- Identifies stale connections by comparing last used times against a cutoff timestamp.  \n- Asynchronously disconnects stale services via `disconnect_service`.  \n- Maintains a `_services` dictionary mapping service names to service instances (`BaseService` or subclasses).  \n- Provides synchronous methods to retrieve a service instance (`get_service`) and list all registered service names (`list_services`).  \n- Implements a singleton-like global instance `service_manager` for centralized service management.\n\n3. **Business Logic**:  \nEnsures efficient resource utilization by cleaning up unused or stale service connections, preventing resource leaks and potential performance degradation. It also provides a centralized registry to access and manage multiple service instances, facilitating modular and maintainable service orchestration.\n\n4. **Dependencies**:  \n- Relies on an asynchronous environment (e.g., `asyncio`) for `await` usage in `disconnect_service`.  \n- Uses a logger instance (`logger`) for informational logging.  \n- Depends on `BaseService` as a base class for service instances.  \n- Uses Python standard typing (`Optional`, `List`) for type hints.\n\n5. **Configuration**:  \nNo explicit environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:52.502183",
      "status": "summarized"
    },
    "parser.py:chunk_0": {
      "chunk_id": "parser.py:chunk_0",
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "chunk_hash": "bb5ac26f1e7a20207f38e4349c5ad89029c2f12d7bc1a320b3c055e861ebde56",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration\\message_parser\\implementations\\parser.py`**\n\n---\n\n1. **Purpose**  \n   This module implements a message parser that extracts structured references such as URLs, ticket IDs, and issue numbers from raw user messages. It is designed to identify and categorize references to GitHub issues, Jira tickets, and Confluence pages embedded in text.\n\n2. **Technical Details**  \n   - Uses regular expressions (`re.compile`) to detect patterns corresponding to different reference types (GitHub issues, Jira URLs and tickets, Confluence URLs).  \n   - Employs a class-based design (`MessageParser` implementing `IMessageParser` interface) to encapsulate parsing logic.  \n   - Integrates a specialized extractor (`GitHubExtractor`) for enhanced GitHub issue extraction beyond simple regex matching.  \n   - Uses typed collections (`Dict`, `List`) and type hints for clarity and maintainability.  \n   - Leverages Python\u2019s `logging` module for internal diagnostics and error reporting.  \n   - Uses `urlparse` from `urllib.parse` for URL parsing (though not shown fully in snippet, implied by import).\n\n3. **Business Logic**  \n   The parser automates the extraction of references to development artifacts (issues, tickets, documentation pages) from user-generated messages, enabling downstream systems to link, track, or process these references automatically. This supports workflows in software development, project management, and documentation by bridging communication and tooling.\n\n4. **Dependencies**",
      "embedding_id": null,
      "created_at": "2025-10-22T18:39:59.012975",
      "status": "summarized"
    },
    "parser.py:chunk_2": {
      "chunk_id": "parser.py:chunk_2",
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "chunk_hash": "688a3b2cef02531a3a706f1031f458549d334ac2542db9d57aa50f3709ed4583",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method `parse` processes a raw user message string to identify and extract various types of references such as GitHub URLs, GitHub issues, Jira URLs and tickets, and Confluence URLs, returning a structured `ParsedMessage` object containing these references.\n\n2. **Technical Details**:  \n- Uses regular expressions (regex) for pattern matching URLs and ticket identifiers.  \n- Employs multiple specialized extractor methods (`github_extractor.extract`, `_extract_github_issues`, `_extract_jira_urls`, `_extract_jira_tickets`, `_extract_confluence_urls`) to modularize extraction logic by reference type.  \n- Aggregates extracted references into a list of `Reference` objects, each presumably tagged with a `ReferenceType` enum for classification.  \n- Uses asynchronous programming (`async def`) to potentially integrate with async workflows or I/O operations.  \n- Logging is integrated at info and debug levels with contextual metadata (e.g., message length, counts of extracted references by type).\n\n3. **Business Logic**:  \nEnables automated parsing and identification of key references embedded in user messages, facilitating downstream workflows such as issue tracking, documentation linking, and project management integrations. This supports business processes that rely on linking communication content to development and project artifacts.\n\n4. **Dependencies**:  \n- Python `re` module for regex operations.  \n- Custom classes and enums such as `ParsedMessage`, `Reference`, and `ReferenceType`.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:07.819782",
      "status": "summarized"
    },
    "parser.py:chunk_4": {
      "chunk_id": "parser.py:chunk_4",
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "chunk_hash": "3949bc55dccc5230cc7e5019dc521822bceecd8b41b479a81680dbf157357f17",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a message parsing module that identifies and extracts various types of references (e.g., Jira tickets, Confluence URLs, GitHub issues) from a given text message, replaces the raw references with standardized placeholders, and returns a structured parsed message object.\n\n2. **Technical Details**:  \n- Uses list comprehensions to filter and count references by type.  \n- Iterates over extracted references to replace raw text in the original message with a normalized placeholder format (e.g., `[JIRA_TICKET]`).  \n- Utilizes regex pattern matching (`self.patterns[ReferenceType.GITHUB_ISSUE].finditer`) to identify GitHub issue references in the message.  \n- Constructs `Reference` objects containing type, raw text, and normalized value for each detected reference.  \n- Returns a `ParsedMessage` data structure encapsulating the original message, list of references, cleaned message, and metadata such as total references count.  \n- Logging is used to record the completion of parsing with contextual information.\n\n3. **Business Logic**:  \nThe code supports automated extraction and normalization of issue tracking and documentation references embedded in communication messages. This facilitates better traceability, linking, and integration with project management tools like Jira, Confluence, and GitHub, improving collaboration and workflow automation.\n\n4. **Dependencies**:  \n- Custom types and classes such as `ReferenceType`, `Reference`, and `ParsedMessage` (likely defined",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:11.852322",
      "status": "summarized"
    },
    "parser.py:chunk_6": {
      "chunk_id": "parser.py:chunk_6",
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "chunk_hash": "8024001a9ebe7f2e084fabab376fbb94ee1684c3a109d34637b61e2d9da02003",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a message parser that extracts references to Jira issues from text messages. It identifies Jira URLs and Jira ticket IDs within a given message and returns structured reference objects representing these findings.\n\n2. **Technical Details**:  \n- Uses regular expressions stored in `self.patterns` keyed by `ReferenceType` enums to find matches in the input message.  \n- Iterates over regex matches using `finditer()` to extract relevant substrings.  \n- Constructs `Reference` objects containing the type of reference (Jira URL or ticket), raw matched text, normalized ticket ID, metadata dictionary, and a confidence score.  \n- Deduplicates Jira ticket IDs within the same message to avoid repeated references.  \n- Returns lists of `Reference` objects for further processing.\n\n3. **Business Logic**:  \nThe code supports automated extraction of Jira issue references from unstructured text (e.g., chat messages, commit messages, emails). This enables downstream systems to link conversations or commits to specific Jira tickets, improving traceability, issue tracking, and integration between communication and project management tools.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regex operations (implied by usage of `finditer()`).  \n- Custom types: `Reference`, `ReferenceType` (likely enums or classes defined elsewhere in the codebase).  \n- Possibly part of a larger orchestration or message parsing framework (based on file path).",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:19.002416",
      "status": "summarized"
    },
    "parser.py:chunk_8": {
      "chunk_id": "parser.py:chunk_8",
      "file_path": "orchestration\\message_parser\\implementations\\parser.py",
      "chunk_hash": "698121ed8bc8fd0e50df4d593b157a2025f7a5c296ccc6db5c7ba8ffdba95e4a",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a method `_extract_confluence_urls` that parses a given text message to identify and extract Confluence URL references, returning them as structured `Reference` objects with detailed metadata.\n\n2. **Technical Details**:  \n- Uses regular expressions (`self.patterns[ReferenceType.CONFLUENCE_URL].finditer`) to scan the input string for matches corresponding to Confluence URLs.  \n- Extracts groups from regex matches representing `space_key`, `page_id`, and `page_title`.  \n- Constructs a list of `Reference` objects, each encapsulating the type, raw matched text, a normalized identifier (`page_id`), metadata dictionary, and a confidence score (set to 1.0).  \n- The `page_title` is normalized by replacing hyphens with spaces.  \n- The method returns a list of these `Reference` instances.\n\n3. **Business Logic**:  \nThis method supports the business need to automatically detect and extract references to Confluence pages embedded in user messages or documents, enabling downstream processes such as linking, indexing, or content enrichment based on these references.\n\n4. **Dependencies**:  \n- Relies on a `Reference` data structure/class and a `ReferenceType` enum or similar construct to categorize references.  \n- Uses precompiled regex patterns stored in `self.patterns` keyed by `ReferenceType.CONFLUENCE_URL`.  \n- Python standard library modules such as `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:22.785738",
      "status": "summarized"
    },
    "App.tsx:chunk_0": {
      "chunk_id": "App.tsx:chunk_0",
      "file_path": "frontend\\src\\App.tsx",
      "chunk_hash": "2656673fdb538f8fb36bcd52de99f7133e614152ed10a9c96f57ae85056561c0",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component serves as the main application container for a frontend UI, managing navigation between different feature panels via a tab-based interface.\n\n2. **Technical Details**:  \n- Utilizes React hooks (`useState`, `useEffect`) for state management and lifecycle events.  \n- Defines a `Tab` type union for strict typing of active tabs.  \n- Implements a tab switching handler that updates state and logs tab changes.  \n- Conditional rendering is used to display different panels based on the active tab.  \n- Layout is structured using CSS utility classes (likely Tailwind CSS) for responsive flexbox design.\n\n3. **Business Logic**:  \nEnables users to switch between multiple functional areas of the application (Voice Assistant, LLM testing, Integrations Hub, Document Orchestrator), supporting workflows related to AI interaction, integrations management, and document processing.\n\n4. **Dependencies**:  \n- React (core library for UI)  \n- Custom components: `Sidebar`, `Header`, `LLMTestPanel`, `IntegrationsHub`, `DocOrchestratorPanel`, `VoiceAssistantPanel`, `LogViewer`  \n- A custom `logger` utility for UI event logging\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are referenced within this snippet.\n\n6. **Error Handling**:  \nNo explicit error handling or exception management is implemented in this component.\n\n7. **API/Interface**:  \n- Public interface",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:31.937957",
      "status": "summarized"
    },
    "App.tsx:chunk_2": {
      "chunk_id": "App.tsx:chunk_2",
      "file_path": "frontend\\src\\App.tsx",
      "chunk_hash": "21210608a543fa307c8e44dcc63ef8a4a43ce80dcb8cc1c01f372faf648fe056",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component (`App`) renders the main user interface of a frontend application, conditionally displaying different panels (`IntegrationsHub`, `LLMTestPanel`, `DocOrchestratorPanel`) based on application state, and includes a persistent `LogViewer` component.\n\n2. **Technical Details**:  \n- Uses conditional rendering to switch between components based on the `activeTab` state and other conditions (not fully shown here).  \n- Employs React functional component structure with JSX for UI composition.  \n- Layout uses Tailwind CSS utility classes (`max-w-7xl`, `mx-auto`, `px-6`, `py-8`, `h-full`, `overflow-y-auto`) for responsive styling and scrollable content areas.\n\n3. **Business Logic**:  \n- Supports different operational modes or features via tabs: a Large Language Model testing panel (`LLMTestPanel`), a document orchestration panel (`DocOrchestratorPanel`), and an integrations hub (`IntegrationsHub`).  \n- Enables users to interact with and manage integrations or test AI models and document workflows, addressing business needs around AI experimentation and document management.\n\n4. **Dependencies**:  \n- React library for UI rendering.  \n- Tailwind CSS for styling.  \n- Custom components: `IntegrationsHub`, `LLMTestPanel`, `DocOrchestratorPanel`, `LogViewer` (likely imported from local modules).  \n- No explicit external",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:39.361645",
      "status": "summarized"
    },
    "integrations.ts:chunk_0": {
      "chunk_id": "integrations.ts:chunk_0",
      "file_path": "frontend\\src\\types\\integrations.ts",
      "chunk_hash": "df4be260de50af50ffc1d959f446464064c68584d949bf944641d2895f171d46",
      "chunk_index": 0,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis TypeScript module defines type aliases and interfaces to model integration services and their configurations within a frontend application. It standardizes how different third-party services (e.g., version control, monitoring, AI providers) are described, configured, and tested.\n\n2. **Technical Details**:  \n- Uses TypeScript union types (`ServiceCategory`, `FieldType`, `AuthType`) to constrain allowed values for service categories, configuration field types, and authentication methods.  \n- Defines interfaces (`ConfigField`, `TestAction`, `ServiceDefinition`, `ServiceConfig`, `CategoryInfo`) to represent structured data for service metadata, configuration fields, authentication, and testing actions.  \n- Uses a `Record` type (`CATEGORIES`) to map service categories to descriptive metadata objects, enabling easy lookup and UI rendering.\n\n3. **Business Logic**:  \nEnables a consistent and extensible framework for integrating various external services into the platform. This supports business needs such as connecting to version control systems, issue trackers, cloud providers, or AI services with standardized configuration and authentication flows, facilitating service management and operational monitoring.\n\n4. **Dependencies**:  \nNo external libraries or modules are imported or referenced in this snippet; it is a pure type definition module intended for use within a larger TypeScript React or frontend codebase.\n\n5. **Configuration**:  \nNo environment variables or runtime configuration are handled here; this file purely defines static types and constants to be used",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:44.117621",
      "status": "summarized"
    },
    "integrations.ts:chunk_2": {
      "chunk_id": "integrations.ts:chunk_2",
      "file_path": "frontend\\src\\types\\integrations.ts",
      "chunk_hash": "32248886e1d62333aae24e8db87a97885f7ac08edbba11353626cc652706e561",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines a structured collection of integration categories used in a frontend application, each representing a type of external system or service (e.g., version control, issue tracking, cloud platforms) with associated metadata such as ID, display name, description, and icon.\n\n2. **Technical Details**:  \n- The code uses a plain object (likely a constant) where each key corresponds to an integration category.  \n- Each category is an object containing four string properties: `id`, `name`, `description`, and `icon`.  \n- The structure is static and declarative, serving as a centralized type or configuration for integration categories.  \n- No algorithms or complex data structures are present; it is essentially a typed dictionary or map.\n\n3. **Business Logic**:  \n- Provides a standardized taxonomy of integration types to categorize and display various external tools and services within the application.  \n- Facilitates consistent UI representation (via icons and descriptions) and potentially drives logic for integration management, selection, or filtering in the frontend.\n\n4. **Dependencies**:  \n- No explicit external libraries or modules are referenced in this snippet.  \n- The `icon` values suggest usage of an icon library or component set (e.g., React icons or a custom icon system), but this is not shown here.\n\n5. **Configuration**:  \n- No environment variables or external configuration files are involved.  \n- The data is hardcoded and likely imported as",
      "embedding_id": null,
      "created_at": "2025-10-22T18:40:50.921921",
      "status": "summarized"
    },
    "metrics.py:chunk_0": {
      "chunk_id": "metrics.py:chunk_0",
      "file_path": "observability\\metrics.py",
      "chunk_hash": "a9c3eff5e9cb38c08f0b838cdecd81f3d0240ffe04ad3f2bd6d1929ff4e6eec0",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `Metrics` class that encapsulates Prometheus metrics for monitoring various aspects of an AI development agent's operations, such as issue analysis, fix generation, PR creation, and LLM API usage.\n\n2. **Technical Details**:  \n- Uses Prometheus client library metric types: `Counter`, `Histogram`, and `Gauge`.  \n- Metrics are labeled with dimensions like `source`, `severity`, `repository`, and `operation` to enable detailed filtering and aggregation.  \n- Histogram buckets are explicitly defined for measuring analysis duration with fine granularity.  \n- Encapsulated within a class for organized metric management.\n\n3. **Business Logic**:  \nEnables observability and operational insights into the AI development agent\u2019s workflow by tracking key performance indicators such as the number of issues analyzed, fixes generated, PRs created, duration of analysis, and LLM API calls. This supports monitoring, alerting, and capacity planning.\n\n4. **Dependencies**:  \n- `prometheus_client`: For defining and exposing metrics.  \n- `fastapi.Response`: Imported but not used in the snippet; likely for serving metrics via HTTP in the broader application.  \n- `logging`: For logging purposes, though no logging calls are present in this snippet.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. Metric names and labels are hardcoded. Configuration of Prometheus scraping (endpoint exposure) is presumably",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:00.496091",
      "status": "summarized"
    },
    "metrics.py:chunk_2": {
      "chunk_id": "metrics.py:chunk_2",
      "file_path": "observability\\metrics.py",
      "chunk_hash": "3cb8559c8ca33a62e2407eb8a83a537138c5a75a9ce10be3df20a30137c2d72a",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines a metrics tracking component that records various operational events (issues analyzed, fixes generated, PRs created, LLM calls) and exposes these metrics in a format suitable for Prometheus monitoring.\n\n2. **Technical Details**:  \n- Uses labeled counters (`self.issues_analyzed.labels(...)`, etc.) to increment counts for different event types.  \n- The `get_metrics` method returns the current metrics in Prometheus exposition format using `generate_latest()`.  \n- The code snippet appears to be part of a class (likely `Metrics`) that encapsulates Prometheus metric counters as attributes.  \n- Uses `Response` and `CONTENT_TYPE_LATEST` to format the HTTP response for metrics scraping.\n\n3. **Business Logic**:  \nEnables observability into key business operations such as issue analysis, fix generation, pull request creation, and calls to large language models (LLMs). This helps monitor system usage, performance, and operational health, supporting data-driven decision making and alerting.\n\n4. **Dependencies**:  \n- Prometheus client library (for counters and `generate_latest`)  \n- A web framework providing `Response` and `CONTENT_TYPE_LATEST` (likely FastAPI or Starlette)  \n- A logger instance for informational logging\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet. Metric labels like `source`, `severity`, `repository`, and `operation`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:06.820800",
      "status": "summarized"
    },
    "agent.py:chunk_0": {
      "chunk_id": "agent.py:chunk_0",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "904ab184d0d1e3ee0af2d86c8c51d092dd223b05202bec4e30fafd655f85f21b",
      "chunk_index": 0,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines the `LangGraphAgent` class, an implementation of the `ILangGraphAgent` interface, responsible for orchestrating and executing tasks by leveraging large language models (LLMs) within a workflow-driven environment.\n\n2. **Technical Details**:  \n- Implements a class-based design pattern adhering to an interface (`ILangGraphAgent`) for abstraction and extensibility.  \n- Uses dependency injection for `ServiceManager` and optionally an `LLMFactory` to manage external service integrations and LLM instantiation.  \n- Initializes an LLM client dynamically based on configuration, supporting multiple LLM providers (defaulting to \"azure\").  \n- Employs structured data models (`EnrichedContext`, `AgentTask`, `ContextSourceType`) to represent task context and workflow state.  \n- Uses Python\u2019s standard logging for traceability and debugging.\n\n3. **Business Logic**:  \nThe agent coordinates complex task executions that require natural language understanding and generation, enabling automated workflows powered by LLMs. This supports business scenarios such as intelligent automation, decision-making assistance, or conversational agents that integrate multiple services.\n\n4. **Dependencies**:  \n- Python standard libraries: `logging`, `typing`, `datetime`, `uuid`.  \n- Internal modules:  \n  - `orchestration.shared.interfaces.ILangGraphAgent` (interface contract)  \n  - `orchestration.shared.models` (data models for context and tasks)",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:11.813003",
      "status": "summarized"
    },
    "agent.py:chunk_2": {
      "chunk_id": "agent.py:chunk_2",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "161720652f8a1e1fe5d387002348fa194058f7118f986e9771f540b96bcda86b",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an agent implementation that manages and executes asynchronous tasks, specifically designed to handle different types of agent tasks such as code analysis. It initializes API configurations for various AI service providers and maintains a registry of tasks being executed.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def execute`) to allow non-blocking task execution.  \n- Maintains a dictionary (`self.task_registry: Dict[str, AgentTask]`) to track tasks by their unique IDs.  \n- Uses structured logging to capture task metadata at the start of execution.  \n- Conditional logic to branch execution based on `task.task_type` (e.g., `\"code_analysis\"`).  \n- Configuration parameters for Azure OpenAI and Together AI models are injected via a `settings` object, supporting fallback defaults.\n\n3. **Business Logic**:  \nEnables an orchestration layer that can execute various AI-driven tasks (like code analysis) asynchronously, allowing integration with multiple AI service providers. This supports business needs for scalable, flexible AI task execution pipelines that can handle different AI models and deployment environments.\n\n4. **Dependencies**:  \n- Azure OpenAI services (via endpoint, API key, deployment name, API version).  \n- Together AI API (via API key and model name).  \n- Presumably a logging framework (`logger`) for structured logs.  \n- A custom `AgentTask` class/type representing tasks.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:18.017890",
      "status": "summarized"
    },
    "agent.py:chunk_4": {
      "chunk_id": "agent.py:chunk_4",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "4241d0f35962233b7428250e1da455bbcc5910ed1bca12efc0cada10837cac0d",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet handles the execution of various task types within an agent component, processing tasks such as code analysis, bug diagnosis, documentation generation, and code generation, then updating the task status and logging the outcome.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to execute task-specific methods based on the `task.task_type`.  \n- Implements a conditional dispatch pattern to route tasks to the appropriate handler method (`_execute_code_analysis`, `_execute_bug_diagnosis`, etc.).  \n- Updates task metadata including status, result, and completion timestamp (`datetime.utcnow()`).  \n- Uses structured logging with contextual information (`task_id`, `task_type`, `status`, `error`).  \n- Exception handling wraps the entire execution block to catch and log any errors, marking the task as failed.\n\n3. **Business Logic**:  \nEnables an orchestration agent to process diverse software engineering-related tasks automatically, improving developer productivity by automating code analysis, bug diagnosis, documentation, and code generation workflows.\n\n4. **Dependencies**:  \n- Python's `datetime` module for timestamps.  \n- An asynchronous runtime (e.g., `asyncio`) implied by `await`.  \n- A logging framework supporting structured logs with `logger.info` and `logger.error`.  \n- Internal task objects with attributes like `task_type`, `status`, `result`, `error`, and `completed_at`.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:25.575876",
      "status": "summarized"
    },
    "agent.py:chunk_6": {
      "chunk_id": "agent.py:chunk_6",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "8f6b5e1a91616ca19b2102a4e5cb42a0b8c76166a628bb187ea81e2d3734cf9b",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method `plan_tasks` generates a list of actionable tasks based on an enriched context and a user's intent, facilitating automated task planning within an agent orchestration system.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to support non-blocking operations.  \n- Accepts an `EnrichedContext` object containing multiple `context_items`, each with a `source_type`.  \n- Checks for the presence of specific context sources (GitHub repositories/issues and Jira issues) using Python's `any()` function and list comprehensions.  \n- Converts the user intent string to lowercase for case-insensitive processing.  \n- Logs the start of the task planning process with contextual metadata using a structured logger.\n\n3. **Business Logic**:  \nThe method supports intelligent task planning by analyzing the user's intent alongside enriched contextual data from multiple sources (e.g., GitHub, Jira). This enables the orchestration agent to tailor task generation based on relevant project management and code repository information, improving automation in software development workflows.\n\n4. **Dependencies**:  \n- `EnrichedContext` and `AgentTask` classes/types (likely defined elsewhere in the codebase).  \n- `ContextSourceType` enum or constants defining source types such as `GITHUB_REPOSITORY`, `GITHUB_ISSUE`, and `JIRA_ISSUE`.  \n- A logging framework supporting structured logging with `extra` metadata.  \n- Python's standard",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:32.802301",
      "status": "summarized"
    },
    "agent.py:chunk_8": {
      "chunk_id": "agent.py:chunk_8",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "7111a37ce7dcaab690052239ca559dfafdfd7d7e894380e1539fc93ff07942ef",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet dynamically creates a list of tasks for an agent based on the detected intent keywords in a given input. It maps intent indicators to specific task types such as bug diagnosis, documentation generation, code generation, and code analysis.\n\n2. **Technical Details**:  \n- Uses conditional checks on a lowercase string `intent_lower` to identify keywords.  \n- For each matched intent, it appends an `AgentTask` object to a `tasks` list.  \n- Each `AgentTask` is instantiated with a unique `task_id` generated via `uuid.uuid4()`, a `task_type` string, a descriptive text, a shared `enriched_context` object, and optional parameters (e.g., `include_tests`, `format`).  \n- The design follows a simple rule-based intent-to-task mapping pattern.\n\n3. **Business Logic**:  \nThe code automates the orchestration of development-related tasks by interpreting user or system intents and generating corresponding actionable tasks. This supports workflows such as bug fixing, documentation creation, code implementation, and code review, thereby streamlining software development processes.\n\n4. **Dependencies**:  \n- Python standard library: `uuid` for generating unique task IDs.  \n- Custom class/module: `AgentTask` (likely defined elsewhere in the codebase).  \n- Assumes `enriched_context` is prepared prior to this snippet.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:44.810455",
      "status": "summarized"
    },
    "agent.py:chunk_10": {
      "chunk_id": "agent.py:chunk_10",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "44fbd054811f96557917c7dc5f9512b3dd30488f356a47afac9972e0ed005419",
      "chunk_index": 10,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an agent implementation that plans and executes code analysis tasks by leveraging a large language model (LLM) to provide insights such as code quality, bugs, improvements, and security considerations.\n\n2. **Technical Details**  \n- Uses an asynchronous method `_execute_code_analysis` to perform code analysis tasks.  \n- Constructs a prompt dynamically by formatting the task context for the LLM.  \n- Calls an LLM client\u2019s `chat_completion` method asynchronously to get analysis results.  \n- Uses a list of `AgentTask` objects to represent discrete units of work, each with attributes like `task_id`, `task_type`, `description`, and `context`.  \n- Employs UUIDs to generate unique task identifiers.  \n- Logs task planning details with structured logging including the number and types of tasks planned.\n\n3. **Business Logic**  \nThe code supports an automated agent that assists developers or users by analyzing code snippets or contexts and providing actionable insights. This helps improve code quality, identify bugs early, and enhance security, thereby reducing manual code review effort and accelerating development cycles.\n\n4. **Dependencies**  \n- `uuid` module for generating unique task IDs.  \n- An asynchronous LLM client (likely Azure OpenAI or similar) for natural language processing and code analysis.  \n- A logging framework for structured logging.  \n- Custom classes such as `AgentTask` and possibly helper methods like `_format_context_for_llm`.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:49.476708",
      "status": "summarized"
    },
    "agent.py:chunk_12": {
      "chunk_id": "agent.py:chunk_12",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "0a62552e10077be228a16026ff81fdc01ac5d181d67c81bfa416d6401b5d4cf9",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code defines asynchronous methods within an agent implementation to automate two distinct tasks using a large language model (LLM): diagnosing software bugs and generating documentation based on provided context.\n\n2. **Technical Details**:  \n- Both methods construct detailed prompts incorporating contextual information formatted via a helper method `_format_context_for_llm`.  \n- They use an asynchronous call to `self.llm_client.chat_completion` to interact with an LLM service (defaulting to Azure).  \n- The methods return structured dictionaries containing the LLM's response and metadata about the task type or output format.  \n- The design follows an asynchronous programming model suitable for I/O-bound operations, leveraging Python\u2019s `async/await` syntax.\n\n3. **Business Logic**:  \n- Automates root cause analysis and remediation suggestions for bugs, reducing manual debugging effort.  \n- Generates comprehensive, formatted documentation to improve developer onboarding, API usability, and maintenance.  \n- Both features aim to accelerate software development lifecycle and improve code quality through AI-assisted automation.\n\n4. **Dependencies**:  \n- An LLM client (`self.llm_client`), likely an abstraction over Azure OpenAI or similar services, providing `chat_completion` API.  \n- The `AgentTask` data structure, which encapsulates task context and parameters.  \n- Python\u2019s asynchronous programming features (`async def`, `await`).\n\n5. **Configuration**:  \n- The LLM client is configured externally, with Azure as the",
      "embedding_id": null,
      "created_at": "2025-10-22T18:41:56.736833",
      "status": "summarized"
    },
    "agent.py:chunk_14": {
      "chunk_id": "agent.py:chunk_14",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "e3ea95433eb53c8e5e7de6440c34a7a2fc51c60eb071bee04acbd5687d465fb0",
      "chunk_index": 14,
      "summary": "1. **Purpose**  \nThis Python code defines asynchronous methods within an agent implementation to execute different types of tasks\u2014specifically code generation and generic tasks\u2014by interacting with a configured large language model (LLM) client to generate responses based on provided context and descriptions.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle potentially long-running LLM calls without blocking.  \n- Constructs prompts dynamically by formatting task context and descriptions into natural language instructions for the LLM.  \n- Invokes an LLM client\u2019s `chat_completion` method, passing a user-role message containing the prompt.  \n- Returns structured dictionaries containing the LLM response and a task type identifier.  \n- Employs a helper method `_format_context_for_llm` (not shown) to prepare context data for prompt inclusion.\n\n3. **Business Logic**  \nEnables automated task execution by leveraging AI-generated content, specifically:  \n- Generating complete, commented, and example-illustrated code snippets based on requirements.  \n- Handling generic tasks that require comprehensive responses based on contextual information.  \nThis supports business workflows that need scalable, AI-driven content or code generation to accelerate development or documentation processes.\n\n4. **Dependencies**  \n- An asynchronous LLM client interface (`self.llm_client`) configured to use Azure by default, likely wrapping an Azure OpenAI or similar service.  \n- The `AgentTask` data structure, which encapsulates task details such as `description` and `context",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:04.301321",
      "status": "summarized"
    },
    "agent.py:chunk_16": {
      "chunk_id": "agent.py:chunk_16",
      "file_path": "orchestration\\langgraph_agent\\implementations\\agent.py",
      "chunk_hash": "503ee25ad5afd3234192b0a994ee7be3a39146276c60379782237da225fe4529",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis code provides utility methods within an agent implementation to format enriched conversational context into a string suitable for prompting a large language model (LLM) and to retrieve the status of asynchronous tasks managed by the agent.\n\n2. **Technical Details**:  \n- `_format_context_for_llm` constructs a formatted string by concatenating the original user message and any additional enriched context items. It iterates over a list of context items, appending their source type and data in a readable format.  \n- `get_task_status` accesses a task registry (likely a dictionary or similar mapping) to fetch the current status of a task by its unique identifier.  \n- Uses simple list appending and string joining for efficient string construction.\n\n3. **Business Logic**:  \n- The formatting method prepares contextual information to enhance the prompt sent to an LLM, improving the relevance and accuracy of AI-generated responses.  \n- The task status retrieval supports monitoring and managing asynchronous or long-running operations within the agent, enabling status tracking and potentially informing user feedback or workflow control.\n\n4. **Dependencies**:  \n- Relies on the `EnrichedContext` type, which encapsulates the parsed user message and context items.  \n- Uses `AgentTask` type for task status representation.  \n- Assumes existence of `self.task_registry`, a data structure managing task states.  \n- No explicit external libraries are shown in this snippet.\n\n5. **Configuration**:  \n- No direct",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:11.741953",
      "status": "summarized"
    },
    "interfaces.py:chunk_0": {
      "chunk_id": "interfaces.py:chunk_0",
      "file_path": "orchestration\\shared\\interfaces.py",
      "chunk_hash": "fab91116e4f82421cda39ce33845e33c48535d51aabeaa317631565779018040",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines abstract base interfaces for core orchestration components involved in processing user messages, enriching context, and building prompts within a modular orchestration system.\n\n2. **Technical Details**:  \n- Uses Python\u2019s `abc` module to define abstract base classes (ABCs) enforcing implementation of asynchronous methods (`async def`) in subclasses.  \n- Defines three interfaces: `IMessageParser`, `IContextEnricher`, and `IPromptBuilder` (partially shown), each with a single abstract async method.  \n- Method signatures use type hints with custom domain models (`ParsedMessage`, `EnrichedContext`, etc.) imported from `orchestration.shared.models`.  \n- The design follows the Dependency Inversion Principle by programming against interfaces, enabling flexible and testable implementations.\n\n3. **Business Logic**:  \nThese interfaces formalize the contract for components that:  \n- Parse raw user messages to extract meaningful references or intents.  \n- Enrich parsed data with additional context from external data sources or services.  \n- Build formatted prompts for downstream processing (e.g., AI agents, workflows).  \nThis modular approach supports complex conversational or task orchestration scenarios in business domains requiring dynamic context handling and prompt generation.\n\n4. **Dependencies**:  \n- Python standard library: `abc` for abstract classes, `typing` for type annotations.  \n- Internal module: `orchestration.shared.models` providing domain-specific data models (`ParsedMessage`, `En",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:18.370979",
      "status": "summarized"
    },
    "interfaces.py:chunk_2": {
      "chunk_id": "interfaces.py:chunk_2",
      "file_path": "orchestration\\shared\\interfaces.py",
      "chunk_hash": "50b89d90500c5ed12aeec9ae8138bf52dc69a74622cb984f6b736f724502392a",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines abstract interfaces for components involved in orchestrating language model-driven agents. It specifies contracts for building prompts from enriched context and for a LangGraph agent that plans and executes tasks asynchronously.\n\n2. **Technical Details**:  \n- Uses Python's Abstract Base Classes (`ABC`) and `@abstractmethod` decorators to enforce interface implementation.  \n- Defines asynchronous methods (`async def`) for non-blocking task execution and planning.  \n- Methods accept enriched context objects and user intents to generate tasks and formatted prompts.  \n- Returns domain-specific types like `FormattedPrompt` and `AgentTask`, indicating a structured approach to prompt and task management.\n\n3. **Business Logic**:  \nEnables modular, extensible orchestration of AI-driven workflows by abstracting prompt construction and agent task management. This supports business scenarios requiring dynamic task planning and execution based on user intent and contextual data, such as automated customer support, intelligent assistants, or workflow automation.\n\n4. **Dependencies**:  \n- Python standard library modules: `abc` for abstract base classes, `typing` for type hints like `List`.  \n- Domain-specific types (`EnrichedContext`, `FormattedPrompt`, `AgentTask`) presumably defined elsewhere in the codebase.  \n- No direct external libraries or services are referenced in this snippet.\n\n5. **Configuration**:  \nNo explicit configuration, environment variables, or settings are referenced or required by these interfaces.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:24.566900",
      "status": "summarized"
    },
    "templates.py:chunk_0": {
      "chunk_id": "templates.py:chunk_0",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "0f46a083bc31be009ee41474ac2af1af3200b4ed16b53ab496d309b9b949474c",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines pre-filled templates for commit and publish workflows targeting platforms like GitHub, Confluence, and Jira, enabling users to generate standardized commit messages or content before execution.\n\n2. **Technical Details**  \n- Uses Python `Enum` (`TemplatePlatform`) to represent supported platforms.  \n- Defines a `dataclass` (`CommitTemplate`) encapsulating template data: platform, title, description, and customizable fields.  \n- Implements a factory class (`CommitTemplateFactory`) with static methods to generate platform-specific templates, supporting optional parameters for customization.  \n- Serialization support via `to_dict()` method for easy JSON conversion.\n\n3. **Business Logic**  \nFacilitates consistent and efficient creation of commit or publishing workflows by providing users with pre-filled, customizable templates tailored to different platforms, reducing manual input errors and streamlining integration with GitHub, Confluence, and Jira.\n\n4. **Dependencies**  \n- Standard Python libraries: `logging`, `typing` (Dict, Any, Optional), `dataclasses`, and `enum`.  \n- No external third-party libraries or services are referenced in the provided snippet.\n\n5. **Configuration**  \n- No explicit environment variables or configuration files are referenced in the snippet.  \n- Logging is configured via the standard Python `logging` module, presumably configured elsewhere in the application.\n\n6. **Error Handling**  \n- No explicit error handling or exception management is present in the shown code.  \n- The factory methods likely rely",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:29.543815",
      "status": "summarized"
    },
    "templates.py:chunk_2": {
      "chunk_id": "templates.py:chunk_2",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "77b38dfcf0c672895e57677cef3cb34edfea0bd2a7dad25c714dcd49538e7974",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines static methods to create structured templates for GitHub operations, specifically for committing files and creating pull requests. These templates encapsulate necessary metadata and content to facilitate automated GitHub workflows.\n\n2. **Technical Details**:  \n- Uses static methods to generate instances of a `CommitTemplate` class (likely a data container or DTO).  \n- Employs optional typing (`Optional[str]`) for flexible input parameters.  \n- Uses dictionaries to represent file paths and their contents (`files`), and to store template fields.  \n- The `CommitTemplate` is instantiated with platform-specific metadata (`TemplatePlatform.GITHUB`), descriptive text, and a dictionary of fields representing the commit or PR details.\n\n3. **Business Logic**:  \nThe code supports automation of GitHub repository management by programmatically generating commit and pull request templates. This enables consistent, repeatable workflows for code integration, reducing manual errors and improving developer productivity.\n\n4. **Dependencies**:  \n- `CommitTemplate` class and `TemplatePlatform` enum or constants (likely defined elsewhere in the codebase).  \n- Python standard library typing module for `Optional`.  \n- No direct external libraries or GitHub API calls are shown in this snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in this snippet.  \n- Default branch names (\"main\") are hardcoded as default parameters for PR creation.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:36.462240",
      "status": "summarized"
    },
    "templates.py:chunk_4": {
      "chunk_id": "templates.py:chunk_4",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "ec7e8d97724297fdf91c044eaedbf0a420fb2009e3100584864978e76e8b0f6c",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines a function that creates a structured template object representing a GitHub pull request (PR), encapsulating all necessary metadata such as repository info, branches, title, description, reviewers, assignees, labels, and draft status.\n\n2. **Technical Details**:  \n- Uses Python typing with `Optional[list]` and `bool` for parameters.  \n- Returns an instance of `CommitTemplate`, presumably a data structure or class designed to hold PR-related information.  \n- Utilizes default values and fallback empty lists/strings to ensure fields are always populated.  \n- The template includes a platform identifier (`TemplatePlatform.GITHUB`), a title, description, and a dictionary of fields representing the PR attributes.\n\n3. **Business Logic**:  \nFacilitates automation or orchestration of GitHub pull request creation by standardizing the input parameters into a reusable template format. This supports workflows that programmatically manage PRs, such as CI/CD pipelines or developer tooling.\n\n4. **Dependencies**:  \n- `CommitTemplate` class or data structure (likely internal or from a shared module).  \n- `TemplatePlatform` enum or constant defining supported platforms (here, GitHub).  \n- Python standard typing module for type hints (`Optional`, `list`).\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. Configuration likely occurs elsewhere in the application or via parameters passed to this function.\n\n6.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:46.259493",
      "status": "summarized"
    },
    "templates.py:chunk_6": {
      "chunk_id": "templates.py:chunk_6",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "aab11e60258fc5873c4f579a6484e4fe2b179cb8f8a06cdbdbc4510a3f504ab0",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code defines a static method to create a template for a combined GitHub commit and pull request (PR) workflow. It facilitates committing files to a repository and simultaneously creating a PR through a single structured template.\n\n2. **Technical Details**:  \n- The method `create_github_commit_and_pr_template` is a static method that returns an instance of `CommitTemplate`.  \n- It uses default and optional parameters to configure repository details, branches, commit messages, PR metadata, and workflow participants (reviewers, assignees, labels).  \n- The method constructs a dictionary of fields representing the inputs required for the workflow, which is then passed to the `CommitTemplate` constructor.  \n- The design follows a factory pattern to encapsulate the creation of a workflow template object.\n\n3. **Business Logic**:  \nThe code addresses the business need to streamline code contribution processes by combining commit and PR creation into a single automated workflow. This reduces manual steps for developers and enforces consistency in how commits and PRs are created within an organization.\n\n4. **Dependencies**:  \n- `CommitTemplate` class and `TemplatePlatform` enum or constants are dependencies, likely defined elsewhere in the codebase.  \n- The method signature uses Python typing hints (`Optional`, `Dict`, `list`), implying use of the `typing` module.  \n- No external third-party libraries are explicitly referenced in the snippet.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:42:54.303127",
      "status": "summarized"
    },
    "templates.py:chunk_8": {
      "chunk_id": "templates.py:chunk_8",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "7754bba077aa319199d8adff325b2ec62a92cbb6ba33019487bdaf1a991987e1",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet defines a static method to create a template object specifically for publishing content to a Confluence page. It encapsulates the necessary parameters into a structured `CommitTemplate` for use in an orchestration workflow related to commit or content publishing.\n\n2. **Technical Details**:  \n- Uses a static method within a class (likely a factory or builder pattern) to generate a `CommitTemplate` instance.  \n- Accepts optional parameters such as `space_key`, `page_title`, `content`, `parent_page_id`, and `version_comment` to customize the Confluence page publishing template.  \n- Uses default empty or fallback values via Python\u2019s `or` operator to ensure no `None` values propagate into the template.  \n- The method returns a `CommitTemplate` object initialized with a platform enum `TemplatePlatform.CONFLUENCE` and a fixed title \"Publish to Confluence\".  \n- The snippet suggests a structured approach to templating for different platforms (e.g., GitHub, Confluence).\n\n3. **Business Logic**:  \n- Facilitates automated or semi-automated publishing of content to Confluence, a popular enterprise wiki and documentation platform.  \n- Supports workflows where commit-related data or documentation needs to be programmatically pushed to Confluence pages, improving documentation consistency and reducing manual effort.\n\n4. **Dependencies**:  \n- `CommitTemplate` class or data structure (likely defined elsewhere in the codebase",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:01.729762",
      "status": "summarized"
    },
    "templates.py:chunk_10": {
      "chunk_id": "templates.py:chunk_10",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "9f053cd9e1487d519057e42189de09950f8dbca745a762c0b8cdc8604cf1228d",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a static method to create a structured template for Jira ticket creation, encapsulating common fields and default values for issue creation workflows.\n\n2. **Technical Details**:  \n- Uses a static method within a class (likely a factory or utility class) to generate a `CommitTemplate` object.  \n- Accepts optional parameters with default values for key Jira issue attributes such as project key, issue type, priority, assignee, labels, components, and epic link.  \n- Uses Python typing hints (`Optional[str]`, `list`) for parameter clarity.  \n- The method returns a `CommitTemplate` instance, suggesting a design pattern where templates are predefined objects used to standardize issue creation.\n\n3. **Business Logic**:  \n- Facilitates automated or semi-automated creation of Jira tickets with consistent formatting and default values, streamlining issue tracking and project management workflows.  \n- Supports customization of ticket attributes to fit different project needs or workflows, improving efficiency in software development or operational task management.\n\n4. **Dependencies**:  \n- Relies on a `CommitTemplate` class or data structure (not shown in the snippet) which likely encapsulates the template data.  \n- Uses Python standard typing module for type hints.  \n- Possibly part of a larger orchestration or workflow automation system (inferred from the file path `orchestration/commit_workflow/templates.py`).\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:09.285267",
      "status": "summarized"
    },
    "templates.py:chunk_12": {
      "chunk_id": "templates.py:chunk_12",
      "file_path": "orchestration\\commit_workflow\\templates.py",
      "chunk_hash": "f1273b2d225a58b35c4bddfe5fdeb40aa4b19c4f34c76e28564eab6e03125ae7",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a function that returns a `CommitTemplate` object configured for creating a Jira ticket, encapsulating necessary fields such as project key, issue type, summary, and other ticket attributes.\n\n2. **Technical Details**:  \n- Utilizes a factory-like pattern to instantiate and return a `CommitTemplate` object.  \n- Uses a dictionary to map field names to their respective values, applying default empty strings or lists when optional parameters are not provided.  \n- The `platform` attribute is set to a constant `TemplatePlatform.JIRA`, indicating the template is specific to Jira.\n\n3. **Business Logic**:  \nThe code supports automating the creation of Jira tickets by providing a standardized template with all required and optional fields. This facilitates consistent issue tracking and integration within a commit workflow or orchestration system.\n\n4. **Dependencies**:  \n- `CommitTemplate` class (likely a custom or domain-specific class).  \n- `TemplatePlatform` enum or constant, specifically the `JIRA` platform identifier.  \n- No explicit external libraries are shown in this snippet, but it depends on the definitions of `CommitTemplate` and `TemplatePlatform`.\n\n5. **Configuration**:  \n- No direct environment variables or config files are referenced here.  \n- The function parameters such as `project_key`, `issue_type`, `priority`, etc., are expected to be provided by the caller, possibly sourced from configuration or user input.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:14.348532",
      "status": "summarized"
    },
    "github_client.py:chunk_0": {
      "chunk_id": "github_client.py:chunk_0",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "6b0633e5ca0f5ad58d559c2035dbb34756df11f42927817119bd477f1bb1b52d",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `GitHubClient` class that provides an interface to interact with the GitHub API, specifically to fetch issue details from a given repository asynchronously.\n\n2. **Technical Details**:  \n- Uses the official `PyGithub` library (`Github` class) to interact with GitHub's REST API.  \n- Encapsulates GitHub API client initialization within a private method `_initialize_client`.  \n- Uses asynchronous method `get_issue` to fetch issue data, returning a dictionary with selected issue attributes.  \n- Employs Python typing hints (`Optional`, `Dict`, `Any`) for clarity and type safety.  \n- Uses Python's standard `logging` module for logging warnings, info, and errors.  \n- Relies on a singleton-like pattern where the GitHub client instance is stored as an instance attribute (`self.client`).\n\n3. **Business Logic**:  \nEnables the application to programmatically retrieve issue details from GitHub repositories, which can be used for issue tracking, reporting, or integration with other business workflows that depend on GitHub issue data.\n\n4. **Dependencies**:  \n- `PyGithub` library (`github` package) for GitHub API interactions.  \n- Python standard libraries: `logging`, `datetime` (imported but not used in the snippet), `typing`.  \n- Internal module `..config` for application settings (specifically `settings.github_token`).\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:20.393113",
      "status": "summarized"
    },
    "github_client.py:chunk_2": {
      "chunk_id": "github_client.py:chunk_2",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "04b0966224b579cd2be29557e6a8cb503ca0ec93ebc77aeb18ac2c5b7158597f",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `github_client.py`**\n\n1. **Purpose**  \n   The error handling code is designed to manage failures when interacting with the GitHub API, specifically when fetching issue or pull request data from a repository. It aims to catch and handle errors that occur during API calls to prevent application crashes and provide controlled failure responses.\n\n2. **Exception Types**  \n   The code explicitly catches `GithubException`, which is a common exception type raised by the GitHub API client library when API requests fail due to reasons such as network issues, authentication errors, rate limiting, or invalid repository/issue/PR identifiers.\n\n3. **Recovery Strategy**  \n   Upon catching a `GithubException`, the code does not attempt retries or alternative recovery mechanisms. Instead, it logs the error and returns `None` to indicate failure. This approach delegates any retry or fallback logic to higher-level application components or user interfaces.\n\n4. **Logging**  \n   Errors are logged using a `logger.error` call with a descriptive message including the repository name and issue or pull request number, along with the exception details. This facilitates monitoring and troubleshooting by providing clear, contextual error information in logs.\n\n5. **User Impact**  \n   When an error occurs, the method returns `None`, signaling to the caller that the requested data could not be retrieved. This likely results in the user not seeing the issue or pull request details. The absence of data is handled gracefully without crashing the application, but users may",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:27.514102",
      "status": "summarized"
    },
    "github_client.py:chunk_4": {
      "chunk_id": "github_client.py:chunk_4",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "517986cf2ad305b08e67dc07bd91e878c363b202cbf46807bb905587b879bf61",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles errors that may occur during interactions with the GitHub API, specifically when creating pull requests and retrieving file contents from a repository. It aims to manage failures such as network issues, permission errors, or invalid repository/file references.\n\n2. **Exception Types**:  \n   - Catches `GithubException`, which is a general exception type from the GitHub API client library indicating API request failures.\n\n3. **Recovery Strategy**:  \n   - The code does not implement retries or alternative recovery mechanisms. Instead, it recovers by safely returning `None` to indicate failure, allowing the caller to handle the absence of expected data or operation success.\n\n4. **Logging**:  \n   - Errors are logged using `logger.error` with descriptive messages including the repository name, file path, and exception details.  \n   - Successful pull request creation is logged at the info level with the PR number and repository name.\n\n5. **User Impact**:  \n   - End users or calling functions receive `None` when operations fail, signaling that the requested action (creating a PR or fetching file content) did not succeed.  \n   - This prevents exceptions from propagating and potentially crashing the application but requires callers to handle `None` responses appropriately.\n\n6. **Fallback**:  \n   - Returns `None` as a default fallback value when the GitHub client is not initialized or when an exception occurs.  \n   - For the file",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:36.831498",
      "status": "summarized"
    },
    "github_client.py:chunk_6": {
      "chunk_id": "github_client.py:chunk_6",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "97d7be4e642f300050c11768afb591c6dcfaa592108cdb16717b6190b34faa1c",
      "chunk_index": 6,
      "summary": "**Summary of Error Handling in `create_or_update_file` Method**\n\n1. **Purpose**  \n   The method handles errors related to interacting with the GitHub API when creating or updating a file in a repository. It specifically addresses failures such as:  \n   - The GitHub client not being initialized  \n   - The target file not existing (to decide between update vs create)  \n   - API errors during file retrieval, update, or creation  \n\n2. **Exception Types**  \n   - `GithubException`: This is the only exception type explicitly caught, which is a general exception from the GitHub API client library indicating API call failures (e.g., file not found, permission issues, rate limits).  \n\n3. **Recovery Strategy**  \n   - The method first attempts to retrieve the file to determine if it should update or create.  \n   - If retrieving the file raises a `GithubException` (likely file not found), it falls back to creating the file instead of updating.  \n   - If any other `GithubException` occurs during update or create, it logs the error and returns `False` without retrying.  \n   - No retries or exponential backoff are implemented; recovery is limited to switching between update and create operations.  \n\n4. **Logging**  \n   - Successful updates and creations are logged at the info level with file path and repository details.  \n   - Failures are logged at the error level, including the exception message, to aid in monitoring and troubleshooting",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:45.529891",
      "status": "summarized"
    },
    "github_client.py:chunk_8": {
      "chunk_id": "github_client.py:chunk_8",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "cf207242723e039a750d4872f2bbc807e4f1e99d633c0a4f97cc9a80d282cb2c",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python method performs a code search within a specified GitHub repository using a query string and returns a list of matching code snippets along with metadata, limited by a maximum number of results.\n\n2. **Technical Details**:  \n- Constructs a GitHub search query scoped to a specific repository.  \n- Uses the GitHub API client\u2019s `search_code` method to retrieve search results.  \n- Iterates over the results, extracting relevant fields (`path`, `name`, `repository.full_name`, `html_url`) into dictionaries.  \n- Limits the output list size to `max_results`.  \n- Returns a list of dictionaries representing search hits.\n\n3. **Business Logic**:  \nEnables users or systems to programmatically search for code fragments within a particular GitHub repository, facilitating code discovery, auditing, or analysis workflows.\n\n4. **Dependencies**:  \n- A GitHub API client instance (`self.client`), likely from a library such as PyGithub or a custom wrapper.  \n- Python standard libraries for typing (`List`, `Dict`, `Any`).  \n- A logger for warning messages.\n\n5. **Configuration**:  \n- Requires initialization of `self.client` with proper GitHub API authentication tokens or credentials (not shown in snippet).  \n- No explicit environment variables or config files are referenced in the snippet, but authentication and API endpoint configuration are implied.\n\n6. **Error Handling**:  \n- Checks if the GitHub client",
      "embedding_id": null,
      "created_at": "2025-10-22T18:43:53.799424",
      "status": "summarized"
    },
    "github_client.py:chunk_10": {
      "chunk_id": "github_client.py:chunk_10",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "572af19121edfa6f8529bc06c3597b281694704e35261c5ff70b55b860f3e062",
      "chunk_index": 10,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code is designed to manage failures that occur during GitHub code search operations and file retrieval within a repository. It ensures that issues such as API errors or unexpected exceptions do not crash the application and provides controlled responses.\n\n2. **Exception Types**:  \n   - `GithubException`: A specific exception likely raised by the GitHub API client when API calls fail (e.g., rate limits, authentication errors, or invalid queries).  \n   - `Exception`: A generic catch-all for any other unexpected errors that might arise during execution.\n\n3. **Recovery Strategy**:  \n   Upon encountering exceptions, the code does not attempt retries but instead recovers by returning empty results (`[]` for code search results, `{}` for file contents). This prevents propagation of errors and allows the calling code to handle empty responses gracefully.\n\n4. **Logging**:  \n   - Errors are logged with `logger.error` including contextual information such as repository name and error messages.  \n   - Warnings are logged if the GitHub client is not initialized, indicating potential misconfiguration or setup issues.  \n   - Informational logs (`logger.info`) provide visibility into successful operations, including the number of results found.\n\n5. **User Impact**:  \n   End users receive empty results or missing file contents when errors occur, which may manifest as no search results or unavailable files. However, the application remains stable and responsive, avoiding crashes or unhandled",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:01.176109",
      "status": "summarized"
    },
    "github_client.py:chunk_12": {
      "chunk_id": "github_client.py:chunk_12",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "a788b53c51067989be87ebaf4f8b021dfe15be2b68fface6b840a03fc7df7edb",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines an asynchronous method to fetch the contents of multiple files from a specified GitHub repository and branch, returning a dictionary mapping file paths to their content or None if unavailable.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to potentially allow concurrent operations.  \n- Iterates over a list of file paths, retrieving each file\u2019s content via the GitHub API client.  \n- Uses a dictionary (`results`) to store file path keys and their corresponding file content values.  \n- Checks the type of the content to ensure it is a file before decoding from bytes to UTF-8 string.\n\n3. **Business Logic**:  \nEnables retrieval of multiple source or configuration files from a GitHub repository, supporting use cases such as automated code analysis, configuration management, or content synchronization in business workflows.\n\n4. **Dependencies**:  \n- A GitHub API client library (likely PyGithub or similar) providing `get_repo` and `get_contents` methods.  \n- Python standard libraries for async programming and logging.\n\n5. **Configuration**:  \n- Repository name and branch (defaulting to \"main\") are passed as parameters.  \n- The GitHub client instance (`self.client`) must be initialized and authenticated elsewhere in the class.  \n- No explicit environment variables or config files shown in this snippet.\n\n6. **Error Handling**:  \n- Checks if the GitHub client is initialized; if not",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:08.029499",
      "status": "summarized"
    },
    "github_client.py:chunk_14": {
      "chunk_id": "github_client.py:chunk_14",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "dbcad539e26e77a77dc49c1b1fba29bb845a9accb679bf1feec133986bf2f604",
      "chunk_index": 14,
      "summary": "**Summary: Error Handling in `github_client.py`**\n\n1. **Purpose**:  \n   The error handling code is designed to manage failures during GitHub API interactions, specifically when fetching multiple files from a repository and when performing code searches. It aims to handle issues such as API request failures, missing files, or other unexpected exceptions that may occur during these operations.\n\n2. **Exception Types**:  \n   - `GithubException`: This is a specific exception likely raised by the GitHub API client library when an API call fails (e.g., file not found, permission issues, rate limiting).  \n   - `Exception`: A generic catch-all for any other unexpected errors that might arise during the fetching or searching processes.\n\n3. **Recovery Strategy**:  \n   - For individual file fetch failures (`GithubException`), the code logs a warning and sets the corresponding file's result to `None`, allowing the process to continue fetching other files without interruption.  \n   - For broader failures (caught by the generic `Exception`), the code logs an error and returns whatever partial results have been accumulated, avoiding a complete failure or crash.\n\n4. **Logging**:  \n   - Warnings are logged when a specific file cannot be fetched, including the file path and the exception message.  \n   - Errors are logged when the entire batch fetch operation fails, including the repository name and the exception details.  \n   - Informational logs record the number of files successfully fetched from a repository, aiding",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:13.714991",
      "status": "summarized"
    },
    "github_client.py:chunk_16": {
      "chunk_id": "github_client.py:chunk_16",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "43d0c10e8d35b2335bc1eeeec1f97db0565ad6b963071ae13da7f3d84e1fbb78",
      "chunk_index": 16,
      "summary": "**Summary of Error Handling in `github_client.py`**\n\n1. **Purpose**  \n   The error handling code is designed to manage failures during GitHub API interactions, specifically when searching code repositories and retrieving repository file trees. It ensures that API exceptions do not crash the application and provides fallback mechanisms to maintain functionality.\n\n2. **Exception Types**  \n   - `GithubException`: This is the primary exception caught, which is a generic exception type from the GitHub API client library indicating API request failures or issues such as rate limiting, invalid parameters, or network errors.\n\n3. **Recovery Strategy**  \n   - For code search failures (`search_code` method), the code catches `GithubException` and returns an empty list, effectively signaling no results without raising an error further.  \n   - For retrieving the repository tree (`get_repository_tree` method), if fetching the tree for a specified branch/ref fails, it attempts a fallback by retrieving the tree from the repository\u2019s default branch. This is a retry with a different parameter to recover from branch-specific errors.\n\n4. **Logging**  \n   - Errors are logged at the `error` level with descriptive messages including the query or operation context and the exception details.  \n   - Successful operations log informational messages (`info` level), such as the number of search results found, aiding monitoring and debugging.\n\n5. **User Impact**  \n   - When errors occur during code search, users receive an empty result set instead of an error, which may appear",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:20.983261",
      "status": "summarized"
    },
    "github_client.py:chunk_18": {
      "chunk_id": "github_client.py:chunk_18",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "32b952a71252ea114d1861d2276c4c3064828a8d6e1598d0b6105bc7385dede7",
      "chunk_index": 18,
      "summary": "**Summary of Error Handling in `github_client.py`**\n\n1. **Purpose**  \n   The error handling code is designed to manage failures when interacting with the GitHub API, specifically when fetching repository trees or directory contents. It addresses issues such as missing branches, inaccessible paths, or API request failures.\n\n2. **Exception Types**  \n   - Catches `GithubException`, which is a general exception type from the GitHub API client library. This likely covers a range of API errors including not found errors, permission issues, rate limiting, and other HTTP errors.\n\n3. **Recovery Strategy**  \n   - When a specified branch (`ref`) is not found, the code logs an informational message and falls back to using the repository\u2019s default branch to retrieve the tree.\n   - If an exception occurs during the API call to get the repository tree, the error is logged, and the function returns `None` to indicate failure without raising further exceptions.\n   - In the `list_directory` method, if the client is not initialized (`self.client` is `None`), it immediately returns `None`, avoiding further errors.\n\n4. **Logging**  \n   - Uses `logger.info` to record non-error conditions such as falling back to the default branch and the number of items fetched.\n   - Uses `logger.error` to record exceptions with detailed error messages including the repository name and exception details, aiding in monitoring and troubleshooting.\n\n5. **User Impact**  \n   - End users receive `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:29.417584",
      "status": "summarized"
    },
    "github_client.py:chunk_20": {
      "chunk_id": "github_client.py:chunk_20",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "f86682fff8a8ab90938f7dd325551f5f602484e96909b68cefbc374c559e6ee9",
      "chunk_index": 20,
      "summary": "**Summary of Error Handling in `github_client.py`**\n\n1. **Purpose**:  \n   The error handling code is designed to manage failures that occur when interacting with the GitHub API, specifically when listing directory contents of a repository and retrieving issues from a repository. It aims to catch API-related errors that might arise due to network issues, permission problems, invalid repository names, or rate limiting.\n\n2. **Exception Types**:  \n   - The code explicitly catches `GithubException`, which is a common exception type from the PyGithub library used to handle various GitHub API errors such as HTTP errors, authentication failures, or resource not found errors.\n\n3. **Recovery Strategy**:  \n   - Upon catching an exception, the code does not attempt retries or alternative recovery mechanisms. Instead, it logs the error and returns `None` to indicate failure. This approach avoids cascading failures but relies on the caller to handle the `None` response appropriately.\n\n4. **Logging**:  \n   - Errors are logged at the `error` level with descriptive messages including the repository name and path involved, as well as the exception details.  \n   - Successful operations are logged at the `info` level, indicating the number of items listed, which aids in monitoring normal operation and troubleshooting.\n\n5. **User Impact**:  \n   - When an error occurs, the functions return `None`, which likely translates to no data being displayed or processed downstream. This may result in missing directory listings or issue data",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:36.164548",
      "status": "summarized"
    },
    "github_client.py:chunk_22": {
      "chunk_id": "github_client.py:chunk_22",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "e01b1af42ad40475d2d839c39f8aa956c39a1157dec10738d713e43880520405",
      "chunk_index": 22,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling in this code is designed to manage failures related to GitHub API interactions, specifically when fetching issues from a repository and when creating a new branch. It ensures that the application can handle API errors gracefully without crashing.\n\n2. **Exception Types**:  \n   - `GithubException`: This is the specific exception caught, which likely represents errors returned by the GitHub API client library when API calls fail (e.g., network issues, permission errors, resource not found).\n\n3. **Recovery Strategy**:  \n   - For fetching issues: Upon encountering a `GithubException`, the method logs the error and returns `None`, signaling failure without raising further exceptions.  \n   - For creating a branch: If the specified base branch does not exist (caught as a `GithubException` when fetching the git ref), the code falls back to using the repository\u2019s default branch as the base for the new branch.\n\n4. **Logging**:  \n   - Errors are logged at the `error` level with descriptive messages including the repository name and exception details, aiding in monitoring and troubleshooting.  \n   - Informational logs (`info` level) are used to indicate successful operations (e.g., number of issues fetched) and fallback actions (e.g., switching to default branch when the specified base branch is missing).\n\n5. **User Impact**:  \n   - When fetching issues fails, the method returns `None`, which likely results in",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:42.273522",
      "status": "summarized"
    },
    "github_client.py:chunk_24": {
      "chunk_id": "github_client.py:chunk_24",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "750f441c086b25de6742ec0bd1b0ab81b96ebc508c96a1577bed668585544bc1",
      "chunk_index": 24,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles errors related to GitHub repository operations, specifically creating new branches and committing documentation files. It aims to manage failures that occur during these Git interactions, such as permission issues, branch conflicts, or API errors.\n\n2. **Exception Types**:  \n   - Catches `GithubException`, which is a general exception type from the GitHub API client library indicating API call failures or GitHub-specific errors.\n\n3. **Recovery Strategy**:  \n   - Upon encountering a `GithubException` during branch creation, the method logs the error and returns `False` to indicate failure without raising further exceptions.  \n   - In the `commit_documentation` method, the code snippet shows a nested try block (not fully visible) likely intended to handle file creation or update errors, suggesting localized error handling.  \n   - No explicit retry mechanism is shown; recovery is primarily through error logging and returning failure indicators.\n\n4. **Logging**:  \n   - Errors are logged with detailed messages including the branch name, repository name, and exception details to facilitate debugging and monitoring.  \n   - Informational logs are present for successful operations (e.g., branch creation, default branch identification).\n\n5. **User Impact**:  \n   - Failures in branch creation or committing documentation result in the operation returning `False` or `None`, signaling to the caller that the action did not succeed.  \n   - End users or calling services may experience",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:46.312985",
      "status": "summarized"
    },
    "github_client.py:chunk_26": {
      "chunk_id": "github_client.py:chunk_26",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "1fbe034f7e500d3223878ebde8be280618117147c593837cf8d8905df7e2fd0a",
      "chunk_index": 26,
      "summary": "**Summary of Error Handling Code in `shared\\clients\\github_client.py`:**\n\n1. **Purpose**:  \n   This code handles errors related to updating or creating files in a GitHub repository via the GitHub API. Specifically, it manages the scenario where an attempt to update a file fails because the file does not exist, triggering a fallback to create the file instead.\n\n2. **Exception Types**:  \n   - Catches `GithubException` from the GitHub API client library. This is a broad exception that can represent various API errors, including \"file not found\" or permission issues.\n\n3. **Recovery Strategy**:  \n   - The code first attempts to update an existing file at a specified path and branch.  \n   - If updating fails (likely because the file does not exist), it catches the `GithubException` and attempts to create the file instead.  \n   - This try-update-then-create approach ensures that the operation succeeds whether the file is already present or not.\n\n4. **Logging**:  \n   - The provided snippet does not include any explicit error logging or monitoring statements (e.g., no `logging.error` or telemetry calls).  \n   - Errors are silently handled by switching from update to create without logging the exception details.\n\n5. **User Impact**:  \n   - End users or calling services receive a result dictionary indicating whether the file was \"updated\" or \"created,\" along with commit metadata.  \n   - Because errors are handled internally",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:53.681685",
      "status": "summarized"
    },
    "github_client.py:chunk_28": {
      "chunk_id": "github_client.py:chunk_28",
      "file_path": "shared\\clients\\github_client.py",
      "chunk_hash": "57e3d213e7442df847dd00dd48d752d685bca7fd6dec72ca59ec387164a63426",
      "chunk_index": 28,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This error handling code is designed to catch and manage failures that occur during the process of committing documentation files to a GitHub repository. It specifically targets issues that might arise when interacting with the GitHub API, such as network errors, permission issues, or invalid commit data.\n\n2. **Exception Types**:  \n   The code catches exceptions of type `GithubException`, which is a general exception class from the GitHub API client library used to represent errors returned by GitHub.\n\n3. **Recovery Strategy**:  \n   The strategy here is minimal; upon catching an exception, the function logs the error and returns `None`. There is no retry mechanism or alternative recovery path implemented in this snippet.\n\n4. **Logging**:  \n   Errors are logged at the error level with a descriptive message including the repository name and the exception details. This facilitates monitoring and troubleshooting by providing clear context about the failure.\n\n5. **User Impact**:  \n   Since the function returns `None` on failure, any calling code must handle this case appropriately. End users may experience missing or outdated documentation if commits fail and are not retried or otherwise handled upstream.\n\n6. **Fallback**:  \n   The fallback behavior is to return `None`, signaling failure to the caller. There is no default value or alternative action taken within this code block to degrade gracefully beyond this.\n\n---\n\nThis error handling approach ensures that failures are logged for visibility but relies on higher-level",
      "embedding_id": null,
      "created_at": "2025-10-22T18:44:58.267720",
      "status": "summarized"
    },
    "registry.py:chunk_0": {
      "chunk_id": "registry.py:chunk_0",
      "file_path": "orchestration\\cloud_providers\\registry.py",
      "chunk_hash": "5eac51ea6c3503bafca56c1bbeb7ae1141b9558688e0f5987236c91f6f77724e",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module registers multiple cloud provider implementations with a centralized factory to enable dynamic provider instantiation across the orchestration system. Importing this module ensures all supported providers are available for use.\n\n2. **Technical Details**  \n- Uses the Factory design pattern via `ProviderFactory` to manage provider classes keyed by string identifiers.  \n- The `register_all_providers` function explicitly registers each provider class (`AzureProvider`, `TogetherProvider`, `OpenAIProvider`) with the factory.  \n- Logging is integrated to track the registration process.  \n- The registration function is invoked immediately upon module import, ensuring providers are registered as a side effect.\n\n3. **Business Logic**  \nEnables the orchestration system to support multiple cloud AI providers interchangeably, facilitating flexibility in choosing or switching providers for AI workloads, which is critical for cost optimization, feature access, or redundancy.\n\n4. **Dependencies**  \n- Internal modules:  \n  - `.factory.ProviderFactory` (central registry and factory for providers)  \n  - `.implementations.azure_provider.AzureProvider`  \n  - `.implementations.together_provider.TogetherProvider`  \n  - `.implementations.openai_provider.OpenAIProvider`  \n- Shared logging utility: `shared.logger.get_logger`\n\n5. **Configuration**  \nNo direct configuration or environment variables are handled in this module. Provider-specific configurations are likely managed within each provider implementation or the factory.\n\n6. **Error Handling**  \nNo explicit error handling is implemented in",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:05.649490",
      "status": "summarized"
    },
    "base_parser.py:chunk_0": {
      "chunk_id": "base_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "20ba4705f6f91a5554e4861bcbbbbb52a3b4ba0ec76a756964da66db8b392a1f",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a base interface and data structures for parsing source code into logical chunks using tree-sitter, enabling consistent extraction of code segments (functions, classes, modules, etc.) across multiple programming languages.\n\n2. **Technical Details**  \n- Uses Python\u2019s `abc` module to define an abstract base class `BaseParser` that enforces implementation of language-specific parsing logic in subclasses.  \n- Defines two `@dataclass` structures:  \n  - `ChunkMetadata` holds detailed metadata about a code chunk, including location, type, dependencies, and token count.  \n  - `CodeChunk` encapsulates a code segment along with its metadata, providing convenient accessors for chunk ID and token count.  \n- Employs composition by embedding `ChunkMetadata` inside `CodeChunk`.  \n- Uses optional and default mutable arguments carefully (initializing `dependencies` in `__post_init__` to avoid mutable default pitfalls).  \n- Logging is set up for diagnostic purposes but no explicit logging calls are shown in the snippet.\n\n3. **Business Logic**  \nEnables a unified framework for parsing and chunking source code across different programming languages, facilitating downstream tasks such as code analysis, indexing, search, or intelligence features (e.g., code navigation, refactoring tools, or automated documentation generation).\n\n4. **Dependencies**  \n- Standard Python libraries: `abc` for abstract base classes, `dataclasses` for structured data, `typing` for type",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:09.172924",
      "status": "summarized"
    },
    "base_parser.py:chunk_2": {
      "chunk_id": "base_parser.py:chunk_2",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "132d2afb5d5f6722763db396dedfe57ee82d395a1ff454c6d0b6587ec54f2f44",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines an abstract base class for source code parsers that extract code chunks from files and identify the programming language. It provides a framework for token-based chunking of source code files.\n\n2. **Technical Details**:  \n- Implements an abstract base class pattern with `@abstractmethod` decorators enforcing subclasses to implement `parse_file` and `get_language`.  \n- Uses token count heuristics to split source code into chunks, with configurable soft (`target_chunk_tokens`) and hard (`max_chunk_tokens`) token limits.  \n- Provides a simple token estimation method based on character count (1 token \u2248 4 characters), which can be overridden for language-specific accuracy.  \n- Returns a list of `CodeChunk` objects (presumably a data structure encapsulating code snippets and metadata).\n\n3. **Business Logic**:  \nEnables modular parsing of source code files into manageable chunks for downstream processing such as code analysis, indexing, or AI-based code intelligence features. This supports business needs like code search, automated review, or documentation generation by breaking large files into token-limited segments.\n\n4. **Dependencies**:  \n- Python standard library only (typing for `List`, `abstractmethod` from `abc` module assumed).  \n- Relies on a `CodeChunk` class or data structure defined elsewhere in the codebase.\n\n5. **Configuration**:  \n- Configurable token limits via constructor parameters: `target_chunk_tokens` (soft limit",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:20.253537",
      "status": "summarized"
    },
    "base_parser.py:chunk_4": {
      "chunk_id": "base_parser.py:chunk_4",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "51d076c99378e3c117d3c3da72f20b12928d7d9c746a3517636fdb2625c95c2e",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \n   The `should_skip_chunk` method determines whether a given block of code (chunk) is trivial or unimportant enough to be skipped during summarization or further processing. It filters out code chunks such as comments-only blocks, simple getters/setters, import statements, trivial one-liners, and auto-generated code markers.\n\n2. **Technical Details**:  \n   - The method processes the input string `content` by splitting it into non-empty, stripped lines.  \n   - It uses a line-by-line analysis to count meaningful code lines, excluding comments, docstrings, and import statements.  \n   - Docstrings are detected and tracked using flags (`in_docstring`) and the type of docstring delimiter (`\"\"\"` or `'''`). The method handles multi-line docstrings by toggling the `in_docstring` state.  \n   - Early exit conditions include skipping chunks with one or fewer lines.  \n   - The method is designed to be extensible with an optional `chunk_type` parameter, though it is unused in the provided snippet.\n\n3. **Business Logic**:  \n   This function supports a code intelligence or summarization tool by filtering out trivial or non-informative code blocks. This improves the quality and relevance of code summaries or analyses by focusing on substantive code rather than boilerplate or comments.\n\n4. **Dependencies**:  \n   The snippet uses only Python built-in functions and types (e.g., `str`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:25.002645",
      "status": "summarized"
    },
    "base_parser.py:chunk_6": {
      "chunk_id": "base_parser.py:chunk_6",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "c3dad535d345f75a518893cf750e202d165051d3e57339f414d523a476693062",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet analyzes a block of source code content to determine if it represents trivial or boilerplate code, such as simple getters, setters, or minimal code blocks, and returns `True` to indicate such cases should be skipped or treated differently.\n\n2. **Technical Details**:  \n- Iterates through lines of code, skipping lines inside docstrings, comments, import statements, and common language keywords that do not represent executable logic.  \n- Counts the number of meaningful code lines (`code_lines`).  \n- Applies heuristics based on line count and presence of specific patterns (e.g., `@property`, `self.`, `return this.`) to detect simple getter/setter methods across multiple languages (Python, Java, JavaScript).  \n- Uses string operations like `startswith`, `in`, and `lower()` to perform pattern matching.\n\n3. **Business Logic**:  \nThe code helps filter out trivial or boilerplate code snippets (like simple property accessors) from further processing, likely to focus analysis, metrics, or transformations on substantive code only. This improves the quality and relevance of code intelligence features such as complexity analysis, code summarization, or refactoring suggestions.\n\n4. **Dependencies**:  \nNo explicit external libraries or modules are used in this snippet; it relies solely on Python built-in string operations and control flow.\n\n5. **Configuration**:  \nNo environment variables, configuration files, or external settings influence this logic directly. The",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:33.140014",
      "status": "summarized"
    },
    "base_parser.py:chunk_10": {
      "chunk_id": "base_parser.py:chunk_10",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "6849b0ac96ba4dc5b73d14c5ce0f3efced160980de962307c0cc6bfa620fa1d5",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a parser module that processes source code by splitting it into manageable chunks based on token counts. It organizes these chunks with associated metadata for further analysis or processing.\n\n2. **Technical Details**:  \n- The code accumulates lines of code into `current_chunk` until a token limit is reached, then starts a new chunk.  \n- Each chunk is represented by a `CodeChunk` object containing `ChunkMetadata` with detailed attributes such as chunk ID, file path, language, line numbers, chunk type, symbol names, and token counts.  \n- The chunking logic uses a simple linear iteration over lines and token counts, appending lines to the current chunk or starting a new one when needed.  \n- Metadata for each chunk is carefully constructed to maintain traceability to the original source code and its structure.\n\n3. **Business Logic**:  \nThis chunking mechanism supports business needs such as incremental code analysis, indexing, or code intelligence features (e.g., syntax highlighting, code search, or refactoring tools) by breaking large source files into smaller, manageable pieces with rich metadata.\n\n4. **Dependencies**:  \n- Custom data structures/classes: `ChunkMetadata` and `CodeChunk` (likely defined elsewhere in the codebase).  \n- Standard Python data types and typing hints (`List[str]`).  \n- No explicit external libraries are shown in this snippet.\n\n5. **Configuration**:  \n- No",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:40.085263",
      "status": "summarized"
    },
    "base_parser.py:chunk_12": {
      "chunk_id": "base_parser.py:chunk_12",
      "file_path": "code-intelligence\\parsers\\base_parser.py",
      "chunk_hash": "bf1cb15fb8f3614dd4b64bf78d0a77cae6631831fa61e3f6c0f294a8c6774ce7",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a base parser class designed to identify dependencies in file content and determine if a file is supported based on its extension. It provides foundational methods intended to be overridden by language-specific parsers for improved accuracy.\n\n2. **Technical Details**:  \n- The `get_dependencies` method scans the file content line-by-line, stripping whitespace and collecting lines that start with common import or inclusion keywords (`import`, `from`, `require(`, `use `).  \n- `get_file_extension` returns a list of file extensions the parser can handle; the base implementation returns an empty list and is expected to be overridden.  \n- `supports_file` uses Python\u2019s `Path` from the `pathlib` module to extract the file extension and checks if it is in the supported extensions list.  \n- Uses simple string operations and list data structures.  \n- The design follows an inheritance pattern where base methods provide default behavior and language-specific subclasses override them.\n\n3. **Business Logic**:  \nThis code supports a system that analyzes source code files to extract dependency information and verify file compatibility with parsers. It enables modular, language-specific parsing strategies, facilitating code intelligence features such as dependency graph generation, impact analysis, or automated code review.\n\n4. **Dependencies**:  \n- Uses Python standard library\u2019s `pathlib.Path` for file path manipulation.  \n- No external third-party libraries are referenced in this snippet.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:45.736390",
      "status": "summarized"
    },
    "enricher.py:chunk_0": {
      "chunk_id": "enricher.py:chunk_0",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "38d01cbf6c1e32d5a7bb8815c38bccdf81e5e81414433042ee22961184b16339",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a `ContextEnricher` class that enriches parsed messages by fetching and aggregating contextual data from external services such as GitHub, Jira, and Confluence based on references extracted from the messages.\n\n2. **Technical Details**  \n- Implements the `IContextEnricher` interface, ensuring a contract for enrichment functionality.  \n- Uses asynchronous programming (`async def enrich`) to perform potentially I/O-bound enrichment operations concurrently.  \n- Maintains an internal cache (`Dict[str, ContextData]`) to store previously fetched context data keyed by reference identifiers, reducing redundant external calls.  \n- Leverages typed data models (`ParsedMessage`, `EnrichedContext`, `ContextData`, etc.) for structured input and output, improving type safety and clarity.  \n- Uses a `ServiceManager` to abstract access to various external integrations, promoting modularity and separation of concerns.\n\n3. **Business Logic**  \nThe class addresses the business need to provide richer, contextual information around parsed messages (e.g., issue references, code commits) by aggregating relevant data from multiple external platforms. This enrichment supports better decision-making, traceability, and collaboration in workflows that depend on cross-system references.\n\n4. **Dependencies**  \n- Python standard library: `logging`, `typing` (for type annotations).  \n- Internal modules:  \n  - `orchestration.shared.interfaces.IContextEnricher` (interface definition).  \n  - `orches",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:51.239276",
      "status": "summarized"
    },
    "enricher.py:chunk_3": {
      "chunk_id": "enricher.py:chunk_3",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "9da8a6f16108ba6ccbc14a109a9665860e28015e5f2cb6eb093d394292d3c015",
      "chunk_index": 3,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an asynchronous context enrichment system that enhances references found in messages by fetching additional data from external sources, specifically GitHub in this excerpt. It enriches references with contextual information to provide a richer understanding of the content.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to perform non-blocking I/O operations.  \n- Implements caching to avoid redundant data fetches, using a dictionary-like cache keyed by normalized reference values.  \n- Employs a service manager pattern to dynamically retrieve external service clients (e.g., GitHub service).  \n- Constructs and returns an `EnrichedContext` object containing the original parsed message and the enriched context items.  \n- Uses structured logging with contextual metadata (e.g., number of items fetched, cache hits).\n\n3. **Business Logic**:  \nThe code enriches references (such as GitHub issues, pull requests, or repositories) found in user messages or documents by fetching detailed metadata. This enrichment supports business needs like enhanced search, better issue tracking, or improved user assistance by providing relevant contextual information automatically.\n\n4. **Dependencies**:  \n- An external `github` service accessed via a service manager (`self.service_manager.get_service('github')`).  \n- A caching mechanism (`self.cache`) likely implemented as an in-memory dictionary or similar.  \n- Logging framework (`logger`) for operational insights.  \n- Data models such as `Reference`, `ContextData",
      "embedding_id": null,
      "created_at": "2025-10-22T18:45:58.618149",
      "status": "summarized"
    },
    "enricher.py:chunk_5": {
      "chunk_id": "enricher.py:chunk_5",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "4b135505db2748d30a9c9a471f6ad50038f0751cc79971e587d7cbf390b91d55",
      "chunk_index": 5,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code snippet enriches a given context by fetching detailed repository information from GitHub based on metadata references, and then constructs a structured context data object to be used downstream.\n\n2. **Technical Details**:  \n- Extracts `owner` and `repo` identifiers from a metadata dictionary.  \n- Asynchronously calls a GitHub service method `execute` with the action `'get_repository'` to retrieve repository details.  \n- Constructs a `ContextData` object encapsulating repository attributes such as name, description, language, star count, default branch, and URL.  \n- Appends the enriched context data to a list and optionally caches it using a dictionary keyed by `cache_key`.  \n- Uses asynchronous programming (`await`) to handle I/O-bound GitHub API calls efficiently.\n\n3. **Business Logic**:  \nThe code supports enriching orchestration or workflow contexts with GitHub repository metadata, enabling downstream processes or analytics to have richer, actionable information about code repositories referenced in the system.\n\n4. **Dependencies**:  \n- `github_service`: An asynchronous service client interfacing with GitHub\u2019s API.  \n- `ContextData` and `ContextSourceType`: Domain-specific data structures/enums for representing enriched context information.  \n- Python async/await syntax for asynchronous operations.\n\n5. **Configuration**:  \n- Likely depends on GitHub API credentials and endpoint configurations managed outside this snippet (e.g., environment variables or config",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:06.770636",
      "status": "summarized"
    },
    "enricher.py:chunk_7": {
      "chunk_id": "enricher.py:chunk_7",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "9d8c243c242975578a88a09f44a5efad111d456a7a692a34af78a27448dc8a90",
      "chunk_index": 7,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet asynchronously fetches detailed information about a GitHub issue using metadata from a reference object, enriches the context with this issue data, and appends it to a collection of context items for further processing.\n\n2. **Technical Details**:  \n- Uses asynchronous calls (`await`) to interact with an external GitHub service API.  \n- Extracts issue number from a metadata dictionary and converts it to an integer.  \n- Constructs a `ContextData` object containing structured issue details such as title, body, state, labels, comment count, and URL.  \n- Uses list comprehension to extract label names from the issue's labels list.  \n- Appends the enriched context data to a list (`context_items`).  \n- Exception handling with logging captures errors during the enrichment process.\n\n3. **Business Logic**:  \nThe code enriches a processing context with detailed GitHub issue information, enabling downstream components to leverage issue metadata for tasks such as issue tracking, reporting, or automated decision-making in workflows that integrate GitHub issue data.\n\n4. **Dependencies**:  \n- `github_service`: An asynchronous service client for GitHub API interactions.  \n- `ContextData` and `ContextSourceType`: Custom data structures/enums likely defined elsewhere in the orchestration context enricher module.  \n- `logger`: Logging utility for error reporting.\n\n5. **Configuration**:  \n- Assumes configuration for GitHub API access (e.g.,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:11.337603",
      "status": "summarized"
    },
    "enricher.py:chunk_9": {
      "chunk_id": "enricher.py:chunk_9",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "866bca43ac9f1d59ee51a3b292154bb8f55e1e8c2ddf67326b33b8358b01d95e",
      "chunk_index": 9,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method enriches a Jira reference by fetching detailed ticket data from a Jira service, optionally utilizing a cache to avoid redundant calls.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking I/O operations.  \n- Implements caching via an in-memory dictionary (`self.cache`) keyed by a string combining \"jira_\" and the normalized reference value.  \n- Retrieves Jira ticket information by invoking a service manager's `get_service('jira')` method and calling an asynchronous `execute` method with the 'get_issue' command and ticket key.  \n- Extracts relevant fields from the returned issue data dictionary.\n\n3. **Business Logic**:  \nThe method supports the enrichment of context data related to Jira tickets, enabling downstream processes to have richer metadata about Jira issues referenced in the system. This is crucial for workflows that depend on accurate and detailed issue tracking information.\n\n4. **Dependencies**:  \n- A `service_manager` component responsible for providing service clients (specifically a Jira service).  \n- An asynchronous Jira service client exposing an `execute` method for API calls.  \n- A `Reference` data structure containing normalized values and metadata.  \n- Python's async/await syntax and standard data structures like lists and dictionaries.\n\n5. **Configuration**:  \n- Cache usage is controlled by the `use_cache` boolean parameter.  \n- Cache keys are constructed dynamically based on the normalized reference value.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:16.701445",
      "status": "summarized"
    },
    "enricher.py:chunk_11": {
      "chunk_id": "enricher.py:chunk_11",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "0c9b9d4f248c46e21ae093918cf5620a5470133e2a671f7c9c299b3dbf6d2f4a",
      "chunk_index": 11,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code snippet enriches a context with detailed information extracted from a Jira issue, encapsulating it into a structured `ContextData` object for further processing or storage.\n\n2. **Technical Details**:  \n- Constructs a `ContextData` instance with fields populated from a Jira issue's JSON response (`issue_info` and `fields`).  \n- Uses nested `.get()` calls to safely extract optional fields like status, priority, issue type, assignee, and creation date.  \n- Appends the enriched context data to a list (`context_items`).  \n- Implements a caching mechanism by storing the enriched context data in `self.cache` keyed by `cache_key` if caching is enabled (`use_cache`).  \n- Exception handling wraps the enrichment process, logging errors with contextual metadata.\n\n3. **Business Logic**:  \nThe code enriches references to Jira tickets by extracting and structuring relevant issue details (summary, status, priority, assignee, etc.) to provide enhanced context for downstream workflows such as issue tracking, reporting, or automated orchestration.\n\n4. **Dependencies**:  \n- `ContextData` and `ContextSourceType` classes/enums, likely part of the orchestration or context enrichment framework.  \n- A logger instance (`logger`) for error logging.  \n- Jira API or data source providing `issue_info` and `fields` dictionaries.  \n- Internal caching mechanism (`self.cache`).\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:21.030921",
      "status": "summarized"
    },
    "enricher.py:chunk_13": {
      "chunk_id": "enricher.py:chunk_13",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "f32fd4baf410e782f4b5c0c506596af042133e6e7b3eaa56d0db44e834ea50bc",
      "chunk_index": 13,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method enriches a given Confluence reference by fetching detailed page data and returning it as contextual information, optionally utilizing a cache to improve performance.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking I/O operations.  \n- Employs a caching mechanism keyed by a normalized reference value to avoid redundant data retrieval.  \n- Retrieves a Confluence service instance via a service manager pattern (`self.service_manager.get_service`).  \n- Constructs and returns a list of `ContextData` objects containing enriched metadata about a Confluence page.  \n- Uses dictionary `.get()` methods to safely access metadata and page information.\n\n3. **Business Logic**:  \nThe code supports the business need to augment references to Confluence pages with rich metadata (e.g., page ID, title) to provide enhanced context in workflows such as ticketing, documentation linking, or knowledge management systems.\n\n4. **Dependencies**:  \n- An external Confluence service accessed asynchronously (`confluence_service.execute`).  \n- Custom classes/types such as `Reference`, `ContextData`, and `ContextSourceType`.  \n- A caching mechanism implemented as a dictionary (`self.cache`).  \n- A service manager component (`self.service_manager`) for service retrieval.\n\n5. **Configuration**:  \n- Cache usage is controlled via the `use_cache` boolean parameter.  \n- The Confluence page ID is expected to be present in the `reference",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:28.294122",
      "status": "summarized"
    },
    "enricher.py:chunk_15": {
      "chunk_id": "enricher.py:chunk_15",
      "file_path": "orchestration\\context_enricher\\implementations\\enricher.py",
      "chunk_hash": "2e2a02924815930542a8b5e8424017f7abb9feb915161b54cff27d4906201dfa",
      "chunk_index": 15,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a Confluence context enricher that processes references to Confluence pages, extracts relevant content and metadata, and optionally caches the enriched context data for reuse.\n\n2. **Technical Details**:  \n- Uses nested dictionary `.get()` calls to safely extract deeply nested data such as page content (`body.storage.value`), space name, and page URL from a `page_info` dictionary.  \n- Constructs a `context_data` object (likely a domain-specific data structure) containing the extracted content and associated metadata.  \n- Maintains an internal cache (`self.cache`) keyed by a `cache_key` to store and retrieve enriched context data, improving efficiency by avoiding redundant enrichment operations.  \n- Appends enriched data to a `context_items` list that is returned at the end of the method.  \n- Implements a `clear_cache()` method to reset the cache state.\n\n3. **Business Logic**:  \nEnriches references to Confluence pages with detailed content and metadata, enabling downstream processes (e.g., search, display, or analysis) to have richer contextual information. The caching mechanism supports performance optimization in scenarios where the same references are enriched multiple times.\n\n4. **Dependencies**:  \n- Assumes existence of a `logger` for error logging.  \n- Uses a `reference` object with attributes like `type`, `normalized_value`, and `metadata`.  \n- Likely part of a larger orchestration framework",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:34.273214",
      "status": "summarized"
    },
    "builder.py:chunk_0": {
      "chunk_id": "builder.py:chunk_0",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "c94f74e165f5ef9cbbac7634df7c4ed217f62dc132e2f53aab79f56f655f7745",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `PromptBuilder` class that formats enriched contextual data into structured prompts tailored for large language model (LLM) consumption, enabling AI agents to respond accurately to software development-related queries.\n\n2. **Technical Details**:  \n- Implements the `IPromptBuilder` interface, ensuring adherence to a contract for prompt construction.  \n- Uses a dictionary of prompt templates keyed by context type (e.g., 'default', 'bug_analysis'), each containing system and user message templates with placeholders.  \n- Employs Python string formatting to inject dynamic content such as user messages and contextual sections into the prompt templates.  \n- The class encapsulates prompt-building logic, promoting modularity and extensibility for adding new prompt types.\n\n3. **Business Logic**:  \nSolves the problem of converting diverse enriched context (from sources like GitHub, Jira, Confluence) into coherent, domain-specific prompts that guide AI agents in assisting software development tasks, including bug analysis and general user requests. This enables automated, context-aware AI assistance, improving developer productivity and issue resolution quality.\n\n4. **Dependencies**:  \n- Standard Python `logging` module for logging purposes.  \n- `typing` module for type annotations (`Dict`, `Any`).  \n- Internal modules:  \n  - `orchestration.shared.interfaces.IPromptBuilder` (interface contract)  \n  - `orchestration.shared.models` for domain models such as `EnrichedContext`, `FormattedPrompt",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:41.186708",
      "status": "summarized"
    },
    "builder.py:chunk_2": {
      "chunk_id": "builder.py:chunk_2",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "46da3981f79285b69aa1fe95786af39694f793b0e6b59aeca4d0c941fd5701a7",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a prompt builder component that constructs formatted prompts for use with large language models (LLMs) based on enriched contextual data and predefined templates.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def build`) to support non-blocking prompt construction.  \n- Employs a template-driven approach where prompts are generated by filling in variables within named templates.  \n- Likely uses structured data classes such as `EnrichedContext` for input and returns a `FormattedPrompt` object.  \n- Contains predefined prompt templates for different use cases like code review, documentation generation, and suggested fixes.  \n- Logging is integrated to trace the prompt building process.\n\n3. **Business Logic**:  \nEnables dynamic generation of context-aware prompts tailored to various developer workflows (e.g., code review, documentation, testing) to improve productivity and automate interactions with LLMs in software development processes.\n\n4. **Dependencies**:  \n- Custom data types such as `EnrichedContext` and `FormattedPrompt` (likely defined elsewhere in the codebase).  \n- Standard Python logging module for operational insights.  \n- Possibly depends on an LLM service or SDK that consumes the generated prompts (not shown in the snippet).\n\n5. **Configuration**:  \n- Supports selection of prompt templates via the `template_name` parameter.  \n- Additional template variables can be passed via `**kwargs` to customize prompt content dynamically.  \n- No explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:47.637547",
      "status": "summarized"
    },
    "builder.py:chunk_4": {
      "chunk_id": "builder.py:chunk_4",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "56b44f6fa1478056173e4b866a8d4a3e7b6515cac47f5f46184f81b1cba5be2c",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet constructs a formatted prompt by combining a system prompt template, a user prompt template, and enriched contextual information. It logs details about the prompt-building process and returns a structured prompt object.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.templates`) to retrieve prompt templates by name, with a fallback to a default template.  \n- Builds context sections and summaries via helper methods (`_build_context_section`, `_build_context_summary`).  \n- Formats user prompts using Python's `str.format()` with dynamic keyword arguments.  \n- Uses structured logging with contextual metadata (`extra` dictionary) to track template usage and prompt lengths.  \n- Returns a `FormattedPrompt` data structure encapsulating the system and user prompts.\n\n3. **Business Logic**:  \nEnables dynamic generation of prompts for an orchestration or conversational AI system, tailoring prompts based on enriched message context and user input. This supports personalized, context-aware interactions, improving response relevance and quality.\n\n4. **Dependencies**:  \n- Assumes existence of `self.templates` dictionary and `FormattedPrompt` class or namedtuple.  \n- Uses a `logger` object for structured logging (likely Python\u2019s standard `logging` module or a wrapper).  \n- Relies on enriched context objects with attributes like `context_items` and `parsed_message.references`.\n\n5. **Configuration**:  \n- Template definitions are likely configured externally and loaded into `self.templates`.  \n- No",
      "embedding_id": null,
      "created_at": "2025-10-22T18:46:56.675172",
      "status": "summarized"
    },
    "builder.py:chunk_6": {
      "chunk_id": "builder.py:chunk_6",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "c16eb1c67ab501ba9590f5e6891aa2e0e9eaee71de81f3da98373ba6a37bda0e",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a method `_build_context_section` that constructs a formatted textual section summarizing enriched contextual information, particularly focusing on GitHub repositories and issues, to be included in a prompt or report.\n\n2. **Technical Details**:  \n- The method accepts an `EnrichedContext` object containing multiple `context_items`.  \n- It filters these items by their `source_type` (e.g., `GITHUB_REPOSITORY`) using list comprehensions.  \n- It builds a Markdown-formatted string with headings and bullet points describing each repository\u2019s attributes such as name, description, language, stars, and URL.  \n- The code uses Python f-strings for string interpolation and conditional default values with `.get()` on dictionaries.  \n- The method returns a string representing the entire context section or a default message if no context is available.\n\n3. **Business Logic**:  \nThe method supports generating human-readable context summaries that enrich prompts or reports with relevant external data (e.g., GitHub repos/issues). This helps users or downstream systems understand the background or references related to a particular message or task, improving decision-making or automation quality.\n\n4. **Dependencies**:  \n- Custom types such as `EnrichedContext` and `ContextSourceType` are used, likely defined elsewhere in the codebase.  \n- No explicit external libraries are shown in the snippet, but it depends on the data structure and enums defined in the orchestration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:07.600189",
      "status": "summarized"
    },
    "builder.py:chunk_8": {
      "chunk_id": "builder.py:chunk_8",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "81322c42b2c367eea750d8872fdb5121ca68600e451b59b443c96a95e4b3c636",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet constructs formatted textual sections summarizing issue and ticket data extracted from enriched contextual items, specifically GitHub issues and Jira tickets, for inclusion in a larger prompt or report.\n\n2. **Technical Details**:  \n- Uses list comprehensions to filter `enriched_context.context_items` by `source_type` (e.g., `ContextSourceType.GITHUB_ISSUE`, `ContextSourceType.JIRA_ISSUE`).  \n- Iterates over filtered items to extract relevant fields from each item's `data` dictionary.  \n- Builds markdown-formatted strings with issue/ticket details such as title, state, labels, description (truncated to 500 characters), URLs, status, priority, type, and assignee.  \n- Appends these formatted strings to a `sections` list, presumably to be joined later into a final prompt or document.  \n- Uses Python f-strings for clear and concise string interpolation.\n\n3. **Business Logic**:  \nThe code aggregates and formats issue tracking data from multiple sources (GitHub and Jira) to provide a unified, human-readable summary. This supports business processes like status reporting, context enrichment for automated workflows, or generating prompts for AI systems that require consolidated project issue context.\n\n4. **Dependencies**:  \n- Relies on an `enriched_context` object containing `context_items` with a `source_type` attribute and a `data` dictionary.  \n- Uses `Context",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:14.702943",
      "status": "summarized"
    },
    "builder.py:chunk_10": {
      "chunk_id": "builder.py:chunk_10",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "63174de81ccaf3366060b3516cba1c1b2e7a2aae1de4487799d8376867a52178",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a prompt builder module that constructs textual summaries from enriched contextual data, specifically aggregating and formatting information from various source types such as Confluence pages and GitHub/Jira items.\n\n2. **Technical Details**:  \n- Uses list comprehensions and conditional filtering to extract context items by their source type (e.g., Confluence pages).  \n- Builds formatted Markdown-like text sections with titles, metadata, and content previews.  \n- Maintains a dictionary counter to tally different types of context items (repositories, issues, pull requests, Jira issues, Confluence pages).  \n- The code is structured in methods, likely within a class, to modularize summary building logic.\n\n3. **Business Logic**:  \nThe code supports generating concise, human-readable summaries of aggregated project or organizational knowledge from multiple integrated sources (GitHub, Jira, Confluence). This helps users quickly understand the scope and content of relevant context items, facilitating better decision-making or automated prompt generation for AI workflows.\n\n4. **Dependencies**:  \n- Relies on domain-specific enumerations like `ContextSourceType` to identify source types.  \n- Uses a data model `EnrichedContext` which encapsulates context items with metadata.  \n- No explicit external libraries shown in the snippet, but likely depends on internal modules defining these types.\n\n5. **Configuration**:  \n- No direct environment variables or configuration files are referenced in this snippet.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:18.679963",
      "status": "summarized"
    },
    "builder.py:chunk_12": {
      "chunk_id": "builder.py:chunk_12",
      "file_path": "orchestration\\prompt_builder\\implementations\\builder.py",
      "chunk_hash": "82a6e5f69d95935232a55c0f68c2a106b401841661499ee8e5c9ff775d540d33",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a prompt builder module that aggregates counts of different context sources (e.g., repositories, GitHub issues, PRs, Jira tickets, Confluence pages) to generate a summary string describing the available context enrichment. It also provides a method to add custom prompt templates consisting of system and user messages.\n\n2. **Technical Details**:  \n- Uses a dictionary `counts` to track the number of items per context source type.  \n- Constructs a list of descriptive strings (`parts`) conditionally based on the counts.  \n- Joins these parts into a human-readable summary string or returns a default message if no context is present.  \n- Maintains a `templates` dictionary keyed by template name, storing system and user prompt strings.  \n- The code snippet uses simple control flow (if-elif) and string formatting.\n\n3. **Business Logic**:  \n- Helps in dynamically building enriched prompts by summarizing the types and quantities of contextual data available, which can be used to tailor AI or chatbot interactions.  \n- Supports extensibility by allowing addition of custom prompt templates, enabling flexible prompt engineering for different use cases or clients.\n\n4. **Dependencies**:  \n- References an enum or constant `ContextSourceType` (likely defined elsewhere) to identify source types.  \n- No external libraries or services are explicitly used in this snippet.\n\n5. **Configuration**:  \n- No environment variables or external configuration are evident",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:25.168576",
      "status": "summarized"
    },
    "azure_services.py:chunk_0": {
      "chunk_id": "azure_services.py:chunk_0",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "c3115068382e5be7ffe972a5526322119536708d84d3745834f52cb07417869e",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\services\\integrations\\azure_services.py`**\n\n1. **Purpose**  \n   This module implements Azure AI service integrations specifically for speech capabilities (Speech-to-Text and Text-to-Speech) within an Integration Hub platform, providing asynchronous connection management and status testing.\n\n2. **Technical Details**  \n   - Defines an `AzureSpeechService` class inheriting from a generic `BaseService` base class.  \n   - Uses asynchronous methods (`async def`) for non-blocking operations, suitable for I/O-bound tasks like network calls.  \n   - Utilizes a manager singleton (`azure_ai_manager.speech`) to check service availability and presumably handle underlying Azure Speech SDK interactions.  \n   - Employs structured logging via a shared logger instance.  \n   - Uses service status enums (`ServiceStatus`) to track connection state.  \n   - Returns structured dictionaries for connection test results.\n\n3. **Business Logic**  \n   Enables the Integration Hub to connect to Azure\u2019s Speech AI services, facilitating speech recognition and synthesis capabilities. This supports business use cases such as voice-enabled applications, transcription services, or interactive voice response systems.\n\n4. **Dependencies**  \n   - `httpx`: Although imported, not used in the shown snippet, likely for HTTP requests elsewhere.  \n   - `typing`: For type hinting (`Dict`, `Any`, `List`).  \n   - Internal modules:  \n     - `shared.services.base` for base service abstractions and status enums.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:32.442254",
      "status": "summarized"
    },
    "azure_services.py:chunk_2": {
      "chunk_id": "azure_services.py:chunk_2",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "660addffbe5499c8ac458f9ac42c40bedc03f8477042f3d327c91c2200cb8d12",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an Azure Speech Service integration within a larger application, providing methods to check service connectivity, list speech-related capabilities, and handle execution requests related to Azure's speech functionalities.\n\n2. **Technical Details**:  \n- The code uses asynchronous methods (`async def`) to support non-blocking operations, likely to integrate with async frameworks or event loops.  \n- It returns structured dictionaries indicating success status, error messages, and available features.  \n- The design follows a service class pattern, encapsulating Azure Speech Service interactions within a class (implied by method indentation and naming).  \n- It uses attribute checking (`hasattr`) to safely access configuration details like the service region.\n\n3. **Business Logic**:  \n- Enables the application to verify if Azure Speech Service is properly configured and connected.  \n- Provides a list of supported speech features (Speech-to-Text, Text-to-Speech, Voice Recognition) to inform other components or UI elements about available capabilities.  \n- Prevents unsupported direct execution of speech actions, guiding users to use designated Azure test endpoints instead.\n\n4. **Dependencies**:  \n- Azure AI Manager or SDK (implied by `azure_ai_manager.speech` usage).  \n- Python async features and typing (`Dict`, `Any`, `List`).  \n- Base classes or modules such as `BaseService` (for `AzureTranslatorService`), indicating a larger service framework.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:37.689304",
      "status": "summarized"
    },
    "azure_services.py:chunk_4": {
      "chunk_id": "azure_services.py:chunk_4",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "f0aa9c24f5e630de0e3c02a8c1a2d351a718b6a6fcd9c41d844dd83d6f242783",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code manages the connection lifecycle and health check for the Azure Translator service within an application, enabling translation and language detection capabilities.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) for disconnect and connection testing, suggesting integration in an async environment.  \n- Checks service availability via `azure_ai_manager.translation.is_available()`.  \n- Maintains internal service status using methods like `_set_connected()`, `_set_error()`, and a `status` attribute with enum `ServiceStatus`.  \n- Returns structured dictionaries for connection test results, including success flags, error messages, and supported features.\n\n3. **Business Logic**:  \nEnsures reliable integration with Azure Translator to provide multilingual translation and language detection features, critical for applications requiring internationalization or communication across languages.\n\n4. **Dependencies**:  \n- `azure_ai_manager` module or object managing Azure AI service clients.  \n- Logging via `logger`.  \n- `ServiceStatus` enum for service state management.  \n- Python standard libraries for async programming and exception handling.\n\n5. **Configuration**:  \n- Requires Azure Translator credentials via environment variables or config keys: `AZURE_TRANSLATOR_KEY` and `AZURE_TRANSLATOR_REGION`.  \n- These are validated implicitly by `azure_ai_manager.translation.is_available()`.\n\n6. **Error Handling**:  \n- Catches generic `Exception` during connection attempts, logs error messages, and updates service status accordingly.  \n- Handles",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:43.005340",
      "status": "summarized"
    },
    "azure_services.py:chunk_6": {
      "chunk_id": "azure_services.py:chunk_6",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "ac436be5057d1a0e48af6ad4c3727eb1300cbbcdbae7338f6110ff1069a3e065",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines service classes to interface with Azure AI offerings, specifically Azure Translator and Azure OpenAI services, providing connection management, capability querying, and action execution stubs.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) for non-blocking operations.  \n- Implements service classes (`AzureTranslatorService`, `AzureOpenAIService`) inheriting from a base class (`BaseService`).  \n- Uses try-except blocks for error handling.  \n- Returns structured dictionaries indicating success status, error messages, and feature lists.  \n- Checks attributes dynamically (e.g., `hasattr`) to determine configuration details.\n\n3. **Business Logic**:  \nEnables integration with Azure AI services to support language translation, language detection, and access to Azure OpenAI models, facilitating multilingual communication and AI-powered text generation within business applications.\n\n4. **Dependencies**:  \n- `azure_ai_manager` module or object managing Azure AI service instances and configurations.  \n- `logger` for logging informational and error messages.  \n- Python standard libraries for typing (`Dict`, `Any`, `List`) and async programming.\n\n5. **Configuration**:  \n- Relies on Azure AI manager's internal configuration for region and model availability.  \n- Configuration details such as region are accessed dynamically from the `azure_ai_manager.translation.region` attribute if present.  \n- No explicit environment variables or config files shown, but implied through `azure_ai_manager",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:51.055013",
      "status": "summarized"
    },
    "azure_services.py:chunk_8": {
      "chunk_id": "azure_services.py:chunk_8",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "87d51072f1f02c739103c2ad5b55ba04212ac17c6c8590f3602c64e754c42e83",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code provides asynchronous service methods to manage and test connections to the Azure OpenAI service, including disconnecting and verifying the availability and configuration of the Azure OpenAI models.\n\n2. **Technical Details**:  \n- Uses asynchronous Python (`async def`) for non-blocking I/O operations.  \n- Interacts with an `azure_ai_manager` object that encapsulates Azure OpenAI model management, including checking availability and fetching deployment info.  \n- Returns structured dictionaries to communicate connection test results, including success status, error messages, and available models.  \n- Uses try-except blocks for error handling and fallback logic when fetching deployment info.\n\n3. **Business Logic**:  \nEnables the application to programmatically verify and manage connectivity to Azure OpenAI services, ensuring that the AI models are properly configured and accessible. This supports business use cases requiring AI model inference or generation by validating service readiness and providing meaningful feedback on configuration issues.\n\n4. **Dependencies**:  \n- `azure_ai_manager`: A presumably custom or third-party manager handling Azure OpenAI interactions.  \n- `ServiceStatus`: An enum or constant set representing connection states (e.g., `DISCONNECTED`).  \n- Python's `asyncio` for asynchronous execution.  \n- Standard Python typing (`Dict`, `Any`) for type hints.\n\n5. **Configuration**:  \n- Requires environment variables or configuration settings: `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_KEY` to authenticate",
      "embedding_id": null,
      "created_at": "2025-10-22T18:47:58.631913",
      "status": "summarized"
    },
    "azure_services.py:chunk_10": {
      "chunk_id": "azure_services.py:chunk_10",
      "file_path": "shared\\services\\integrations\\azure_services.py",
      "chunk_hash": "5a8f8b6f1df414bc239c3a705e520fa23401922ac611a4ce133afaeea34507e5",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis snippet is part of an Azure OpenAI integration service that provides asynchronous methods to execute actions related to Azure OpenAI and retrieve the capabilities supported by the service.\n\n2. **Technical Details**:  \n- Uses asynchronous Python (`async def`) for non-blocking I/O operations.  \n- Returns structured dictionaries indicating success status, errors, and data payloads.  \n- The `execute` method explicitly disallows direct execution, suggesting a design that enforces usage of specific test endpoints instead.  \n- The `get_capabilities` method returns a static list of supported Azure OpenAI features.\n\n3. **Business Logic**:  \n- Facilitates interaction with Azure OpenAI services by exposing capabilities and controlling how actions are executed, likely to ensure compliance with usage policies or testing workflows.  \n- Helps clients understand what AI functionalities are available (e.g., GPT-4 models, code generation) without allowing direct execution in this context.\n\n4. **Dependencies**:  \n- Likely depends on Python\u2019s `asyncio` for asynchronous execution.  \n- Uses standard typing hints (`Dict`, `Any`, `List`) from Python\u2019s `typing` module.  \n- Presumably part of a larger codebase that integrates with Azure OpenAI SDK or REST APIs (not shown in snippet).\n\n5. **Configuration**:  \n- No explicit configuration or environment variables are shown in this snippet.  \n- The comment in `execute` implies that actual execution requires configuration of Azure",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:04.871808",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_0": {
      "chunk_id": "fallback_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "44650f96c911f7efc5f25358872b3b2559773a7401e15b1e90969b3fe03cba62",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a fallback parser class for parsing source code files in unsupported or generic text-based languages by chunking the content based on simple line heuristics, enabling basic code intelligence features when advanced parsers (like tree-sitter) are unavailable.\n\n2. **Technical Details**:  \n- Implements a `FallbackParser` class inheriting from `BaseParser`.  \n- Uses line-based chunking heuristics including blank lines, indentation changes, function/class signature detection, comment blocks, and token count thresholds (200-400 tokens) to split code into manageable chunks.  \n- Reads file content with UTF-8 encoding and ignores decoding errors.  \n- Logging is used for error reporting.  \n- Returns a list of `CodeChunk` objects representing parsed code segments.  \n- The parser identifies supported file extensions broadly, including `.txt`, `.md`, `.json`, `.yaml`, `.xml`, `.html`, `.css`, etc.\n\n3. **Business Logic**:  \nProvides a robust fallback mechanism to parse and chunk code files when language-specific parsers are not available, ensuring that the code intelligence system can still process and analyze a wide variety of file types, thereby improving coverage and user experience in multi-language environments.\n\n4. **Dependencies**:  \n- Python standard libraries: `typing` (for type hints), `pathlib` (file path handling), `logging` (error logging).  \n- Internal modules: `.base_parser` providing `BaseParser",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:12.986178",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_2": {
      "chunk_id": "fallback_parser.py:chunk_2",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "be7b7218ab91ff3ceb01b2244912ef3f3b139b8f678a7055a2c84605e408e7ad",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis method `_chunk_by_lines` splits a given text content from a file into smaller semantic chunks based on line boundaries and token count limits, facilitating manageable processing of large code files.\n\n2. **Technical Details**:  \n- The content is split into lines and iterated line-by-line.  \n- Each line's token count is estimated via `estimate_tokens(line)`.  \n- Chunks accumulate lines until token thresholds are met.  \n- Semantic boundaries (blank lines, function/class starts detected by `_is_semantic_boundary`) influence chunk breaks.  \n- Two token limits control chunk size: a target chunk size (`target_chunk_tokens`) and a hard max chunk size (`max_chunk_tokens`).  \n- The algorithm prefers breaking chunks at semantic boundaries or blank lines once the target size is reached but forces a break if the max size is exceeded.  \n- Data structures: uses lists to accumulate lines and track chunks; likely returns a list of `CodeChunk` objects (custom data structure).\n\n3. **Business Logic**:  \nEnables efficient and semantically meaningful segmentation of source code files for downstream tasks such as code analysis, indexing, or AI code intelligence processing, improving accuracy and performance by respecting logical code boundaries.\n\n4. **Dependencies**:  \n- Uses a custom `estimate_tokens` method (likely internal or from a tokenizer module).  \n- Uses a custom `_is_semantic_boundary` method to detect logical code boundaries.  \n- Returns a list",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:19.346501",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_4": {
      "chunk_id": "fallback_parser.py:chunk_4",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "b22722f0d8163e6724f5b0880197d3cfe0c9f18018ac437f6c527cd15771014a",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code processes lines of text to form and manage chunks of code blocks, filtering out trivial chunks and creating metadata-enriched code chunk objects for further use.\n\n2. **Technical Details**:  \n- Joins lines in `current_chunk` into a single string `chunk_content`.  \n- Uses a filtering method `should_skip_chunk` to exclude trivial or irrelevant chunks based on content and type (\"code_block\").  \n- Generates a unique chunk identifier via `create_chunk_id` using the file path and chunk index.  \n- Constructs a `ChunkMetadata` object containing chunk ID, file path, detected programming language, line range, chunk type, token count, and content.  \n- Appends a `CodeChunk` object (metadata + content) to a `chunks` list.  \n- Manages chunk boundaries by resetting `current_chunk`, `current_tokens`, and updating `start_line` and `chunk_index`.  \n- Uses incremental token counting (`current_tokens`) and line indexing (`start_line`, `i`) to track chunk size and position.\n\n3. **Business Logic**:  \nThe code supports a fallback parsing mechanism in a code intelligence system, enabling robust extraction and segmentation of code blocks from source files. This facilitates downstream tasks such as code analysis, search indexing, or language detection by structuring raw source code into meaningful, metadata-rich chunks.\n\n4. **Dependencies**:  \n- Custom classes: `ChunkMetadata`, `CodeChunk`  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:26.347642",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_6": {
      "chunk_id": "fallback_parser.py:chunk_6",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "c8109a982553bb108888bf5a65a3992c8a633d05407710767f3918add6fa597b",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code finalizes the processing of a text file by aggregating the last chunk of lines into a code chunk object, filtering out trivial chunks, and returning a list of structured code chunks with associated metadata.\n\n2. **Technical Details**:  \n- The code collects lines into `current_chunk` and joins them into a single string `chunk_content`.  \n- It uses a filtering method `should_skip_chunk` to exclude trivial or irrelevant chunks based on content and type (\"code_block\").  \n- A unique chunk identifier is generated via `create_chunk_id` using the file path and chunk index.  \n- Metadata for each chunk is encapsulated in a `ChunkMetadata` data structure, including file path, language (detected by `_detect_language`), line range, chunk type, token count, and content.  \n- The chunk and its metadata are wrapped into a `CodeChunk` object and appended to the `chunks` list.  \n- Debug logging is used to trace skipped chunks and the total number of chunks created.  \n- The method `_is_semantic_boundary` (partially shown) suggests semantic parsing capabilities, likely to detect logical code boundaries such as functions or classes.\n\n3. **Business Logic**:  \nThis code supports a code intelligence or analysis platform by breaking source files into meaningful, manageable chunks for downstream processing such as indexing, searching, or semantic analysis. Filtering trivial chunks improves data quality and relevance.\n\n4. **Dependencies**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:33.639215",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_8": {
      "chunk_id": "fallback_parser.py:chunk_8",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "22ffe4af0bbfd314d4058b1842779057721675724c35003448088bf725fa2f1c",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a fallback parser module designed to identify whether a given line of code likely represents a function, class, or related code structure by matching common language-specific keywords. It also includes a simple utility to detect the programming language of a source file based on its file extension.\n\n2. **Technical Details**:  \n- Uses a predefined list of string patterns representing keywords and comment styles common in multiple programming languages (Python, JavaScript, Java, C++, etc.).  \n- Implements a check using Python\u2019s `str.startswith()` method combined with `any()` to efficiently determine if a line starts with any of these patterns.  \n- Language detection is performed by extracting the file extension using `Path(file_path).suffix.lower()` and mapping it to a language string via a dictionary (`ext_map`).  \n- The code snippet shows partial implementation, indicating modular design with private methods (e.g., `_detect_language`) likely used internally within a class.\n\n3. **Business Logic**:  \nThis code supports a code intelligence or analysis tool that needs to parse and understand source code files from multiple languages. By detecting language and identifying key code constructs, it enables features such as syntax highlighting, code navigation, or automated documentation generation, thereby improving developer productivity and code quality analysis.\n\n4. **Dependencies**:  \n- Uses Python\u2019s standard library `pathlib.Path` for file path and extension handling.  \n- No external third-party libraries are shown in",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:39.550911",
      "status": "summarized"
    },
    "fallback_parser.py:chunk_10": {
      "chunk_id": "fallback_parser.py:chunk_10",
      "file_path": "code-intelligence\\parsers\\fallback_parser.py",
      "chunk_hash": "f08e246377555c8fe9fd6cf1a285fc0c8fe47f11954a2c7aa9dfb95e51f162e6",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet maps file extensions to corresponding language or format identifiers, returning a default value of `'text'` if the extension is not recognized.\n\n2. **Technical Details**:  \n- Uses a Python dictionary (`ext_map`) to associate file extensions (e.g., `.php`, `.md`) with language keys (e.g., `'php'`, `'markdown'`).  \n- Utilizes the dictionary `.get()` method to retrieve the mapped language or return a fallback `'text'` string if the extension is absent from the map.\n\n3. **Business Logic**:  \nEnables the system to identify the language or content type of a file based on its extension, which is essential for syntax highlighting, parsing, or processing files correctly in a code intelligence or analysis platform.\n\n4. **Dependencies**:  \nNo external libraries or modules are used in this snippet; it relies solely on built-in Python data structures.\n\n5. **Configuration**:  \nNo environment variables or external configuration influence this mapping; the extension-to-language mapping is hardcoded.\n\n6. **Error Handling**:  \nNo explicit error handling is present; the use of `.get()` with a default value ensures that missing keys do not raise exceptions.\n\n7. **API/Interface**:  \nThis snippet appears to be part of a function or method that accepts a file extension (`ext`) and returns a language identifier string. The exact function signature is not shown.\n\n8. **Performance",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:43.850276",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_0": {
      "chunk_id": "resilient_orchestrator.py:chunk_0",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "c3a4be7e6c0a0d6cd2f442e722de19c6f783ec03bab9b107877cc02a37eec924",
      "chunk_index": 0,
      "summary": "**Summary of `shared/llm_providers/resilient_orchestrator.py`**\n\n---\n\n1. **Purpose**  \n   This module implements a resilient orchestrator for Large Language Model (LLM) providers, enabling automatic fallback and retry mechanisms to ensure reliable LLM request fulfillment across multiple providers.\n\n2. **Technical Details**  \n   - Uses an `Enum` (`ProviderStatus`) to represent various outcomes of provider attempts (success, failure, timeout, rate limiting, unavailability).  \n   - Implements a priority-based provider selection list, configurable via application settings.  \n   - Employs retry logic and a circuit breaker pattern to avoid repeatedly calling failing providers.  \n   - Uses asynchronous programming (`asyncio`) to potentially handle concurrent or asynchronous LLM calls.  \n   - Tracks detailed error states for each provider attempt to inform fallback decisions and reporting.\n\n3. **Business Logic**  \n   Ensures high availability and reliability of LLM-powered features by automatically switching between multiple LLM providers (e.g., Azure, Together, OpenAI) when one or more providers fail or become unavailable, thus minimizing downtime or degraded user experience.\n\n4. **Dependencies**  \n   - Python standard libraries: `logging`, `enum`, `asyncio`, `typing` (for type hints).  \n   - Internal module: `shared.config.settings` for configuration management.  \n   - LLM providers (Azure, Together, OpenAI) are implied dependencies, though their SDKs or APIs are not shown",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:50.719550",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_2": {
      "chunk_id": "resilient_orchestrator.py:chunk_2",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "c6e74c52dc867c3ecfb761782101392e03b88cf46cdc1c66c1aa75ab6ec512aa",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a resilient orchestrator designed to perform chat completions using multiple large language model (LLM) providers with automatic fallback and retry logic to ensure high availability and reliability.\n\n2. **Technical Details**:  \n- Maintains a prioritized list of LLM providers: `'together'` (primary), `'azure'` (fallback 1), and `'openai'` (fallback 2 if configured).  \n- Tracks failure counts per provider in a dictionary (`provider_failures`) to avoid repeatedly calling failing providers beyond a threshold (`max_failures_before_skip`).  \n- Implements an asynchronous method `chat_completion_with_fallback` that accepts chat messages and parameters like temperature, max retries, preferred provider, and model choice.  \n- Uses a helper method `_get_provider_order` to reorder providers based on preference.  \n- Supports retry logic per provider (`max_retries`) and enforces a timeout (`timeout_seconds`) for each call.  \n- Returns a tuple containing the response text and associated metadata.\n\n3. **Business Logic**:  \nEnsures robust and uninterrupted chat completion services by automatically switching between multiple LLM providers in case of failures or unavailability, thus improving user experience and service reliability in applications relying on AI-driven conversational capabilities.\n\n4. **Dependencies**:  \n- Python `asyncio` for asynchronous execution.  \n- Typing module for type hints (`List`, `Dict`, `Tuple`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:48:56.888898",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_4": {
      "chunk_id": "resilient_orchestrator.py:chunk_4",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "e5567e8b6e5ab8a3573983f75aa20b057d1b0ab5a7b4031ac056676e08632874",
      "chunk_index": 4,
      "summary": "**Summary of `shared\\llm_providers\\resilient_orchestrator.py` snippet**\n\n---\n\n1. **Purpose**  \nThis code snippet implements a resilient orchestration mechanism to send requests to multiple Large Language Model (LLM) providers sequentially, with retry logic and failure tracking to ensure high availability and fault tolerance.\n\n2. **Technical Details**  \n- Iterates over a list of LLM providers in a specified order.  \n- Maintains a failure count per provider (`self.provider_failures`) to implement a circuit breaker pattern, skipping providers with too many recent failures.  \n- For each provider, attempts multiple retries (`max_retries`) to get a successful response.  \n- Uses asynchronous calls (`await self._try_provider(...)`) to interact with providers, enabling concurrency and non-blocking IO.  \n- Logs detailed attempt and failure information for observability.  \n- Collects errors and attempt logs in lists (`all_errors`, `attempts_log`) for further processing or reporting.  \n\n3. **Business Logic**  \nThe code addresses the business need for reliable and resilient access to multiple LLM providers, ensuring that service degradation or outages in one provider do not block the overall system. It balances load and availability by skipping providers that are currently failing too often, thus improving user experience and system robustness.\n\n4. **Dependencies**  \n- Uses an asynchronous programming model (likely `asyncio`).  \n- Relies on a logging framework (`logger`).  \n- Depends on an",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:03.963308",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_6": {
      "chunk_id": "resilient_orchestrator.py:chunk_6",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "e67433b5c0252134fb6e3c10552d99b6a359dd9afccf1f01f5b5719500704752",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a resilient orchestrator that attempts to call multiple language model providers sequentially until one succeeds or all fail, managing retries and fallback logic.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`asyncio.TimeoutError` handling) to manage timeouts on provider calls.  \n- Maintains a failure count per provider (`self.provider_failures`) to track reliability.  \n- Logs attempts and metadata including which provider was used, attempt number, and whether fallback was needed.  \n- Uses a list (`attempts_log`) to record each attempt's details for diagnostics or auditing.\n\n3. **Business Logic**:  \nEnsures high availability and reliability of language model responses by orchestrating multiple providers with fallback and retry mechanisms, minimizing downtime or failed requests in production AI services.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous timeout handling.  \n- A logging framework (`logger`) for info and warning messages.  \n- Presumably internal modules or classes managing provider calls and metadata updates.\n\n5. **Configuration**:  \n- Timeout duration configured via `self.timeout_seconds`.  \n- Provider names and models likely configured elsewhere in the orchestrator or injected dynamically.\n\n6. **Error Handling**:  \n- Specifically catches `asyncio.TimeoutError` to handle provider call timeouts gracefully.  \n- On timeout, logs a warning and appends attempt details to `attempts_log` for tracking.\n\n7. **",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:13.090877",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_8": {
      "chunk_id": "resilient_orchestrator.py:chunk_8",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "bb04a837fc1aadacb4d01eaea1a4c61bc6cfecd1610a5408ce3de0a62452a564",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an asynchronous retry mechanism that attempts to call multiple providers in sequence, logging failures and timeouts, and tracking the number of failed attempts per provider.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`asyncio.sleep`) to introduce delays between retries.  \n- Implements retry logic with a maximum number of attempts (`max_retries`).  \n- Maintains logs of each attempt with status and error messages in `attempts_log`.  \n- Tracks cumulative failures per provider in `self.provider_failures`.  \n- Uses structured error handling with specific handling for timeouts and generic exceptions.  \n- Aggregates error messages in `all_errors` for reporting or further processing.\n\n3. **Business Logic**:  \nEnsures resilience and reliability when interacting with multiple external LLM (Large Language Model) providers by retrying failed calls, logging errors, and tracking provider health to potentially avoid or deprioritize unreliable providers.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous operations and delays.  \n- A logging module (`logger`) for warning messages.  \n- `ProviderStatus` enum or similar construct for standardized status codes (e.g., TIMEOUT, FAILED).  \n- Presumably part of a larger orchestrator managing multiple LLM providers.\n\n5. **Configuration**:  \n- `max_retries` controls the number of retry attempts per provider.  \n- `self.provider_failures` likely initialized elsewhere",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:16.915919",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_10": {
      "chunk_id": "resilient_orchestrator.py:chunk_10",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "69b7f10db179e301f29ee15e5216ad136045f222a0d7fc855f4539a19fa6eac4",
      "chunk_index": 10,
      "summary": "1. **Purpose**  \nThis code snippet defines an asynchronous method `_try_provider` within a resilient orchestrator that attempts to query a specified Large Language Model (LLM) provider with given chat messages, enforcing a timeout to ensure responsiveness. It is part of a broader orchestration mechanism that tries multiple LLM providers and logs errors if all fail.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle potentially slow network I/O calls to LLM providers.  \n- Employs a factory design pattern (`LLMFactory`) to instantiate provider objects dynamically based on the provider name.  \n- Uses `asyncio.wait_for` to impose a timeout on the provider call, preventing indefinite waits.  \n- Returns a tuple containing the LLM response and associated metadata (though metadata construction is incomplete in the snippet).  \n- Logs errors and raises exceptions when all providers fail, aggregating error messages for diagnostics.\n\n3. **Business Logic**  \nThe code supports a fault-tolerant mechanism to query multiple LLM providers for chat completions, ensuring high availability and reliability of AI-driven conversational features. It allows fallback across providers to maintain service continuity if one or more providers fail or timeout.\n\n4. **Dependencies**  \n- Internal module: `shared.llm_providers.factory.LLMFactory` for provider instantiation.  \n- Python standard library: `asyncio` for asynchronous execution and timeout management.  \n- Logging (implied by `logger.error`) for error tracking",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:21.607751",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_12": {
      "chunk_id": "resilient_orchestrator.py:chunk_12",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "a73ba46952acd9d96dac67736f50b5565d01ca5b019e53457a11f14e0b8018e5",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code is part of a resilient orchestrator module managing multiple LLM (Large Language Model) providers. It determines the order of providers to use, resets failure counters (circuit breakers), and selects providers based on roles to ensure reliable and prioritized usage of LLM services.\n\n2. **Technical Details**:  \n- Uses a list (`provider_priority`) to maintain provider order and priority.  \n- Implements a method `_get_provider_order` that optionally reorders providers to prioritize a preferred one by moving it to the front of the list.  \n- Maintains a dictionary (`provider_failures`) to track failure counts per provider, enabling a circuit breaker pattern to avoid repeatedly calling failing providers.  \n- The `reset_circuit_breakers` method resets all failure counts to zero.  \n- The `get_provider_for_role` method fetches the configured provider for a given role, likely from a centralized settings module.\n\n3. **Business Logic**:  \nThe code supports business continuity and reliability in AI service consumption by orchestrating multiple LLM providers. It prioritizes providers, handles failover through circuit breakers, and allows role-based provider selection, ensuring that the best or preferred AI model is used depending on the task (e.g., chat, embedding, beautify).\n\n4. **Dependencies**:  \n- Imports `settings` from `shared.config`, indicating reliance on a centralized configuration system.  \n- Uses standard Python typing (`Optional`, `List`).",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:29.384551",
      "status": "summarized"
    },
    "resilient_orchestrator.py:chunk_14": {
      "chunk_id": "resilient_orchestrator.py:chunk_14",
      "file_path": "shared\\llm_providers\\resilient_orchestrator.py",
      "chunk_hash": "3f9c4dccb0327e28d0ef1005e6c13641498c1ecaa5ff8e43b7915a2c90cf8320",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a resilient orchestrator for managing multiple large language model (LLM) providers. It maps roles to specific providers, retrieves the health status of all providers, and exposes a global orchestrator instance for consistent access.\n\n2. **Technical Details**:  \n- Uses a dictionary (`role_mapping`) to map functional roles (e.g., \"chat\", \"embedding\", \"beautify\") to configured LLM providers.  \n- Implements a fallback mechanism where if the role is not explicitly mapped, it defaults to an \"auto\" provider which resolves to a default LLM provider from settings.  \n- Tracks provider failure counts in `self.provider_failures` and uses a threshold (`self.max_failures_before_skip`) to determine if a circuit breaker is active for a provider, preventing further calls to failing providers.  \n- The `get_provider_health` method returns a nested dictionary summarizing failure counts and circuit breaker status per provider, along with the threshold value.  \n- Uses a singleton/global pattern with `_global_orchestrator` and a getter function `get_resilient_orchestrator()` to provide a single orchestrator instance application-wide.\n\n3. **Business Logic**:  \nThis orchestrator ensures high availability and fault tolerance when interacting with multiple LLM providers by dynamically selecting providers based on role and health status. It helps maintain service continuity by avoiding providers that have recently failed beyond a threshold, thus improving reliability of AI-driven features like chat",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:37.243783",
      "status": "summarized"
    },
    "embedding_service.py:chunk_0": {
      "chunk_id": "embedding_service.py:chunk_0",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "23dba47e21b25bc7cb8d75d737a4b31003e09d05f8082c23d6291d587caa0c37",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module defines an `EmbeddingService` class responsible for generating vector embeddings from text inputs. It primarily uses Together AI's embedding models with a fallback to a hash-based embedding approach if the primary service is unavailable.\n\n2. **Technical Details**  \n- The service supports multiple embedding providers, selected dynamically based on a \"role\" via a resilient orchestrator pattern.  \n- It imports Together AI SDK for embedding generation.  \n- The fallback embedding method uses hashing (likely SHA or similar) combined with struct packing to produce deterministic fixed-size vector embeddings when the AI service is not accessible.  \n- The design follows a provider abstraction pattern, allowing easy extension to other embedding providers (e.g., Azure).  \n- Uses Python standard logging for traceability.\n\n3. **Business Logic**  \nThe service addresses the need for consistent, high-quality vector embeddings for text data, which are foundational for downstream applications such as semantic search, recommendation systems, or NLP tasks. By supporting multiple providers and fallback mechanisms, it ensures robustness and availability in production environments.\n\n4. **Dependencies**  \n- `together` Python SDK for Together AI embeddings.  \n- Internal modules: `shared.config.settings` for configuration, and `shared.llm_providers.resilient_orchestrator` for provider selection logic.  \n- Standard Python libraries: `logging`, `os`, `hashlib`, `struct`, and typing utilities.\n\n5. **Configuration**  \n- Provider selection can be configured via",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:42.052525",
      "status": "summarized"
    },
    "embedding_service.py:chunk_2": {
      "chunk_id": "embedding_service.py:chunk_2",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "bef95ac77083a846a05ac6549583af792c8bcd2a3ef9715339d1d37d4bf971b9",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet initializes an embedding service by selecting and configuring an embedding model based on the provider (Azure OpenAI or Together AI). It sets the embedding vector dimensions dynamically according to the chosen model and initializes the corresponding client for generating embeddings.\n\n2. **Technical Details**:  \n- Uses conditional logic to determine embedding vector dimensions based on the model name string (e.g., \"3-large\" \u2192 3072 dimensions, \"3-small\" \u2192 1536 dimensions).  \n- Supports multiple embedding providers with separate initialization methods (`_initialize_azure_client()` and `_initialize_together_client()`).  \n- Employs logging to track initialization details.  \n- Uses instance variables (`self.embedding_model`, `self.dimension`, `self.fallback_dimension`) to store configuration state.  \n\n3. **Business Logic**:  \nThe code supports flexible embedding generation for different AI providers, enabling the application to embed technical documentation, code, and business content efficiently. This flexibility allows the business to leverage multiple AI services and optimize embedding quality and dimensionality for downstream tasks such as search, recommendation, or semantic analysis.\n\n4. **Dependencies**:  \n- Azure OpenAI service (implied by `azure_openai_embedding_deployment` setting and Azure client initialization).  \n- Together AI embedding service (implied by `together_embedding_model` and client initialization).  \n- A logging framework (indicated by `logger.info`).  \n- Configuration/settings management (accessed via `self",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:48.489597",
      "status": "summarized"
    },
    "embedding_service.py:chunk_4": {
      "chunk_id": "embedding_service.py:chunk_4",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "2a2047825e9939cdd172832aa438b467e613b3a977f4e112891163a16f184bf7",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis code snippet initializes an Azure OpenAI client specifically for generating embeddings, enabling the application to leverage Azure's OpenAI embedding services. It also logs relevant configuration details and falls back to a hash-based embedding method if Azure credentials are missing.\n\n2. **Technical Details**  \n- Uses a private method `_initialize_azure_client` to encapsulate client setup logic.  \n- Dynamically imports `AzureOpenAI` from the `openai` package within the method scope to avoid import errors if the package is unavailable.  \n- Reads API keys, endpoint URLs, and API versions from a settings object.  \n- Uses conditional logic to select the embedding API version, preferring a dedicated embedding API version if available.  \n- Sets a boolean flag `self.api_available` to indicate client readiness.  \n- Logs detailed information about the client initialization and fallback status.\n\n3. **Business Logic**  \nEnables the application to generate vector embeddings for data (e.g., text) using Azure OpenAI\u2019s embedding API, which is critical for features like semantic search, recommendation, or similarity detection. The fallback to hash-based embeddings ensures continued operation even if Azure credentials are missing, maintaining service availability.\n\n4. **Dependencies**  \n- `openai` Python package, specifically the `AzureOpenAI` client class.  \n- A `settings` object or module providing Azure OpenAI credentials and API version configurations.  \n- A `logger` for logging informational and",
      "embedding_id": null,
      "created_at": "2025-10-22T18:49:56.102423",
      "status": "summarized"
    },
    "embedding_service.py:chunk_6": {
      "chunk_id": "embedding_service.py:chunk_6",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "89d3baed4b9b6e9a0ac2cbf8bdb8bb1ae37dd879136ffa1b5c1a00337a0fa479",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an embedding service that initializes a client for Together AI's embedding API. It attempts to configure the client using API keys from settings or environment variables, falling back to a hash-based embedding method if initialization fails.\n\n2. **Technical Details**:  \n- Uses environment variables and application settings to retrieve API keys.  \n- Implements a fallback mechanism by setting `self.client` to `None` and `self.api_available` to `False` if initialization fails.  \n- Uses logging extensively to track initialization success or failure and to provide diagnostic information.  \n- Encapsulated in a method `_initialize_together_client`, suggesting an object-oriented design pattern where the embedding service manages multiple client initializations.\n\n3. **Business Logic**:  \nThe code supports embedding generation for vector databases or AI models by integrating with Together AI's embedding service. It ensures that if the external API is unavailable or misconfigured, the system gracefully falls back to a hash-based embedding method, maintaining service continuity.\n\n4. **Dependencies**:  \n- `Together` client library (likely a third-party SDK for Together AI).  \n- `os` module for environment variable access.  \n- `logger` for logging warnings and info messages.  \n- `self.settings` object for configuration management.\n\n5. **Configuration**:  \n- Environment variable: `TOGETHER_API_KEY` for API authentication.  \n- Settings attribute: `together_api_key` as",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:03.267746",
      "status": "summarized"
    },
    "embedding_service.py:chunk_8": {
      "chunk_id": "embedding_service.py:chunk_8",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "7947f6aca89c2e4df10d10bb0064966db78ffa648001675d1e37faef7a2b51c1",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an embedding service that generates vector embeddings for input text using either a configured AI provider (Azure OpenAI or Together AI) or falls back to a hash-based embedding method if the provider is unavailable.\n\n2. **Technical Details**:  \n- Uses asynchronous method `generate_embedding` to produce embeddings.  \n- Supports multiple providers via conditional logic (`self.provider_name`), specifically Azure OpenAI SDK and Together AI REST API.  \n- Embeddings are expected to be 768-dimensional vectors.  \n- Fallback mechanism implemented by setting `self.client = None` and `self.api_available = False` when initialization fails, triggering hash-based embeddings instead.  \n- Uses Python `requests` library for REST API calls to Together AI due to SDK issues.  \n- Logging is used to track initialization failures and fallback usage.\n\n3. **Business Logic**:  \nEnables the application to convert textual data into numerical embeddings for downstream tasks such as semantic search, recommendation, or NLP model input, ensuring robustness by providing a fallback when the preferred AI service is unavailable.\n\n4. **Dependencies**:  \n- `requests` library for HTTP calls to Together AI REST API.  \n- Azure OpenAI SDK (implied by `self.client.embeddings.create`).  \n- Environment variables or settings for API keys (`TOGETHER_API_KEY`).  \n- Logging framework for warnings and info messages.\n\n5. **Configuration**:  \n- API keys retrieved from `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:12.320893",
      "status": "summarized"
    },
    "embedding_service.py:chunk_10": {
      "chunk_id": "embedding_service.py:chunk_10",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "de3488160861f8137eedaf8c902b78dc4ae4b1e641a83426af2faabf7f480d39",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet generates vector embeddings for input text by calling an external embedding API, processes the returned embedding to ensure a fixed dimensionality, and returns the processed embedding vector.\n\n2. **Technical Details**:  \n- Uses an HTTP POST request to send JSON payload containing the model name and input text to an external embedding service endpoint.  \n- Parses the JSON response to extract the embedding vector from a nested data structure.  \n- Adjusts the embedding vector length by truncating or zero-padding to match a predefined fixed dimension.  \n- Utilizes structured logging for debugging embedding generation success and dimensionality.  \n- Implements exception handling to catch and manage any errors during the API call or processing.\n\n3. **Business Logic**:  \nEnables consistent generation of text embeddings for downstream applications such as semantic search, recommendation, or natural language understanding by interfacing with a third-party embedding provider and normalizing output vector sizes.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- External embedding API at `https://api.together.xyz/v1/embeddings`.  \n- Logging module (likely Python\u2019s standard `logging`).\n\n5. **Configuration**:  \n- `api_key` for authorization, presumably injected or loaded from environment variables or secure config.  \n- `self.embedding_model` specifying the embedding model to use, sourced from application settings.  \n- `self.dimension` defining the fixed embedding vector size expected by the application",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:20.178501",
      "status": "summarized"
    },
    "embedding_service.py:chunk_12": {
      "chunk_id": "embedding_service.py:chunk_12",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "20547d9b7632488e62f0d47df10162a47373315cb80eb1f6f3ba8e49803d90db",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet provides a fallback mechanism for generating text embeddings when the primary embedding provider fails. It creates a deterministic, hash-based embedding vector from the input text as a backup.\n\n2. **Technical Details**:  \n- Uses SHA-256 hashing (`hashlib.sha256`) to generate a fixed-length hash of the input text.  \n- Converts the hash bytes into a list of floating-point numbers by unpacking every 4 bytes into a float using `struct.unpack('f', chunk)`.  \n- Ensures the resulting embedding vector meets a required dimensionality (`self.fallback_dimension`) by padding with zeros if necessary.  \n- Logging is used to warn about failures and inform about fallback usage.\n\n3. **Business Logic**:  \nEnsures robustness and continuity in embedding generation for downstream applications (e.g., search, recommendation, NLP tasks) by providing a deterministic fallback embedding when the primary embedding service is unavailable or fails, preventing total failure of embedding-dependent features.\n\n4. **Dependencies**:  \n- Python standard libraries: `hashlib` for hashing, `struct` for byte-to-float conversion, and a logging framework (`logger`).  \n- Presumably part of a larger embedding service class that manages provider interactions.\n\n5. **Configuration**:  \n- `self.provider_name`: identifies the primary embedding provider (likely set elsewhere).  \n- `self.fallback_dimension`: the target dimensionality for the fallback embedding vector, configured as a class attribute or",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:32.439754",
      "status": "summarized"
    },
    "embedding_service.py:chunk_14": {
      "chunk_id": "embedding_service.py:chunk_14",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "5264ee0c773527567ba0f8b5bb5a660eb6b0e8cdc3f3f1bbd3b69f64a1f4b1f0",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis Python code provides an asynchronous service to generate vector embeddings for text data, including batch processing with fallback mechanisms to ensure robustness in embedding generation.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle batch embedding generation efficiently.  \n- Implements chunked batching to process large lists of texts in manageable sizes (`batch_size`).  \n- Introduces delays between batches (`delay_between_batches`) to throttle requests, likely to comply with API rate limits.  \n- Employs slicing to truncate or pad embeddings to a fixed fallback dimension.  \n- Uses exception handling to catch errors during embedding generation and returns a zero vector as a fallback.  \n- Logging is used for debugging and error reporting.  \n- The method signature suggests use of Python type hints (`List[str]`, `Optional[int]`, `Optional[float]`).\n\n3. **Business Logic**:  \nThe code addresses the need to convert textual data into numerical vector embeddings, which are essential for downstream tasks such as semantic search, recommendation systems, or machine learning models. The batch processing and fallback mechanisms ensure reliability and scalability when dealing with large volumes of text data.\n\n4. **Dependencies**:  \n- Python standard library: `asyncio` for asynchronous operations.  \n- Logging module (implied by `logger.debug` and `logger.error`).  \n- Possibly other internal modules or services for actual embedding generation (not shown in snippet).  \n- Type hinting from `typing`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:39.218119",
      "status": "summarized"
    },
    "embedding_service.py:chunk_16": {
      "chunk_id": "embedding_service.py:chunk_16",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "6bc84cd32818f0bbfebe18ba13e79bd99092ade7ad50d65243679274e46001aa",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis code processes a list of text inputs by generating embeddings in batches using an Azure OpenAI embedding service client, managing rate limits and batching to efficiently handle large volumes of texts.\n\n2. **Technical Details**:  \n- Uses batch processing by splitting the input texts into chunks of configurable size (`batch_size`).  \n- Iterates over batches with indexed slicing and logs progress per batch.  \n- Conditional logic to select the embedding provider (here specifically for \"azure\").  \n- Uses a client object (`self.client`) to call the Azure OpenAI embeddings API.  \n- Tracks metrics such as successful provider calls and fallback usage (though fallback logic is not fully shown).  \n- Uses logging for operational visibility.\n\n3. **Business Logic**:  \nEnables scalable and efficient generation of text embeddings, which are foundational for downstream tasks such as semantic search, recommendation, or NLP model input. The batching approach helps avoid API rate limits and ensures reliable embedding generation for potentially large datasets.\n\n4. **Dependencies**:  \n- Azure OpenAI API client (likely from Azure SDK or OpenAI Python SDK adapted for Azure).  \n- Logging module for info-level logs.  \n- Internal settings/configuration management (`self.settings`).  \n- Possibly other internal modules for fallback embedding providers (not fully shown).\n\n5. **Configuration**:  \n- `azure_openai_embedding_batch_size`: controls the number of texts processed per batch.  \n- `azure_openai_embedding_batch_delay`: optional delay",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:47.413141",
      "status": "summarized"
    },
    "embedding_service.py:chunk_18": {
      "chunk_id": "embedding_service.py:chunk_18",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "5a355f0de77176adf369fcaadf95bfd75075ee43ccb58f1d5e9f4d545a7de9da",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a service that generates vector embeddings for batches of text inputs using an external embedding model API. It processes each batch, normalizes embedding dimensions, and logs progress.\n\n2. **Technical Details**:  \n- The code sends batched text inputs to an embedding model API and receives embedding vectors in response.  \n- It iterates over each embedding vector to ensure consistent dimensionality by truncating or zero-padding embeddings to a fixed size (`self.dimension`).  \n- Embeddings are collected into a list for further use.  \n- Logging is used to track batch processing progress.  \n- There is conditional logic to switch between different embedding providers, including a fallback to a direct REST API call (Together AI) with API key authentication.\n\n3. **Business Logic**:  \nThe code supports generating consistent vector representations of text data, which is critical for downstream applications such as semantic search, recommendation systems, or machine learning pipelines that rely on fixed-size embeddings.\n\n4. **Dependencies**:  \n- `requests` library for HTTP REST API calls.  \n- An external embedding model API (likely a cloud or third-party service).  \n- Environment variables or settings for API keys (`TOGETHER_API_KEY`).  \n- A logging framework (implied by `logger.info`).\n\n5. **Configuration**:  \n- Embedding model identifier (`self.embedding_model`).  \n- Embedding vector dimension (`self.dimension`).  \n- API keys sourced from `self",
      "embedding_id": null,
      "created_at": "2025-10-22T18:50:55.760650",
      "status": "summarized"
    },
    "embedding_service.py:chunk_20": {
      "chunk_id": "embedding_service.py:chunk_20",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "fe98cda0883bd54f5f48c6c3ea209bf335d8fee145b63fa7ab7d089ed2947bc6",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet sends a batch of text inputs to an external embedding service API to obtain vector embeddings, then normalizes the embedding vectors to a fixed dimension.\n\n2. **Technical Details**:  \n- Uses an HTTP POST request with JSON payload to interact with the embedding API.  \n- Processes the JSON response to extract embedding vectors.  \n- Ensures all embeddings have a consistent fixed length by truncating or zero-padding vectors.  \n- Embeddings are collected in a list for further use.\n\n3. **Business Logic**:  \nGenerates vector representations (embeddings) of text data, which are essential for downstream tasks such as semantic search, similarity comparison, or machine learning feature extraction in applications relying on natural language understanding.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- External embedding API hosted at `https://api.together.xyz/v1/embeddings`.\n\n5. **Configuration**:  \n- `api_key`: Authorization token for API access, likely sourced from environment variables or secure config.  \n- `self.embedding_model`: Specifies which embedding model to use, configured in application settings.  \n- `self.dimension`: Target embedding vector size, defined in settings to maintain consistency.\n\n6. **Error Handling**:  \n- Uses `response.raise_for_status()` to raise exceptions on HTTP errors (e.g., 4xx or 5xx responses).  \n- No explicit try-except shown here, so",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:03.643002",
      "status": "summarized"
    },
    "embedding_service.py:chunk_22": {
      "chunk_id": "embedding_service.py:chunk_22",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "8c88698c6fcac2d6d66939b4b6cc0eea77fae8a542f867b471cab5ce730b5391",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet processes text data in batches to generate embeddings using a specified provider, handling rate limits by introducing delays between batches and falling back to individual processing upon batch failures.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`asyncio.sleep`) to manage delays without blocking.  \n- Processes texts in batches, tracking progress with counters (`provider_success`, `batch_num`, `total_batches`).  \n- Implements a fallback mechanism to process texts individually if batch processing fails.  \n- Logging is extensively used for monitoring batch progress, delays, and error handling.  \n\n3. **Business Logic**:  \nThe code addresses the need to efficiently generate vector embeddings for large sets of text data, which is critical for downstream applications like semantic search, recommendation systems, or NLP tasks. It balances throughput with reliability by batching requests to an embedding provider and gracefully handling failures to ensure maximum data coverage.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous operations and non-blocking delays.  \n- A logging framework (`logger`) for info, debug, and warning messages.  \n- An external embedding provider API/service (implied by `self.provider_name` and embedding generation).  \n\n5. **Configuration**:  \n- `batch_size` and `delay_between_batches` control batch processing granularity and pacing to avoid rate limiting.  \n- `self.provider_name` identifies the embedding service provider, likely configured elsewhere in the class or environment.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:10.717010",
      "status": "summarized"
    },
    "embedding_service.py:chunk_24": {
      "chunk_id": "embedding_service.py:chunk_24",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "fdf5d3e9c4d6c35a9dbb88d18eebf2a6e45a931e9f5a4b7344764b24d18b7c41",
      "chunk_index": 24,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an embedding service responsible for generating vector embeddings from text inputs, tracking the success of the embedding provider versus a hash-based fallback, and exposing metadata and health status about the embedding model.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to generate embeddings, likely to handle I/O-bound operations such as API calls efficiently.  \n- Embeddings are collected in a list.  \n- Implements a heuristic to detect fallback embeddings by checking the diversity of the last 10 values in the embedding vector (if the set size \u2264 2, it is considered a hash-based fallback).  \n- Provides methods to retrieve embedding dimension and model metadata as dictionaries.  \n- Logging is used to track embedding generation statistics and fallback usage.\n\n3. **Business Logic**  \n- Ensures robust embedding generation by falling back to a hash-based method if the primary provider fails or returns suspicious embeddings.  \n- Tracks and logs the usage of the primary provider versus fallback to monitor service quality and reliability.  \n- Provides metadata and health check capabilities to support monitoring and integration with other components.\n\n4. **Dependencies**  \n- Likely depends on an asynchronous embedding generation method (`self.generate_embedding`).  \n- Uses a logger (`logger.info`) for operational logging.  \n- No explicit external libraries shown in the snippet, but typical dependencies might include async HTTP clients or ML model SDKs.\n\n5. **Configuration**  \n- Embedding provider name, model",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:15.257499",
      "status": "summarized"
    },
    "embedding_service.py:chunk_26": {
      "chunk_id": "embedding_service.py:chunk_26",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "9715ab02821e0ea5ffd4cb5ded2a44bbbdd6c8557dcab71a3048347b74af23d5",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet checks the health of an embedding service by attempting to generate an embedding vector using the configured provider and model, then returns a status dictionary reflecting the connection and service health.\n\n2. **Technical Details**:  \n- Uses an asynchronous method (`await self.generate_embedding(...)`) to perform an actual embedding generation API call.  \n- Constructs a status dictionary with metadata about the embedding service (provider, model, dimension, API availability).  \n- Validates the returned embedding vector by checking its existence and dimensionality against the expected dimension.  \n- Uses logging for tracing the health check process.  \n\n3. **Business Logic**:  \nEnsures the embedding service is operational and correctly configured by performing a real embedding generation test. This health check helps maintain reliability in applications relying on vector embeddings for search, recommendation, or NLP tasks.\n\n4. **Dependencies**:  \n- An embedding client accessible via `self.client` that supports asynchronous embedding generation.  \n- A logging utility (`logger`) for informational messages.  \n- The embedding provider API (e.g., OpenAI, HuggingFace, or custom service) accessed through `self.generate_embedding`.  \n\n5. **Configuration**:  \n- `self.provider_name`: identifies the embedding service provider.  \n- `self.embedding_model`: specifies the embedding model used.  \n- `self.dimension`: expected dimensionality of the embedding vectors.  \n- `self.api_available`: boolean flag indicating if the API is reachable",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:25.868932",
      "status": "summarized"
    },
    "embedding_service.py:chunk_28": {
      "chunk_id": "embedding_service.py:chunk_28",
      "file_path": "shared\\vector_db\\embedding_service.py",
      "chunk_hash": "de0b69a538633e917abaeb25fa012909722f827fd29b0638e319451af339c2a2",
      "chunk_index": 28,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a health check routine for an embedding service provider. It verifies the connectivity and correctness of the embedding API by generating test embeddings and validating their dimensions, while also testing a fallback embedding mechanism.\n\n2. **Technical Details**:  \n- Uses a dictionary `status` to track the health and configuration state of the embedding service.  \n- Attempts to generate a test embedding and checks if the embedding dimension matches expected values.  \n- Implements a fallback embedding generation via a hash-based method `_generate_hash_embedding`.  \n- Uses logging at different levels (warning, error) to record issues and status updates.  \n- Exception handling wraps embedding generation calls to capture and report errors gracefully.\n\n3. **Business Logic**:  \nEnsures that the embedding service provider is properly configured and operational, which is critical for downstream applications relying on embeddings for tasks like search, recommendations, or NLP. The fallback mechanism ensures continued service availability even if the primary embedding API fails.\n\n4. **Dependencies**:  \n- A logger instance (`logger`) for logging warnings and errors.  \n- An embedding provider interface or client referenced via `self.provider_name` and embedding generation methods (not fully shown).  \n- The `_generate_hash_embedding` method, presumably implemented elsewhere in the class or module.\n\n5. **Configuration**:  \n- Embedding API configuration is implied but not shown; the code checks if the API is configured before attempting calls.  \n- Likely",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:31.679818",
      "status": "summarized"
    },
    "embed_repo.py:chunk_0": {
      "chunk_id": "embed_repo.py:chunk_0",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "784cbb44cddff19500a8736fa2136573fc7254a04c0e55fe04154c994f2043e1",
      "chunk_index": 0,
      "summary": "**Summary of `embed_repo.py`**\n\n---\n\n1. **Purpose**  \nThis module orchestrates a two-phase pipeline to process source code repositories by parsing and summarizing code files, then embedding these summaries and code snippets into a vector database (Qdrant) for code intelligence applications such as search or recommendation.\n\n2. **Technical Details**  \n- **Two-phase pipeline:**  \n  - *Phase 1:* Parse source files and generate summaries with caching to avoid redundant work.  \n  - *Phase 2:* Embed both code and summaries into a vector store.  \n- **Incremental updates:** Uses a change planner to detect and prioritize changed files for embedding, improving efficiency.  \n- **Rate limiting:** Employs a `RateLimitController` to adaptively batch embedding requests respecting API quotas.  \n- **Data structures:** Uses domain-specific classes like `RepoState` to track repository status, `EmbeddingPoint` to represent vector embeddings, and registries for parsers and summarizers.  \n- **Design patterns:**  \n  - Orchestrator pattern to coordinate multiple components.  \n  - Registry pattern for parsers.  \n  - Dependency injection for embedding services and vector stores.  \n- **Progress tracking:** Uses `tqdm` for progress bars during long-running operations.\n\n3. **Business Logic**  \nEnables scalable, incremental embedding of large codebases to power developer tools that require semantic understanding of code, such as intelligent code search, automated code review, or knowledge",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:38.704730",
      "status": "summarized"
    },
    "embed_repo.py:chunk_2": {
      "chunk_id": "embed_repo.py:chunk_2",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "0061609175c15479cead37d6f0ce6de74f6c924705f4a650022768a90b425db8",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python class orchestrates a multi-stage pipeline for code intelligence within a software repository, handling file discovery, change detection, code summarization, embedding generation, and storage in a vector database.\n\n2. **Technical Details**:  \n- The constructor initializes key components such as rate limiting, repository state management, change planning, and enhanced code summarization.  \n- Uses composition to integrate modular components like `RateLimitController`, `RepoState`, `ChangePlanner`, and `EnhancedCodeSummarizer`.  \n- The pipeline stages (discovery, prioritization, parsing, summarization, embedding, storage) are coordinated but not fully shown in this snippet.  \n- Paths and collection names are managed via `Path` objects and string parameters for flexibility.\n\n3. **Business Logic**:  \nEnables automated, incremental analysis and embedding of code repositories to support advanced code search, understanding, or recommendation features, improving developer productivity and codebase maintainability.\n\n4. **Dependencies**:  \n- Likely depends on internal modules/classes: `RateLimitController`, `RepoState`, `ChangePlanner`, `EnhancedCodeSummarizer`.  \n- Uses Python's `pathlib.Path` for filesystem path management.  \n- Logging is used (`logger.info`) for operational visibility.  \n- External embedding providers hinted (`azure`, `together`), suggesting integration with cloud or third-party AI services.\n\n5. **Configuration**:  \n- Configurable repository path,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:47.003794",
      "status": "summarized"
    },
    "embed_repo.py:chunk_4": {
      "chunk_id": "embed_repo.py:chunk_4",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "89029054d87018d88016cb90777701b7022fddf0115bc6215358731d5c14edfb",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code initializes and verifies an embedding service used for generating vector embeddings, then sets up a vector store to manage and query these embeddings efficiently.\n\n2. **Technical Details**:  \n- Uses an `EmbeddingService` class instantiated with a specified provider to generate embeddings and retrieve their dimensionality.  \n- Initializes a `VectorStore` with parameters including collection name, storage path, and embedding dimension, likely backed by Qdrant (a vector similarity search engine).  \n- Contains an asynchronous method `_verify_embedding_service` that performs a health check on the embedding service by awaiting a `health_check()` coroutine and logging connection status and metadata.\n\n3. **Business Logic**:  \nEnables embedding-based search or similarity operations on repository data by providing a pipeline that converts raw data into vector representations and stores them for efficient retrieval, supporting features like code intelligence, semantic search, or recommendation.\n\n4. **Dependencies**:  \n- `EmbeddingService`: likely a custom or third-party service wrapper for embedding providers (e.g., OpenAI, Hugging Face).  \n- `VectorStore`: an abstraction over a vector database, probably using Qdrant as the backend.  \n- `logger`: for structured logging.  \n- Asyncio or an async framework to support asynchronous health checks.\n\n5. **Configuration**:  \n- `embedding_provider`: specifies which embedding backend to use, probably configured via environment variables or application settings.  \n- `collection_name` and `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:51:54.321684",
      "status": "summarized"
    },
    "embed_repo.py:chunk_6": {
      "chunk_id": "embed_repo.py:chunk_6",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "2c3abffea5d9317af97c36378c9c883201a73bcf0d426e55840a9b7dd35b2a63",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a class responsible for interacting with an embedding service and discovering code files within a repository. Specifically, it includes error handling for embedding service connectivity and a method to recursively discover code files while excluding specified patterns.\n\n2. **Technical Details**:  \n- The code uses exception handling (`try-except`) to manage errors when verifying the embedding service connection.  \n- The `discover_files` method accepts an optional list of exclusion patterns and returns a list of file paths found in the repository, excluding directories and files matching these patterns.  \n- Default exclusion patterns cover common version control directories, dependency folders, Python virtual environments, build outputs, and framework-specific caches.  \n- The method likely uses filesystem traversal (e.g., `os.walk` or similar) to locate files, although the traversal code is not shown in the snippet.\n\n3. **Business Logic**:  \n- Ensures that the embedding service is operational before proceeding, which is critical for embedding-related functionalities such as code intelligence or search.  \n- Efficiently identifies relevant source code files in a repository by ignoring irrelevant or large directories (e.g., dependencies, build artifacts), optimizing downstream processing like embedding generation or analysis.\n\n4. **Dependencies**:  \n- Uses a `logger` for error logging (likely Python\u2019s standard `logging` module or a configured logger).  \n- The embedding service health check implies an external service or API, though the exact client or SDK",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:01.200068",
      "status": "summarized"
    },
    "embed_repo.py:chunk_8": {
      "chunk_id": "embed_repo.py:chunk_8",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "d9fda61b701d22c43dfbc73822f448d1d5cf7d3dd7b45c43c8ca695602b6f2e8",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a file discovery process within a repository, designed to recursively traverse directories while excluding certain unwanted directories, files, and file patterns to identify relevant source files for further processing.\n\n2. **Technical Details**:  \n- Uses `os.walk()` to recursively iterate through the directory tree starting from `self.repo_path`.  \n- Maintains lists and sets for filtering:  \n  - `exclude_patterns`: directory names to skip entirely (e.g., `.idea`, `.vscode`, `logs`).  \n  - `skip_file_patterns`: substrings in filenames indicating test files, minified files, or bundles to skip.  \n  - `skip_filenames`: exact filenames to exclude (e.g., lock files).  \n- Filters directories in-place by modifying the `dirs` list during traversal to prevent descending into excluded directories, improving efficiency.  \n- Uses a `parser_registry` to obtain supported file extensions, presumably to filter files by type.  \n- Logging is used to provide progress and debugging information.\n\n3. **Business Logic**:  \nThe code supports a business need to analyze or embed repository content by selectively indexing only relevant source files, ignoring configuration, test, log, and temporary files that do not contribute to the core code intelligence or embedding process. This ensures cleaner data input for downstream tasks like code search, analysis, or embedding generation.\n\n4. **Dependencies**:  \n- Standard Python library: `os` for",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:06.912858",
      "status": "summarized"
    },
    "embed_repo.py:chunk_10": {
      "chunk_id": "embed_repo.py:chunk_10",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "1ff0c8790902d4a500dc366b225157c0b85dd6c844b26cfbee448d393fddbe55",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a repository embedding tool that scans a code repository directory tree, filters files based on skip rules and supported extensions, and collects a list of relevant code files for further processing such as embedding generation.\n\n2. **Technical Details**:  \n- Uses directory traversal (likely via `os.walk` or similar) to iterate through directories and files.  \n- Maintains counters for skipped directories and files based on exact filename matches and substring pattern matches (case-insensitive).  \n- Uses `Path` objects from `pathlib` for file path manipulations, including relative path calculation.  \n- Filters files by checking their extensions against a predefined set of supported extensions.  \n- Logs summary information about discovered and skipped files/directories.  \n- The snippet is part of a class with an asynchronous method `run_incremental` indicating support for incremental processing of changed files.\n\n3. **Business Logic**:  \nThe code supports the business need to efficiently index and embed source code files from a repository while ignoring irrelevant or unsupported files. This enables downstream processes such as code search, analysis, or AI-powered code intelligence to operate only on meaningful code files, improving accuracy and performance.\n\n4. **Dependencies**:  \n- Python standard libraries: `pathlib` for path operations, `logging` for logging.  \n- Possibly `os` or `os.walk` for directory traversal (not shown but implied).  \n- Async support suggests use of",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:14.492725",
      "status": "summarized"
    },
    "embed_repo.py:chunk_12": {
      "chunk_id": "embed_repo.py:chunk_12",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "9e1a5eac0ee2232474ac697235caa3d38cc4dd80e307c08d081abb68dd720130",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an incremental embedding pipeline designed to process and embed files from a repository. It selectively re-embeds files based on changes detected or forces a full re-embedding, facilitating efficient updates to an embedding service.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially long-running operations such as verifying the embedding service and starting rate limiter workers.  \n- Implements a rate limiter to control the throughput of embedding requests, likely to avoid service throttling.  \n- Discovers files in a repository and determines which files have changed since the last run using a `repo_state` component.  \n- Supports prioritization of files via a `change_planner` component to optimize processing order.  \n- Uses sets and lists to manage collections of files for efficient membership testing and ordering.\n\n3. **Business Logic**:  \nThe code addresses the business need to maintain up-to-date embeddings of repository files for applications such as code search, recommendation, or analysis. By incrementally embedding only changed files (or all files if forced), it reduces unnecessary computation and speeds up updates, improving responsiveness and resource utilization.\n\n4. **Dependencies**:  \n- An embedding service (external or internal) that provides embedding capabilities.  \n- `rate_limiter` module or class to manage request rates.  \n- `repo_state` module/class to track file changes.  \n- `change_planner` module/class to prioritize files.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:19.137073",
      "status": "summarized"
    },
    "embed_repo.py:chunk_14": {
      "chunk_id": "embed_repo.py:chunk_14",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "62c91a3ee38e0807e3c37f10b11b4e7d0e00eed2e7c3a9574b6cb9c30b2f884b",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet processes a prioritized list of source code files by parsing each file into smaller chunks for further analysis or embedding, while logging progress and handling parsing errors.\n\n2. **Technical Details**:  \n- Iterates over a prioritized list of file paths (`prioritized_files`).  \n- Uses a `parser_registry` to parse each file, which likely abstracts multiple file parsers.  \n- Collects parsed chunks into a single list (`all_chunks`).  \n- Utilizes `tqdm` for progress visualization during parsing.  \n- Logs detailed info and debug messages about parsing success and chunk counts.  \n- Captures and logs exceptions per file, storing errors in `parse_errors`.  \n- Uses Python\u2019s exception handling (`try-except`) to isolate failures without stopping the entire process.\n\n3. **Business Logic**:  \nThe code supports a business need to analyze or embed source code repositories by breaking down files into manageable chunks. This is typically used in code intelligence platforms for search, summarization, or machine learning embedding generation, enabling efficient processing of changed or prioritized files.\n\n4. **Dependencies**:  \n- `parser_registry`: A module or object responsible for parsing files into chunks.  \n- `tqdm`: For progress bar display during iteration.  \n- `logger`: For structured logging of info, debug, warning, and error messages.\n\n5. **Configuration**:  \n- `max_files` and `changed_files` appear to be configurable",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:27.468816",
      "status": "summarized"
    },
    "embed_repo.py:chunk_16": {
      "chunk_id": "embed_repo.py:chunk_16",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "bceff8aa2ca8231afcc42600d117a70eedcc1f72d330e8492a50e51c01ac185b",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code segment processes a collection of data chunks by categorizing them by type, generating AI-based summaries for each chunk, and preparing for the next phase of embedding generation and incremental storage.\n\n2. **Technical Details**:  \n- Uses a dictionary (`chunk_types`) to count occurrences of each chunk type extracted from chunk metadata.  \n- Logs chunk type distribution sorted by frequency.  \n- Invokes an asynchronous batch summarization method (`self.summarizer.summarize_batch`) to generate enhanced summaries for all chunks.  \n- Calculates and logs average summary length for quality monitoring.  \n- Prepares for embedding generation and storage by logging the start of Phase 2 processing.  \n- Data structures: dictionary for counting, list comprehension for summary length calculation.  \n- Design pattern: asynchronous processing for batch summarization to improve throughput.\n\n3. **Business Logic**:  \nThe code supports a business need to analyze and summarize segmented data (e.g., code snippets, documents) to create concise representations that can be embedded and stored for efficient retrieval, search, or further AI processing. This enhances knowledge management and accelerates insights extraction from large repositories.\n\n4. **Dependencies**:  \n- An asynchronous summarizer component (`self.summarizer`) likely backed by an AI model or external service.  \n- A logging framework (`logger`) for operational visibility.  \n- Data chunks with metadata structure, presumably from a prior ingestion or parsing step.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:35.082462",
      "status": "summarized"
    },
    "embed_repo.py:chunk_18": {
      "chunk_id": "embed_repo.py:chunk_18",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "b05c353405cd5a9d6d1a32e350703971ef77d6f9551f15674c2f959f6ba8a63a",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis code asynchronously embeds textual chunks from a repository, updates the repository state to reflect processed files, and generates a detailed report summarizing the embedding operation's outcomes.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to perform embedding and storage incrementally, likely improving throughput.  \n- Iterates over prioritized files to filter and group chunks by file path.  \n- Updates a repository state object with metadata such as language, chunk count, and processing status.  \n- Persists the updated state via a manifest save operation.  \n- Constructs a statistics dictionary capturing counts of files and chunks processed, embedding success rates, and rate limiter metrics keyed by quota values.  \n- Data structures include lists (`all_chunks`, `prioritized_files`), dictionaries (`stats`), and custom objects (`repo_state`, `rate_limiter`).  \n\n3. **Business Logic**:  \nEnables incremental embedding of code or text chunks from a source repository to support downstream code intelligence features such as search, summarization, or analysis. It tracks processing progress per file to allow efficient updates and provides operational metrics for monitoring embedding success and rate limiting.\n\n4. **Dependencies**:  \n- An asynchronous embedding and storage mechanism (`_embed_and_store_incremental`).  \n- A `repo_state` module or class managing file states and manifest persistence.  \n- A `rate_limiter` component providing quota-based metrics.  \n- Likely depends on external embedding services or ML models",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:39.097595",
      "status": "summarized"
    },
    "embed_repo.py:chunk_20": {
      "chunk_id": "embed_repo.py:chunk_20",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "4ab04646a4a37e6af67db62a49f539253779caaea74f6900c52f5eb29ada5cae",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code asynchronously generates embeddings for chunks of code and stores them incrementally in batches, optimizing memory usage and enabling progress tracking during the embedding pipeline.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle embedding and storage operations without blocking.  \n- Employs batching to process chunks in manageable sizes, dynamically adjusting batch size via a rate limiter (`self.rate_limiter.get_adaptive_batch_size`) with an upper cap of 50 to avoid memory overload.  \n- Tracks statistics such as total chunks processed, chunks embedded, and success rate, logging these metrics upon pipeline completion.  \n- Uses dictionaries (`summaries: Dict[str, str]`) to map chunk identifiers to their summaries, facilitating contextual embedding.\n\n3. **Business Logic**:  \nSolves the problem of embedding large repositories of code efficiently by breaking down the embedding process into incremental batches, thus preventing memory issues and providing real-time progress feedback. This supports scalable code intelligence features such as search, analysis, or recommendation in developer tools or platforms.\n\n4. **Dependencies**:  \n- An asynchronous rate limiter component (`self.rate_limiter`) that controls API usage quotas, specifically for embedding operations (`QuotaType.EMBEDDING`).  \n- A logging framework (`logger`) for structured informational output.  \n- Likely depends on external embedding services or APIs (not shown in snippet) to generate embeddings.\n\n5. **Configuration**:  \n- Batch size is adapt",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:46.552719",
      "status": "summarized"
    },
    "embed_repo.py:chunk_22": {
      "chunk_id": "embed_repo.py:chunk_22",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "917dc66b0e8dad60cafd429d21d8ba09cca676adc60bfcea484591d806c346cd",
      "chunk_index": 22,
      "summary": "**Summary of `embed_repo.py` code snippet**\n\n---\n\n1. **Purpose**  \nThis code processes a large collection of text chunks by batching them and generating embeddings asynchronously for each batch, enabling efficient handling of large datasets for downstream tasks like search or analysis.\n\n2. **Technical Details**  \n- **Batching Algorithm**: Divides `total_chunks` into batches of size `batch_size` using integer division with ceiling.  \n- **Data Structures**: Uses lists for `chunks` and `texts`. Each batch is a slice of the `chunks` list.  \n- **Progress Calculation**: Computes percentage completion per batch for logging.  \n- **Asynchronous Embedding**: Defines an async function `embed_batch` to call `generate_embeddings_batch` on the embedding service, supporting non-blocking I/O.  \n- **Text Preparation**: Concatenates a summary (from a dictionary keyed by `chunk_id`) and a truncated chunk content (up to 2000 characters) for embedding input.\n\n3. **Business Logic**  \nEnables scalable embedding generation for repository code or documents by chunking and summarizing content, which supports business needs such as semantic search, code intelligence, or knowledge discovery in large codebases or document collections.\n\n4. **Dependencies**  \n- `self.embedding_service`: An external or internal service providing the method `generate_embeddings_batch` for embedding generation.  \n- `logger`: Used for informational logging of progress and batch details.  \n- Ass",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:50.675696",
      "status": "summarized"
    },
    "embed_repo.py:chunk_24": {
      "chunk_id": "embed_repo.py:chunk_24",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "6aab2710dd1bbf0759ccb3d3778e50ac69c5294f71cf3e0650f82ecae3764880",
      "chunk_index": 24,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code asynchronously generates vector embeddings for a batch of text chunks, then constructs structured embedding points enriched with metadata for downstream processing or storage.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle rate-limited embedding generation via `self.rate_limiter.submit()`.  \n- Employs a batch processing approach to embed multiple text chunks simultaneously.  \n- Constructs a list of `EmbeddingPoint` objects, each containing the embedding vector, original content, optional summary, and detailed metadata extracted from each chunk.  \n- Uses list comprehension for efficient creation of embedding points aligned with the batch order.\n\n3. **Business Logic**:  \nTransforms raw code or document chunks into vector embeddings with rich contextual metadata, enabling advanced code intelligence features such as semantic search, code summarization, or recommendation systems.\n\n4. **Dependencies**:  \n- `self.rate_limiter`: a custom or third-party rate limiting service managing API quota for embedding generation.  \n- `QuotaType.EMBEDDING`: an enum or constant indicating the quota category.  \n- `EmbeddingPoint`: a data structure or class representing an embedding with associated metadata.  \n- `logger`: for debug-level logging.\n\n5. **Configuration**:  \n- Rate limiter settings (e.g., API keys, quotas) likely configured externally.  \n- Priority level (set to 2) for rate limiter submission, possibly configurable.  \n- Metadata fields depend on the chunk\u2019s metadata schema",
      "embedding_id": null,
      "created_at": "2025-10-22T18:52:56.405971",
      "status": "summarized"
    },
    "embed_repo.py:chunk_26": {
      "chunk_id": "embed_repo.py:chunk_26",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "9ddf2e1257773b5c0c326f69826dfb8bc9aa0537e2a8239acd7deff730a218bb",
      "chunk_index": 26,
      "summary": "1. **Purpose**  \nThis asynchronous Python code snippet is part of a pipeline that processes batches of embeddings generated from code repositories and stores them into a Qdrant vector database for later retrieval and search.\n\n2. **Technical Details**  \n- The code processes embeddings in batches, creating a list of embedding points to upsert into Qdrant.  \n- It uses asynchronous calls (`await`) to perform batch upsert operations to the vector store, enabling non-blocking I/O.  \n- Logging is used extensively to track progress and batch results.  \n- The code maintains counters for successful and failed embeddings to provide progress metrics.  \n- Exception handling is implemented around the batch processing to catch and log errors without stopping the entire embedding process.\n\n3. **Business Logic**  \nThis code supports a code intelligence platform by embedding chunks of code into a vector database, enabling semantic search, code analysis, or recommendation features. It ensures that large repositories can be processed in manageable batches with progress tracking and error resilience.\n\n4. **Dependencies**  \n- `argparse` for command-line argument parsing (shown in the `main` function).  \n- A vector store client (likely a Qdrant client) accessed via `self.vector_store.upsert_batch`.  \n- A logging framework (`logger`) for debug and info messages.  \n- Asyncio for asynchronous execution (implied by `async def` and `await` usage).\n\n5. **Configuration**  \n- Command-line arguments parsed via `argparse",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:00.678251",
      "status": "summarized"
    },
    "embed_repo.py:chunk_28": {
      "chunk_id": "embed_repo.py:chunk_28",
      "file_path": "code-intelligence\\embed_repo.py",
      "chunk_hash": "f6025b9cf0b7d8b43d2c03b0419fbba5a4c7983a5842fb653b5aa2f37d165fcc",
      "chunk_index": 28,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python script incrementally processes and embeds source code files from a specified repository into a Qdrant vector database collection, enabling efficient code intelligence and search capabilities.\n\n2. **Technical Details**:  \n- Uses `argparse` to parse command-line arguments for repository path, max files to process, force re-embedding, and Qdrant collection name.  \n- Instantiates an `EmbeddingOrchestrator` class responsible for managing the embedding workflow.  \n- Calls an asynchronous method `run_incremental` on the orchestrator to process files incrementally, optionally forcing re-indexing.  \n- Outputs statistics including number of files processed, chunks embedded, and success rate.  \n- Uses Python's `asyncio` for asynchronous execution of the main embedding routine.\n\n3. **Business Logic**:  \nThe code supports continuous and incremental embedding of code repositories to maintain an up-to-date vector search index. This enables developers or automated systems to perform semantic search, code analysis, or AI-driven code intelligence on large codebases efficiently.\n\n4. **Dependencies**:  \n- `argparse` for CLI argument parsing (standard library).  \n- `asyncio` for asynchronous execution (standard library).  \n- Custom module/class `EmbeddingOrchestrator` (likely part of the same project) which handles embedding logic and interaction with Qdrant.  \n- Qdrant vector database (implied by collection name and embedding context).\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:08.701629",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_0": {
      "chunk_id": "enhanced_summarizer.py:chunk_0",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "843f930939b40a3671d022a6fd4f3c97e80eae0b8231dff40eb5495f26f64344",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module implements an enhanced code summarizer that generates rich, structured summaries of source code by incorporating technical implementation details, business logic, configuration insights, and error handling information. It aims to provide comprehensive context for codebases across multiple languages and file types.\n\n2. **Technical Details**:  \n- Uses language-specific prompts to tailor summaries for languages like Java, Kotlin, and Python.  \n- Detects file types including Docker, Helm charts, and API specifications to extract relevant configuration and infrastructure details.  \n- Employs structured summary extraction techniques to organize information into categories such as technical details, business logic, and exception handling.  \n- Integrates asynchronous programming (via `asyncio`) for potentially concurrent processing.  \n- Utilizes classes like `RepoState` to represent repository context and `RateLimitController` to manage API usage quotas.  \n- Uses a templating system (`EnhancedSummaryTemplate`) to format the generated summaries.\n\n3. **Business Logic**:  \nAddresses the business need for automated, detailed documentation and understanding of complex codebases, improving developer productivity and onboarding by providing clear insights into code functionality, configuration, and operational context.\n\n4. **Dependencies**:  \n- Standard Python libraries: `asyncio`, `re`, `logging`, `pathlib`, `typing`.  \n- Internal modules:  \n  - `parsers.base_parser` for code chunk abstractions.  \n  - `repo_state` for repository metadata and state management.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:14.877841",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_2": {
      "chunk_id": "enhanced_summarizer.py:chunk_2",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "7403811163a81b6eb79394f5ce4258c86d2604ebac85cab1ca7bc391161aad74",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an enhanced summarization module that initializes an Azure OpenAI client for generating advanced summaries and detects specific file types (e.g., Kafka-related files) to tailor the summarization process accordingly.\n\n2. **Technical Details**:  \n- Uses lazy initialization for the Azure OpenAI client via the `_init_azure_client` method.  \n- Checks availability of Azure AI models through `azure_ai_manager.models.is_available()`.  \n- Implements a heuristic file type detection method `detect_file_type` that inspects file path and content strings for keywords related to Kafka configurations.  \n- Uses string containment checks and case normalization (`lower()`) for keyword detection.  \n- Employs logging for informational, warning, and error messages.\n\n3. **Business Logic**:  \nThe code supports a business need to provide context-aware enhanced summarization of code or configuration files by detecting special file types (like Kafka configurations). This enables generating more relevant and precise summaries, improving developer productivity and understanding of complex systems.\n\n4. **Dependencies**:  \n- `shared.azure_services.azure_ai_manager`: A custom module managing Azure AI service clients.  \n- `EnhancedSummaryTemplate`: Presumably a class for managing summarization templates (not fully shown).  \n- `logger`: A logging utility (import or initialization not shown in snippet).  \n- Azure OpenAI services accessed via `azure_ai_manager`.\n\n5. **Configuration**:  \n- Azure OpenAI client configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:23.151420",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_4": {
      "chunk_id": "enhanced_summarizer.py:chunk_4",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "9c8ddf261638b510eccf9b64bffafcd11099642b0a28bb63bbb448b059043b4c",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet classifies a given file path and its content into specific categories such as message queues, database schemas, infrastructure as code, or CI/CD pipelines based on keywords in the file path or content.\n\n2. **Technical Details**:  \n- Uses conditional checks with `any()` and substring membership to detect keywords in lowercase file paths (`file_path_lower`).  \n- Checks file extensions using `str.endswith()` to identify file types.  \n- Performs content inspection by searching for SQL DDL commands in uppercase content strings.  \n- The logic is a sequence of if-statements returning classification strings upon the first match.\n\n3. **Business Logic**:  \nThe code supports automated categorization of code files for enhanced summarization or indexing in a code intelligence platform. This helps in organizing files by their functional domain (e.g., messaging, database, infrastructure, CI/CD), enabling better search, analysis, or documentation generation.\n\n4. **Dependencies**:  \nNo external libraries or modules are explicitly used in this snippet; it relies solely on built-in Python string operations.\n\n5. **Configuration**:  \nNo environment variables or external configuration files are referenced or required by this code.\n\n6. **Error Handling**:  \nNo explicit error handling is implemented; the code assumes valid string inputs for `file_path`, `file_path_lower`, and `content`.\n\n7. **API/Interface**:  \nThis snippet appears to be part of a function (not",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:28.625487",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_6": {
      "chunk_id": "enhanced_summarizer.py:chunk_6",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "9322aae701373691f5eae4276c7986f4b3cc0377307fbdd4709dfbc54fe50bbd",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code snippet classifies a given file path into specific DevOps or infrastructure-related categories based on keywords and file extensions present in the path string.\n\n2. **Technical Details**:  \n- Uses sequential conditional checks (`if` statements) to inspect substrings within the file path (case-insensitive for most checks via `file_path_lower`).  \n- Employs string containment checks (`in` operator) and suffix checks (`str.endswith`) to identify relevant keywords or file extensions.  \n- Uses `any()` with list comprehensions for matching multiple possible keywords in a single condition.  \n- No complex data structures; primarily string operations.\n\n3. **Business Logic**:  \nThe code helps automate the identification and categorization of configuration or infrastructure files within a codebase, enabling enhanced summarization, organization, or processing of CI/CD pipelines, monitoring setups, service meshes, API gateways, containerization, and orchestration configurations. This supports tooling that improves developer productivity, infrastructure management, or compliance auditing.\n\n4. **Dependencies**:  \nNo external libraries or modules are used in this snippet; it relies solely on built-in Python string operations.\n\n5. **Configuration**:  \nNo direct environment variables or external configuration influence this logic. The classification depends entirely on the input `file_path` string.\n\n6. **Error Handling**:  \nNo explicit error handling is present. The code assumes `file_path` and `file_path_lower` are valid strings. Potential errors",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:35.020242",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_8": {
      "chunk_id": "enhanced_summarizer.py:chunk_8",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "28b47847f42640d753eaccfad6e7bf4f59c51be68ffad61abb53f41412e795cb",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a file type classification utility within a code summarization or analysis tool. It determines the category of a given file based on its filename or path, facilitating specialized processing such as metadata extraction or enhanced summarization.\n\n2. **Technical Details**:  \n- Uses conditional checks on file extensions and substrings within the file path (case-insensitive) to classify files into categories like 'openapi', 'protobuf', 'graphql', 'env', 'config-yaml', 'config', 'dependencies', or defaults to 'code'.  \n- The classification logic is implemented as a series of `if` statements checking for specific patterns in the filename or path.  \n- The snippet also shows the start of a method `extract_metadata` that appears to parse a `CodeChunk` object to extract metadata such as imports and exports, indicating a design that processes code in chunks with associated metadata.\n\n3. **Business Logic**:  \nThe code supports a business need to intelligently identify and categorize source files and configuration files within a codebase. This categorization enables tailored summarization, analysis, or processing workflows depending on file type, improving the accuracy and relevance of code intelligence features.\n\n4. **Dependencies**:  \n- The snippet references a `CodeChunk` type and uses Python typing (`Dict[str, Any]`), implying dependencies on typing modules and possibly custom domain models for code chunks.  \n- No explicit external libraries or services are",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:42.083626",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_10": {
      "chunk_id": "enhanced_summarizer.py:chunk_10",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "67a8bc8a13d1c8ef6c16be9e9f877594b73e5bce1935102ef2f710434a08cbe2",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a metadata extraction utility designed to analyze source code files in multiple programming languages and extract structured information such as imports, exceptions, annotations, environment variables, API endpoints, and configuration keys.\n\n2. **Technical Details**:  \n- The code uses language-specific conditional logic to selectively extract metadata relevant to the source code language (e.g., imports for Python, Java, Kotlin, JavaScript, TypeScript; annotations for Java/Kotlin).  \n- It organizes extracted data into a dictionary with keys like 'classes', 'functions', 'exceptions', etc.  \n- Extraction methods (e.g., `_extract_imports`, `_extract_exceptions`) likely use pattern matching or regex-based parsing to identify relevant code constructs.  \n- The design follows a modular approach with private helper methods for each metadata type, promoting separation of concerns and extensibility.\n\n3. **Business Logic**:  \nThis code supports enhanced code intelligence features such as automated code summarization, dependency analysis, or documentation generation. By extracting key metadata, it enables tools to provide developers and business stakeholders with insights into code structure, dependencies, and configuration, facilitating better code understanding, auditing, and maintenance.\n\n4. **Dependencies**:  \n- The snippet references internal methods (e.g., `_extract_imports`) which may rely on standard Python libraries such as `re` for regex parsing.  \n- No explicit external third-party libraries are shown in the snippet, but the",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:47.508195",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_12": {
      "chunk_id": "enhanced_summarizer.py:chunk_12",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "f5408651a83ac2488907c911e4dba17e3440eeb1bd02c39d7b95befedfafda7d",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a larger module designed to analyze source code content and extract specific syntactic elements such as import statements, exception types, and annotations from multiple programming languages.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.findall`) to identify language-specific patterns in source code strings.  \n- Maintains dictionaries and lists of regex patterns tailored for different languages (e.g., Python, Java, Kotlin, JavaScript, TypeScript).  \n- Extracts up to a fixed number of matches (e.g., top 10 imports or exceptions, top 15 annotations) to limit output size.  \n- The methods `_extract_imports`, `_extract_exceptions`, and `_extract_annotations` encapsulate logic for parsing imports, exceptions, and annotations respectively.  \n- Uses sets to remove duplicate exception names before truncating the list.\n\n3. **Business Logic**:  \nThis code supports a business need to perform enhanced code summarization or static analysis by extracting key structural elements from source code. This can be used in tools for code intelligence, automated documentation, code review assistance, or developer productivity enhancements.\n\n4. **Dependencies**:  \n- Python standard library module `re` for regular expression operations.  \n- Typing module for type hints (`List[str]`).\n\n5. **Configuration**:  \n- No explicit environment variables or external configuration files are referenced in this snippet.  \n- Language-specific regex patterns are hardcoded within the",
      "embedding_id": null,
      "created_at": "2025-10-22T18:53:55.618994",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_14": {
      "chunk_id": "enhanced_summarizer.py:chunk_14",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "fd65ab9a4afb9d8ac732cea980751e9b9e80b2adbc7d3bb19a6ea77b0427acc3",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides utility methods to extract environment variable references and API endpoint definitions from source code content strings, supporting multiple programming languages and frameworks.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.findall`) to identify patterns corresponding to environment variables and API endpoints in code snippets.  \n- Maintains lists of regex patterns tailored to different languages and frameworks (e.g., Node.js, Python, Java for env vars; Spring, FastAPI, Express for endpoints).  \n- Aggregates matches from all patterns, removes duplicates for environment variables, and limits results to a maximum of 10 entries.  \n- Returns lists of extracted strings representing environment variable names or API endpoint paths.\n\n3. **Business Logic**:  \nEnables automated analysis or summarization of codebases by identifying key configuration references (env vars) and API routes, which can be used for documentation, security auditing, or dependency mapping in software projects.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regex operations.  \n- Type hinting with `List` from `typing` (implied by method signatures).  \nNo external third-party libraries are used.\n\n5. **Configuration**:  \n- No external configuration or environment variables are required for these methods.  \n- The methods operate purely on input strings representing source code content.\n\n6. **Error Handling**:  \n- No explicit error handling is implemented.  \n- Assumes input `content`",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:02.164937",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_16": {
      "chunk_id": "enhanced_summarizer.py:chunk_16",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "e377fd8c95cf4e360e84dbeb8dbb97ea6453cb6873f9dbf3c9bc0863b7773504",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an enhanced code summarization tool that extracts configuration keys from source code content and builds context-aware prompts for further processing, such as generating summaries or insights based on code metadata.\n\n2. **Technical Details**:  \n- Uses regular expressions to identify configuration keys accessed via common patterns (e.g., `config.get()`, `properties.getProperty()`, and Spring's `@Value` annotation).  \n- Aggregates matches from multiple regex patterns into a unique list, limiting the result to the first 10 keys to avoid overload.  \n- Implements a method to build an enhanced prompt by detecting the file type (e.g., Kafka, database schema, infrastructure as code) and selecting an appropriate template for further processing.  \n- Uses metadata from a `CodeChunk` object, including file path and language, to guide template selection.\n\n3. **Business Logic**:  \nThe code supports automated code intelligence workflows by extracting relevant configuration keys and tailoring prompts based on the type of code artifact. This facilitates better understanding, documentation, or analysis of codebases, which is valuable for developers, DevOps, and architects managing complex systems.\n\n4. **Dependencies**:  \n- Python standard library: `re` module for regex matching.  \n- Custom or external classes/types: `CodeChunk` (likely a data structure encapsulating code and metadata), and `self.templates` which holds predefined prompt templates.  \n- No explicit external services",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:07.621434",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_18": {
      "chunk_id": "enhanced_summarizer.py:chunk_18",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "0eb01e9a9ef694a43cf2dc1fc2b7e62f11f44d1e48caad6ec8d8b3fe382abcc4",
      "chunk_index": 18,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This code snippet selects an appropriate summarization template based on the type of a given file chunk and constructs contextual metadata strings to enrich the summary output.\n\n2. **Technical Details**:  \n   - Uses conditional branching (`elif` statements) to map file types to predefined template constants (e.g., `CICD_TEMPLATE`, `MONITORING_TEMPLATE`).  \n   - Checks for exception-related metadata to assign an exception-specific template.  \n   - Builds auxiliary strings such as `symbol_info` if a symbol name exists, and compiles a list of import statements (limited to the first 5) for additional context.  \n   - Relies on metadata attributes (`chunk.metadata`, `metadata`) to guide template selection and context enrichment.\n\n3. **Business Logic**:  \n   The code supports enhanced summarization of code or configuration files by applying domain-specific templates, improving the relevance and clarity of generated summaries for different file types (CI/CD, monitoring, infrastructure, API specs, configs, exceptions, or generic code). This aids developers and stakeholders in quickly understanding codebases or configurations in diverse environments.\n\n4. **Dependencies**:  \n   - Internal dependency on a `templates` object or module that provides various template strings or objects (e.g., `CICD_TEMPLATE`).  \n   - Assumes a `chunk` object with metadata attributes and a `metadata` dictionary containing keys like `'imports'` and `'exceptions'`.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:15.424314",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_20": {
      "chunk_id": "enhanced_summarizer.py:chunk_20",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "d19b8530746438266f0332e1a725e3688cd412f1f4287512cddbe66566704b4e",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a method that constructs a formatted prompt string for summarizing a code chunk, incorporating various metadata elements such as exceptions, annotations, environment variables, and API endpoints. It also includes an asynchronous method stub for generating an enhanced summary of the code chunk, potentially leveraging caching.\n\n2. **Technical Details**:  \n- The code builds a list `metadata_context` by conditionally appending formatted strings based on the presence of metadata fields (`exceptions`, `annotations`, `env_vars`, `api_endpoints`).  \n- It limits the number of items displayed for annotations (up to 5), environment variables (up to 5), and API endpoints (up to 3) to keep the context concise.  \n- The `symbol_info` string is augmented with this metadata context if any metadata exists.  \n- A prompt string is created using a `template.format()` call, injecting language, file path, chunk type, file type, symbol info, and a truncated version of the chunk content (up to 2000 characters).  \n- The `summarize_chunk` method is defined as asynchronous and includes a parameter to optionally use caching, though its implementation is incomplete in the snippet.\n\n3. **Business Logic**:  \nThe code aims to generate enriched summaries of code segments that include both technical details (like exceptions and annotations) and contextual metadata (environment variables, API endpoints). This supports business needs such as improving code understanding,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:23.768116",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_22": {
      "chunk_id": "enhanced_summarizer.py:chunk_22",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "305a98739f8596ccf5a5400de4ea46d95b7a107c91a2bd636db12ccfeffaea29",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet is part of a summarization system that generates enhanced summaries for code chunks, leveraging caching to avoid redundant processing and using an AI model (Azure GPT-4o mini) for summary generation.\n\n2. **Technical Details**:  \n- Uses an asynchronous method to generate summaries (`await self._generate_enhanced_summary`).  \n- Implements a caching mechanism via `self.repo_state.get_cached_summary` to retrieve previously computed summaries by `chunk_id`.  \n- Extracts metadata from code chunks before summarization.  \n- Updates the cache/state after successful summarization with detailed chunk info including file path, content, index, and status.  \n- Uses exception handling to catch any errors during summary generation and falls back to a default summary method (`self._fallback_summary`).  \n- The chunk index is parsed from the chunk ID string, assuming a naming convention with underscores.\n\n3. **Business Logic**:  \nThe code addresses the need to efficiently generate and store enhanced summaries of code segments, which can be used for code intelligence, documentation, or developer productivity tools. By caching summaries, it reduces redundant AI calls, saving costs and improving response times.\n\n4. **Dependencies**:  \n- An Azure AI client (`self.azure_client`) for GPT-4o mini model inference.  \n- A repository state manager (`self.repo_state`) for caching and state updates.  \n- Logging utility (`logger`) for debug and error messages.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:32.327185",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_24": {
      "chunk_id": "enhanced_summarizer.py:chunk_24",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "62a9a885573835bbe098f8c34556714e25e93836499957ad9e229efda4cbf4a5",
      "chunk_index": 24,
      "summary": "**Summary of `enhanced_summarizer.py` snippet**\n\n1. **Purpose**  \nThis code snippet is part of a summarization component that generates enhanced summaries for code chunks, leveraging Azure's chat completion API when available, and falling back to a local summarization method otherwise.\n\n2. **Technical Details**  \n- Uses a conditional check to determine if an Azure client is available; if not, it falls back to a local summarization method (`_fallback_summary`).  \n- Constructs an enhanced prompt by combining the chunk content and metadata via `build_enhanced_prompt`.  \n- Logs detailed debug information about the chunk being summarized, including file path, chunk type, symbol name, line numbers, prompt length, and counts of various metadata categories (imports, exceptions, annotations, environment variables, API endpoints).  \n- Defines an asynchronous inner function `call_api` to invoke the Azure Chat Completion API, indicating asynchronous API calls and potential rate limiting handling.\n\n3. **Business Logic**  \nThe code addresses the business need to generate high-quality, context-aware summaries of code segments, which can be used for documentation, code review automation, or knowledge extraction in software development workflows. It ensures robustness by providing a fallback mechanism if the Azure service is unavailable.\n\n4. **Dependencies**  \n- Azure Chat Completion API (likely from Azure OpenAI or Cognitive Services SDK) for generating summaries.  \n- A logging framework (`logger`) for debug-level tracing.  \n- Internal methods like `_fallback_summary` and",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:38.616417",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_26": {
      "chunk_id": "enhanced_summarizer.py:chunk_26",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "e0b6a736c6da8d822b0abbbd56f63420da853975a8d380292236c8c44038e128",
      "chunk_index": 26,
      "summary": "**Summary of `enhanced_summarizer.py` snippet**\n\n1. **Purpose**  \nThis code asynchronously generates structured, technical summaries of code chunks by invoking an Azure OpenAI chat completion API, with a fallback mechanism for non-AI summarization.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) for non-blocking API calls.  \n- Constructs a chat completion request with a system prompt defining the AI\u2019s role and a user prompt containing the code chunk to summarize.  \n- Calls Azure OpenAI\u2019s `chat_completion` method with parameters: model `\"gpt-4.1-mini\"`, `max_tokens=300` for detailed output, and `temperature=0.2` to favor factual responses.  \n- Employs a rate limiter (`self.rate_limiter.submit`) to control API usage quotas with priority handling.  \n- Logs debug information about the received summary length.  \n- Implements a fallback method `_fallback_summary` to generate summaries without AI if the API call fails or returns empty.\n\n3. **Business Logic**  \nEnables automated, high-quality summarization of code for software architects or developers, improving code understanding, documentation, and review processes while managing API usage costs and limits.\n\n4. **Dependencies**  \n- Azure OpenAI client (`self.azure_client`) for chat completions.  \n- A rate limiter component (`self.rate_limiter`) managing quota types (`QuotaType.SUMMARIZATION`).  \n- Logging module (`logger`) for",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:46.349161",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_28": {
      "chunk_id": "enhanced_summarizer.py:chunk_28",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "f2252f7697ddfeaf703f7f959ee5e5275d47100f1da5d37aa439c5e402144663",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis Python code snippet generates a concise, formatted summary string for a given code chunk by extracting and presenting key metadata attributes such as symbol names, file locations, dependencies, exceptions handled, annotations, environment variables used, and API endpoints. It also includes the start of an asynchronous method intended to summarize multiple code chunks in batches with progress tracking.\n\n2. **Technical Details**:  \n- Uses string formatting and list aggregation (`parts.append()`) to build a summary string.  \n- Extracts metadata from a `chunk` object and a separate `metadata` dictionary, selectively including up to a few items from lists (e.g., first 3 imports, annotations).  \n- Uses Python\u2019s `Path` from `pathlib` to extract file names from file paths.  \n- The method `summarize_batch` is declared as asynchronous (`async def`), indicating use of async I/O or concurrency for batch processing.  \n- The code snippet implies a design pattern of incremental enrichment of summaries by combining static chunk metadata with dynamic metadata insights.\n\n3. **Business Logic**:  \nThe code supports automated code intelligence or documentation generation tools by summarizing code chunks with relevant contextual information. This helps developers quickly understand code components, their dependencies, error handling, and environment interactions, thereby improving code review efficiency, onboarding, or automated documentation.\n\n4. **Dependencies**:  \n- Python standard library: `pathlib.Path` for file path manipulation.  \n- Likely depends",
      "embedding_id": null,
      "created_at": "2025-10-22T18:54:53.752569",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_30": {
      "chunk_id": "enhanced_summarizer.py:chunk_30",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "a5221aeeb3770901e7d711e4135ff22fdd073d154280fa522d0a752514a5b5ef",
      "chunk_index": 30,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet manages batch summarization of text chunks, leveraging caching to avoid redundant processing and improve efficiency. It prepares chunks for summarization by separating cached results from those requiring new summaries.\n\n2. **Technical Details**:  \n- Uses a list (`chunks`) representing text segments to summarize.  \n- Implements a caching mechanism by checking each chunk's state (`repo_state.get_chunk_state`) for existing summaries.  \n- Separates chunks into `chunks_to_process` (needing summarization) and `cached_results` (already summarized).  \n- Uses counters (`cache_hits`, `error_count`, `fallback_count`, `total_processed`) to track progress and errors.  \n- Processes chunks in batches of size 10 to provide incremental progress updates.\n\n3. **Business Logic**:  \nThe code optimizes the summarization workflow by reusing previously computed summaries, reducing computational costs and latency. This is critical in business contexts where summarizing large volumes of text efficiently impacts user experience and resource utilization.\n\n4. **Dependencies**:  \n- `logger`: A logging utility for info-level messages (likely Python\u2019s standard `logging` module or a custom wrapper).  \n- `self.repo_state`: An internal repository or state management component that stores chunk summaries and metadata.\n\n5. **Configuration**:  \n- `use_cache`: A boolean flag controlling whether to leverage cached summaries or force reprocessing.  \n- `batch_size`: Hardcoded to 10, indicating",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:03.485138",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_32": {
      "chunk_id": "enhanced_summarizer.py:chunk_32",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "61188163b73053d25c228bd9a80e228eb8caefa19d81dba8b8e7b13272cf8755",
      "chunk_index": 32,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis asynchronous Python code processes a list of text chunks by summarizing them in batches, handling each batch concurrently to improve throughput. It logs progress and manages failures by applying fallback summaries when errors occur.\n\n2. **Technical Details**:  \n- Uses asynchronous programming with `asyncio` to run multiple summarization tasks in parallel (`asyncio.gather`).  \n- Processes data in fixed-size batches (`batch_size`) to balance load and resource usage.  \n- Employs list slicing to create batches from the input list (`chunks_to_process[i:i + batch_size]`).  \n- Uses exception handling within `asyncio.gather` by setting `return_exceptions=True` to capture and handle individual task failures without stopping the batch processing.  \n- Maintains counters (`total_processed`, `error_count`, `fallback_count`) to track progress and error metrics.  \n- Uses logging for informational and debug-level messages to trace processing status and errors.  \n- Calls helper methods `self.summarize_chunk()`, `self.extract_metadata()`, and `self._fallback_summary()` indicating modular design.\n\n3. **Business Logic**:  \nThe code supports a business need to generate concise summaries of large text data (e.g., documents, code, or reports) efficiently and reliably. By batching and parallelizing summarization, it aims to provide timely insights while ensuring robustness through fallback mechanisms in case of summarization failures.\n\n4. **Dependencies**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:11.480522",
      "status": "summarized"
    },
    "enhanced_summarizer.py:chunk_34": {
      "chunk_id": "enhanced_summarizer.py:chunk_34",
      "file_path": "code-intelligence\\enhanced_summarizer.py",
      "chunk_hash": "4fc401393bfddc950e33dc275d2590756aec25911cb97098265c8cf564547ca3",
      "chunk_index": 34,
      "summary": "1. **Purpose**:  \nThis code snippet calculates and logs the progress and estimated time of arrival (ETA) for processing a batch of summaries, then logs the completion status including any errors or fallback summaries used, and finally returns the batch results.\n\n2. **Technical Details**:  \n- Uses asynchronous event loop time measurement (`asyncio.get_event_loop().time()`) to calculate elapsed batch processing time.  \n- Computes progress percentage based on processed chunks vs total chunks.  \n- Calculates average processing time per chunk and estimates remaining time (ETA) in minutes.  \n- Logs progress updates and final batch completion status using a logger.  \n- Tracks and reports error and fallback summary counts.\n\n3. **Business Logic**:  \nThe code supports monitoring and reporting the progress of generating text summaries in batches, providing visibility into processing status and expected completion time, which is critical for managing long-running batch jobs and ensuring timely delivery of summarized content.\n\n4. **Dependencies**:  \n- `asyncio` for event loop time measurement.  \n- A logging framework (referred to as `logger`) for info and warning messages.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet. The logger and batch parameters (`total_chunks`, `total_processed`, `batch_start_time`, `batch`, `result`, `error_count`, `fallback_count`) are assumed to be provided by the surrounding context.\n\n6. **Error Handling**:  \n- Does not explicitly handle exceptions",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:20.767753",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_0": {
      "chunk_id": "rate_limiter.py:chunk_0",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "34a71d37dfb1addd5f36d464e6e7346d016b5f0f41375a0622a11ce00883a024",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code implements a rate limiting controller tailored for the Azure OpenAI API, specifically designed to manage embedding operations by adaptively batching requests and applying exponential backoff to avoid HTTP 429 (Too Many Requests) errors.\n\n2. **Technical Details**:  \n- Uses Python `dataclasses` to define configuration (`RateLimitConfig`) and metrics (`RequestMetrics`) for tracking request performance and adapting batching strategies.  \n- Defines an enumeration (`QuotaType`) to categorize different Azure service quotas (embedding, summarization, chat).  \n- Employs adaptive batching by adjusting batch sizes based on request metrics such as success and throttling rates.  \n- Implements exponential backoff with jitter to space out retries after throttling, reducing contention and improving throughput.  \n- Uses standard Python modules like `asyncio` for asynchronous operations, `time` for timing, and `logging` for diagnostics.\n\n3. **Business Logic**:  \nPrevents service disruptions and degraded user experience caused by exceeding Azure OpenAI API rate limits. By managing request rates and batch sizes dynamically, it ensures efficient utilization of API quotas while minimizing failed or throttled requests, thus maintaining smooth and cost-effective embedding operations.\n\n4. **Dependencies**:  \n- Python standard libraries: `asyncio`, `time`, `random`, `logging`, `dataclasses`, `enum`, `collections`  \n- Typing hints from `typing` module for better code clarity and maintainability  \n- No external third-party",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:25.301753",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_2": {
      "chunk_id": "rate_limiter.py:chunk_2",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "55e365225a88bb8a3ce0ac92cdb9f577f72bc38d22e419fa13f4208cbd67c1a3",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code implements an intelligent rate limiter designed to control API request rates and token consumption per model type, optimizing throughput while preventing quota overuse.\n\n2. **Technical Details**:  \n- Utilizes a leaky bucket algorithm to smooth out request bursts.  \n- Employs adaptive batching, dynamically adjusting batch sizes based on observed throughput metrics.  \n- Implements exponential backoff with jitter to handle retries gracefully and avoid thundering herd problems.  \n- Uses token-based and request-based limiting strategies concurrently.  \n- Maintains a priority queue for scheduling tasks efficiently.  \n- Uses a `deque` with a fixed maximum length (100) to track recent request timestamps for rate calculations.  \n- Configuration is managed via a dictionary keyed by `QuotaType` enums, each associated with a `RateLimitConfig` dataclass specifying limits.\n\n3. **Business Logic**:  \nSolves the problem of enforcing API usage quotas for different AI model types (e.g., embeddings, summarization, chat) to ensure fair usage, prevent service degradation, and optimize resource allocation by adapting batch sizes and retry strategies.\n\n4. **Dependencies**:  \n- Python standard library: `collections.deque`, `dataclasses.field`  \n- Custom types/enums: `QuotaType`, `RateLimitConfig` (likely defined elsewhere in the codebase)  \n- No explicit external third-party libraries shown in the snippet.\n\n5. **Configuration**:  \n- Default rate limits",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:32.934465",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_4": {
      "chunk_id": "rate_limiter.py:chunk_4",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "c102e193fcaf6b3640d2dc29f1a31e71425399695ef8ec6b230ecf0f53915c3c",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a rate limiting controller that manages and enforces request quotas asynchronously across different quota categories. It orchestrates background workers to process queued tasks with priority, ensuring controlled request throughput per quota type.\n\n2. **Technical Details**:  \n- Uses Python's `asyncio` library for asynchronous concurrency.  \n- Maintains multiple `asyncio.PriorityQueue` instances keyed by `QuotaType` to hold tasks prioritized for execution.  \n- Employs `asyncio.Lock` objects per quota type to synchronize access and prevent race conditions.  \n- Uses a dictionary of `RequestMetrics` objects to track request statistics per quota type.  \n- Implements a worker coroutine (`_worker`) per quota type that continuously processes tasks from its queue while the controller is running.  \n- A unique task counter is used to break ties in priority queue ordering, ensuring deterministic task processing order.\n\n3. **Business Logic**:  \nThe code addresses the business need to enforce rate limits on different categories of requests (quota types), preventing system overload and ensuring fair resource allocation. This is critical for services that must comply with API usage policies, avoid throttling, or maintain quality of service.\n\n4. **Dependencies**:  \n- Python standard library: `asyncio` for asynchronous programming.  \n- Custom or external modules/types: `QuotaType` (likely an Enum defining quota categories), `RequestMetrics` (for tracking metrics), and `logger` for",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:38.722899",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_6": {
      "chunk_id": "rate_limiter.py:chunk_6",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "94d04ec46ec03cea6caae3cf73381e14cbf66d8b4a39139621f36a34097b6240",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code implements an asynchronous background worker that processes tasks from prioritized queues with rate limiting, ensuring controlled execution of functions based on quota types.\n\n2. **Technical Details**:  \n- Uses `asyncio` for asynchronous task management and concurrency.  \n- Maintains multiple task queues indexed by `quota_type`, each holding tasks with associated priority, function, arguments, and a future for result handling.  \n- Uses `asyncio.wait_for` with a timeout to fetch tasks, enabling periodic checks for the running state.  \n- Executes tasks via an internal `_execute_with_limit` method that enforces rate limiting per quota type.  \n- Uses `asyncio.Future` objects to communicate task completion or exceptions back to the submitter.  \n- Implements a producer-consumer pattern with task queues and background workers.\n\n3. **Business Logic**:  \nThis code solves the problem of controlling the rate at which certain operations (e.g., API calls, resource-intensive computations) are executed, preventing quota overruns and ensuring fair resource usage across different quota categories.\n\n4. **Dependencies**:  \n- Python standard library's `asyncio` for asynchronous programming.  \n- A `QuotaType` enum or class (not shown) to categorize tasks.  \n- A logging facility (`logger`) for error reporting.\n\n5. **Configuration**:  \n- The rate limits and quota types are likely configured elsewhere, possibly via environment variables or configuration files that define quotas per `",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:47.525808",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_8": {
      "chunk_id": "rate_limiter.py:chunk_8",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "730565add041635f46dd844ae02f0867a6edfab95140eeba98ee41716d252762",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous rate limiter that manages task execution based on different quota types (e.g., embedding, summarization, chat). It queues tasks with priorities and executes them while enforcing rate limits.\n\n2. **Technical Details**:  \n- Uses `asyncio` for asynchronous task management.  \n- Maintains multiple priority queues (`self.task_queues`) keyed by `quota_type` to segregate tasks by quota category.  \n- Each task is wrapped in a tuple `(priority, counter, func, args, kwargs, future)` to ensure unique ordering and priority-based execution.  \n- Uses a monotonically increasing counter (`self._task_counter`) to break ties in priority and maintain FIFO order among same-priority tasks.  \n- Tasks are submitted via an async method that returns a future, which resolves when the task completes.  \n- Logging is used extensively for debugging task submissions.\n\n3. **Business Logic**:  \nThe code enforces usage quotas for different AI-related services (embedding generation, summarization, chat) by controlling the rate at which tasks are executed. This prevents overuse of resources, manages costs, and ensures fair usage according to predefined limits.\n\n4. **Dependencies**:  \n- Python standard library: `asyncio` for asynchronous programming.  \n- Likely a custom `QuotaType` enum or class to define quota categories.  \n- A logging framework (`logger`) for debug output.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:55:54.487376",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_10": {
      "chunk_id": "rate_limiter.py:chunk_10",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "4be0bf2d258cf66d79dfcb00c420151909a4c3476e8fd70aafeef5426dfa7b66",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet implements a rate-limiting mechanism that controls the execution of a given function based on quota types, ensuring that calls adhere to defined limits while providing retry logic on failure.\n\n2. **Technical Details**:  \n- Uses asynchronous context managers (`async with`) to acquire locks per quota type, ensuring serialized access and preventing race conditions.  \n- Maintains metrics per quota type, tracking total and throttled requests.  \n- Implements a retry loop with a maximum of 5 attempts and an initial retry delay (configurable).  \n- Measures execution time for each function call to update performance metrics.  \n- Uses dynamic function name retrieval for logging purposes.  \n\n3. **Business Logic**:  \nThe code enforces quota-based rate limiting to prevent overuse of resources or APIs, ensuring fair usage and protecting backend services from overload. It also provides resilience by retrying failed operations, improving reliability in transient failure scenarios.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous programming and locks (implied by `async with`).  \n- `time` module for measuring execution duration.  \n- A `logger` instance for debug logging.  \n- A `config` object providing retry delay settings.  \n- Custom `metrics` data structures indexed by `quota_type`.  \n\n5. **Configuration**:  \n- `config.initial_retry_delay` controls the initial wait time between retries.  \n- Quota types and their associated",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:00.192206",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_12": {
      "chunk_id": "rate_limiter.py:chunk_12",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "68937ba5f230fdead39d24360981b5b41c27ffbe903546dedb2a6a617f759e7b",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet handles exceptions during API calls or operations that may be rate limited, specifically detecting HTTP 429 \"Too Many Requests\" errors and implementing a retry mechanism with exponential backoff and jitter to manage request throttling.\n\n2. **Technical Details**:  \n- Uses exception handling (`try-except`) to catch errors during an operation.  \n- Detects rate limiting by checking if the error message contains \"429\" or \"Too Many Requests\".  \n- Maintains a metric counter (`metrics.throttled_requests`) to track throttled requests.  \n- Extracts a `retry-after` duration from the error message if available, otherwise calculates a wait time using exponential backoff combined with random jitter to avoid thundering herd problems.  \n- Uses a capped wait time (`config.max_retry_delay`) to limit maximum backoff duration.  \n- Logs warnings with contextual information including quota type, attempt count, and wait time.\n\n3. **Business Logic**:  \nPrevents overwhelming external APIs or services by gracefully handling rate limits, ensuring compliance with usage policies, improving system reliability, and maintaining a smooth user experience by retrying requests after appropriate delays.\n\n4. **Dependencies**:  \n- `random` module for generating jitter.  \n- `metrics` object for tracking throttled requests (likely a custom or third-party monitoring tool).  \n- `logger` for logging warnings.  \n- `config` object providing configuration parameters like `jitter_range` and",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:07.577603",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_14": {
      "chunk_id": "rate_limiter.py:chunk_14",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "7fd9eeb250f95b873dd28cc01355ffc27be39052544047a061e994b693b7d366",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous rate limiter that manages API request pacing by enforcing request quotas per minute and implementing retry logic with exponential backoff on rate limit errors.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle waiting without blocking.  \n- Maintains a deque (`metrics.request_timestamps`) to track timestamps of recent requests for each quota type, enabling efficient removal of outdated entries.  \n- Implements a sliding window rate limiting approach by counting requests within the last 60 seconds.  \n- Applies exponential backoff for retries, doubling the delay after each rate limit error.  \n- Uses a loop to retry requests until the maximum retry count is reached or a non-rate-limit error occurs.\n\n3. **Business Logic**:  \nEnsures that API calls comply with rate limits imposed by external services or internal policies, preventing service disruptions or penalties due to excessive request rates. This protects system stability and maintains good standing with third-party APIs.\n\n4. **Dependencies**:  \n- Python standard libraries: `asyncio` for asynchronous operations, `time` for timestamp management, and `collections.deque` for efficient timestamp queue management.  \n- Custom types or modules: `QuotaType` (likely an enum or class defining different quota categories), and `metrics` and `configs` objects that track usage and configuration per quota type.\n\n5. **Configuration**:  \n- `configs[quota_type].requests",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:12.204526",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_16": {
      "chunk_id": "rate_limiter.py:chunk_16",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "3e1d7f0a704381cb90f32ebc5e5cdb1aa03b5f55e2c9d27076101b5368ded2df",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a rate limiter implementation that manages API request pacing by tracking request metrics and enforcing wait times to avoid exceeding quota limits.\n\n2. **Technical Details**:  \n- Uses timestamps to track request history and calculate wait times before sending new requests.  \n- Implements a moving average algorithm to update average response times for requests, using a weighted average (90% previous average, 10% new elapsed time).  \n- Maintains metrics per quota type, including total requests, successful requests, timestamps, and last request time.  \n- Contains a method to parse error messages for \"retry-after\" durations using regular expressions.  \n- Uses asynchronous sleep (`asyncio.sleep`) to pause execution when rate limits are near.\n\n3. **Business Logic**:  \nThe code helps prevent exceeding API rate limits by monitoring request frequency and response times, thereby reducing the risk of service denials or throttling from external APIs. This ensures reliable and compliant API consumption, improving system stability and user experience.\n\n4. **Dependencies**:  \n- Python standard library modules: `time`, `asyncio`, and `re` (regular expressions).  \n- A `QuotaType` enum or class (not shown) to categorize different rate limit quotas.  \n- A `logger` instance for logging informational messages.  \n- A `metrics` data structure (likely a dictionary keyed by quota type) to store request statistics.\n\n5. **Configuration**:  \nNo explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:20.073163",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_18": {
      "chunk_id": "rate_limiter.py:chunk_18",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "c62f9ac04f5221bc76ff0ead575c1ebeee561141115b52f8922c542818290924",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a rate limiter module designed to monitor and control API request quotas by tracking metrics and dynamically adjusting batch sizes for different quota types.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.search`) to parse error strings for retry-after durations.  \n- Maintains per-quota-type metrics in a dictionary (`self.metrics`), likely using custom metric objects with counters such as total, successful, throttled, and failed requests.  \n- Tracks request timestamps to calculate request rates (e.g., requests in the last minute).  \n- Uses task queues (`self.task_queues`) per quota type to manage pending requests, leveraging queue size as a metric.  \n- Implements methods like `get_metrics` to aggregate and return current quota usage statistics and `get_adaptive_batch_size` to compute batch sizes dynamically based on throughput and configuration.\n\n3. **Business Logic**:  \nThe code addresses the problem of API rate limiting and quota management by providing real-time insights into quota consumption and adapting request batch sizes to optimize throughput while avoiding throttling or failures.\n\n4. **Dependencies**:  \n- Python standard library modules: `re` for regex operations, `queue` (implied by `qsize()` usage).  \n- Custom types such as `QuotaType` (likely an Enum) and metric data structures (not fully shown).  \n- No explicit external services or third-party libraries are visible in the snippet.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:25.073364",
      "status": "summarized"
    },
    "rate_limiter.py:chunk_20": {
      "chunk_id": "rate_limiter.py:chunk_20",
      "file_path": "code-intelligence\\rate_limiter.py",
      "chunk_hash": "d9ffab059090e940b2d53fce195f8f4e373c172e2850779a193026d31051f142",
      "chunk_index": 20,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code dynamically determines the appropriate batch size for processing tasks based on current system metrics and queue backlog, aiming to optimize throughput while avoiding throttling and excessive queue delays.\n\n2. **Technical Details**:  \n- Uses simple conditional logic to adjust `batch_size` starting from a configured maximum.  \n- Calculates a throttling rate as the ratio of throttled requests to total requests to detect overload conditions.  \n- Uses a queue size check (`qsize()`) on a task queue associated with a given `quota_type` to detect backlog.  \n- Applies a halving strategy to reduce batch size when throttling exceeds 10%, bounded by a minimum batch size.  \n- Sets batch size to minimum if the queue size exceeds a threshold (50).  \n\n3. **Business Logic**:  \nThe code addresses the business need to balance processing efficiency with system stability by adapting batch sizes to prevent service degradation caused by request throttling or task queue congestion. This helps maintain responsiveness and throughput in a rate-limited environment.\n\n4. **Dependencies**:  \n- Relies on a `config` object providing `max_batch_size` and `min_batch_size` settings.  \n- Uses a `metrics` object that tracks `throttled_requests` and `total_requests`.  \n- Accesses `self.task_queues`, a dictionary of queues keyed by `quota_type`, each supporting the `qsize()` method (likely `queue.Queue` or",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:30.872515",
      "status": "summarized"
    },
    "repo_state.py:chunk_0": {
      "chunk_id": "repo_state.py:chunk_0",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "694506693ba9a30cf8f260e501cdaea150792a6359d5d1190e615bee1a7bb402",
      "chunk_index": 0,
      "summary": "**Summary of `repo_state.py`**\n\n---\n\n### 1. Purpose\nThis module manages the state of files and their code chunks within a repository to support incremental embedding workflows. It tracks file changes using SHA256 hashes to enable efficient updates, caching, and recovery during embedding operations.\n\n### 2. Technical Details\n- **Data Structures**: Uses Python `dataclasses` (`FileState` and `ChunkState`) to represent metadata and state of files and code chunks.\n- **Hashing**: Employs SHA256 hashing to detect file content changes.\n- **State Tracking**: Maintains detailed metadata including modification time, file size, embedding status, chunk counts, and embedding IDs.\n- **Status Management**: Uses status flags (`pending`, `processing`, `completed`, `failed`) to track progress and handle retries or failures.\n- **Timestamps**: Uses ISO formatted timestamps for tracking last embedding times and chunk creation.\n\n### 3. Business Logic\n- Enables **incremental embedding** by embedding only changed files or chunks, reducing redundant computation.\n- Supports **caching** of summaries and embeddings to speed up repeated operations.\n- Facilitates **fast failure recovery** by persisting and tracking embedding states.\n- Provides **deduplication** of embeddings by tracking chunk hashes and embedding IDs, preventing duplicate embeddings of identical content.\n\n### 4. Dependencies\n- Standard Python libraries: `json`, `hashlib`, `os`, `pathlib.Path`, `datetime`,",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:35.731085",
      "status": "summarized"
    },
    "repo_state.py:chunk_2": {
      "chunk_id": "repo_state.py:chunk_2",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "91c3289206dc8148ba36b09519d33aa04eb0e42fb8f7c28a95b2968d4018172d",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python class manages the state of a source code repository to support incremental embedding processes by tracking file and chunk metadata. It uses a JSON manifest to detect changes efficiently and avoid re-processing unchanged code.\n\n2. **Technical Details**:  \n- Uses a JSON manifest file (default: `.code-intelligence-state.json`) to persist repository state.  \n- Maintains two main in-memory dictionaries: `file_states` keyed by file paths and `chunk_states` keyed by chunk identifiers.  \n- Loads state from the manifest on initialization by deserializing JSON into `FileState` and `ChunkState` objects.  \n- Employs file hashing and embedding metadata to detect changes at both file and chunk granularity.\n\n3. **Business Logic**:  \nEnables incremental updates to code embeddings by quickly identifying which files or code chunks have changed since the last processing run. This reduces redundant computation and accelerates workflows such as code search, analysis, or AI-powered code intelligence.\n\n4. **Dependencies**:  \n- Python standard libraries: `json` for serialization, `pathlib.Path` for file path handling, and presumably `logging` for logging messages.  \n- Custom data structures or classes: `FileState` and `ChunkState` (not shown but implied).  \n\n5. **Configuration**:  \n- The manifest file path is configurable via the `manifest_path` parameter, defaulting to `.code-intelligence-state.json`.  \n- No environment",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:41.505349",
      "status": "summarized"
    },
    "repo_state.py:chunk_4": {
      "chunk_id": "repo_state.py:chunk_4",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "a1446cce481f0ae35a3e934f6f06cb1aba130ae7fe45876ffd6795034a9fcf9b",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code manages the loading and saving of a manifest file that tracks the state of files and chunks within a repository, enabling persistent storage of the repository state.\n\n2. **Technical Details**:  \n- Uses Python dictionaries (`self.file_states` and `self.chunk_states`) to maintain state keyed by file paths and chunk IDs respectively.  \n- Serialization and deserialization of state objects are done via `asdict()` (likely from `dataclasses`) and unpacking dictionaries into `ChunkState` instances.  \n- The manifest is stored as a JSON file with structured fields including version, timestamp, files, chunks, and statistics.  \n- Uses `datetime.utcnow().isoformat()` to timestamp the manifest.  \n- Logging is used to record success or failure of load/save operations.\n\n3. **Business Logic**:  \nThe code supports a business need to maintain an up-to-date snapshot of the repository\u2019s state (files and chunks), which is crucial for incremental processing, caching, or resuming operations without reprocessing unchanged data.\n\n4. **Dependencies**:  \n- `json` for serialization.  \n- `datetime` for timestamping.  \n- `dataclasses.asdict` for converting state objects to dictionaries.  \n- A `logger` instance for logging messages.  \n- A `ChunkState` class for representing chunk state objects.\n\n5. **Configuration**:  \n- The manifest file path is stored in `self.manifest_path`, presumably configured",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:47.600026",
      "status": "summarized"
    },
    "repo_state.py:chunk_6": {
      "chunk_id": "repo_state.py:chunk_6",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "19155295f7c18e643f0b6a1337c78bf7d6241b47d1379c45a0211aed28d9133f",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides functionality to compute SHA256 hashes of files and text chunks, and to determine if a file has changed since it was last processed, likely for incremental processing or caching purposes.\n\n2. **Technical Details**:  \n- Uses SHA256 hashing algorithm from Python's `hashlib` to generate file and chunk hashes.  \n- Reads files in 8KB chunks to efficiently handle large files without loading entire content into memory.  \n- Maintains a `file_states` dictionary (implied) to track previously processed files and their states (hashes, modification times).  \n- Uses standard file I/O and OS operations (`open`, `os.path.exists`, `os.path.getmtime`) for file handling and metadata retrieval.\n\n3. **Business Logic**:  \nThe code supports detecting changes in source files to avoid redundant processing, such as re-embedding or re-indexing unchanged files in a code intelligence or search indexing system. This improves efficiency by only updating data for files that have been added or modified.\n\n4. **Dependencies**:  \n- Python standard libraries: `hashlib` for hashing, `os` for file system operations, and a `logger` (likely from `logging` module) for error reporting.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet. The behavior depends on the state stored in `self.file_states`, which is presumably managed elsewhere in the class or application.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:53.174801",
      "status": "summarized"
    },
    "repo_state.py:chunk_8": {
      "chunk_id": "repo_state.py:chunk_8",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "20e10319f285f1079a8d32b2f8b1d618fb7cd8e94ca352e583b23077cd0e9f18",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code manages and tracks the state of files in a repository by detecting changes based on file content hashes and modification times. It identifies which files have changed and updates their stored state accordingly.\n\n2. **Technical Details**:  \n- Uses SHA-256 hashing to detect content changes in files.  \n- Compares stored file states (likely stored in a dictionary `self.file_states` keyed by file path) against current file hashes and modification times.  \n- Implements methods such as `is_file_changed(file_path)` to check if a file has changed, `get_changed_files(file_paths)` to filter a list of files to only those changed, and `update_file_state(file_path, ...)` to update the stored state of a file.  \n- Uses a custom `FileState` data structure or class to encapsulate file metadata including path, hash, and presumably other attributes like modification time, language, chunk count, and status.\n\n3. **Business Logic**:  \nThe code supports incremental processing or analysis of files by efficiently detecting which files have changed since the last check. This avoids redundant work on unchanged files, improving efficiency in workflows like code intelligence, indexing, or CI pipelines.\n\n4. **Dependencies**:  \n- Python standard library modules: `os` for file system operations (e.g., `os.stat`), `hashlib` presumably for SHA-256 hashing (inferred from `compute_file_hash`).  \n- A logger instance (`logger`)",
      "embedding_id": null,
      "created_at": "2025-10-22T18:56:58.598551",
      "status": "summarized"
    },
    "repo_state.py:chunk_10": {
      "chunk_id": "repo_state.py:chunk_10",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "628cd634ccf2b42ddfd330562952b7b7504ba144c1e1d7eb143a6dae276a9bb4",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code manages and updates the state of file chunks within a repository, tracking metadata such as chunk content hashes, summaries, embeddings, and processing status to facilitate efficient code intelligence operations.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.chunk_states`) keyed by `chunk_id` to store `ChunkState` objects representing individual chunk metadata.  \n- Computes a hash of chunk content (`compute_chunk_hash`) to uniquely identify chunk versions.  \n- Timestamps are recorded in ISO 8601 format using `datetime.utcnow().isoformat()`.  \n- Optional fields like `summary` and `embedding_id` allow storing additional semantic information per chunk.  \n- The code follows an object-oriented design, encapsulating chunk state management within methods.\n\n3. **Business Logic**:  \nEnables tracking and updating the processing state of code chunks in a repository, supporting features like incremental indexing, caching of summaries, and embedding management. This supports business goals of efficient code search, analysis, and intelligence by avoiding redundant processing and enabling quick retrieval of chunk metadata.\n\n4. **Dependencies**:  \n- Python standard library modules: `datetime` for timestamps, `Optional` from `typing` for type hints.  \n- Presumably depends on a `ChunkState` data structure/class defined elsewhere in the codebase.  \n- The `compute_chunk_hash` method suggests a hashing utility, likely implemented internally or imported.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:05.333211",
      "status": "summarized"
    },
    "repo_state.py:chunk_12": {
      "chunk_id": "repo_state.py:chunk_12",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "6e62a714e076969b79890720e6f50726891019b2f7c9c1356dbdb2940ac652d6",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code manages and tracks the processing state of file chunks within a repository, specifically focusing on embedding operations. It provides methods to retrieve chunk states, identify failed chunks, mark chunks as failed, and gather overall processing statistics.\n\n2. **Technical Details**:  \n- Uses dictionaries (`chunk_states`, `file_states`) to store state objects keyed by chunk or file identifiers.  \n- Implements list comprehensions and generator expressions for filtering and aggregating state data efficiently.  \n- State objects appear to have a `status` attribute indicating processing outcomes such as `\"completed\"` or `\"failed\"`.  \n- Methods are designed to query and update these states in a straightforward manner without complex algorithms.\n\n3. **Business Logic**:  \nThe code supports a business process where files are divided into chunks that undergo embedding (likely for code intelligence or search indexing). It tracks which chunks/files have completed processing, which have failed, and provides summary statistics to monitor progress and identify issues.\n\n4. **Dependencies**:  \n- Uses Python standard typing annotations (`List`, `Dict`, `Any`).  \n- No explicit external libraries or services are referenced in the snippet.\n\n5. **Configuration**:  \n- No environment variables, configuration files, or external settings are indicated or required by this code snippet.\n\n6. **Error Handling**:  \n- Basic error handling by checking if a chunk ID exists before marking it as failed.  \n- No explicit exception handling or logging is present",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:14.370019",
      "status": "summarized"
    },
    "repo_state.py:chunk_14": {
      "chunk_id": "repo_state.py:chunk_14",
      "file_path": "code-intelligence\\repo_state.py",
      "chunk_hash": "19fc58160ba0d77e7a00842badd6b2c52538a4b622cc393d7ed03ec0257b554a",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet defines a method `cleanup_deleted_files` that removes internal state entries related to files that no longer exist in the current file set, including their associated chunk states, effectively cleaning up stale data from the repository state.\n\n2. **Technical Details**:  \n- Uses Python dictionaries (`self.file_states` and `self.chunk_states`) to track state information keyed by file paths and chunk IDs respectively.  \n- Iterates over a copy of the keys of `file_states` to safely modify the dictionary during iteration.  \n- Identifies deleted files by checking which keys are not present in the provided `current_files` set.  \n- Removes entries from both `file_states` and `chunk_states` that correspond to deleted files.  \n- Logs the number of cleaned-up files using a logger.  \n- Returns a list of deleted file paths for further processing or auditing.\n\n3. **Business Logic**:  \nThis method supports the business need to maintain accurate and up-to-date state information about files and their processing chunks in a code intelligence or analysis system. By cleaning up state for files that have been removed from the repository, it prevents stale or orphaned data from affecting system accuracy, resource usage, or reporting.\n\n4. **Dependencies**:  \n- Uses a `logger` object for informational logging (likely from Python\u2019s standard `logging` module or a configured logger).  \n- Relies on internal data structures `self.file_states` and `self.chunk",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:18.740159",
      "status": "summarized"
    },
    "beautifier.py:chunk_0": {
      "chunk_id": "beautifier.py:chunk_0",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "2ac71281809c85f42b7cab01df968d27e6e1b7d72afadd054d5a9204e2389257",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module defines a `ResponseBeautifier` class responsible for cleaning and formatting raw responses into well-structured, polished messages optimized for consumption by large language models (LLMs).\n\n2. **Technical Details**:  \n- Uses a provider selection pattern to dynamically choose an LLM provider based on a role (\"beautify\") either automatically or explicitly via constructor argument.  \n- The beautification process is asynchronous (`async def beautify`), indicating it likely involves I/O-bound operations such as API calls to LLM services.  \n- Integrates with a response cleaning utility (`response_cleaner`) to preprocess or sanitize raw input before beautification.  \n- Uses typed collections (`List[SourceResult]`) for structured input representing source data to be summarized or beautified.  \n- Logging is used for lifecycle and debugging information.\n\n3. **Business Logic**:  \nEnables the orchestration layer to produce refined, human-readable summaries or messages from raw data sources, improving the quality and usability of outputs generated by LLMs in applications such as automated summarization, code review, or knowledge extraction.\n\n4. **Dependencies**:  \n- `orchestration.github_llm.models` for domain models like `SourceResult` and `QueryType`.  \n- `shared.llm_providers.factory.LLMFactory` and `shared.llm_providers.resilient_orchestrator` for dynamic LLM provider management.  \n- `orchestration.summary_layer.response_clean",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:26.208076",
      "status": "summarized"
    },
    "beautifier.py:chunk_2": {
      "chunk_id": "beautifier.py:chunk_2",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "32d1bb4a1cb305ec9d7f055ab5754375cadfba27cdc7d60a26b630c39b264114",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python method beautifies a generated summary response by leveraging a large language model (LLM), while providing detailed logging for traceability and performance monitoring.\n\n2. **Technical Details**:  \n- Uses structured logging to capture key metrics such as query snippet, query type, number of sources, and summary length.  \n- Measures execution time for building context from source documents.  \n- Invokes a private method `_build_context` to aggregate and prepare contextual information from multiple source inputs based on the query type.  \n- Prepares a prompt for the LLM to generate a refined, user-friendly response (though the prompt creation and LLM call are not fully shown).  \n- Likely uses string operations and time measurement (`time.time()`) for performance tracking.\n\n3. **Business Logic**:  \nEnhances raw summary outputs by reformatting or enriching them to improve readability and relevance for end-users, supporting better decision-making or user experience in applications such as search, knowledge management, or conversational AI.\n\n4. **Dependencies**:  \n- `logger`: a configured logging instance for info-level logs.  \n- `time`: Python standard library module for performance timing.  \n- `QueryType`: an enum or class representing different query categories, influencing context building.  \n- Presumably an LLM interface or API (not shown in snippet) for text beautification.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in the snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:33.740028",
      "status": "summarized"
    },
    "beautifier.py:chunk_4": {
      "chunk_id": "beautifier.py:chunk_4",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "336d76e966feea32128aefda6292ef9519ae8a8b41d6e01bae07faca98f3cfcc",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code snippet generates a beautification prompt based on input parameters and then uses a resilient large language model (LLM) orchestrator to produce a refined, \"beautified\" text output asynchronously.\n\n2. **Technical Details**:  \n- Constructs a prompt string by invoking a method `_create_beautification_prompt` with parameters such as `query`, `summary`, `context`, and `query_type`.  \n- Measures and logs the time taken to create the prompt and its length.  \n- Uses an asynchronous call to a resilient orchestrator's `chat_completion_with_fallback` method to send the prompt to an LLM provider for beautification.  \n- The orchestrator abstracts LLM provider selection and fallback mechanisms, enhancing reliability.  \n- Logs the time taken for the LLM call.  \n- Uses structured logging with emojis for clarity in logs.\n\n3. **Business Logic**:  \nThe code addresses the business need to improve or \"beautify\" textual summaries or responses generated from raw queries and context, likely enhancing user-facing outputs such as summaries, reports, or chatbot responses to be more polished and readable.\n\n4. **Dependencies**:  \n- `shared.llm_providers.resilient_orchestrator.get_resilient_orchestrator`: Provides a resilient orchestrator for LLM calls with fallback capabilities.  \n- `time` module: For performance measurement.  \n- `logger`: Presumably a configured logging instance for info",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:39.464142",
      "status": "summarized"
    },
    "beautifier.py:chunk_6": {
      "chunk_id": "beautifier.py:chunk_6",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "2bbcc47332a7fb02df4b3c4532b91ba7e48776864e5564a708cffc801587ec78",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a response beautification process that logs the length and preview of a formatted response, cleans the beautified text using a cleaning utility, logs timing and metadata, and returns the cleaned output. If an error occurs during beautification, it falls back to a simpler formatting method.\n\n2. **Technical Details**:  \n- Uses logging extensively for tracing execution and debugging.  \n- Measures execution time for the cleaning step in milliseconds using `time.time()`.  \n- Calls `response_cleaner.clean_with_metadata()` which returns both cleaned text and associated metadata, indicating a design that captures additional context about the cleaning process.  \n- Implements a try-except block to catch all exceptions during beautification and triggers a fallback formatting method `_fallback_formatting()`.  \n- The fallback method takes inputs like `query`, `summary`, and `sources`, suggesting these are core data elements involved in formatting.\n\n3. **Business Logic**:  \nThe code aims to enhance the readability and quality of textual responses, likely for user-facing summaries or reports. By cleaning and beautifying responses, it improves user experience and ensures consistent output formatting. The fallback mechanism ensures robustness by providing a basic formatted output even if beautification fails.\n\n4. **Dependencies**:  \n- `logger`: a logging utility, probably Python\u2019s standard `logging` module or a configured wrapper.  \n- `time`: Python standard library for timing operations.  \n- `response_cleaner`: an",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:46.151186",
      "status": "summarized"
    },
    "beautifier.py:chunk_8": {
      "chunk_id": "beautifier.py:chunk_8",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "af1a6e26100afd971e917394e7ab3ff9a159e6e8487d860ab753e290e9691aef",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code is part of a \"beautifier\" module that processes and formats textual data extracted from various source results, cleaning fallback responses and constructing a structured context summary to aid in generating improved or \"beautified\" textual outputs.\n\n2. **Technical Details**:  \n- Uses list iteration and string formatting to build a multi-part context string from a list of `SourceResult` objects.  \n- Extracts metadata such as repository name, file path, and relevance score from each source to include in the context.  \n- Limits content preview to the first 500 characters for brevity.  \n- Employs a `response_cleaner` utility (likely a class or function) to sanitize fallback responses.  \n- Logging is used to track cleaning operations and output lengths.  \n- The code snippet shows private methods (prefixed with `_`) indicating an internal API design pattern within a class.\n\n3. **Business Logic**:  \nThe code supports a system that aggregates information from multiple sources (e.g., code repositories or documents) and prepares a clean, human-readable summary context. This is useful in scenarios like automated summarization, knowledge extraction, or AI prompt generation where context quality directly impacts downstream results.\n\n4. **Dependencies**:  \n- `response_cleaner` (an external or internal cleaning utility) for sanitizing text.  \n- `logger` for logging informational messages.  \n- Custom types `SourceResult` and `QueryType` which are likely",
      "embedding_id": null,
      "created_at": "2025-10-22T18:57:53.777672",
      "status": "summarized"
    },
    "beautifier.py:chunk_11": {
      "chunk_id": "beautifier.py:chunk_11",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "57cb4c865cc0c45eeb97301f091841106ae569b3143c12687022afb9eca17c19",
      "chunk_index": 11,
      "summary": "\ud83d\udcc1 `orchestration/summary_layer/beautifier.py` (lines 1-70 approx.)\n\n---\n\n## \ud83d\udd0d 1. Purpose\nThis Python module provides functionality to format and beautify textual summaries and search results, particularly for displaying query results and summaries in a visually structured and engaging manner. It includes fallback formatting logic when a language model (LLM) is unavailable.\n\n---\n\n## \ud83d\udee0\ufe0f 2. Technical Details\n- Implements string formatting using Python f-strings to build markdown-style output.\n- Uses structured headers (with emojis) and horizontal separators (`---`) to create clear visual hierarchy.\n- Supports conditional logic to handle presence or absence of search results.\n- Uses list slicing and pluralization logic to format the number of results displayed.\n- Encapsulated in methods (e.g., `_fallback_formatting`) likely part of a larger class or module.\n\n---\n\n## \ud83d\udcbc 3. Business Logic\n- Enhances user experience by transforming raw search query results and summaries into readable, attractive markdown reports.\n- Supports fallback display when the primary LLM-based formatting is unavailable, ensuring robustness in user-facing summary presentation.\n- Helps downstream consumers (e.g., UI components, reports) by providing consistent, easy-to-scan textual summaries.\n\n---\n\n## \ud83d\udce6 4. Dependencies\n- No explicit external libraries shown in the snippet.\n- References a `SourceResult` type, implying dependency on domain-specific data structures or modules.\n- Likely part of a larger orches",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:03.392047",
      "status": "summarized"
    },
    "beautifier.py:chunk_13": {
      "chunk_id": "beautifier.py:chunk_13",
      "file_path": "orchestration\\summary_layer\\beautifier.py",
      "chunk_hash": "43400ea44ffb99cd8007681f71803971de3c6edb66914208fe6c004bbbf60ca8",
      "chunk_index": 13,
      "summary": "1. **Purpose**  \nThis Python code formats and beautifies search results from a source collection into a human-readable markdown summary, highlighting relevance and metadata for up to three top results or providing guidance if no results are found.\n\n2. **Technical Details**  \n- Iterates over the first three elements of a `sources` list, using enumeration starting at 1.  \n- Extracts metadata fields (`repo`, `file_path`) with default fallbacks.  \n- Computes a relevance percentage from a floating-point relevance score.  \n- Uses conditional logic to assign an emoji icon based on relevance thresholds (\u226580% green, \u226560% yellow, else orange).  \n- Constructs a markdown string with headings, icons, metadata, and a content preview truncated to 300 characters.  \n- Handles the empty results case by appending a markdown block with tips for improving search results.  \n- Adds a footer tip about repository indexing in a Vector DB.  \n- Returns the fully concatenated markdown string.\n\n3. **Business Logic**  \nThis code supports a search or recommendation feature by presenting the most relevant code or document snippets to users in a visually structured and informative way, improving user experience in navigating search results and understanding their context.\n\n4. **Dependencies**  \n- Implicitly depends on the structure of `source` objects having `metadata` dicts, `relevance_score` floats, `source_type` strings, and `content` strings.  \n- No explicit external libraries or modules are",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:09.796847",
      "status": "summarized"
    },
    "speech_service.py:chunk_0": {
      "chunk_id": "speech_service.py:chunk_0",
      "file_path": "shared\\azure_services\\speech_service.py",
      "chunk_hash": "ac28fc28377166d01ed3b194afdfe064f3ad0424a152dcb44b24721ac7aa61e0",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module implements an Azure Speech-to-Text service that performs automatic language detection and speech recognition on audio inputs using Azure Cognitive Services Speech SDK.\n\n2. **Technical Details**:  \n- Uses Azure Cognitive Services Speech SDK (`azure.cognitiveservices.speech`) for speech recognition.  \n- Supports multiple audio formats such as `webm`, `mp3`, and `wav`.  \n- Implements automatic language detection to convert from auto-detected language to a standard language code.  \n- Designed to handle continuous recognition for longer audio streams.  \n- Encapsulated in a class `AzureSpeechService` that initializes and manages the Azure speech configuration internally.  \n- Uses Python logging for warnings and error reporting.  \n- Configuration is initialized lazily in a private method `_initialize_config()`.\n\n3. **Business Logic**:  \nEnables applications to convert spoken audio into text with minimal configuration, supporting multiple languages and audio formats. This facilitates voice-driven features such as transcription, voice commands, or accessibility enhancements in business applications.\n\n4. **Dependencies**:  \n- `azure.cognitiveservices.speech` SDK for speech recognition.  \n- Python standard libraries: `logging`, `base64`, `io`, and typing (`Optional`, `Tuple`).  \n- Internal configuration module `..config` for fetching Azure credentials.\n\n5. **Configuration**:  \n- Requires Azure Speech service credentials: `azure_speech_key` and `azure_speech_region` from",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:16.808693",
      "status": "summarized"
    },
    "speech_service.py:chunk_2": {
      "chunk_id": "speech_service.py:chunk_2",
      "file_path": "shared\\azure_services\\speech_service.py",
      "chunk_hash": "3fa491fc5138773fb4f47bff6f5c1fdbd5563e414151f250fc5501437aec9f85",
      "chunk_index": 2,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling in this code primarily addresses failures during the initialization of the Azure Speech Service configuration and ensures that transcription operations are only attempted if the service is properly configured. It also guards against errors that may arise from invalid or missing configuration before processing audio transcription requests.\n\n2. **Exception Types**:  \n   The code uses a broad `except Exception as e` clause, meaning it catches all exceptions derived from the base `Exception` class during initialization. This includes configuration errors, network issues, or SDK-related exceptions. No specific exception types are targeted.\n\n3. **Recovery Strategy**:  \n   Upon catching an exception during initialization, the code logs the error and sets the internal `_speech_config` attribute to `None`. This effectively disables further speech service operations until re-initialization occurs. There is no retry mechanism or automatic recovery implemented within this snippet.\n\n4. **Logging**:  \n   Errors during initialization are logged with an error-level message including the exception details (`logger.error(f\"\u274c Failed to initialize Azure Speech Service: {e}\")`). Successful initialization is logged with informational messages indicating the region and that auto language detection is enabled. This facilitates monitoring and troubleshooting.\n\n5. **User Impact**:  \n   If initialization fails, the `_speech_config` is set to `None`, and subsequent calls to `transcribe_audio` will raise a `ValueError` indicating the service is not configured. This prevents attempts to transcribe",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:25.672098",
      "status": "summarized"
    },
    "speech_service.py:chunk_4": {
      "chunk_id": "speech_service.py:chunk_4",
      "file_path": "shared\\azure_services\\speech_service.py",
      "chunk_hash": "c9b8bb90b4ead08f5551e655f2e87e1915f5df9d3d475c53f0f79f1a9deb23ef",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet performs speech-to-text transcription using Azure Cognitive Services' Speech SDK, with automatic detection of the spoken language from a predefined set of languages.\n\n2. **Technical Details**:  \n- Uses an in-memory audio stream (`audio_stream`) to hold audio bytes for processing.  \n- Constructs an `AudioConfig` object from the audio stream to feed into the recognizer.  \n- Utilizes `AutoDetectSourceLanguageConfig` to enable automatic detection among multiple languages (`en-US`, `hi-IN`, `es-ES`, `fr-FR`, `de-DE`, `ja-JP`, `zh-CN`).  \n- Creates a `SpeechRecognizer` instance configured with speech settings, audio input, and auto language detection.  \n- Calls `recognize_once()` method to perform a single-shot speech recognition operation.  \n- Extracts the recognized text and detected language from the recognition result properties.\n\n3. **Business Logic**:  \nEnables multi-language speech recognition in applications such as transcription services, voice commands, or multilingual customer support, improving user experience by automatically identifying the spoken language without manual input.\n\n4. **Dependencies**:  \n- `azure.cognitiveservices.speech` (imported as `speechsdk`): Azure Speech SDK for speech recognition.  \n- A logging framework (`logger`) for informational messages.  \n- Presumably, `audio_stream` is a stream-like object compatible with the SDK\u2019s audio input requirements.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:33.248387",
      "status": "summarized"
    },
    "speech_service.py:chunk_6": {
      "chunk_id": "speech_service.py:chunk_6",
      "file_path": "shared\\azure_services\\speech_service.py",
      "chunk_hash": "853eab77c97f8d41522f879ad922014b09a8a946c3efed8423c21812ad047cbe",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a speech-to-text (STT) service implementation using Azure Cognitive Services. It processes audio input to recognize spoken language, returning the transcribed text and detected language or handling errors accordingly.\n\n2. **Technical Details**:  \n- Utilizes the Azure Speech SDK (`speechsdk`) for speech recognition.  \n- Checks the `result.reason` to determine the outcome of the recognition process: success, no match, or cancellation.  \n- Extracts recognized text and optionally the auto-detected source language from the recognition result properties.  \n- Uses structured logging (`logger`) to provide detailed runtime information.  \n- Raises exceptions on critical errors to propagate failure states.\n\n3. **Business Logic**:  \nEnables applications to convert spoken language into text with language detection, facilitating multilingual speech input processing. This supports business scenarios such as voice commands, transcription services, or accessibility features where accurate speech recognition and language identification are critical.\n\n4. **Dependencies**:  \n- `azure.cognitiveservices.speech` (aliased as `speechsdk`) for speech recognition capabilities.  \n- A logging framework (`logger`) for capturing informational, warning, and error messages.\n\n5. **Configuration**:  \n- Likely depends on Azure Speech Service credentials and region settings (not shown in snippet but typical for Azure SDK usage).  \n- Uses SDK properties such as `SpeechServiceConnection_AutoDetectSourceLanguageResult` to retrieve detected language",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:43.617482",
      "status": "summarized"
    },
    "translation_service.py:chunk_0": {
      "chunk_id": "translation_service.py:chunk_0",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "f160b8ab1f3295ed443d57442e07b76ceb95753019cc2ea21ffe6574ce532158",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\azure_services\\translation_service.py`**\n\n1. **Purpose**  \n   This module provides an interface to Azure Cognitive Services Translator API, enabling automatic language detection and text translation into English or other target languages, supporting batch operations and over 100 languages.\n\n2. **Technical Details**  \n   - Implements an `AzureTranslationService` class encapsulating translation logic.  \n   - Uses REST API calls via the `requests` library to communicate with Azure Translator endpoints.  \n   - Supports fallback logic for configuration keys to maintain backward compatibility.  \n   - Likely uses UUIDs for request correlation or unique identification (imported but not shown in snippet).  \n   - Uses Python typing hints (`Optional`, `Tuple`, `List`) for method signatures (not fully shown).  \n   - Logging is integrated for operational visibility.\n\n3. **Business Logic**  \n   Enables applications to translate user-generated or system-generated text dynamically, facilitating multilingual support, localization, and internationalization. This is critical for businesses targeting global audiences or requiring cross-language communication.\n\n4. **Dependencies**  \n   - `requests`: For HTTP communication with Azure Translator API.  \n   - `logging`: For logging operational events and errors.  \n   - `uuid`: Possibly for generating unique request IDs or correlation tokens.  \n   - `typing`: For type annotations.  \n   - Internal module `..config` for loading configuration settings.\n\n5. **Configuration**  \n   - Reads Azure Translator API credentials and endpoint",
      "embedding_id": null,
      "created_at": "2025-10-22T18:58:49.936753",
      "status": "summarized"
    },
    "translation_service.py:chunk_2": {
      "chunk_id": "translation_service.py:chunk_2",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "d8e5be9f6b25f7ae1a2d937254358d618f358d6f6686ad0b08d8f01cb25f2120",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an Azure Translation Service client that initializes API request headers for authenticating and interacting with Azure's translation APIs, and provides an asynchronous method to detect the language of a given text.\n\n2. **Technical Details**:  \n- Uses a class-based design (implied by `self` usage) to encapsulate translation service functionality.  \n- Initializes HTTP headers required for Azure Cognitive Services Translation API calls, including subscription key, region, content type, and a unique client trace ID generated via `uuid.uuid4()`.  \n- Implements an asynchronous method `detect_language` that likely sends text to Azure's language detection endpoint and returns a tuple of detected language code and confidence score.  \n- Uses Python's `async`/`await` syntax for non-blocking I/O operations.\n\n3. **Business Logic**:  \nEnables applications to automatically detect the language of user input or content, facilitating multilingual support, localization, and internationalization workflows in software products.\n\n4. **Dependencies**:  \n- Azure Cognitive Services Translation API (external cloud service).  \n- Python standard libraries: `uuid` for generating unique IDs.  \n- Presumably uses an HTTP client library (e.g., `aiohttp` or `httpx`) for async requests (not shown in snippet).  \n- A logging framework (`logger`) for operational insights.\n\n5. **Configuration**:  \n- `self.translation_key`: Azure subscription key for authentication.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:14.683982",
      "status": "summarized"
    },
    "translation_service.py:chunk_4": {
      "chunk_id": "translation_service.py:chunk_4",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "e4259e1720954f7c72d3a9ef025263b5cdd196b88e1e63c6ba758ea7e9da51a3",
      "chunk_index": 4,
      "summary": "**Summary of Error Handling in `translation_service.py`**\n\n1. **Purpose**:  \n   The error handling in this code is designed to manage failures related to language detection using the Azure Translation Service API. It covers issues such as misconfiguration, HTTP request failures, invalid or unexpected API responses, and JSON parsing errors.\n\n2. **Exception Types**:  \n   - The code uses a broad `except Exception as e` clause, which means it catches all exceptions derived from Python\u2019s base `Exception` class.  \n   - This includes but is not limited to: network errors (e.g., connection timeouts), HTTP errors raised by `response.raise_for_status()`, JSON decoding errors, and any other runtime exceptions during the API call and response processing.\n\n3. **Recovery Strategy**:  \n   - There is no retry mechanism implemented; the code attempts the API call once.  \n   - Upon encountering any exception, it logs the error and recovers by returning a safe default language and confidence score.\n\n4. **Logging**:  \n   - Errors are logged at the `error` level with a clear message prefix (\"\u274c Language detection error:\") followed by the exception details.  \n   - Successful detections are logged at the `info` level with the detected language and confidence score, aiding monitoring and diagnostics.\n\n5. **User Impact**:  \n   - If an error occurs, the system silently falls back to returning English (`\"en\"`) as the detected language with",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:21.070758",
      "status": "summarized"
    },
    "translation_service.py:chunk_6": {
      "chunk_id": "translation_service.py:chunk_6",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "ba0517dcd28c01529a6f4f6f63125178cfb5a92a01313cfc8daaf650ac0f8161",
      "chunk_index": 6,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This code segment handles errors related to the Azure Translation Service configuration and the HTTP request for translating text. It ensures that the service is properly configured before making a request and checks for HTTP errors returned by the Azure API.\n\n2. **Exception Types**:  \n   - Raises a `ValueError` if the translation service headers (`self._headers`) are not configured, indicating a misconfiguration or missing credentials.  \n   - Uses `response.raise_for_status()` which will raise an `HTTPError` (from the `requests` library) if the HTTP response status code indicates an error (4xx or 5xx).\n\n3. **Recovery Strategy**:  \n   - There is no explicit retry or recovery mechanism shown in this snippet.  \n   - The code relies on raising exceptions immediately when configuration or HTTP errors occur, presumably to be handled by higher-level logic or to fail fast.\n\n4. **Logging**:  \n   - Logs informational messages before making the translation request, including the target language, source language (or auto-detect), and text length.  \n   - No explicit error logging is shown in this snippet, but exceptions raised would typically be logged by the caller or global error handlers.\n\n5. **User Impact**:  \n   - If the service is not configured (`ValueError`), translation requests will fail immediately, likely resulting in untranslated text or an error message to the user.  \n   - HTTP errors from the Azure",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:28.257988",
      "status": "summarized"
    },
    "translation_service.py:chunk_8": {
      "chunk_id": "translation_service.py:chunk_8",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "ea9ff798f6d9b24aa11a5cf35f97dd179aea6ef6ce87eae013c4d5b830110a33",
      "chunk_index": 8,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an asynchronous translation service that translates input text from a source language (optionally auto-detected) to a specified target language using an external translation API. It returns both the translated text and the detected or provided source language.\n\n2. **Technical Details**  \n- The method `translate` is an `async` function, indicating asynchronous I/O operations, likely to call an external translation API without blocking.  \n- The translation result is expected to be a nested dictionary/list structure where the translated text is accessed via `result[0]['translations'][0]['text']`.  \n- Language detection is handled by inspecting the `detectedLanguage` key in the API response, falling back to the provided `source_language` or `\"unknown\"`.  \n- Logging is used extensively to record success and failure states, including partial output of the translated text for traceability.  \n- Exception handling is broad, catching all exceptions to ensure the service degrades gracefully by returning the original text and language info.\n\n3. **Business Logic**  \nThis service addresses the business need for multilingual support by enabling dynamic translation of text content into various target languages. It supports automatic source language detection to simplify client usage and improve user experience in globalized applications.\n\n4. **Dependencies**  \n- An external translation API/service (not explicitly named here but implied by the response structure).  \n- A logging framework (`logger`) for info and error messages.  \n- Python standard libraries",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:36.441111",
      "status": "summarized"
    },
    "translation_service.py:chunk_11": {
      "chunk_id": "translation_service.py:chunk_11",
      "file_path": "shared\\azure_services\\translation_service.py",
      "chunk_hash": "10fa523f3e9d70fd43bfd08192cc00d73578d97a0d6dad8e29fdc0e745dc978c",
      "chunk_index": 11,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines part of an AzureTranslationService class that interacts with Azure's Translation Service to translate text and determine the source language. It also provides a method to check the service availability and creates a global instance for reuse.\n\n2. **Technical Details**:  \n- The class likely uses HTTP headers (`self._headers`) for authentication or configuration with the Azure Translation API.  \n- The `is_available()` method checks if the service is ready by verifying the presence of these headers.  \n- The snippet shows a return statement that returns the translated text along with the detected source language or \"unknown\" if detection fails.  \n- A singleton-like global instance (`azure_translation_service`) is created for shared use across the application.\n\n3. **Business Logic**:  \nIt solves the problem of language translation and detection within an application, enabling multilingual support and content localization by leveraging Azure's cloud translation capabilities.\n\n4. **Dependencies**:  \n- Azure Cognitive Services Translation API (implied).  \n- Possibly `requests` or `httpx` for HTTP calls (not shown in snippet).  \n- Internal modules or environment configurations for headers and authentication.\n\n5. **Configuration**:  \n- The service likely depends on environment variables or config files to set API keys or tokens used in `self._headers`.  \n- These configurations are essential for authenticating requests to Azure's Translation Service.\n\n6. **Error Handling**:  \n- Not explicitly shown in the snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:42.937571",
      "status": "summarized"
    },
    "jira_client.py:chunk_0": {
      "chunk_id": "jira_client.py:chunk_0",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "95370d63c8b02b722eafba3fe8227f0e0ef52feca98077708a0efe5c13d7442d",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `JiraClient` class that encapsulates interaction with the Jira REST API, enabling retrieval of Jira issues by their keys.\n\n2. **Technical Details**:  \n- Uses the `jira` Python library to interact with Jira's REST API.  \n- Implements a client initialization pattern in the constructor, with a private `_initialize_client` method to set up the authenticated Jira client instance.  \n- Uses Python typing hints (`Optional`, `Dict`, `Any`) for method signatures and attributes.  \n- The `get_issue` method fetches an issue and returns a simplified dictionary containing key fields (`key`, `summary`, `description`).  \n- Logging is used for informational and error messages.\n\n3. **Business Logic**:  \nProvides a reusable client abstraction to fetch Jira issue details, which can be used in business workflows that require issue tracking, status reporting, or integration with Jira tickets for project management or incident tracking.\n\n4. **Dependencies**:  \n- External library: `jira` (Python Jira client)  \n- Python standard libraries: `logging`, `typing`  \n- Internal module: `..config.settings` for configuration values\n\n5. **Configuration**:  \n- Requires Jira connection details: `jira_url`, `jira_email`, and `jira_api_token` from the `settings` module. These are likely environment-driven or stored in a config file.  \n- The client initialization only proceeds if all three credentials are present.",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:49.245508",
      "status": "summarized"
    },
    "jira_client.py:chunk_2": {
      "chunk_id": "jira_client.py:chunk_2",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "8421089c5d8ce2dae67019085a374a34be380ec047f8307bbf86eaa6056718c2",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `jira_client.py`**\n\n1. **Purpose**:  \n   The error handling code is designed to manage failures when interacting with the Jira API, specifically during operations such as retrieving issue details and searching for issues. It ensures that API call failures do not cause unhandled exceptions in the application.\n\n2. **Exception Types**:  \n   - The code explicitly catches `JIRAError`, which is an exception type raised by the Jira Python client library when API calls fail (e.g., network issues, authentication errors, invalid queries).\n\n3. **Recovery Strategy**:  \n   - Upon catching a `JIRAError`, the methods do not attempt retries or alternative recovery mechanisms. Instead, they handle the failure by returning safe default values (`None` for single issue retrieval, empty list for search results), allowing the application to continue running without interruption.\n\n4. **Logging**:  \n   - Errors are logged using a `logger.error` call with descriptive messages including the context (e.g., issue key or operation type) and the exception details. This facilitates monitoring and troubleshooting by capturing failure events in logs.\n\n5. **User Impact**:  \n   - End users will experience missing or empty data in the UI or downstream processes when these errors occur. For example, a failed issue fetch returns `None`, and a failed search returns an empty list, which may translate to no displayed issues or incomplete information.\n\n6. **Fallback**:  \n   - The code provides",
      "embedding_id": null,
      "created_at": "2025-10-22T18:59:55.191362",
      "status": "summarized"
    },
    "jira_client.py:chunk_4": {
      "chunk_id": "jira_client.py:chunk_4",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "166207a5e4435ac0bccf149cbbab54b27e9410bf5da8854c1632cc78ed3cb31f",
      "chunk_index": 4,
      "summary": "**Summary of Error Handling in `jira_client.py`**\n\n1. **Purpose**:  \n   The error handling is designed to manage failures occurring during the creation of Jira issues via the Jira client API. This includes network issues, authentication problems, invalid input data, or Jira server errors that prevent issue creation.\n\n2. **Exception Types**:  \n   The code specifically catches `JIRAError` exceptions, which are likely raised by the underlying Jira client library when API calls fail.\n\n3. **Recovery Strategy**:  \n   There is no retry mechanism implemented. Upon catching a `JIRAError`, the function logs the error and returns `None`, effectively signaling failure to the caller without attempting recovery or retries.\n\n4. **Logging**:  \n   Errors are logged at the error level using a logger instance with a message that includes the exception details (`logger.error(f\"Failed to create Jira issue: {e}\")`). Successful issue creation is logged at the info level, aiding monitoring and troubleshooting.\n\n5. **User Impact**:  \n   Since the function returns `None` on failure, the calling code must handle this scenario. End users or downstream processes will not receive a Jira issue key or URL, indicating that the issue was not created. This could result in missing traceability or tracking of tasks if not handled properly.\n\n6. **Fallback**:  \n   The fallback behavior is graceful degradation by returning `None` when the Jira client is not initialized (`if not self.client`) or when",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:01.871903",
      "status": "summarized"
    },
    "jira_client.py:chunk_6": {
      "chunk_id": "jira_client.py:chunk_6",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "f235d7c7b1ddbd4aaad59bbb9a71bcc395da4e7f68c4fd7a483545da6cda0913",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a method that creates a Jira ticket to document AI-generated content related to a specific repository. It constructs the ticket summary and description dynamically based on provided inputs.\n\n2. **Technical Details**:  \n- Uses string formatting and list operations to build the Jira ticket summary and description.  \n- Constructs a Markdown-like description with sections and bullet points, including conditional inclusion of URLs.  \n- Returns `None` early if the Jira client is not configured, preventing further execution.\n\n3. **Business Logic**:  \n- Automates the creation of Jira tickets for AI-generated documentation, ensuring traceability and review workflow integration.  \n- Provides contextual links (GitHub commit, Confluence page) to facilitate easy access to related resources.  \n- Encourages team collaboration by outlining next steps for review and feedback.\n\n4. **Dependencies**:  \n- Relies on a configured Jira client instance (`self.client`) to interact with Jira APIs (not shown in snippet).  \n- Uses a logger (`logger.warning`) for warning messages.  \n- Assumes availability of standard Python types (`Optional`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- Requires Jira client configuration prior to invocation (likely via environment variables or config files, not shown).  \n- Inputs such as `doc_type`, `repository`, `github_commit_url`, and `confluence_url` are passed as parameters to the method.\n\n6. **Error Handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:09.032298",
      "status": "summarized"
    },
    "jira_client.py:chunk_8": {
      "chunk_id": "jira_client.py:chunk_8",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "06f5734ac3eb57c2e80776429493008d6d8735f7b6fa5e516e6a5353f713b2ff",
      "chunk_index": 8,
      "summary": "**Summary of Error Handling in `jira_client.py`**\n\n1. **Purpose**:  \n   The error handling in this code focuses on managing failures related to interactions with the JIRA API client, specifically when adding comments to issues and transitioning issue states. It aims to handle cases where the JIRA client is not initialized or when API calls fail due to JIRA-related errors.\n\n2. **Exception Types**:  \n   - The code explicitly catches `JIRAError`, which is a specific exception type related to JIRA API operations.  \n   - There is also a pre-check for `self.client` being `None` or falsy, which prevents attempts to call methods on an uninitialized client.\n\n3. **Recovery Strategy**:  \n   - The recovery strategy is minimal and primarily involves preventing further execution if the client is not available (early return `False`).  \n   - On catching a `JIRAError`, the method logs the error and returns `False` to indicate failure. There is no retry mechanism or alternative recovery path implemented.\n\n4. **Logging**:  \n   - Errors are logged using `logger.error` with descriptive messages including the issue key and the exception details.  \n   - Successful operations (e.g., adding a comment) are logged at the info level, aiding in monitoring normal workflow and failures.\n\n5. **User Impact**:  \n   - The methods return boolean flags (`True` for success, `False` for failure), allowing calling code to detect",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:13.597483",
      "status": "summarized"
    },
    "jira_client.py:chunk_10": {
      "chunk_id": "jira_client.py:chunk_10",
      "file_path": "shared\\clients\\jira_client.py",
      "chunk_hash": "4a870a82d870690bddd462564832255c0082dd2955613cf39aa4de15e002a434",
      "chunk_index": 10,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code is designed to manage failures that occur when attempting to transition a Jira issue to a new state. It ensures that if the transition operation fails (e.g., due to invalid transition name or API issues), the failure is properly logged and the system can continue operating without crashing.\n\n2. **Exception Types**:  \n   The code specifically catches `JIRAError` exceptions, which are likely raised by the Jira API client when an API call fails or encounters an error.\n\n3. **Recovery Strategy**:  \n   Upon catching a `JIRAError`, the code does not attempt retries but instead logs the error and returns `False` to indicate the transition did not succeed. This allows the calling code to handle the failure gracefully or decide on further action.\n\n4. **Logging**:  \n   - Successful transitions are logged at the `info` level.  \n   - Missing transitions (when the requested transition name is not found) are logged as `warning`.  \n   - Exceptions (`JIRAError`) are logged as `error` with the exception message, facilitating monitoring and troubleshooting.\n\n5. **User Impact**:  \n   End users may experience that certain Jira issue transitions fail silently (no exception propagated), but the system logs these failures. The user-facing system can detect the `False` return value and potentially notify users or trigger alternative workflows.\n\n6. **Fallback**:  \n   The fallback behavior is to return `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:24.399223",
      "status": "summarized"
    },
    "github_wrapper.py:chunk_0": {
      "chunk_id": "github_wrapper.py:chunk_0",
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "chunk_hash": "57ae5614ace63378a0fb18761b7131c57fb73cfb7793549a4f8474456d1f33fd",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a `GitHubWrapper` class that abstracts GitHub API client usage by automatically selecting an authentication method based on environment configuration, enabling seamless switching between traditional ENV-based GitHub token authentication and alternative providers like Replit's GitHub integration.\n\n2. **Technical Details**  \n- Uses a wrapper/facade design pattern to unify multiple GitHub client implementations behind a single interface.  \n- Lazy initialization of the underlying client based on environment variables.  \n- Conditional dynamic import of `GitHubClient` to avoid unnecessary dependencies if not configured.  \n- Logging integration to track which provider is active.  \n- Uses Python typing hints (`Optional`, `Dict`, `Any`, `List`) for method signatures (implied from imports).  \n\n3. **Business Logic**  \nSolves the problem of managing multiple GitHub authentication methods transparently, allowing business logic to interact with GitHub APIs without concern for how authentication is handled. This flexibility supports different deployment environments and simplifies integration maintenance.\n\n4. **Dependencies**  \n- `shared.config.settings` for configuration management (likely environment variables).  \n- `shared.clients.github_client.GitHubClient` as the primary GitHub API client.  \n- Python standard `logging` module for logging.  \n- Potentially Replit's GitHub connector (mentioned in docstring, but not shown in snippet).  \n\n5. **Configuration**  \n- Relies on the environment variable `GITHUB_TOKEN` accessed via `settings",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:30.487648",
      "status": "summarized"
    },
    "github_wrapper.py:chunk_2": {
      "chunk_id": "github_wrapper.py:chunk_2",
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "chunk_hash": "66c17113f0b829683a8da2b8b2a47acc07febcbbb59f71aaff7cfe4d043a6b3b",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines part of a GitHub client wrapper that abstracts interaction with GitHub issues and pull requests. It supports multiple providers but primarily relies on an environment-configured GitHub client to fetch issue and pull request data asynchronously.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) to perform network-bound operations for fetching GitHub issues and pull requests.  \n- Employs properties (`@property`) to expose the configuration state (`is_configured`) and active provider name (`provider`).  \n- Conditional logic determines which underlying client to use based on availability (`_env_client`).  \n- Logging is used for informational and error messages, aiding in observability.\n\n3. **Business Logic**:  \nThe wrapper centralizes GitHub API interactions, allowing the application to retrieve issue and pull request details regardless of the underlying provider configuration. This abstraction supports flexibility in deployment environments and simplifies integration with GitHub for issue tracking and code review workflows.\n\n4. **Dependencies**:  \n- An internal or external GitHub client referenced as `_env_client` (likely a class instance capable of async GitHub API calls).  \n- Python standard logging module (`logger`).  \n- Typing module for type hints (`Optional`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- Relies on an environment variable `GITHUB_TOKEN` to initialize the `_env_client`.  \n- If the token is missing or initialization fails, the client disables the",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:36.906204",
      "status": "summarized"
    },
    "github_wrapper.py:chunk_4": {
      "chunk_id": "github_wrapper.py:chunk_4",
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "chunk_hash": "c3a5fa6890a9f97ea19fe9df28616ff9808fb3c165b4ada1128cceda284c3ec9",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines asynchronous wrapper methods to interact with GitHub repositories, enabling operations such as creating pull requests, retrieving repository file trees, and fetching file contents.\n\n2. **Technical Details**:  \n- The code uses asynchronous programming (`async/await`) to perform non-blocking I/O operations with GitHub.  \n- It follows a delegation pattern where calls are forwarded to an underlying client instance (`self._env_client`) that presumably implements the actual GitHub API interactions.  \n- Methods return `Optional` types, indicating that they may return `None` if the underlying client is not configured.  \n- The data structures involved include strings for repository names, file paths, and pull request details, and lists/dictionaries for repository trees.\n\n3. **Business Logic**:  \nThis wrapper abstracts GitHub API interactions to support business workflows such as automating code reviews, managing source code changes via pull requests, and inspecting repository contents programmatically. It enables integration of GitHub repository management into larger systems or CI/CD pipelines.\n\n4. **Dependencies**:  \n- An underlying GitHub client instance (`self._env_client`) which is not defined in this snippet but is critical for actual API calls.  \n- A `logger` object for error logging.  \n- Python standard typing modules for type hints (`Optional`, `List`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- The presence and configuration of `self._env_client",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:43.692687",
      "status": "summarized"
    },
    "github_wrapper.py:chunk_6": {
      "chunk_id": "github_wrapper.py:chunk_6",
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "chunk_hash": "35e54946fde2d3c1a7dabcc0793079238c172cae1498e8cc12675f18359a8f7c",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis Python code defines asynchronous wrapper methods for interacting with GitHub repositories, specifically to create or update files, create branches, and commit documentation. It acts as an abstraction layer over an underlying GitHub client implementation.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to perform non-blocking I/O operations with GitHub APIs.  \n- Delegates actual GitHub operations to an internal client instance (`self._env_client`), following a delegation design pattern.  \n- Methods accept repository details (repo name, file path, content, commit message, branch) as parameters.  \n- Returns boolean or optional dictionary results indicating success or failure of operations.  \n- Uses logging for error reporting when operations are unsupported or misconfigured.\n\n3. **Business Logic**  \nEnables automated management of repository content such as updating files or committing documentation, which supports continuous integration, documentation updates, or DevOps workflows. The branch creation method is explicitly noted as only supported for a specific connector (Replit), indicating conditional feature availability based on environment or client type.\n\n4. **Dependencies**  \n- An internal GitHub client (`self._env_client`) that actually implements the GitHub API calls.  \n- Python `asyncio` for asynchronous method definitions.  \n- A logging utility (`logger`) for error messages.  \n- Optional typing hints (`Optional`, `Dict`, `Any`) from Python's typing module.\n\n5. **Configuration**  \n- The presence and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:50.856134",
      "status": "summarized"
    },
    "github_wrapper.py:chunk_8": {
      "chunk_id": "github_wrapper.py:chunk_8",
      "file_path": "shared\\clients\\wrappers\\github_wrapper.py",
      "chunk_hash": "a887bdccde817846001bd8cb33a2be9cfe05490cc64ca2f7d267d9d23dab122c",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis snippet is part of a GitHub client wrapper that attempts to commit documentation files to a GitHub repository. When the environment client (`_env_client`) is used, it falls back to a `create_or_update_file` method to handle the commit operation, returning success status accordingly.\n\n2. **Technical Details**:  \n- Uses conditional logic to determine which client method to invoke for committing files.  \n- Calls `_env_client.create_or_update_file` with parameters: repository name, file path, file content, commit message, and branch name (defaulting to \"main\" if not provided).  \n- Returns a dictionary with a success flag if the operation succeeds, otherwise returns `None`.  \n- Logs warnings when falling back to `create_or_update_file` and errors if no GitHub provider is configured.  \n- Instantiates a singleton-like `GitHubWrapper` object at the end.\n\n3. **Business Logic**:  \nEnables automated updating or creation of files (likely documentation) in a GitHub repository, supporting environments where the primary commit method is not fully supported. This ensures continuous integration or documentation workflows can proceed without manual intervention.\n\n4. **Dependencies**:  \n- Presumably depends on a logging framework (`logger`).  \n- Uses an internal `_env_client` which abstracts GitHub API interactions.  \n- The `GitHubWrapper` class (not fully shown) encapsulates GitHub operations.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:00:58.018103",
      "status": "summarized"
    },
    "change_planner.py:chunk_0": {
      "chunk_id": "change_planner.py:chunk_0",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "f4749864f46034272301ecb462bd47f47f38efb014e0f94ea55c4dd0a88ac9b7",
      "chunk_index": 0,
      "summary": "**Summary of Error Handling in `change_planner.py`:**\n\n1. **Purpose**:  \n   The code handles the potential absence of the `git` Python package, which is required for interacting with a Git repository to analyze changed files. This is a form of dependency error handling to ensure the module can still load even if Git integration is unavailable.\n\n2. **Exception Types**:  \n   - Catches `ImportError` specifically when attempting to import `Repo` from the `git` package.\n\n3. **Recovery Strategy**:  \n   - Instead of failing or raising an error, the code sets a boolean flag `HAS_GIT` to `False` if the import fails. This flag can be used elsewhere in the code to conditionally enable or disable Git-related functionality.\n   - No retries or alternative import attempts are made.\n\n4. **Logging**:  \n   - No explicit logging occurs at the point of catching the `ImportError`. The import failure is silently handled without notifying via logs.\n\n5. **User Impact**:  \n   - End users will not experience a crash or immediate failure due to missing Git dependencies.\n   - However, features relying on Git repository analysis (e.g., detecting changed files) will likely be disabled or behave differently, potentially reducing the accuracy or usefulness of the change prioritization.\n\n6. **Fallback**:  \n   - The fallback is the `HAS_GIT = False` flag, which acts as a graceful degradation mechanism.\n   -",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:03.977241",
      "status": "summarized"
    },
    "change_planner.py:chunk_2": {
      "chunk_id": "change_planner.py:chunk_2",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "235c1feedd9d368fff03134e521ec065a1ebe8ae48e5a211a6efe59e02de1311",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a class designed to interact with a Git repository to identify files that have changed between different references or in the working directory.\n\n2. **Technical Details**:  \n- Uses the `gitpython` library's `Repo` class to interface with a Git repository.  \n- Maintains a `git_repo` instance variable initialized with the repository at `repo_path` if Git is available (`HAS_GIT`).  \n- The method `get_changed_files` returns a set of file paths that have changed, including untracked, modified (working directory), and staged files.  \n- Uses sets to store changed file paths to avoid duplicates.  \n- Uses Git concepts such as `HEAD`, index diffs, and untracked files to determine changes.\n\n3. **Business Logic**:  \nThis code supports workflows that depend on detecting file changes in a Git repository, such as incremental builds, code analysis, or deployment pipelines that only operate on changed files to optimize resource usage and speed.\n\n4. **Dependencies**:  \n- `gitpython` library (`Repo` class) for Git operations.  \n- A logger instance for warnings and informational messages.  \n- A boolean flag `HAS_GIT` indicating if Git functionality is available.\n\n5. **Configuration**:  \n- `repo_path` is a parameter or variable specifying the path to the Git repository.  \n- Defaults for `base_ref` (\"HEAD\") and optional `compare_ref`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:14.185482",
      "status": "summarized"
    },
    "change_planner.py:chunk_4": {
      "chunk_id": "change_planner.py:chunk_4",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "9c68baaeb520747917a541fba9b5453534ef02798ce6a9924f7aa2f8c5e5bfcd",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a module that identifies changed files in a Git working directory and detects \"entry point\" files within a given list of files, typically used to determine starting points for application execution or analysis.\n\n2. **Technical Details**:  \n- Uses a `set` data structure (`changed_files`, `entry_points`) to store unique file paths efficiently.  \n- Implements file name pattern matching against a predefined list of common entry point filenames across multiple programming languages (Python, JavaScript, Java, C/C++, Dart, Kotlin).  \n- Uses `Path(file_path).name` from the `pathlib` module to extract filenames from paths.  \n- Exception handling with a broad `try-except` block around Git operations (not fully shown) to capture and log errors.\n\n3. **Business Logic**:  \nThe code supports a business need to automatically detect which files have changed in a code repository and identify key entry point files that likely represent application start scripts or main modules. This is useful in change impact analysis, automated testing, deployment planning, or incremental builds.\n\n4. **Dependencies**:  \n- Python standard library modules: `pathlib` (for path manipulations), `logging` (for logging info and errors).  \n- Implicit dependency on Git tooling or a Git Python library (e.g., `gitpython`) for detecting changed files, as indicated by the context of `git changes` and `item",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:22.747422",
      "status": "summarized"
    },
    "change_planner.py:chunk_6": {
      "chunk_id": "change_planner.py:chunk_6",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "01a84cf8f7f0c8154039af4c830b7e62a5b2460ad6d8bf24ac20d46534530af7",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \n   This Python code snippet is part of a module that identifies entry points in a codebase by detecting `__init__.py` files near the root directory and analyzes import dependencies across multiple Python files using a simple heuristic.\n\n2. **Technical Details**:  \n   - Uses `Path` from `pathlib` to determine file path depth and extract file stems.  \n   - Maintains a set `entry_points` to collect root-level `__init__.py` files (depth \u2264 3).  \n   - Implements a method `analyze_dependencies` that builds a dictionary mapping each file to the count of how many other files import it.  \n   - The import detection heuristic checks if the stem (filename without extension) of other files appears as a substring in the file content, implying an import.  \n   - Uses standard file I/O with UTF-8 encoding and ignores decoding errors.\n\n3. **Business Logic**:  \n   Helps in understanding the structure and coupling of a Python project by identifying key package entry points and measuring how many files depend on each file. This can be useful for impact analysis, refactoring, or change planning in software maintenance.\n\n4. **Dependencies**:  \n   - Python standard library modules: `pathlib.Path`, `logging` (implied by `logger.info`), and built-in file I/O.  \n   - No external third-party libraries are explicitly used in the snippet.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:30.147503",
      "status": "summarized"
    },
    "change_planner.py:chunk_8": {
      "chunk_id": "change_planner.py:chunk_8",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "25a21568fb1f032f2b5d8b8e99f0db8d39fc612b7d9b6bf1af833a5b8a42cf43",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a module that analyzes file dependencies and prioritizes files for embedding, likely in a code intelligence or change impact analysis context.\n\n2. **Technical Details**:  \n- Uses a dictionary (`dependency_count`) to track how many times each file is depended upon by others.  \n- Reads and processes files, incrementing dependency counts for related files.  \n- Filters files with a dependency count greater than 5 to identify \"high-centrality\" files, which are logged for informational purposes.  \n- Implements a method `prioritize_files` that accepts all files and optionally a set of changed files, defaulting to auto-detection if not provided.  \n- Uses list comprehensions and sorting with lambda functions for filtering and ordering.  \n- The code snippet shows partial method implementations, indicating a class-based design (likely a planner or analyzer class).\n\n3. **Business Logic**:  \nThe code supports prioritizing files based on their dependency centrality and change status, which helps optimize embedding or analysis workflows by focusing on the most impactful or changed files. This is useful in scenarios like incremental code analysis, build optimization, or intelligent code search.\n\n4. **Dependencies**:  \n- Uses Python standard libraries (e.g., `logging` for `logger`).  \n- Type hints indicate use of `List`, `Set`, and `Optional` from the `typing` module.  \n- The snippet references methods like `get_changed_files",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:40.127830",
      "status": "summarized"
    },
    "change_planner.py:chunk_10": {
      "chunk_id": "change_planner.py:chunk_10",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "24875489db472a5afd1873bbfb58ce59785d27242a54bf48fe6d07982778622f",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code segment assigns priority levels to a list of source files based on their change status, role as entry points, and dependency counts to help plan the order of processing or testing.\n\n2. **Technical Details**:  \n- Uses a dictionary (`dependency_counts`) mapping file paths to their number of dependent imports.  \n- Iterates over all files, checking membership in `changed_files` and `entry_points` sets for boolean flags.  \n- Applies a multi-conditional priority assignment logic with numeric priority values (lower means higher priority).  \n- Constructs a list of `FilePriority` objects encapsulating file path, priority, and a textual reason.  \n- The priority logic uses thresholds (e.g., dependency count > 5) to distinguish core files from regular ones.\n\n3. **Business Logic**:  \nThe code supports a change impact analysis or build/test planning system by prioritizing files that are changed, critical entry points, or heavily depended upon. This helps optimize resource allocation by focusing on the most impactful files first.\n\n4. **Dependencies**:  \n- Relies on a method `self.analyze_dependencies` to produce dependency counts.  \n- Uses a `FilePriority` data structure or class (likely a namedtuple or dataclass) to store priority info.  \n- No external libraries are explicitly referenced in this snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced here.  \n- Thresholds like `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:45.048608",
      "status": "summarized"
    },
    "change_planner.py:chunk_12": {
      "chunk_id": "change_planner.py:chunk_12",
      "file_path": "code-intelligence\\change_planner.py",
      "chunk_hash": "ddca47ba7ccc9b5c24db58edc3b3d6f0145f19a10e6733d9bb00386f60a00224",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a file prioritization system that ranks source files based on their priority, change status, entry point status, and dependency count, enabling selection of the top-priority files for further processing such as embedding or analysis.\n\n2. **Technical Details**:  \n- The code sorts a list of file metadata objects (`priorities`) using a multi-criteria key: primarily by `priority` ascending, then by `dependency_count` descending, and finally by `file_path` lexicographically.  \n- It uses list comprehensions and generator expressions to count files with specific attributes (`is_changed`, `is_entry_point`).  \n- The `get_top_priority_files` method calls `prioritize_files` (not fully shown) to get the sorted list and slices it to return only the top `max_files` file paths.  \n- Data structures involved include lists of custom objects (likely named tuples or dataclasses) representing file metadata, and sets for changed files.\n\n3. **Business Logic**:  \nThe code supports a business need to efficiently prioritize source code files for embedding or further processing in a code intelligence platform. Prioritization helps focus resources on the most relevant files\u2014those recently changed, entry points, or with many dependencies\u2014improving the quality and relevance of downstream tasks like code search, analysis, or automated refactoring.\n\n4. **Dependencies**:  \n- Uses Python standard libraries such as `logging` (ind",
      "embedding_id": null,
      "created_at": "2025-10-22T19:01:52.821313",
      "status": "summarized"
    },
    "vector_store.py:chunk_0": {
      "chunk_id": "vector_store.py:chunk_0",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "ddf6df2c7799f5118dbf96b26b62d8d6a8ae4086dc5c8cb2e196d28017ea1a21",
      "chunk_index": 0,
      "summary": "**Summary of Error Handling in `vector_store.py`**\n\n1. **Purpose**:  \n   The error handling primarily addresses the absence of the Qdrant client library dependency. It ensures that the system can detect whether the Qdrant client is installed and available for use, preventing runtime failures related to missing imports.\n\n2. **Exception Types**:  \n   - The code explicitly catches `ImportError` when attempting to import the Qdrant client and its models.\n\n3. **Recovery Strategy**:  \n   - Upon catching an `ImportError`, the code sets a flag `HAS_QDRANT = False` to indicate the unavailability of the Qdrant client. This flag can be used elsewhere in the application to conditionally enable or disable features that depend on Qdrant.\n   - No retry logic is applied at the import stage since this is a static dependency issue.\n   - The class `VectorStore` includes mention of retry logic for bulk upsert operations, but this is not shown in the provided snippet.\n\n4. **Logging**:  \n   - When the Qdrant client is not available, a warning is logged: `\"Qdrant client not available\"`. This informs developers or operators that the vector store functionality relying on Qdrant will not be operational.\n   - The logger is configured at the module level using Python\u2019s standard logging library.\n\n5. **User Impact**:  \n   - If the Qdrant client is missing, features depending on",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:01.297524",
      "status": "summarized"
    },
    "vector_store.py:chunk_2": {
      "chunk_id": "vector_store.py:chunk_2",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "355f2a9255a1dda4c1507a11229963e1f94bc90e34573f6f268a45f261123b9a",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `vector_store.py`**\n\n1. **Purpose**  \n   The code primarily handles errors related to the initialization and setup of a Qdrant vector store client. It ensures that the required `qdrant-client` library is installed and that a connection to either a remote or local Qdrant instance can be established. Additionally, it verifies the existence of a Qdrant collection and attempts to create it if missing.\n\n2. **Exception Types**  \n   - `ImportError`: Raised explicitly if the `qdrant-client` package is not installed (`HAS_QDRANT` flag is false).  \n   - Other exceptions related to Qdrant client operations (e.g., network errors, API errors) are implicitly handled in the `_ensure_collection` method via a `try` block, though the specific exceptions caught are not shown in the snippet.\n\n3. **Recovery Strategy**  \n   - For missing dependencies (`ImportError`), the code fails fast by raising an exception, preventing further execution without the required package.  \n   - For collection existence, the code attempts to query existing collections and create the collection if it does not exist, thus recovering from a missing collection scenario automatically.  \n   - The snippet does not show explicit retries or fallback connection attempts beyond choosing between remote URL or local path.\n\n4. **Logging**  \n   - Informational logs are emitted upon successful connection to Qdrant, indicating whether the connection is remote (`qdrant",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:07.936713",
      "status": "summarized"
    },
    "vector_store.py:chunk_4": {
      "chunk_id": "vector_store.py:chunk_4",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "409ec576f26632d53186b0dd3a647eb4fd6144820ef7ea18ce9057234c1e4715",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a vector store management module that ensures the existence of a vector collection with specified distance metrics and provides an asynchronous method to batch upsert embedding points into the collection.\n\n2. **Technical Details**:  \n- Uses a mapping (`distance_map`) to translate human-readable distance metric strings (\"Euclidean\", \"Dot\") into internal enum values (`Distance.EUCLID`, `Distance.DOT`), defaulting to cosine distance if unspecified.  \n- Invokes `self.client.create_collection` with `VectorParams` specifying vector size and distance metric, indicating an abstraction over a vector database or search engine.  \n- Implements an asynchronous method `upsert_batch` to insert or update multiple embedding points in batches, supporting configurable batch sizes and retry logic.  \n- Uses structured logging (`logger.info`, `logger.error`) for operational visibility.  \n- Exception handling wraps collection creation to log and propagate errors.\n\n3. **Business Logic**:  \nEnables efficient storage and retrieval of vector embeddings, which are critical for applications like semantic search, recommendation systems, or AI-driven content matching. By managing collections and batch upserts, it supports scalable and reliable vector data management.\n\n4. **Dependencies**:  \n- Presumably depends on a vector database client library exposing `create_collection` and `VectorParams`.  \n- Uses an enum or class `Distance` for distance metrics.  \n- Utilizes Python's `async` features and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:16.663985",
      "status": "summarized"
    },
    "vector_store.py:chunk_6": {
      "chunk_id": "vector_store.py:chunk_6",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "8dfe76a0002fd0430934768e31ae1c254a2c053bc86b51c70f4b6c78f81726bc",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet performs batch upsertion of vector data points into a Qdrant vector search engine, converting application-specific point objects into Qdrant-compatible structures and handling the insertion in controlled batch sizes with retry logic.\n\n2. **Technical Details**:  \n- Uses batching to process a large list of points in chunks defined by `batch_size`.  \n- Each point is transformed into a `PointStruct` with a unique UUID, embedding vector, and a payload containing metadata and content fields.  \n- Implements a retry loop (`max_retries`) to handle transient failures during the upsert operation.  \n- Uses list comprehensions for efficient transformation of data points.\n\n3. **Business Logic**:  \nEnables scalable and reliable ingestion of vectorized data (e.g., text embeddings) into a vector database, supporting applications like semantic search, recommendation systems, or AI-driven content retrieval by maintaining an up-to-date vector store.\n\n4. **Dependencies**:  \n- `uuid` for generating unique identifiers.  \n- `PointStruct` likely from the Qdrant client SDK or a related vector database library.  \n- `self.client.upsert` indicates dependency on a Qdrant client instance for database operations.  \n- `logger` for logging informational messages.\n\n5. **Configuration**:  \n- `batch_size` controls the number of points processed per batch.  \n- `max_retries` defines how many times the code retries failed upsert attempts.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:22.911601",
      "status": "summarized"
    },
    "vector_store.py:chunk_8": {
      "chunk_id": "vector_store.py:chunk_8",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "7249ee94d4992668dc02fcbd494c4f929a426be76dc2a19f527292e5300727ff",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous batch upsert operation to a vector store, handling embedding data points with retry logic and logging. It aims to reliably insert or update multiple data points in batches while tracking success and failure metrics.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to perform non-blocking upsert operations.  \n- Implements batch processing by dividing data points into chunks (`batch_size`).  \n- Employs retry logic with exponential backoff (`await asyncio.sleep(1 * retry_count)`) to handle transient failures.  \n- Uses counters (`successful`, `failed`, `total_points`) to track operation outcomes.  \n- Logging at different levels (`debug`, `warning`, `error`, `info`) provides detailed operational insights.\n\n3. **Business Logic**:  \nThe code supports robust ingestion of vector embeddings (likely for semantic search or recommendation systems) by ensuring data integrity and reliability during bulk upsert operations. It helps maintain an up-to-date vector store that powers downstream AI or search functionalities.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous control flow and sleeping during retries.  \n- A logger instance (`logger`) for structured logging.  \n- The broader context likely includes a vector database or service client (not shown here) that performs the actual upsert.\n\n5. **Configuration**:  \n- `max_retries` controls the maximum number of retry attempts per batch.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:28.086914",
      "status": "summarized"
    },
    "vector_store.py:chunk_10": {
      "chunk_id": "vector_store.py:chunk_10",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "86a8ab904522231454862ce8a77162ac0cfa740d04ee07e81dc7f3c0496275db",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides functionality to upsert (insert or update) and search vector embeddings representing code chunks in a vector store, enabling similarity-based retrieval of code snippets.\n\n2. **Technical Details**:  \n- Uses an `EmbeddingPoint` data structure to encapsulate embedding vectors along with associated metadata and content.  \n- The `upsert` method asynchronously inserts or updates a single embedding by wrapping it into a batch operation (`upsert_batch`).  \n- The `search` method performs similarity search on stored embeddings using a query vector, with optional filtering by metadata and score thresholds.  \n- The search results include similarity scores and are limited by a configurable maximum number of results.\n\n3. **Business Logic**:  \nSolves the problem of efficiently finding similar code fragments based on semantic embeddings, which can be used for code intelligence tasks such as code search, recommendation, or duplication detection in software development workflows.\n\n4. **Dependencies**:  \n- An external vector database client (`self.client`) that supports upsert and search operations on vector collections.  \n- Data types like `EmbeddingPoint` and standard Python typing (`Dict`, `List`, `Optional`).  \n- Async programming constructs (`await`) indicating use of asynchronous I/O frameworks.\n\n5. **Configuration**:  \n- Uses `self.collection_name` to specify the target vector collection, likely configured elsewhere in the class or environment.  \n- Search parameters such as `limit` and `score_threshold` are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:36.551000",
      "status": "summarized"
    },
    "vector_store.py:chunk_12": {
      "chunk_id": "vector_store.py:chunk_12",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "9887e15f3c2d71a2fa41aa132854cbe995052295c821b5e25c0ed59074ccc128",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a vector store management module that interacts with a collection of vectorized data points, enabling search result processing, retrieval of collection metadata, and collection deletion.\n\n2. **Technical Details**:  \n- Uses list comprehension to transform search results (`results`) into a structured list of dictionaries containing chunk identifiers, content, summaries, scores, and additional metadata.  \n- Employs dictionary comprehensions to filter out specific keys (`chunk_id`, `content`, `summary`) from the payload to isolate other metadata fields.  \n- Implements exception handling around client calls to safely manage failures when accessing or modifying the vector collection.  \n- The `get_collection_info` method retrieves collection statistics such as point count, vector count, and status from the underlying client API.\n\n3. **Business Logic**:  \nThis code supports a business need for managing and querying a vector database or vector search engine, likely used in applications such as semantic search, document retrieval, or AI-powered content summarization. It enables efficient retrieval of relevant data chunks along with their metadata and provides administrative capabilities to inspect or delete collections.\n\n4. **Dependencies**:  \n- A client object (`self.client`) that interfaces with the vector database or vector search service (likely an SDK or API client).  \n- A logger instance (`logger`) for error logging.  \n- The code snippet does not explicitly show imports but implies dependencies on a vector search backend and logging framework.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:44.939600",
      "status": "summarized"
    },
    "vector_store.py:chunk_14": {
      "chunk_id": "vector_store.py:chunk_14",
      "file_path": "code-intelligence\\vector_store.py",
      "chunk_hash": "6d3684a00b45c0cad643b8b0fc6f833ba0ab69491884ca986d4e118ffce6cc0e",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet provides functionality to delete a collection from a Qdrant vector database and to perform a health check to verify if the Qdrant service is operational.\n\n2. **Technical Details**:  \n- Uses a client object (`self.client`) to interact with the Qdrant service.  \n- Implements exception handling around API calls to manage failures gracefully.  \n- Logging is used for both successful operations (warning level for deletion) and errors (error level for failures).  \n- The `health_check` method attempts to retrieve collections to confirm service availability.\n\n3. **Business Logic**:  \n- Enables maintenance operations on vector data collections, such as removing obsolete or unwanted collections.  \n- Provides a mechanism to monitor the health/status of the Qdrant vector store, which is critical for ensuring reliable vector search and storage services in applications like recommendation engines, semantic search, or AI-driven analytics.\n\n4. **Dependencies**:  \n- Qdrant client library (likely `qdrant-client` or similar) for interacting with the vector database.  \n- A logging framework (e.g., Python\u2019s built-in `logging` module) for recording operational events and errors.\n\n5. **Configuration**:  \n- The collection name (`self.collection_name`) is a key configuration parameter, presumably set elsewhere in the class or passed during initialization.  \n- Qdrant client connection details (host, port, API key) are likely configured outside this snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:49.900281",
      "status": "summarized"
    },
    "domain.py:chunk_0": {
      "chunk_id": "domain.py:chunk_0",
      "file_path": "features\\context_resolver\\domain.py",
      "chunk_hash": "b6386b939292f74a18488c00870a86db10702b57a3ebc94919152b508b4c0dea",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `ContextEnricher` class responsible for aggregating and enriching a base issue context with related issues, code snippets, logs, and metrics into a comprehensive `EnrichedContextModel` for enhanced analysis or display.\n\n2. **Technical Details**:  \n- Uses a static method `enrich_context` to transform and combine multiple input data sources into a single enriched domain model.  \n- Employs list comprehensions to map raw dictionaries into strongly-typed domain objects (`RelatedIssue`, `CodeContext`, `LogEntry`).  \n- Utilizes Python typing annotations for clarity and type safety.  \n- Leverages enums (`SourceType`, `SeverityLevel`) for standardized attribute values.  \n- Logging is set up but not explicitly used in the shown snippet.\n\n3. **Business Logic**:  \nThe code addresses the need to consolidate disparate contextual information related to an issue (e.g., bug or ticket) from various sources such as related issues, code snippets, and logs. This enriched context supports better decision-making, debugging, or automated analysis in issue tracking or incident management workflows.\n\n4. **Dependencies**:  \n- Internal modules: `.model` (defines domain models like `EnrichedContextModel`, `RelatedIssue`, etc.)  \n- Shared models from `shared.models` (defines `Context`, `SourceType`, `SeverityLevel`)  \n- Standard Python libraries: `typing` for type hints, `logging` for diagnostics.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:02:59.133855",
      "status": "summarized"
    },
    "domain.py:chunk_2": {
      "chunk_id": "domain.py:chunk_2",
      "file_path": "features\\context_resolver\\domain.py",
      "chunk_hash": "bedb67867c6f9284c74c61eb3585eb22b7fcecf05a3faf2724ee3c1c9c347c30",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code enriches an issue report object with detailed code snippets, logs, and metrics, and calculates the severity level of the issue based on priority and error rate metrics.\n\n2. **Technical Details**:  \n- Uses list comprehensions to transform raw dictionaries of code snippets and logs into structured objects (`CodeSnippet`, `LogEntry`).  \n- Implements a static method `calculate_severity` that applies conditional logic to determine the severity level (`SeverityLevel`) based on issue priority and error rate thresholds.  \n- Data structures involved include dictionaries for input data and custom classes/enums for structured output.\n\n3. **Business Logic**:  \nThe code supports automated issue triaging by enriching issue data with contextual information (code, logs, metrics) and assigning a severity level. This helps prioritize issues for faster resolution based on their criticality and observed error rates.\n\n4. **Dependencies**:  \n- Custom domain classes/enums such as `CodeSnippet`, `LogEntry`, and `SeverityLevel` (likely defined elsewhere in the codebase).  \n- Standard Python data types (`dict`, `list`).  \n- No explicit external libraries are shown in the snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or configuration files are referenced in this snippet.  \n- Severity thresholds (e.g., error_rate > 0.1) are hardcoded.\n\n6. **Error Handling**:  \n- Uses `.get()` with default values to",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:04.952190",
      "status": "summarized"
    },
    "Header.tsx:chunk_0": {
      "chunk_id": "Header.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Layout\\Header.tsx",
      "chunk_hash": "fce8a82e9612c6f3006a8c5ea37715b4c04f23f3cf7925a06b21b39becda99f9",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component renders the header section of a web application, dynamically displaying a title and description based on the currently active tab.\n\n2. **Technical Details**:  \n- Uses TypeScript with a typed `HeaderProps` interface to enforce that `activeTab` is of type `Tab`.  \n- Utilizes two `Record<Tab, string>` objects (`titles` and `descriptions`) to map tab keys to their respective display strings.  \n- Implements a simple presentational component pattern with JSX and Tailwind CSS classes for styling.  \n- Imports icons (`Activity`, `HelpCircle`) from the `lucide-react` icon library, though they are not shown used in the provided snippet.\n\n3. **Business Logic**:  \nThe component supports a multi-tab interface where each tab corresponds to a different feature or module of the application (e.g., AI Voice Assistant, LLM testing). It provides contextual information to users by showing relevant titles and descriptions, enhancing user navigation and understanding of the app\u2019s capabilities.\n\n4. **Dependencies**:  \n- `lucide-react`: For SVG icon components.  \n- Local type `Tab` imported from `../../App` which defines valid tab keys.  \n- Tailwind CSS classes for styling.\n\n5. **Configuration**:  \nNo environment variables or external configuration are referenced or required in this component.\n\n6. **Error Handling**:  \nNo explicit error handling is implemented. The use of TypeScript and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:12.472527",
      "status": "summarized"
    },
    "Header.tsx:chunk_2": {
      "chunk_id": "Header.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Layout\\Header.tsx",
      "chunk_hash": "903864929865ab5cfd8806876a9745db0f8a93bf86024488736cb4ba1ca4c5af",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React functional component snippet renders two interactive icon buttons within a header layout, likely part of a website or web application's top navigation bar.\n\n2. **Technical Details**:  \n- Uses JSX to define UI elements.  \n- Each button includes Tailwind CSS utility classes for padding, color, hover effects, rounded corners, and smooth color transitions.  \n- Icons (`Activity` and `HelpCircle`) are rendered as React components with fixed width and height.  \n- The snippet is part of a larger `Header` component that returns a header HTML element.\n\n3. **Business Logic**:  \nProvides users with quick access to activity-related features and help/support options, enhancing user navigation and support accessibility within the application.\n\n4. **Dependencies**:  \n- React for component structure.  \n- Tailwind CSS for styling.  \n- Icon components (`Activity`, `HelpCircle`) likely imported from an icon library such as `react-feather` or similar.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \nNo error handling or exception management is present or required in this UI rendering code.\n\n7. **API/Interface**:  \n- Exports a default React component named `Header`.  \n- No props or external API interactions are shown in this snippet.\n\n8. **Performance Notes**:  \n- Lightweight UI elements with minimal rendering overhead.  \n- Use of Tailwind CSS",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:19.058491",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_0": {
      "chunk_id": "azure_ai_manager.py:chunk_0",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "eb60070a157108651115287bee43eac71f5e77e58b0673b356eeae87ced6d707",
      "chunk_index": 0,
      "summary": "Summary:\n\n1. **Purpose**:  \n   This module defines a unified manager class, `AzureAIManager`, that coordinates multiple Azure AI services such as speech-to-text, translation, and language model deployments. It provides a high-level interface to orchestrate complex AI workflows involving these services.\n\n2. **Technical Details**:  \n   - Uses Python `Enum` to define supported AI workflow types for clarity and type safety.  \n   - Aggregates service clients (`AzureSpeechService`, `AzureTranslationService`, `AzureModelDeploymentService`) to enable multi-step AI workflows.  \n   - Likely employs a facade or coordinator design pattern to abstract and unify interactions with disparate Azure AI services.  \n   - Uses type hints (`Optional`, `Dict`, `Any`, `List`) for better code clarity and static analysis.  \n   - Logging is integrated for monitoring and debugging.\n\n3. **Business Logic**:  \n   Enables business applications to implement advanced AI-driven features such as voice assistants, meeting transcription with diarization and summarization, multilingual chat, and audio content analysis by combining Azure AI capabilities seamlessly. This supports enhanced user experiences and productivity tools.\n\n4. **Dependencies**:  \n   - Azure AI service wrappers: `AzureSpeechService`, `AzureTranslationService`, `AzureModelDeploymentService` (custom modules).  \n   - Configuration validator: `azure_config_validator`.  \n   - Application settings from `shared.config.settings`.  \n   - Standard Python libraries: `logging`, `enum`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:25.802551",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_2": {
      "chunk_id": "azure_ai_manager.py:chunk_2",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "0d94ba1d0303ee677a8470c2a7906da2a09b9a82293c4433dee457993e7f0f1a",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**  \nThis Python class manages and coordinates multiple Azure AI services\u2014including speech, translation, and model deployment\u2014providing a unified interface to initialize, validate, and report on their configuration status for AI workflows.\n\n2. **Technical Details**  \n- The class initializes three service objects: `AzureSpeechService`, `AzureTranslationService`, and `AzureModelDeploymentService`.  \n- It uses an external `azure_config_validator` module to validate environment configurations and log validation results.  \n- Logging is used extensively to report the availability status of each service upon initialization.  \n- Methods return dictionaries with detailed configuration status and missing environment variables, facilitating programmatic checks.\n\n3. **Business Logic**  \nThe code addresses the need for centralized management of Azure AI service endpoints and model deployments, ensuring that all required services are properly configured and available before running AI workflows. This reduces runtime errors and simplifies operational monitoring in AI-driven applications.\n\n4. **Dependencies**  \n- Azure AI service wrappers: `AzureSpeechService`, `AzureTranslationService`, `AzureModelDeploymentService` (likely custom or SDK-based classes).  \n- `azure_config_validator`: an external module responsible for validating environment variables and configurations.  \n- `logger`: a logging utility for info-level messages.\n\n5. **Configuration**  \n- Relies on environment variables (likely stored in a `.env` file) for service credentials and endpoints.  \n- Uses `azure_config_validator` to check and report on the completeness and correctness",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:34.161294",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_4": {
      "chunk_id": "azure_ai_manager.py:chunk_4",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "9cd10b7dd66042652bb4dc0c4295992d14918c4978303f5074c25572d7e8d45a",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis Python code snippet is part of an Azure AI management module that provides status information about configured Azure AI services and implements an asynchronous voice assistant workflow integrating speech-to-text (STT), translation, and further backend orchestration.\n\n2. **Technical Details**  \n- The `get_service_status` method aggregates service availability and configuration details into a nested dictionary structure, pulling status from internal service wrappers (`speech`, `translation`, `models`) and configuration data.  \n- The `voice_assistant_flow` method is an asynchronous coroutine designed to process audio input encoded in base64, perform speech recognition (potentially with diarization), translate the recognized text to English, and prepare the data for downstream processing.  \n- Uses type hints (`Dict[str, Any]`) for clarity and maintainability.  \n- Likely employs an object-oriented design pattern where `self.speech`, `self.translation`, and `self.models` represent encapsulated service clients or adapters.\n\n3. **Business Logic**  \n- Enables monitoring and health-checking of Azure AI services used in the application, ensuring that speech, translation, and model deployment services are operational and correctly configured.  \n- Implements a voice assistant pipeline that supports multi-lingual audio input, converting speech to text and translating it to English, facilitating natural language understanding and interaction in a multilingual context.\n\n4. **Dependencies**  \n- Azure AI services (Speech, Translation, OpenAI models) accessed via SDKs or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:38.261105",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_6": {
      "chunk_id": "azure_ai_manager.py:chunk_6",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "0f1345ffe27764c41619de6d0fe3426187f75a28d8ff89e5e2dd875f84d6ffcb",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method processes Base64-encoded audio input to perform speech-to-text transcription, optionally using an enhanced GPT-4o model, and returns the transcribed text along with detected language and metadata.\n\n2. **Technical Details**:  \n- Uses conditional logic to select between two transcription approaches: a standard Azure Speech Service or an enhanced GPT-4o-based transcription (currently a placeholder).  \n- Employs asynchronous calls (`await`) for non-blocking I/O during transcription.  \n- Logs key steps for observability.  \n- Returns a dictionary containing original text, translated text, language, and metadata (implied by docstring).  \n- The enhanced transcription path requires audio to be saved to a file (not yet implemented).  \n\n3. **Business Logic**:  \nEnables voice assistant functionality by converting spoken audio into text, supporting multilingual input detection and potentially higher accuracy transcription via GPT-4o, improving user interaction quality in voice-driven applications.\n\n4. **Dependencies**:  \n- Azure Speech Service SDK or API for standard speech-to-text.  \n- A custom `self.models` component to check availability of GPT-4o transcription.  \n- A `self.speech` service object responsible for the actual transcription calls.  \n- Python `logging` for logging.  \n\n5. **Configuration**:  \n- The choice to use enhanced transcription is controlled by the `use_enhanced_transcription` boolean parameter.  \n- Audio format is",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:45.449101",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_8": {
      "chunk_id": "azure_ai_manager.py:chunk_8",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "60f5eebbb58f1704dc56b1afbef93a72b53b365d97559a35a1d20e6519f23712",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an asynchronous flow that processes audio input by detecting its language, optionally translating the transcribed text to English if needed, and returning a structured result containing the original and translated text along with metadata.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running I/O operations such as translation.  \n- Conditional logic checks if translation is necessary based on detected language.  \n- Constructs a dictionary (`result`) encapsulating transcription and translation results and metadata.  \n- Logging is used extensively for tracing flow progress and outcomes.  \n- Exception handling wraps the entire flow to catch and log errors before re-raising.\n\n3. **Business Logic**:  \nEnables a voice assistant or transcription service to support multilingual audio inputs by detecting the spoken language and translating non-English content into English, thereby normalizing input for downstream processing or user consumption.\n\n4. **Dependencies**:  \n- A `translation` service object with methods `is_available()` and `translate_to_english()` (likely an Azure Cognitive Services or similar AI translation API wrapper).  \n- A logging utility (`logger`) for info and error messages.  \n- Possibly an external speech-to-text or transcription service (implied by `transcription_method` values like `\"azure_speech\"` or `\"gpt4o\"`).\n\n5. **Configuration**:  \n- The availability of the translation service is dynamically checked (`self.translation.is_available()`).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:51.466583",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_10": {
      "chunk_id": "azure_ai_manager.py:chunk_10",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "6cdb4564333986960bb1abbd04d29995494c50871a8d171f08d7d346ca0690f6",
      "chunk_index": 10,
      "summary": "**Summary of Error Handling in `azure_ai_manager.py` Meeting Transcription Code**\n\n1. **Purpose**  \n   The error handling is designed to manage failures during the meeting transcription process that involves speaker diarization using Azure AI models. It specifically guards against issues such as unavailable model deployments or runtime errors during asynchronous transcription calls.\n\n2. **Exception Types**  \n   - The code explicitly raises a `ValueError` if the required Azure model deployments are not available (`self.models.is_available()` returns `False`).  \n   - It broadly catches all exceptions (`except Exception as e`) during the transcription call, encompassing network errors, API failures, or unexpected runtime exceptions.\n\n3. **Recovery Strategy**  \n   - There is no retry or recovery mechanism implemented. Upon encountering an error, the exception is logged and then re-raised, effectively propagating the error to the caller for handling at a higher level.\n\n4. **Logging**  \n   - Informational logs (`logger.info`) track the start of the transcription flow, successful completion, number of speakers identified, and transcription duration.  \n   - Errors are logged with `logger.error`, including the exception message, providing visibility into failures for monitoring and troubleshooting.\n\n5. **User Impact**  \n   - If an error occurs (e.g., models unavailable or transcription failure), the process raises an exception that likely results in a failure response to the end user or calling service.  \n   - No partial results or fallback outputs are returned, so the user will",
      "embedding_id": null,
      "created_at": "2025-10-22T19:03:55.928161",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_12": {
      "chunk_id": "azure_ai_manager.py:chunk_12",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "7a433c7c63efcae89b056e7c268f0b7e07554372b0d29796c41f491cd2bd65bb",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method implements a multilingual chat flow that translates a user's message to English, processes it through an AI model router, and optionally translates the AI response back to the user's language, enabling seamless multilingual conversational AI interactions.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) for non-blocking I/O operations.  \n- Employs a translation service to detect and translate messages to English.  \n- Utilizes a model router pattern to select and query appropriate AI models for generating responses.  \n- Returns a dictionary containing the original message, detected language, English-translated message, AI response, and optionally the translated response.  \n- Logging is used for tracing flow and language detection details.\n\n3. **Business Logic**:  \nEnables a global user base to interact with AI chatbots in their native languages without requiring them to speak English, thus improving user experience and accessibility across different languages.\n\n4. **Dependencies**:  \n- `self.translation`: A translation service/module with methods like `is_available()` and `translate_to_english()`.  \n- `self.models`: An AI model router service/module with `is_available()` and presumably methods to get AI responses.  \n- `logger`: For logging informational messages.  \n- Likely depends on Azure AI services or similar for translation and AI model inference (inferred from file path and naming).\n\n5. **Configuration**:  \n- Language detection and translation availability are dynamically",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:02.394137",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_14": {
      "chunk_id": "azure_ai_manager.py:chunk_14",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "6efe246799601b62b92016b505ccf52af87ced2354cb66a7a0a832b3dd1c3904",
      "chunk_index": 14,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code snippet primarily handles the scenario where the required Azure Model Deployments for chat functionality are not configured or available. It ensures that the chat operation only proceeds if the model router or Azure deployments are properly set up. Additionally, it manages translation of responses when the target language differs from English.\n\n2. **Exception Types**:  \n   - Explicitly raises a `ValueError` if Azure Model Deployments are missing (`raise ValueError(\"Azure Model Deployments required for chat\")`).  \n   - No other exception types are caught or handled within this snippet.\n\n3. **Recovery Strategy**:  \n   - There is no retry or recovery mechanism shown in this snippet.  \n   - The code fails fast by raising an exception when prerequisites are not met, preventing further execution.  \n   - Translation is conditionally applied only if available, avoiding errors if translation services are not ready.\n\n4. **Logging**:  \n   - Informational logs are present to trace key steps: using the model router and translating the response.  \n   - No explicit error logging is shown for the raised exception or other failures in this snippet.\n\n5. **User Impact**:  \n   - If Azure Model Deployments are missing, the operation will raise an error, likely causing the chat response to fail and potentially surface an error to the user or calling service.  \n   - If translation is unavailable or not needed, the response defaults to English, which may affect",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:07.126726",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_16": {
      "chunk_id": "azure_ai_manager.py:chunk_16",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "bb5d3a9df863671ceb369a13d7c6623ea34850a7ff281a119d583353f47cfd6e",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis Python code defines an asynchronous method `test_all_services` within an Azure AI manager class that tests the availability, configuration, and deployment status of various Azure AI services (such as speech and translation) based on environment configurations.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O operations without blocking.  \n- Retrieves configuration status via a synchronous method `get_configuration_status()`.  \n- Checks service availability through `is_available()` methods on service-specific objects (`self.speech`, `self.translation`, `self.models`).  \n- Gathers deployment information asynchronously if the models service is available.  \n- Constructs and returns a nested dictionary summarizing configuration and health status of each Azure AI service.  \n- Uses structured logging (`logger.info`, `logger.error`) for operational visibility.\n\n3. **Business Logic**:  \nThe method provides a consolidated health check and configuration audit for multiple Azure AI services used by the application. This helps ensure that all AI capabilities (speech recognition, translation, model deployments) are correctly configured and operational, which is critical for delivering reliable multilingual AI features.\n\n4. **Dependencies**:  \n- Azure AI services (speech, translation, models) accessed via custom service wrappers (`self.speech`, `self.translation`, `self.models`).  \n- Logging framework (`logger`) for recording operational events.  \n- Environment variables or configuration files (implied by usage of `.env` in docstring",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:14.154779",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_18": {
      "chunk_id": "azure_ai_manager.py:chunk_18",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "b1f138c3efb7c987a9994dbaaf3fc46ab0b5d61e8db87931249314f361ab45b3",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet constructs a status report summarizing the configuration and availability of various Azure AI services (speech, translation, and OpenAI model deployments) and determines which AI-driven workflows are currently available based on these services.\n\n2. **Technical Details**:  \n- Uses a dictionary (`results`) to aggregate service status and workflow availability.  \n- Checks availability via method calls like `self.speech.is_available()`, `self.translation.is_available()`, and `self.models.is_available()`.  \n- Conditionally appends workflow names to a list based on service availability.  \n- Logs the outcome using structured logging calls (`logger.info`).  \n- The design follows a simple procedural pattern within a class context, likely part of a service manager or status checker.\n\n3. **Business Logic**:  \n- Determines which AI-powered workflows (e.g., voice assistant, meeting transcription, multilingual chat) can be activated based on the current configuration and availability of Azure AI services.  \n- Enables dynamic feature gating to ensure only supported workflows are exposed to end-users or downstream systems, preventing failures due to missing configurations or unavailable services.\n\n4. **Dependencies**:  \n- Azure AI services for speech, translation, and OpenAI models (implied by `self.speech`, `self.translation`, `self.models`).  \n- A configuration status dictionary (`config_status`) that holds endpoint URLs and boolean flags indicating if services are configured.  \n- A logging framework (`logger`) for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:22.760595",
      "status": "summarized"
    },
    "azure_ai_manager.py:chunk_20": {
      "chunk_id": "azure_ai_manager.py:chunk_20",
      "file_path": "shared\\azure_services\\azure_ai_manager.py",
      "chunk_hash": "2d0347e5b1f4d7d4a738dc5f958dab27a9581c8be8d3bb51a5bb793ad98f7203",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an Azure AI Manager module responsible for managing and validating Azure OpenAI service configurations by checking environment variables and returning their status.\n\n2. **Technical Details**:  \n- Uses a validator object (`azure_config_validator`) to encapsulate configuration validation logic.  \n- Returns dictionaries containing configuration status or missing environment variables.  \n- Implements a singleton-like global instance (`azure_ai_manager`) for centralized access.  \n- Uses logging to report configuration status.\n\n3. **Business Logic**:  \nEnsures that the Azure OpenAI service is properly configured by verifying required environment variables, which is critical for enabling AI-powered features in the application without runtime failures due to misconfiguration.\n\n4. **Dependencies**:  \n- `azure_config_validator`: A module or object responsible for validating Azure-related environment variables.  \n- `logger`: A logging utility for informational output.  \n- Likely depends on environment variables loaded from a `.env` file or system environment.\n\n5. **Configuration**:  \n- Relies on environment variables related to Azure OpenAI configuration.  \n- Uses a `.env` file or system environment to store these variables.  \n- The validator checks and optionally updates missing variables (`update_file` flag).\n\n6. **Error Handling**:  \n- No explicit exception handling shown in this snippet.  \n- Presumably, the validator internally handles missing or invalid environment variables and returns structured status information.\n\n7. **API/Interface**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:30.599116",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_0": {
      "chunk_id": "model_deployment_service.py:chunk_0",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "6ffed1cae8716a34f08b3203c545fda5a12ffde5bc2ecbd046ed0bfc7107aa33",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module defines a service class that integrates with Azure OpenAI Model Deployments, enabling advanced AI capabilities such as transcription with speaker diarization, intelligent model routing, and lightweight audio processing.\n\n2. **Technical Details**  \n- Implements an `AzureModelDeploymentService` class encapsulating Azure OpenAI model deployment interactions.  \n- Uses asynchronous Azure OpenAI client (`AsyncAzureOpenAI`) for non-blocking API calls (implied by import).  \n- Configuration-driven initialization pattern, reading endpoint, API keys, and version from centralized settings.  \n- Designed to support multiple specialized AI models (e.g., GPT-4o Transcribe, model-router, gpt-audio-mini) likely via method calls (not shown in snippet).  \n- Uses Python typing hints for method signatures and parameters to improve code clarity and maintainability.\n\n3. **Business Logic**  \nEnables enterprise applications to leverage Azure\u2019s AI models for enhanced audio transcription with speaker diarization, intelligent routing among GPT models for optimized responses, and efficient audio processing. This supports business scenarios requiring accurate speech-to-text conversion, context-aware AI interactions, and scalable audio analysis.\n\n4. **Dependencies**  \n- `openai` Python SDK, specifically `AsyncAzureOpenAI` for Azure OpenAI service integration.  \n- `shared.config.settings` module for centralized configuration management.  \n- Standard Python libraries: `logging`, `typing` for structured logging and type annotations.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:36.213013",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_2": {
      "chunk_id": "model_deployment_service.py:chunk_2",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "94e26ebff9556097c27ec4fcfc8c3772020abbc5a01aaf4b9a173c3bb2a6174e",
      "chunk_index": 2,
      "summary": "**Summary of `shared\\azure_services\\model_deployment_service.py` snippet**\n\n1. **Purpose**  \nThis code initializes configuration and client setup for interacting with Azure OpenAI model deployments, enabling asynchronous calls to various AI models hosted on Azure.\n\n2. **Technical Details**  \n- Uses Python class attributes to store deployment names and API versions with fallback defaults.  \n- Conditional initialization of an asynchronous Azure OpenAI client (`AsyncAzureOpenAI`) based on the presence of endpoint and API key credentials.  \n- Logging is used to confirm successful initialization and configuration details.  \n- Uses optional typing (`Optional[AsyncAzureOpenAI]`) to handle the presence or absence of the client instance.\n\n3. **Business Logic**  \nSupports dynamic selection and routing of AI models deployed on Azure for tasks such as chat, transcription, and audio processing. This enables flexible integration of AI capabilities into business applications, adapting to different deployment environments or model versions without code changes.\n\n4. **Dependencies**  \n- `AsyncAzureOpenAI`: An asynchronous client wrapper for Azure OpenAI service (likely from an Azure SDK or custom wrapper).  \n- `settings`: Configuration object or module providing environment-specific variables.  \n- `logger`: Logging utility for operational visibility.\n\n5. **Configuration**  \n- Environment variables or config settings accessed via `settings`, including:  \n  - `azure_chat_model`, `azure_openai_deployment_name` (model deployment names)  \n  - `azure_chat_api_version` (API",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:42.764120",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_4": {
      "chunk_id": "model_deployment_service.py:chunk_4",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "337c0bce3db73ece3f3b63bc4e6ee1dde6d487ee8a6813504d532df9fbd1c046",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a service class responsible for managing Azure OpenAI model deployments, specifically enabling transcription of audio files with speaker diarization using the GPT-4o model.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for non-blocking transcription operations.  \n- Employs structured logging to report the status of model deployment initialization and configuration.  \n- Checks for the presence of Azure OpenAI credentials before initializing the client.  \n- The transcription method supports optional language hints and returns a dictionary with transcription results.  \n- Exception handling is used to catch and log initialization failures.\n\n3. **Business Logic**:  \nEnables automated transcription of audio content with speaker diarization, which is valuable for businesses needing accurate, multi-speaker transcription services (e.g., meetings, interviews) powered by Azure OpenAI models.\n\n4. **Dependencies**:  \n- Azure OpenAI service (implied by environment variables and client usage).  \n- Python logging module for logging.  \n- Asyncio or similar async framework for asynchronous method execution.  \n- Possibly other internal modules or SDKs for Azure OpenAI client interaction (not shown in snippet).\n\n5. **Configuration**:  \n- Requires environment variables: `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_API_KEY` for authentication and service endpoint configuration.  \n- Model deployment names and API versions are configured as instance variables (e.g., `self.chat_model`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:48.356451",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_7": {
      "chunk_id": "model_deployment_service.py:chunk_7",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "49d280ed3d9070f3618cecb67ad9386864d61e124c0c847d2a6fda118a753fd3",
      "chunk_index": 7,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a service that processes transcription segments, aggregates speaker information, logs transcription metadata, and provides an asynchronous chat completion method for Azure-based chat models.\n\n2. **Technical Details**:  \n- The code iterates over transcription segments, extracting start time, end time, text, and speaker attributes.  \n- It uses a dictionary (`result`) to accumulate segments and track unique speakers in a list.  \n- Logging is used extensively to provide detailed information about the transcription process, including duration, language, number of speakers, and segment count.  \n- The `chat_completion` method is defined as an asynchronous function that accepts a list of message dictionaries and parameters like temperature, max tokens, and model name, designed to interface with Azure chat models.  \n- Exception handling is implemented with a broad `try-except` block to catch and log any errors during transcription.\n\n3. **Business Logic**:  \nThe code supports transcription and conversational AI capabilities, enabling applications to convert audio into structured text with speaker diarization and to generate chat completions. This facilitates business use cases such as meeting transcription, customer service automation, and conversational agents.\n\n4. **Dependencies**:  \n- Likely depends on Azure Cognitive Services SDKs for speech-to-text and chat completion (not explicitly shown in snippet).  \n- Uses Python standard libraries such as `logging`.  \n- Uses asynchronous programming constructs (`async def`) indicating use of `asyncio` or compatible",
      "embedding_id": null,
      "created_at": "2025-10-22T19:04:58.994663",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_9": {
      "chunk_id": "model_deployment_service.py:chunk_9",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "a8b9cb8b620079ad17b62718453167788ec6b847e4975c4a94d5fb8e027e6088",
      "chunk_index": 9,
      "summary": "**Summary of Error Handling in `model_deployment_service.py`**\n\n1. **Purpose**:  \n   The code snippet primarily handles the scenario where the Azure Model Deployment service is not available. It ensures that attempts to invoke the service do not proceed if the service is offline or unreachable.\n\n2. **Exception Types**:  \n   - Explicitly raises a `ValueError` with the message `\"Azure Model Deployment service not available\"` when the service availability check fails (`self.is_available()` returns `False`).  \n   - No other exceptions are explicitly caught in the provided snippet (the `try` block is incomplete, so further exception handling may exist beyond the snippet).\n\n3. **Recovery Strategy**:  \n   - There is no retry or recovery mechanism shown in the snippet.  \n   - The code fails fast by raising an exception if the service is unavailable, preventing further execution.\n\n4. **Logging**:  \n   - Uses `logger.info` to log key request details such as the model used, number of messages, temperature, and max tokens if specified.  \n   - Logs message details at a debug level (though the snippet cuts off before showing the full debug logging).  \n   - No explicit error logging is shown in the snippet, but the structured logging of request parameters aids in monitoring and troubleshooting.\n\n5. **User Impact**:  \n   - If the Azure Model Deployment service is unavailable, the user request will fail immediately with a `ValueError`.  \n   - This likely results",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:06.402737",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_11": {
      "chunk_id": "model_deployment_service.py:chunk_11",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "7a3df6d58cd5e370d709948bdeb87c368abb49b618d3340c542cf1ab0ea76252",
      "chunk_index": 11,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an asynchronous service method that interacts with an Azure-hosted chat completion model to generate conversational AI responses based on input messages. It logs detailed information about the request and response, and provides a legacy method for routing chat requests through a model-router deployment.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running network calls without blocking.  \n- Interacts with an Azure OpenAI client (`self.client.chat.completions.create`) to request chat completions from a specified model deployment.  \n- Accepts a list of message dictionaries, each containing roles and content, and sends them as input to the model.  \n- Logs detailed info including message previews, model used, response length, and a snippet of the response.  \n- Implements exception handling to catch and log any errors during the chat completion call, then re-raises the exception.  \n- Contains a legacy method `chat_with_model_router` for routing requests through a model-router deployment, indicating a design evolution towards more flexible model routing.\n\n3. **Business Logic**  \nEnables integration of conversational AI capabilities into business applications by providing a reusable service layer that abstracts calls to Azure OpenAI chat models. This supports use cases such as customer support bots, virtual assistants, or any scenario requiring natural language understanding and generation.\n\n4. **Dependencies**  \n- Azure OpenAI Python SDK or a similar Azure client library for chat completions.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:13.602849",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_13": {
      "chunk_id": "model_deployment_service.py:chunk_13",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "8ccf8faaa4782bc22bb5953d89258d580f0e9d07e9e996e88988402765f58d60",
      "chunk_index": 13,
      "summary": "**Summary of Error Handling in `process_audio_mini` Method**\n\n1. **Purpose**:  \n   The error handling in this code segment is designed to manage issues related to the availability of the Azure Model Deployment service and potential failures during audio processing tasks such as transcription or translation. It ensures that the service is ready before processing and attempts to handle runtime errors during file handling and task execution.\n\n2. **Exception Types**:  \n   - Explicitly raises a `ValueError` if the Azure Model Deployment service is not available (`if not self.is_available()` check).  \n   - The provided snippet does not show any `except` blocks, so no specific exceptions are caught within the shown code. However, the presence of a `try` block suggests that exceptions during file I/O or processing might be caught in the omitted part of the code.\n\n3. **Recovery Strategy**:  \n   - Currently, the code raises an immediate exception if the service is unavailable, preventing further processing.  \n   - No retry mechanism or alternative recovery strategy is visible in the snippet.  \n   - The `try` block indicates an intention to catch exceptions during processing, but the recovery logic is not shown.\n\n4. **Logging**:  \n   - Uses `logger.info` to log the start of audio processing and the task type, which aids in monitoring normal operation flow.  \n   - No explicit error logging is shown in the snippet, but it is likely present in the omitted exception handling code.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:21.222163",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_15": {
      "chunk_id": "model_deployment_service.py:chunk_15",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "58784870fa80c037e22fbae6f33fdc30797aee1b4b1a99d1cbcffce5c9955630",
      "chunk_index": 15,
      "summary": "**Summary of Error Handling in `model_deployment_service.py`**\n\n1. **Purpose**  \n   The error handling code is designed to catch and manage exceptions arising during asynchronous audio processing tasks, specifically when creating audio transcriptions or translations via an Azure-based client. It ensures that unexpected issues during API calls or task validation do not cause silent failures.\n\n2. **Exception Types**  \n   - The code uses a broad `except Exception as e` clause, which means it catches all exceptions derived from Python\u2019s base `Exception` class.  \n   - This includes network errors, API errors, invalid task errors (e.g., when `task` is neither `\"transcribe\"` nor `\"translate\"`), and any runtime exceptions during the async call or response handling.\n\n3. **Recovery Strategy**  \n   - There is no explicit recovery or retry mechanism implemented.  \n   - Upon catching an exception, the error is logged, and then the exception is re-raised to propagate the failure up the call stack. This implies that recovery or retries, if any, must be handled by the caller or higher-level logic.\n\n4. **Logging**  \n   - Errors are logged with `logger.error` including the exception message, prefixed with a clear failure indicator (`\u274c Audio processing error:`).  \n   - Successful completions are logged with `logger.info` including a success indicator (`\u2705 Audio processing complete`) and metadata such as the length of the result text.  \n   - This logging strategy supports",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:29.694129",
      "status": "summarized"
    },
    "model_deployment_service.py:chunk_17": {
      "chunk_id": "model_deployment_service.py:chunk_17",
      "file_path": "shared\\azure_services\\model_deployment_service.py",
      "chunk_hash": "21075d8ef1b6196f4e654b2936663a8a2fbb560a360654f597d333c7012b5d86",
      "chunk_index": 17,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a configuration dictionary within an Azure model deployment service that maps various AI model deployments to their respective capabilities and endpoint URLs. It facilitates interaction with different Azure OpenAI service deployments for tasks such as chat completions, transcription, and intelligent routing.\n\n2. **Technical Details**:  \n- Uses a nested dictionary data structure to organize deployment configurations by model names (e.g., \"chat\", \"gpt4o_transcribe\").  \n- Each deployment entry contains keys like `name`, `capabilities` (a list of supported features), and optionally an `url` for API calls.  \n- The URL for the chat model is dynamically constructed using instance variables (`self.endpoint`, `self.chat_model`, `self.chat_api_version`).  \n- The code snippet ends with the instantiation of a singleton-like global instance `azure_model_deployment` of the `AzureModelDeploymentService` class.\n\n3. **Business Logic**:  \nEnables a unified interface to manage and route requests to multiple Azure OpenAI model deployments, supporting diverse AI capabilities such as chat-based completions, transcription with diarization, and multi-model intelligent routing. This abstraction simplifies integration of AI services into business applications requiring natural language processing and audio transcription.\n\n4. **Dependencies**:  \n- Azure OpenAI service endpoints (implied by URL structure).  \n- Likely depends on other parts of the `AzureModelDeploymentService` class (not shown) for authentication,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:36.626379",
      "status": "summarized"
    },
    "together_provider.py:chunk_0": {
      "chunk_id": "together_provider.py:chunk_0",
      "file_path": "shared\\llm_providers\\together_provider.py",
      "chunk_hash": "df6e654e7dd18f2bc57a58453f4c6e52a1eff670b22f21603ec8b27a22942c4a",
      "chunk_index": 0,
      "summary": "**Summary of `shared/llm_providers/together_provider.py`**\n\n---\n\n1. **Purpose**  \nThis module implements a provider class `TogetherAIProvider` that integrates with the Together AI large language model (LLM) service, enabling the application to interact with Together's LLM APIs for natural language processing tasks.\n\n2. **Technical Details**  \n- The class inherits from a base class `BaseLLMProvider`, suggesting a polymorphic design pattern for interchangeable LLM providers.  \n- It encapsulates the Together AI client initialization, relying on environment variables for authentication.  \n- Uses Python typing hints for clarity (`Optional[str]`, `Any`).  \n- The client initialization method `_initialize_client` sets environment variables dynamically and instantiates the Together client.  \n- Logging is integrated for observability using a shared logger instance.\n\n3. **Business Logic**  \n- Provides a standardized interface to access Together AI's LLM capabilities, abstracting away direct API calls and authentication details.  \n- Supports configurable model selection, enabling business flexibility to switch or upgrade LLM models without code changes.  \n- Ensures secure API key management by reading from environment variables or constructor parameters.\n\n4. **Dependencies**  \n- External Python package: `together` (Together AI SDK/client).  \n- Standard libraries: `os` (environment variables), `json`, `time`.  \n- Internal modules: `BaseLLMProvider` (base class), `shared.logger` (logging utility).\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:43.934049",
      "status": "summarized"
    },
    "together_provider.py:chunk_2": {
      "chunk_id": "together_provider.py:chunk_2",
      "file_path": "shared\\llm_providers\\together_provider.py",
      "chunk_hash": "e78d821ae46c0410cd8ca8fb713fd8a60ef305a0cc3e253f360412bdc4a26b11",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a client wrapper for the Together AI language model provider. It initializes the Together AI client, checks its availability, and implements an asynchronous method to request chat completions from the model.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def chat_completion`) to handle potentially long-running API calls without blocking.  \n- Accepts a list of message dictionaries (`List[Dict[str, str]]`) representing chat history, extracting the latest user prompt for logging.  \n- Implements structured logging with contextual metadata (provider name, model, status, errors).  \n- Uses a simple boolean check (`self.client is not None`) to determine client readiness.  \n- Measures request start time (likely for latency tracking, though the snippet cuts off before usage).  \n\n3. **Business Logic**:  \nEnables integration with Together AI\u2019s language model to generate conversational AI responses, supporting features like temperature tuning and token limits. This facilitates building chatbots or AI assistants that rely on Together AI\u2019s capabilities.\n\n4. **Dependencies**:  \n- A `logger` module/object for structured logging (likely custom or third-party).  \n- Together AI client SDK or API (implied by `self.client` initialization, not shown here).  \n- Python standard libraries: `time` for timing, `typing` for type hints (`List`, `Dict`, `Optional`).  \n\n5. **Configuration**:  \n- Model identifier",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:48.973474",
      "status": "summarized"
    },
    "together_provider.py:chunk_4": {
      "chunk_id": "together_provider.py:chunk_4",
      "file_path": "shared\\llm_providers\\together_provider.py",
      "chunk_hash": "041d488eb937487f4c2f87501c5d4f4c112b027ea096788442ea24014cae577a",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet interacts with the Together AI language model API to generate chat completions based on input messages, handling both streaming and non-streaming responses while logging performance and usage metrics.\n\n2. **Technical Details**:  \n- Uses a client object (`self.client.chat.completions.create`) to call the Together AI chat completion endpoint.  \n- Supports parameters such as `model`, `messages`, `temperature`, `max_tokens`, and `stream` to customize the request.  \n- Measures request duration in milliseconds using `time.time()`.  \n- Extracts the generated text from the first choice in the response (`response.choices[0].message.content`).  \n- Logs detailed response information including provider name, response content, duration, and token usage if available.  \n- Handles streaming responses by returning the response object immediately.  \n- Uses a try-except block to catch all exceptions, log errors, and return `None` on failure.\n\n3. **Business Logic**:  \nEnables integration with Together AI\u2019s chat completion service to provide AI-powered conversational capabilities, supporting both synchronous and streaming modes. This facilitates building chatbots, virtual assistants, or other NLP-driven applications requiring dynamic text generation.\n\n4. **Dependencies**:  \n- Together AI SDK or client library (implied by `self.client.chat.completions.create`).  \n- `time` module for timing.  \n- A `logger` module or object with a `log_llm",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:55.279673",
      "status": "summarized"
    },
    "together_provider.py:chunk_6": {
      "chunk_id": "together_provider.py:chunk_6",
      "file_path": "shared\\llm_providers\\together_provider.py",
      "chunk_hash": "9d02135cf3f9eb020d5c0fc024b0d6bc2277a2fbc2bec24948794cfc75c688aa",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method sends a code snippet along with contextual information to an AI chat completion service (Together AI) to obtain a detailed, structured analysis of the code, including root causes of issues, affected components, suggested fixes, and corrected code samples.\n\n2. **Technical Details**:  \n- Constructs a system prompt defining the AI's role as an expert code analyst.  \n- Formats a user message embedding the task, context, and code snippet, requesting a JSON-formatted response with specific fields.  \n- Uses an asynchronous call (`await self.chat_completion`) to interact with the AI service, passing a message list with system and user roles.  \n- Parses the AI response from JSON; if parsing fails, logs an error and returns the raw response wrapped in a dictionary.  \n- Returns `None` if no response is received.  \n- Uses Python typing hints (`Optional[Dict[str, Any]]`) for clarity.\n\n3. **Business Logic**:  \nAutomates the process of code review and analysis by leveraging AI, enabling faster identification of code issues and actionable fixes. This supports software quality assurance workflows, reduces manual review effort, and accelerates development cycles.\n\n4. **Dependencies**:  \n- An asynchronous chat completion method (`self.chat_completion`), presumably interfacing with Together AI's API.  \n- Python standard libraries: `json` for parsing, and a `logger` for error reporting.  \n- The code snippet is part of a larger",
      "embedding_id": null,
      "created_at": "2025-10-22T19:05:59.619902",
      "status": "summarized"
    },
    "together_provider.py:chunk_8": {
      "chunk_id": "together_provider.py:chunk_8",
      "file_path": "shared\\llm_providers\\together_provider.py",
      "chunk_hash": "94c8b9185c961f7ab28e143475c024246ad95a36b64bb3682253fc4f5a66b262",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines asynchronous methods to generate AI-driven content, specifically comprehensive unit tests for source code and technical documentation in a specified format, by interacting with a chat-based language model.\n\n2. **Technical Details**:  \n- Uses asynchronous functions (`async def`) to perform non-blocking calls.  \n- Constructs prompt messages with a system role and user role to guide the language model\u2019s behavior.  \n- Employs formatted multi-line strings (f-strings) to dynamically insert code snippets, language types, and documentation content into prompts.  \n- Calls an asynchronous method `chat_completion` (presumably an API wrapper) with a temperature parameter to control output randomness.  \n- Returns optional strings containing the generated text output from the language model.\n\n3. **Business Logic**:  \nAutomates the generation of unit tests and technical documentation, reducing manual effort for software engineers and technical writers. This accelerates development workflows, improves code quality through consistent test coverage, and standardizes documentation formats (e.g., Confluence markdown).\n\n4. **Dependencies**:  \n- Relies on an external asynchronous chat completion service or API, likely an LLM provider (e.g., OpenAI, Together).  \n- The `chat_completion` method is not defined here but is critical for sending prompts and receiving generated content.  \n- Uses Python\u2019s `asyncio` for asynchronous execution.\n\n5. **Configuration**:  \n- The temperature parameter is configurable per method call (`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:07.502854",
      "status": "summarized"
    },
    "dto.py:chunk_0": {
      "chunk_id": "dto.py:chunk_0",
      "file_path": "features\\context_resolver\\dto.py",
      "chunk_hash": "d4ce2787366cae63f3b2172d95aa6ccd663d735ba20cb2471d1bb246319f7fb8",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines data transfer objects (DTOs) for input and output related to a context resolution feature, encapsulating the parameters needed to request context enrichment for an issue and the structure of the response containing enriched data and metadata.\n\n2. **Technical Details**:  \n- Uses Python type annotations and the `BaseModel` class (likely from a shared internal model or a Pydantic-like base) to enforce data validation and serialization.  \n- Defines two classes: `ContextResolverInput` for input parameters and `ContextResolverOutput` for output results.  \n- Utilizes standard Python data structures such as strings, booleans, dictionaries, and lists to represent complex nested data.\n\n3. **Business Logic**:  \n- Supports a business process that enriches issue data by querying multiple sources (e.g., logs, metrics, related issues) within a specified time range to provide comprehensive context for an issue identified by `issue_id`.  \n- Enables configurable inclusion/exclusion of logs, metrics, and related issues to tailor the enrichment process.\n\n4. **Dependencies**:  \n- Imports `BaseModel` and `SourceType` from a shared internal module `shared.models`, indicating reliance on a common data modeling framework and predefined source enumerations.  \n- Uses Python's built-in typing module for type hints.\n\n5. **Configuration**:  \n- No explicit environment variables or external configuration settings are referenced in this code snippet.  \n- Default values are provided for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:16.091975",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_0": {
      "chunk_id": "IntegrationsHub.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "e04bc5d8325c0b7ae2e2addda531758dfb3b8f2f3e55c22cc8d237cd61c96573",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React component, `IntegrationsHub`, provides a user interface for managing and interacting with various third-party service integrations categorized by type. It allows users to select service categories, view services, and manage connection statuses and configurations.\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (`useState`, `useEffect`) for state management and lifecycle handling.  \n- Maintains state for selected service category, selected service, visibility of secret fields, and configuration data using React state hooks.  \n- Defines a mapping (`ICON_MAP`) from service names to icon components imported from the `lucide-react` icon library for dynamic icon rendering.  \n- Uses TypeScript interfaces to strongly type data structures such as `ConnectionHistory` and service-related types (`ServiceCategory`, `ServiceDefinition`).  \n- Imports utility functions and constants from local modules (`serviceRegistry`, `integrations` types, and `servicesClient` API client) to fetch service data and statuses.\n\n3. **Business Logic**:  \nEnables users to browse and manage integrations with external services (e.g., version control, databases, cloud providers) within a centralized hub. This supports business needs for monitoring connection statuses, configuring integrations, and maintaining an audit trail of connection actions.\n\n4. **Dependencies**:  \n- React (hooks API) for UI and state management.  \n- `lucide-react` for SVG icon components.  \n- Local modules:  \n  - `service",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:24.840592",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_2": {
      "chunk_id": "IntegrationsHub.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "f7104d408ea9f78a7ae71a2aa6abbc2b577c80e3f17ffbff5be4c863c034ca38",
      "chunk_index": 2,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis React component code manages the integration hub panel's state and UI logic by fetching and displaying the live connection statuses of various external services, allowing users to view test results and connection history.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`) for state management and lifecycle handling.  \n- Maintains multiple state variables: `isTesting` (boolean), `testResult` (object or null), `showHistory` (boolean), `history` (array of connection history objects), `serviceStatuses` (dictionary mapping service IDs to their statuses), and `isLoadingStatuses` (boolean).  \n- Implements an asynchronous function `fetchStatuses` to retrieve live service statuses via `getAllServiceStatuses()`, updating state accordingly.  \n- Uses `try-catch-finally` for async error handling and state cleanup.  \n- Maps services by category and merges live statuses with static service data to produce a current view of service connectivity.\n\n3. **Business Logic**:  \nEnables monitoring and management of third-party or internal service integrations by providing real-time status updates, testing connectivity, and viewing historical connection data, which supports operational reliability and troubleshooting.\n\n4. **Dependencies**:  \n- React (hooks API)  \n- Presumably custom modules or services: `getAllServiceStatuses()`, `getServicesByCategory()`, `SERVICE_REGISTRY`, and `CATEGORIES` constants or imports.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:31.676105",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_4": {
      "chunk_id": "IntegrationsHub.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "32b7cb71f98869ab25c5ed6ea428e1746bff8922d5513a4ba771230fe402d5f6",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component code manages the integration status and configuration of various external services within a user interface panel. It tracks connection statuses, allows users to select services, configure settings, and maintain a history of connection actions.\n\n2. **Technical Details**:  \n- Uses React state hooks (`useState`) to manage selected service, configuration data, visibility of secret fields, test results, and connection history.  \n- Filters and maps service data to determine connection statuses (`connected`, `disconnected`, etc.).  \n- Maintains a capped history list (max 50 entries) of connection actions with timestamps and optional messages.  \n- Initializes configuration objects based on service-defined config fields and their default values.  \n- Provides handlers for user interactions such as selecting a service, changing config values, toggling secret visibility, and initiating connection tests (test handler partially shown).\n\n3. **Business Logic**:  \nEnables users to manage and monitor integrations with multiple external services, facilitating configuration, connection testing, and tracking of connection state changes. This supports operational visibility and control over third-party service integrations critical for business workflows.\n\n4. **Dependencies**:  \n- React (functional components and hooks)  \n- Presumably imports or references to `SERVICE_REGISTRY`, `serviceStatuses`, and type definitions like `ServiceDefinition` and `ConnectionHistory` (not shown in snippet).  \n- No explicit external libraries or APIs are shown in this snippet.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:39.347526",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_6": {
      "chunk_id": "IntegrationsHub.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "b6e8d0710e38fb6719c7eaef3ec71cddac344563bc3dc847a83d5c91e0fd2505",
      "chunk_index": 6,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code snippet is part of a React component that manages testing the connection of an external service integration. It attempts to connect to a selected service with provided configuration, tests the connection, updates the UI with the test result, logs the outcome, and refreshes service statuses.\n\n2. **Technical Details**:  \n- Uses asynchronous functions with `async/await` for handling API calls.  \n- Dynamically imports service client functions (`connectService` and `testService`) from an external module to reduce initial bundle size or enable code splitting.  \n- State management via React hooks (`setIsTesting`, `setTestResult`).  \n- Conditional logic to handle success and failure scenarios, including customizable success messages.  \n- Calls a history logging function (`addToHistory`) to record test outcomes.  \n- Refreshes service statuses after testing by calling `fetchStatuses`.  \n- Uses a `try-catch-finally` block to manage asynchronous flow and error handling.\n\n3. **Business Logic**:  \nEnables users to verify the connectivity and correctness of configurations for third-party service integrations before saving or using them, ensuring reliability and reducing runtime errors in the integrations hub.\n\n4. **Dependencies**:  \n- External API client module: `../../api/servicesClient` providing `connectService` and `testService` functions.  \n- React state management hooks (implied).  \n- Functions `addToHistory` and `fetchStatuses` which are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:43.077231",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_8": {
      "chunk_id": "IntegrationsHub.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "e0fb67f8dc697b0b4c6e9a3eabe8a8bc16b2f1f14ed7ac5acdeb65a1924ad4ff",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component code snippet manages the connection and status display of external services within an integrations hub, allowing users to save configurations, track connection statuses, and visualize service states with color-coded indicators and icons.\n\n2. **Technical Details**:  \n- Dynamically imports a `connectService` function from an API client module to establish service connections asynchronously.  \n- Uses async/await for handling asynchronous operations such as connecting services and fetching updated statuses.  \n- Implements a status-to-UI mapping via `getStatusColor` and `getStatusIcon` functions, which return CSS classes and SVG icons respectively based on service connection states.  \n- Maintains state updates for selected services, test results, and history logging through functions like `setSelectedService`, `setTestResult`, and `addToHistory`.\n\n3. **Business Logic**:  \nEnables users to configure and connect third-party services within an application, ensuring that connection statuses are saved, tracked, and visually communicated. This supports operational transparency and troubleshooting in integration workflows.\n\n4. **Dependencies**:  \n- Dynamic import of `connectService` from `../../api/servicesClient` for backend communication.  \n- React component state management hooks (implied by usage of `setSelectedService`, `setTestResult`).  \n- UI icon components such as `<CheckCircle />` and `<XCircle />` for status visualization (likely from a UI icon library).\n\n5. **Configuration**:  \n- The connection",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:49.889068",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_10": {
      "chunk_id": "IntegrationsHub.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "fc8d3cc1709c25426526438892be42b3270ac62414bdf1ed8905ac8af6c0c24e",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component snippet from `IntegrationsHub.tsx` renders UI elements representing the connection status and history of various services within an integrations hub, including status icons and a refresh button to update service statuses.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX for UI rendering.  \n- Implements switch-case logic to map connection states and actions to corresponding SVG icon components with Tailwind CSS classes for styling and animation.  \n- Displays a status bar showing the count of connected services out of total services.  \n- Includes an event handler (`fetchStatuses`) tied to a refresh button to trigger status updates.  \n- Uses TypeScript types, e.g., `ConnectionHistory['action']`, for type safety.\n\n3. **Business Logic**:  \nThe component visually communicates the real-time connectivity status of integrated services to users, enabling monitoring and management of service connections. The refresh button allows users to manually update the statuses, supporting operational awareness and troubleshooting.\n\n4. **Dependencies**:  \n- React and React DOM for UI rendering.  \n- Tailwind CSS for utility-first styling and animations.  \n- Icon components such as `Loader2`, `AlertCircle`, `Plug`, `X`, `Activity`, and `XCircle` (likely from a UI icon library like Lucide or similar).  \n- TypeScript for static typing.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. The component likely",
      "embedding_id": null,
      "created_at": "2025-10-22T19:06:58.248805",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_12": {
      "chunk_id": "IntegrationsHub.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "36b5b0f7048ab44686acd0857ddb567b43653066d3a3db51f2b175f06da39936",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a user interface section within the Integrations Hub panel that allows users to refresh the connection statuses of integrated services and displays a quick status overview of up to five connected services with their respective icons.\n\n2. **Technical Details**:  \n- Uses React functional components and JSX for UI rendering.  \n- Implements conditional rendering and dynamic class assignment (e.g., spinning animation on the refresh icon when loading).  \n- Utilizes array slicing (`connectedServices.slice(0, 5)`) to limit displayed services.  \n- Maps over an array of service objects to dynamically render UI elements.  \n- Uses a mapping object `ICON_MAP` to resolve service icon components dynamically.  \n- Employs Tailwind CSS utility classes for styling and responsive design.\n\n3. **Business Logic**:  \nProvides users with a quick visual summary of their active service integrations and a manual refresh control to update connection statuses, enhancing user awareness and control over integration health.\n\n4. **Dependencies**:  \n- React library for component rendering.  \n- Tailwind CSS for styling.  \n- An icon library/component set (e.g., `RefreshCw` icon and icons referenced in `ICON_MAP`).  \n- Presumably, a state management or data fetching mechanism managing `isLoadingStatuses` and `connectedServices` (not shown in snippet).\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration likely occurs",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:05.885159",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_14": {
      "chunk_id": "IntegrationsHub.tsx:chunk_14",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "b107311725a0ad6118dc2fdcd89937c0e2dc45a37d958adda473eb6643c44ad7",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis React component snippet from `IntegrationsHub.tsx` renders a user interface panel displaying connected services and a history toggle button, along with a sidebar listing service categories with associated icons.\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (e.g., `setShowHistory`) for state management.  \n- Conditional rendering is employed to display different UI elements based on the length of arrays such as `connectedServices` and `history`.  \n- Maps over `categories` to dynamically render category items, retrieving icons from a mapping object `ICON_MAP` and filtering services per category via `getServicesByCategory`.  \n- Utilizes Tailwind CSS utility classes for styling and layout.  \n- The button toggles the visibility of a history panel, indicating an interactive UI element.\n\n3. **Business Logic**:  \nEnables users to view and manage integrations with various connected services, providing quick insights into the number of connected services and recent activity history. The sidebar categorizes these services to improve navigation and organization, supporting efficient integration management.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Custom components/icons such as `History`  \n- Presumably local utility functions or constants like `ICON_MAP` and `getServicesByCategory`\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. Configuration likely resides elsewhere for service data and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:14.025401",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_16": {
      "chunk_id": "IntegrationsHub.tsx:chunk_16",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "83d925c2e1d17e9a34da727b65cbcf071af57f808f40b8f956444ac0b98ba3e4",
      "chunk_index": 16,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis React component snippet renders a list of integration categories as selectable buttons, displaying the count of connected services per category. It allows users to select a category, highlighting the selected one and showing connection status.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Filters an array (`categoryServices`) to count services with status `'connected'`.  \n- Applies conditional CSS classes based on whether a category is selected (`selectedCategory === category.id`).  \n- Uses array `.filter()` and `.length` for counting connected services.  \n- Employs event handling via `onClick` to update the selected category state (`setSelectedCategory`).  \n- Utilizes utility-first CSS classes (likely Tailwind CSS) for styling and transitions.  \n- Renders an icon component (`<Icon />`) dynamically per category.\n\n3. **Business Logic**:  \nEnables users to view and manage integration categories by showing how many services within each category are connected, facilitating quick assessment and selection of integration groups for further actions or configurations.\n\n4. **Dependencies**:  \n- React (JSX, state management via hooks).  \n- Tailwind CSS (inferred from class names like `bg-primary-50`, `text-gray-700`).  \n- Custom or third-party `<Icon />` component for category icons.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:21.528624",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_18": {
      "chunk_id": "IntegrationsHub.tsx:chunk_18",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "9bd5fd1fa595319fdb63f7c60ef54937c3311fd3e880568067c2f67efcdf051f",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a categorized list of integration services in a responsive grid layout. It displays the selected category's name and description, then maps over a list of services to render clickable service cards with icons and metadata.\n\n2. **Technical Details**:  \n- Uses React functional components and JSX for UI rendering.  \n- Utilizes a grid system with Tailwind CSS classes (`grid-cols-1 md:grid-cols-2 lg:grid-cols-3`) for responsive design.  \n- Dynamically selects icons from an `ICON_MAP` object based on service metadata.  \n- Filters service configuration fields to count required fields (`service.configFields.filter(f => f.required).length`).  \n- Implements event handling with `onClick` to trigger `handleServiceClick(service)`.  \n- Uses utility-first CSS (Tailwind) for styling and hover effects with transitions.\n\n3. **Business Logic**:  \nEnables users to browse and select integration services categorized by type, facilitating the configuration and management of third-party integrations within the application. The required fields count likely informs users about the complexity or setup requirements of each service.\n\n4. **Dependencies**:  \n- React (JSX, components)  \n- Tailwind CSS for styling and responsive layout  \n- An external or internal `ICON_MAP` mapping service identifiers to icon components  \n- Presumably, `CATEGORIES` and `services` data structures are imported or passed as props\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:28.563498",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_20": {
      "chunk_id": "IntegrationsHub.tsx:chunk_20",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "19b4f0217b7a7eda65f1046f66dcd5945ad0ef76424c554261e900f128faa39b",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a UI panel displaying details about an integration service, including its name, status with an icon and color coding, description, and a summary of its configuration state.\n\n2. **Technical Details**:  \n- Uses JSX to structure the UI elements.  \n- Conditional rendering (`service.isConfigured && ...`) to show configuration summary only if the service is configured.  \n- Dynamic class names and icons are applied based on the service status via helper functions `getStatusColor(service.status)` and `getStatusIcon(service.status)`.  \n- Utilizes Tailwind CSS utility classes for styling and layout.  \n- The `line-clamp-2` class is used to truncate the description text to two lines for consistent UI appearance.\n\n3. **Business Logic**:  \nThe code visually communicates the integration service\u2019s current connection status and configuration completeness to users, helping them quickly assess which services are active and properly set up, thus facilitating management of multiple integrations.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Custom helper functions: `getStatusColor`, `getStatusIcon` (likely imported from utility modules)  \n- A `Settings` icon component (likely from an icon library or custom component set)\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. Configuration state is derived from the `service` object passed as a prop, specifically",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:35.492186",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_22": {
      "chunk_id": "IntegrationsHub.tsx:chunk_22",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "187c1e962564bd9381e85ccdb8d929cfbc4a1f06d8e1ddb0979e22cf159ab712",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a list of service capabilities within an integrations hub panel, displaying up to three capabilities per service and indicating if more exist. It also handles the empty state when no services are available in a category.\n\n2. **Technical Details**:  \n- Uses conditional rendering to check if `service.capabilities` exists and has elements.  \n- Utilizes array slicing (`slice(0, 3)`) to limit displayed capabilities to three.  \n- Maps over capabilities to generate styled `<span>` elements with unique keys based on index.  \n- Displays a \"+X more\" indicator if capabilities exceed three.  \n- Renders a fallback UI with an icon and messages when the `services` array is empty.  \n- Employs Tailwind CSS utility classes for styling.  \n- Uses JSX syntax within a React functional component context.\n\n3. **Business Logic**:  \nSupports the business need to showcase integrations and their features succinctly, improving user experience by preventing UI clutter while still informing users about additional capabilities. The empty state messaging encourages users to revisit for future integrations, maintaining engagement.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- A `Database` icon/component (likely from an icon library or internal component set)\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \nNo explicit error",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:41.081915",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_24": {
      "chunk_id": "IntegrationsHub.tsx:chunk_24",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "f57dde0a9f896c29b5b9430239a3e78c3f4f748444c1ce899843fd33bebde7a7",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a sidebar panel displaying a \"Connection History\" list, allowing users to view past connection activities and close the panel.\n\n2. **Technical Details**:  \n- Utilizes React functional components with JSX for UI rendering.  \n- Uses conditional rendering to show either a placeholder message when no history exists or a list of history items (not fully shown).  \n- Employs Tailwind CSS utility classes for styling and layout.  \n- Uses state management via `setShowHistory` to toggle the visibility of the history panel.  \n- Incorporates icon components (`History`, `X`) for visual cues.\n\n3. **Business Logic**:  \nProvides users with visibility into their connection or integration activity history, helping them track and audit service connections or tests within the application.\n\n4. **Dependencies**:  \n- React (for component structure and state management).  \n- Tailwind CSS (for styling).  \n- Icon components (`History`, `X`), likely from an icon library or custom SVG components.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \nNo explicit error handling or exception management is present in this UI rendering code.\n\n7. **API/Interface**:  \n- The component exposes an interface via the `setShowHistory` callback prop or state setter to control panel visibility.  \n- The `history` array is used as input data to render",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:50.827554",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_26": {
      "chunk_id": "IntegrationsHub.tsx:chunk_26",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "95dee6f0410d898d637693bc255eb3e5a3da3b97ad0e2004383daf0877596554",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis React JSX snippet renders a list of historical integration events, displaying each event's service name, action type, timestamp, and an optional message in a styled panel.\n\n2. **Technical Details**:  \n- Uses the `map` function to iterate over an array named `history`.  \n- Each entry is rendered inside a `<div>` with a unique `key` based on `entry.id`.  \n- Utilizes utility CSS classes (likely Tailwind CSS) for styling and layout.  \n- Calls a helper function `getActionIcon(entry.action)` to render an icon corresponding to the action type.  \n- Formats timestamps using JavaScript's `Date` object and `toLocaleTimeString()` for human-readable time.  \n- Conditional rendering is used to display the `entry.message` only if it exists, with text truncation via `line-clamp-2`.\n\n3. **Business Logic**:  \nThis component provides users with a visual audit trail or activity log of integration events, helping them track actions performed by or on connected services within the Integrations Hub. It supports transparency and troubleshooting by showing what happened, when, and any relevant messages.\n\n4. **Dependencies**:  \n- React (JSX syntax).  \n- Tailwind CSS (inferred from class names like `p-3`, `bg-gray-50`, `line-clamp-2`).  \n- A local helper function `getActionIcon` (not shown) that maps",
      "embedding_id": null,
      "created_at": "2025-10-22T19:07:59.017765",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_28": {
      "chunk_id": "IntegrationsHub.tsx:chunk_28",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "a69d43270343ea45a8ae6fa9435a963cd98507987c884761a645457d7dbbba12",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a modal dialog displaying detailed information about a selected service within an integrations hub interface. It shows the service icon, name, description, and provides a close button to dismiss the modal.\n\n2. **Technical Details**:  \n- Uses React functional component JSX syntax with conditional rendering (`selectedService && ...`) to show the modal only when a service is selected.  \n- Dynamically renders an icon component by mapping `selectedService.icon` to a React component from `ICON_MAP`.  \n- Utilizes Tailwind CSS utility classes for styling and layout (e.g., fixed positioning, flexbox, spacing, colors).  \n- The modal structure includes a header with service details and a close button that resets the `selectedService` state to `null`.  \n- Inline anonymous function used to render the icon component dynamically.\n\n3. **Business Logic**:  \nEnables users to view detailed information about a particular integration service in a focused modal view, improving user experience by providing contextual data without navigating away from the main interface.\n\n4. **Dependencies**:  \n- React (JSX, state management via `setSelectedService`)  \n- Tailwind CSS for styling  \n- `ICON_MAP` object that maps service icon identifiers to React icon components  \n- `X` icon component used for the close button (likely from an icon library such as Heroicons or similar)\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration settings are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:05.338731",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_30": {
      "chunk_id": "IntegrationsHub.tsx:chunk_30",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "c47f233210389775225369abe72e29e41e904fe0d0395629aa073bd89e01d200",
      "chunk_index": 30,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a dynamic configuration form for an integration service, allowing users to input or select configuration values based on the selected service's authentication type and required fields.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX for UI rendering.  \n- Iterates over an array (`selectedService.configFields`) to dynamically generate form fields.  \n- Supports conditional rendering based on field types (e.g., `select` dropdown).  \n- Uses controlled components pattern with `value` and `onChange` handlers to manage form state (`configData`).  \n- Employs Tailwind CSS classes for styling and layout.\n\n3. **Business Logic**:  \nEnables users to configure third-party integrations by providing necessary authentication and configuration parameters dynamically, supporting multiple services with varying requirements and authentication types.\n\n4. **Dependencies**:  \n- React (for component and state management).  \n- Tailwind CSS (for styling).  \n- Presumably internal state management or context hooks (e.g., `handleConfigChange` function) to update configuration data.\n\n5. **Configuration**:  \n- The form fields and their metadata (name, label, type, required, options, defaultValue) are provided via the `selectedService` object, likely sourced from a higher-level state or API response.  \n- No explicit environment variables or external config files are referenced in this snippet.\n\n6. **Error Handling**:  \n- No explicit error handling is shown",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:11.029936",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_32": {
      "chunk_id": "IntegrationsHub.tsx:chunk_32",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "dd199ca0af65ea2e2b36fd6417b02d2d81bdcff796379c7a8d8e8924fcc7c078",
      "chunk_index": 32,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a form input field that conditionally displays either a dropdown select or a password input with a toggleable visibility feature, allowing users to view or hide sensitive information.\n\n2. **Technical Details**:  \n- Uses conditional rendering based on the `field.type` property to switch between input types.  \n- Implements controlled components pattern with `value` and `onChange` handlers to manage form state (`configData`).  \n- Utilizes a boolean state object `showSecrets` keyed by field names to toggle password visibility.  \n- Employs inline event handlers and dynamic class names for UI interaction and styling.  \n- Uses icon components (`Eye`, `EyeOff`) to visually indicate password visibility state.\n\n3. **Business Logic**:  \nEnables secure configuration input by allowing users to enter sensitive data (e.g., passwords) with the option to reveal or mask the input, improving usability without compromising security in configuration forms.\n\n4. **Dependencies**:  \n- React (functional components, hooks assumed)  \n- Icon components (`Eye`, `EyeOff`), likely from a UI icon library such as Heroicons or similar  \n- CSS classes suggest TailwindCSS or a similar utility-first CSS framework\n\n5. **Configuration**:  \n- Relies on `configData` state object to hold form values.  \n- Uses `showSecrets` state to track visibility toggles per field.  \n- No explicit environment variables or external config files",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:15.839439",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_34": {
      "chunk_id": "IntegrationsHub.tsx:chunk_34",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "ffcfcef811263b7a8f5b12b9675679ed44365bfa91e29565e62c663f19587330",
      "chunk_index": 34,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet dynamically renders input fields based on the type of configuration fields for an integration service, allowing users to input or modify configuration data and test the connection to the selected service.\n\n2. **Technical Details**:  \n- Uses conditional rendering to switch between input types (`number` and `text`) based on the `field.type` property.  \n- Controlled components pattern is applied where input values are bound to `configData` state and updated via `handleConfigChange`.  \n- Supports default values and placeholders for inputs.  \n- Displays optional field descriptions below inputs.  \n- Includes a conditional button to trigger a test connection action (`handleTest`) if the selected service supports it.  \n- Uses JSX and React functional component conventions.\n\n3. **Business Logic**:  \nEnables users to configure integration services by providing a flexible UI that adapts to different field types and validates input formats (e.g., parsing numbers). The test connection feature helps verify that the integration settings are correct before saving or deploying, reducing configuration errors and improving user confidence.\n\n4. **Dependencies**:  \n- React (JSX syntax, state management assumed)  \n- CSS classes suggest Tailwind CSS or similar utility-first CSS framework for styling  \n- No explicit external libraries shown in this snippet, but likely part of a larger React app ecosystem.\n\n5. **Configuration**:  \n- Relies on `configData` object to hold current input values.  \n- Uses",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:23.284005",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_36": {
      "chunk_id": "IntegrationsHub.tsx:chunk_36",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "84b29ce95104c0783d7f80fadd61015b1be4f19c0734638b2066bb6d05e85814",
      "chunk_index": 36,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a button to test an integration connection and displays the result of the test with appropriate visual feedback indicating success or failure.\n\n2. **Technical Details**:  \n- Uses conditional rendering to toggle button state and iconography based on an `isTesting` boolean flag.  \n- Displays a loading spinner (`Loader2` icon) and disables the button during the test operation.  \n- Upon receiving a `testResult` object, it conditionally renders a styled message box with success or error styles and corresponding icons (`CheckCircle` for success, `XCircle` for failure).  \n- Utilizes Tailwind CSS utility classes for styling and layout.  \n- JSX fragments (`<>...</>`) are used for grouping elements without extra nodes.\n\n3. **Business Logic**:  \nEnables users to verify the connectivity of an integration endpoint or service before saving or proceeding, ensuring that integrations are correctly configured and operational, thereby reducing runtime errors and improving user confidence.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Icon components: `Loader2`, `Activity`, `CheckCircle`, `XCircle` (likely from a UI icon library such as Heroicons or a custom icon set)  \n- Tailwind CSS for styling\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are shown in this snippet. The component likely depends on props or context for `isTesting` and `testResult` state",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:31.888684",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_38": {
      "chunk_id": "IntegrationsHub.tsx:chunk_38",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "911ca8e4a9472aeb1a4a25152bb8037a7403026c6b55d47f389a13f747ccd500",
      "chunk_index": 38,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a UI panel section displaying the capabilities of a selected integration service, including a list of capabilities with icons and a footer area for action buttons.\n\n2. **Technical Details**:  \n- Uses React functional component JSX syntax.  \n- Conditional rendering based on the presence and length of `selectedService.capabilities`.  \n- Maps over an array (`selectedService.capabilities`) to dynamically generate UI elements.  \n- Utilizes Tailwind CSS utility classes for styling.  \n- Incorporates an icon component `<Check />` for visual indication.  \n- Structured with semantic HTML elements and accessible class names.\n\n3. **Business Logic**:  \nDisplays detailed information about an integration service\u2019s capabilities to users, helping them understand what features or functionalities the selected service supports, which aids in decision-making or configuration within an integrations hub.\n\n4. **Dependencies**:  \n- React (JSX rendering).  \n- Tailwind CSS for styling.  \n- A custom or third-party icon component named `Check`.  \n- Likely part of a larger integrations management system.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet. Configuration likely occurs at a higher component or application level.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. It assumes `selectedService.capabilities` is either undefined or an array; conditional checks prevent runtime errors from undefined values.\n\n7. **API/Interface",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:38.222281",
      "status": "summarized"
    },
    "IntegrationsHub.tsx:chunk_40": {
      "chunk_id": "IntegrationsHub.tsx:chunk_40",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsHub.tsx",
      "chunk_hash": "791edd936826c26ddcbb5d4572e4bc9e7e88484425a661dca3c6724824ea1250",
      "chunk_index": 40,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet provides UI controls for managing integration service configurations, allowing users to cancel changes or save the current configuration.\n\n2. **Technical Details**:  \n- Utilizes React functional components with hooks (e.g., `setSelectedService` state setter).  \n- Event handlers (`onClick`) trigger state updates and save operations (`handleSave`).  \n- Uses JSX for rendering buttons with CSS classes (`btn-secondary`, `btn-primary`) for styling.\n\n3. **Business Logic**:  \nEnables users to configure integration services within an application, supporting workflows to either discard changes (Cancel) or persist them (Save Configuration), facilitating integration management.\n\n4. **Dependencies**:  \n- React library for component and state management.  \n- CSS classes imply a styling framework or custom styles but no explicit external UI libraries are shown in this snippet.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \nNo explicit error handling is visible in this code fragment; error management likely occurs within the `handleSave` function or higher-level components.\n\n7. **API/Interface**:  \n- Exposes no public methods directly; the component exports as default (`IntegrationsHub`).  \n- Interaction occurs via UI events and internal state changes.\n\n8. **Performance Notes**:  \nNo specific performance optimizations or caching mechanisms are evident in this snippet; standard React rendering applies.\n\n---",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:42.585091",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_0": {
      "chunk_id": "ThinkingProcess.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "b76e9b7b2bc84c1ea466cdc664f85c0e117bfbacb0ea5e8877a7a59af28378d1",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React component, `ThinkingProcess`, visually represents the detailed steps of a backend workflow or processing sequence, showing each step's status, timing, and metadata in an expandable UI format.\n\n2. **Technical Details**:  \n- Uses React functional component with hooks (`useState`) to manage UI state such as overall expansion and individual step expansion.  \n- Defines TypeScript interfaces (`ThinkingStep`, `ThinkingProcessData`, `ThinkingProcessProps`) for strong typing of workflow data.  \n- Utilizes a `Set` data structure to efficiently track which steps are expanded or collapsed.  \n- Conditional rendering is applied to handle null or missing data gracefully.  \n- Status icons are mapped to step statuses for intuitive visual feedback (icons imported from `lucide-react`).  \n\n3. **Business Logic**:  \nThe component provides a clear, user-friendly visualization of backend processing workflows, enabling users (likely developers or operators) to monitor the progress, duration, and errors of each step in a complex backend process. This aids in debugging, auditing, and operational transparency.\n\n4. **Dependencies**:  \n- `lucide-react`: For SVG icon components representing step statuses and UI controls.  \n- React: Core library for building the component and managing state.  \n\n5. **Configuration**:  \nNo explicit environment variables or external configuration files are referenced in this snippet. The component relies solely on props passed down (`ThinkingProcessData`), which presumably come from higher-level application",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:49.788024",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_2": {
      "chunk_id": "ThinkingProcess.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "5c8977459ced2a30d2b29de0fdd0d6e7b4dc68d29f23d6785a768a36f30c0923",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component code snippet provides visual status indicators by mapping different process statuses (e.g., completed, failed, in_progress) to corresponding icons and CSS styles for UI display.\n\n2. **Technical Details**:  \n- Uses `switch` statements to map string status values to JSX elements (icons or styled divs) and CSS class strings.  \n- Icons like `<CheckCircle>`, `<XCircle>`, `<Loader2>`, and `<Clock>` are rendered conditionally based on status.  \n- CSS utility classes (likely Tailwind CSS) are applied for colors, sizing, borders, and animations (e.g., `animate-spin`, `animate-pulse`).  \n- Functions are pure and stateless, returning UI elements or style strings based on input status.\n\n3. **Business Logic**:  \nThe code visually communicates the current state of a process or task (such as a workflow step or operation) to the user, enhancing UX by providing immediate, intuitive feedback on progress, success, failure, or pending states.\n\n4. **Dependencies**:  \n- React for JSX rendering.  \n- Icon components (`CheckCircle`, `XCircle`, `Loader2`, `Clock`) presumably imported from an icon library (e.g., Heroicons or similar).  \n- Tailwind CSS for utility-first styling classes.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are referenced in this snippet. Styling and icon usage depend on",
      "embedding_id": null,
      "created_at": "2025-10-22T19:08:54.794872",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_4": {
      "chunk_id": "ThinkingProcess.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "57b96b915b7ad052239a795af5f4ab1180f77acbc6fb8db479e77a24b546c0da",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component snippet renders status indicators and formats duration times for a \"thinking process\" UI element, visually representing different states of a process (e.g., done, failed, running) with styled badges and duration formatting.\n\n2. **Technical Details**:  \n- Uses a switch-case pattern to map process states (`done`, `failed`, `in_progress`, `skipped`, `pending`) to styled `<span>` elements with Tailwind CSS classes for color coding and animations.  \n- Implements a `formatDuration` utility function that converts milliseconds to a human-readable string, displaying milliseconds if under 1000ms or seconds with two decimal places otherwise.  \n- Uses React state (`isExpanded`) to toggle UI expansion, with an onClick handler on a container div.  \n- Uses JSX and Tailwind CSS for UI rendering and styling.  \n- Partial code shows conditional rendering of icons (e.g., `ChevronDown`) based on expansion state.\n\n3. **Business Logic**:  \nThe component visually communicates the status and duration of asynchronous or multi-step processes in the frontend, helping users quickly understand the progress and outcome of tasks or workflows in the application.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Presumably an icon library providing `ChevronDown` (not fully shown)  \n- No explicit external services or APIs shown in the snippet.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:00.958624",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_6": {
      "chunk_id": "ThinkingProcess.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "d16562abdfbab78b8c9f0ffc96c76fa6624b41d175787d6c0d565c689fa42804",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a UI section that displays a \"thinking process\" or workflow with multiple steps, showing progress, duration, and allowing expansion to view detailed steps with interactive toggling.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Conditional rendering (`isExpanded` state) to show/hide detailed steps.  \n- Iterates over `data.steps` array to display each step, using `.map()` with unique keys (`step.id`).  \n- Filters steps by status (`completed`) to show progress count.  \n- Uses utility functions like `formatDuration()` to format time and `getStatusColor()` to dynamically assign CSS classes based on step status.  \n- Event handling with `onClick` to toggle step expansion (`toggleStep(step.id)`).  \n- Uses Tailwind CSS classes for styling and layout.  \n- Includes SVG icon components (`ChevronRight`, `Clock`) for visual indicators.\n\n3. **Business Logic**:  \nThe component visually represents the progress of a multi-step process or workflow, providing users with insights into how many steps are completed out of total, the total duration of the process, and the ability to drill down into individual steps. This supports transparency and monitoring of complex tasks or operations in the business domain.\n\n4. **Dependencies**:  \n- React (JSX, state management)  \n- Tailwind CSS for styling  \n- Custom or third-party icon components (`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:07.406746",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_8": {
      "chunk_id": "ThinkingProcess.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "d94f99644ef03e84334e4e0e5464c844fa7743c07e25fc37a4a263817ebbf6f5",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a visual representation of a \"step\" in a thinking or processing workflow, displaying its status, title, duration, description, and optionally expanded error details.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Conditional rendering is employed to show status icons, badges, duration, and expanded error details based on the step's properties and UI state (`expandedSteps` set).  \n- Utility/helper functions like `getStatusIcon`, `getStatusBadge`, and `formatDuration` are used to abstract UI logic for status visualization and formatting.  \n- Uses Tailwind CSS classes for styling and layout (flexbox, spacing, typography, colors).  \n- Data structure: `step` object with properties such as `id`, `status`, `title`, `duration_ms`, `description`, and `error`.  \n- `expandedSteps` is a Set or similar collection tracking which steps are expanded.\n\n3. **Business Logic**:  \nThe component supports a business need to visualize the progress and details of individual steps within a larger process or workflow, helping users understand the status, timing, and errors of each step in a clear, structured manner.\n\n4. **Dependencies**:  \n- React (JSX, component rendering)  \n- Tailwind CSS for styling  \n- Custom utility functions (`getStatusIcon`, `getStatusBadge`, `formatDuration`) likely defined elsewhere in the code",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:15.720202",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_10": {
      "chunk_id": "ThinkingProcess.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "9789b18358d28faf003e7bc2c34e8c0d5a05af39f1ab4999a25a1d66bb45d61f",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React JSX snippet renders UI elements to display error messages, metadata details, and start time information related to a specific \"step\" object within a thinking or processing workflow.\n\n2. **Technical Details**:  \n- Uses conditional rendering to display error information if `step.error` exists.  \n- Checks if `step.metadata` contains any keys and iterates over them using `Object.entries()` to display key-value pairs. Values are stringified with `JSON.stringify()` for display.  \n- Displays the start time of the step formatted as a localized time string using `toLocaleTimeString()`.  \n- Utilizes Tailwind CSS utility classes for styling (e.g., `text-sm`, `text-red-800`, `border-gray-300`).  \n- Data structure: `step` is an object with properties `error` (string), `metadata` (object), and `start_time` (timestamp).\n\n3. **Business Logic**:  \nThis component supports debugging or monitoring workflows by visually presenting error details, associated metadata, and timing information for discrete processing steps, helping users or developers understand the state and context of each step in a process.\n\n4. **Dependencies**:  \n- React (JSX syntax) for component rendering.  \n- Tailwind CSS for styling.  \n- No explicit external services or APIs are referenced in this snippet.\n\n5. **Configuration**:  \n- No environment variables or external configuration settings are directly referenced or required in this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:24.431282",
      "status": "summarized"
    },
    "ThinkingProcess.tsx:chunk_12": {
      "chunk_id": "ThinkingProcess.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Shared\\ThinkingProcess.tsx",
      "chunk_hash": "c9c97b1c76065abf0fa58cfd40f045ce8aaccec2012a8d3fe51044bb367b8b3a",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component, `ThinkingProcess`, renders a list of steps with timestamps, displaying the start and end times formatted as local time strings. It visually represents a sequence of actions or events in a process.\n\n2. **Technical Details**:  \n- Uses JSX to conditionally render elements based on the presence of `step.end_time`.  \n- Utilizes JavaScript's `Date` object and `toLocaleTimeString()` for time formatting.  \n- Employs array mapping to iterate over a collection of steps and render UI elements dynamically.  \n- The component structure suggests nested divs for layout and styling purposes.\n\n3. **Business Logic**:  \nThe component likely supports a business workflow or process tracking feature, allowing users to view the timeline or history of steps taken, including when each step ended. This aids in transparency and auditing of processes.\n\n4. **Dependencies**:  \n- React (for component creation and JSX rendering).  \n- No explicit external libraries or services are shown in the snippet, but likely depends on React and possibly CSS modules or styling frameworks for layout.\n\n5. **Configuration**:  \n- No environment variables or external configuration settings are evident in the snippet.  \n- Time formatting relies on the client\u2019s locale settings via `toLocaleTimeString()`.\n\n6. **Error Handling**:  \n- No explicit error handling is present.  \n- Implicitly handles missing `end_time` by conditionally rendering the end time",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:30.667333",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_0": {
      "chunk_id": "vector_db_api.py:chunk_0",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "f60d475f18f17114b4e1cd7d2468a62c80db655d26fa50e129dd0643e82a79e2",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines REST API endpoints for interacting with a vector database, enabling operations such as repository indexing, semantic search, and collection management within a code intelligence context.\n\n2. **Technical Details**:  \n- Uses FastAPI's `APIRouter` to modularize API routes under the prefix `/api/vector-db`.  \n- Defines request data models using Pydantic (`IndexRepositoryRequest`, `SemanticSearchRequest`) for input validation and serialization.  \n- Integrates with vector database services via a factory pattern (`VectorDBFactory`) and specialized services like `VectorQueryService` for querying vectors.  \n- Employs orchestration components (`GitHubLLMOrchestrator`) to handle complex query workflows involving GitHub repositories and language models.  \n- Uses logging for operational traceability.\n\n3. **Business Logic**:  \nEnables developers or automated systems to index source code repositories into a vector database and perform semantic searches over code collections. This supports enhanced code intelligence features such as code search, recommendation, and analysis, improving developer productivity and codebase understanding.\n\n4. **Dependencies**:  \n- FastAPI for API framework.  \n- Pydantic for data validation.  \n- Custom internal modules:  \n  - `shared.vector_db.factory.VectorDBFactory` for vector DB instantiation.  \n  - `shared.vector_db.embedding_service.EmbeddingService` for embedding generation.  \n  - `shared.vector_db.services.vector_query_service.VectorQueryService` for vector",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:37.651480",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_2": {
      "chunk_id": "vector_db_api.py:chunk_2",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "048758aa5f494722d217bd44f68588b7482d9a2c3419f0aea12dec408460a3fa",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines data models and initializes a vector database system with embedding and query services, primarily aimed at supporting semantic search queries over GitHub repositories using large language models (LLMs).\n\n2. **Technical Details**:  \n- Uses Pydantic `BaseModel` classes (`GitHubLLMQueryRequest`, `VectorDBStatus`) for data validation and structured request/response modeling.  \n- Employs asynchronous initialization (`async def initialize_vector_db()`) to set up vector DB providers and related services.  \n- Implements a global singleton pattern for core components (`vector_db`, `embedding_service`, `query_service`, etc.) to maintain shared state across the application.  \n- Supports provider-specific configuration and fallback mechanisms (e.g., Qdrant vector DB with host config).  \n- Uses logging for operational transparency during initialization.\n\n3. **Business Logic**:  \nEnables semantic search capabilities over code repositories by integrating vector databases and embedding services, facilitating advanced code search and analysis workflows for developers or automated tools interacting with GitHub repositories.\n\n4. **Dependencies**:  \n- Pydantic for data modeling (`BaseModel`).  \n- Asyncio for asynchronous operations.  \n- External vector database providers (e.g., Qdrant).  \n- Embedding services (likely external APIs or ML models).  \n- Configuration and logging modules (e.g., `settings`, `logger`), presumably from the broader application context.\n\n5. **Configuration**:  \n- Uses",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:42.115673",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_4": {
      "chunk_id": "vector_db_api.py:chunk_4",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "24f1fed5b566aceef8ef8a60806bea098a977fa330e284f420a90539d9013075",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet initializes a vector database provider based on a configured provider type, with a fallback mechanism to an in-memory vector database if the primary initialization fails.\n\n2. **Technical Details**:  \n- Uses a Factory design pattern (`VectorDBFactory.create`) to instantiate vector database providers dynamically based on the `provider_type`.  \n- Asynchronous initialization (`await vector_db.initialize()`) to support non-blocking setup of the vector DB.  \n- Conditional logic to handle fallback initialization to an in-memory vector DB if the primary provider fails and fallback is enabled.  \n- Logging is used extensively for tracing initialization steps and warnings.\n\n3. **Business Logic**:  \nEnsures reliable initialization of a vector database service, which is critical for applications relying on vector similarity search or embedding storage. The fallback to an in-memory DB ensures continuity of service even if the preferred vector DB provider is unavailable, improving system robustness.\n\n4. **Dependencies**:  \n- `VectorDBFactory` module/class for creating vector DB instances.  \n- `settings` object for configuration values such as `qdrant_port` and `vector_db_fallback_enabled`.  \n- `logger` for logging informational and warning messages.  \n- Asynchronous programming constructs (`async/await`).\n\n5. **Configuration**:  \n- `settings.qdrant_port`: Port number for the vector DB provider (likely Qdrant).  \n- `settings.vector_db_fallback_enabled`: Boolean flag to enable",
      "embedding_id": null,
      "created_at": "2025-10-22T19:09:53.151194",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_6": {
      "chunk_id": "vector_db_api.py:chunk_6",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "7523bf304b6ee615a4b4dca2d2bb75f946f207998849a028914fcefd3d2b5bd7",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code initializes and configures services for a vector database-based search system, specifically setting up an embedding service, creating a vector collection for GitHub repositories, initializing a query service, and preparing a GitHub API client.\n\n2. **Technical Details**:  \n- Uses an embedding service (`EmbeddingService`) configured with the Azure \"text-embedding-ada-002\" model optimized for technical/business content and code embeddings.  \n- Creates a vector collection named `\"github_repos\"` with a dimensionality matching the embedding output.  \n- Implements asynchronous collection creation (`await vector_db.create_collection`).  \n- Uses a `VectorQueryService` to enable querying over the vector database with the embeddings.  \n- Wraps GitHub API interactions in a `GitHubWrapper` client, checking for proper configuration before use.  \n- Logging is extensively used for operational transparency.\n\n3. **Business Logic**:  \nEnables semantic search or similarity queries over GitHub repository data by embedding repository information into a vector space, facilitating advanced search capabilities for technical/business content. This supports business needs such as code discovery, repository analysis, or knowledge management.\n\n4. **Dependencies**:  \n- Azure embedding model `\"text-embedding-ada-002\"` via `EmbeddingService`.  \n- A vector database interface (`vector_db`) supporting async collection creation.  \n- `VectorQueryService` for querying vectors.  \n- `GitHubWrapper` for GitHub API integration.  \n- Python",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:00.588296",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_8": {
      "chunk_id": "vector_db_api.py:chunk_8",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "6a3eb879636deb48bcf8c1ae814d09e67b64cbf935c5f8a0d248eb335a25afac",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet initializes components for a vector database-backed GitHub repository indexing and query system, setting up a GitHub-LLM orchestrator that uses Azure for language model (LLM) response generation and Together AI for embeddings.\n\n2. **Technical Details**:  \n- Uses a `ResponseBeautifier` class instantiated with a chosen LLM provider to enhance query responses.  \n- Constructs a `GitHubLLMOrchestrator` that integrates a vector query service and the beautifier to handle queries and generate refined responses.  \n- Implements provider selection logic with fallback to an in-memory vector database if the configured provider is unavailable.  \n- Logging is used extensively to track initialization steps and configuration decisions.\n\n3. **Business Logic**:  \nEnables efficient and high-quality querying and indexing of GitHub repositories by combining vector search capabilities with advanced LLM-based response generation, improving developer productivity and insight extraction from code repositories.\n\n4. **Dependencies**:  \n- Azure LLM services (for response generation).  \n- Together AI (for embeddings).  \n- Custom classes/modules: `ResponseBeautifier`, `GitHubLLMOrchestrator`, and `query_service`.  \n- A logging framework for operational visibility.\n\n5. **Configuration**:  \n- `settings.beautify_provider` and `settings.llm_provider` determine the LLM provider, defaulting to \"azure\" if unset.  \n- `settings.vector_db_provider` configures the vector",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:07.316376",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_10": {
      "chunk_id": "vector_db_api.py:chunk_10",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "a580b4fe5f24b9d203d2aa8480b1758c43dd59f4680ecebf8eb3e7b50db45088",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code provides an API endpoint (`/status`) to report the health and status of a vector database system used for managing and querying vector embeddings, specifically for a collection named `github_repos`. It also logs initialization status of various components involved in the vector DB ecosystem.\n\n2. **Technical Details**:  \n- Uses asynchronous FastAPI route handler (`@router.get(\"/status\")`) to serve status information.  \n- Checks the health of the vector database via an async `health_check()` method.  \n- Retrieves collection statistics asynchronously using `get_collection_stats(\"github_repos\")`.  \n- Uses structured logging to report initialization states of components like embedding service, query service, orchestrator, and GitHub client.  \n- Uses a `VectorDBStatus` data model (likely a Pydantic model) to structure the API response.  \n- Implements a try-except block to handle initialization failures and reset global state variables.\n\n3. **Business Logic**:  \nThe code supports monitoring and operational visibility of a vector database system that powers semantic search or embedding-based queries over GitHub repositories. This enables the business to ensure the vector DB and its related services are properly initialized and healthy, which is critical for delivering reliable search or recommendation features.\n\n4. **Dependencies**:  \n- FastAPI for API routing and async endpoint handling.  \n- A vector database client/library exposing async methods like `health_check()` and `get_collection_stats()`.  \n- An",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:13.903618",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_12": {
      "chunk_id": "vector_db_api.py:chunk_12",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "346406acd6837029503854cf9bc31b12a4630952984bfac429ffc0658c0ca17f",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/examples` that returns a static list of example GitHub repositories intended for indexing. It is part of a vector database interface module that also includes health/status checks for embedding services.\n\n2. **Technical Details**:  \n- Uses Python `async` functions with `await` for asynchronous operations.  \n- Defines a FastAPI router endpoint (`@router.get(\"/examples\")`) to serve HTTP GET requests.  \n- Returns a JSON object containing a list of dictionaries, each representing a repository with metadata fields such as owner, repo name, branch, description, and size.  \n- Exception handling is implemented around other parts of the module (not fully shown here) with logging and HTTPException raising.\n\n3. **Business Logic**:  \nProvides clients with predefined example repositories that can be used to demonstrate or bootstrap the indexing process in a vector database system. This helps users quickly test or understand how to integrate repository data for vector embeddings and search.\n\n4. **Dependencies**:  \n- `FastAPI` or a similar ASGI framework for routing and HTTP handling.  \n- An `embedding_service` for health checks (implied but not fully shown).  \n- Logging module for error reporting.  \n- `HTTPException` from FastAPI for error responses.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in the snippet. The active provider type and embedding service are likely configured elsewhere in the application context",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:20.789184",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_14": {
      "chunk_id": "vector_db_api.py:chunk_14",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "e75054cf05042b1360a2bb9a851607ad2b8d1ea63be2c9aa7d7af22a1f1b6922",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/embedding/health` that checks and returns the health status of an embedding service used for vector database operations.\n\n2. **Technical Details**:  \n- Uses FastAPI's `@router.get` decorator to define an asynchronous GET endpoint.  \n- The endpoint calls an asynchronous method `embedding_service.health_check()` to retrieve the service status.  \n- The response includes connection status, provider details, model name, embedding dimension, and API availability.  \n- Raises HTTP exceptions if the embedding service is not initialized or if the connection check fails.\n\n3. **Business Logic**:  \nProvides a health check mechanism for the embedding service, which is critical for applications relying on vector embeddings for search, recommendation, or AI-driven features. Ensures that the embedding backend is operational and correctly configured before processing user requests.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and HTTP exception handling.  \n- An `embedding_service` object/module that encapsulates the embedding provider logic (e.g., Azure or Together AI).  \n- Asynchronous programming constructs (`async/await`).\n\n5. **Configuration**:  \n- The embedding service likely depends on environment variables or configuration files specifying provider credentials, model names, and API endpoints (not shown in the snippet).  \n- Branch and repository metadata hints at configuration for indexing code repositories, possibly related to embedding data sources.\n\n6. **Error Handling**:  \n- Raises `HTTP",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:28.204496",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_16": {
      "chunk_id": "vector_db_api.py:chunk_16",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "1e797bb7a240e9a24fdfa7f0e5eba2724da98616445279318107012f0f25d0f6",
      "chunk_index": 16,
      "summary": "**Summary of Error Handling in `interfaces\\vector_db_api.py`**\n\n1. **Purpose**  \n   The code handles errors related to the health check and usage of an embedding service, specifically detecting when the embedding service is unavailable, unhealthy, or encounters unexpected failures during health checks or embedding generation requests.\n\n2. **Exception Types**  \n   - `HTTPException`: Explicitly raised to signal HTTP error responses with appropriate status codes (e.g., 503 Service Unavailable, 500 Internal Server Error).  \n   - Generic `Exception`: Catches all other unexpected exceptions during health checks or embedding operations to prevent unhandled crashes.\n\n3. **Recovery Strategy**  \n   - No automatic retries are implemented in the shown code.  \n   - On failure, the system raises HTTP exceptions with meaningful status codes and messages to inform clients of service unavailability or internal errors.  \n   - The health check failure leads to a 503 response, signaling clients to potentially retry later.  \n   - The embedding test endpoint checks if the embedding service is initialized before proceeding, raising a 503 if not ready.\n\n4. **Logging**  \n   - Warnings are logged when the embedding service health check fails, including the error message from the health status.  \n   - Errors are logged with detailed messages when unexpected exceptions occur during health checks, aiding monitoring and troubleshooting.\n\n5. **User Impact**  \n   - Clients receive HTTP 503 responses when the embedding service is down or uninitialized, indicating temporary unavailability",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:35.476469",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_18": {
      "chunk_id": "vector_db_api.py:chunk_18",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "3f953d6e09d7783d79b595d7eadef78be5f9baf90c3b8f9763d7f8b8a342b3ff",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an API endpoint that generates vector embeddings for a given text input and optionally returns detailed statistics about the embedding. It also defines a route to list documents from a specified GitHub repository.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to call an embedding service for generating vector embeddings.  \n- Embeddings are numerical vectors representing text, with operations like slicing and statistical calculations (min, max, mean) performed on the embedding list.  \n- The response is a JSON-compatible dictionary including the original text, embedding dimension, model metadata, and optionally a preview of embedding values.  \n- The endpoint is defined using a router decorator (likely FastAPI or similar framework).  \n- Exception handling wraps the embedding generation to log errors and raise HTTP 500 errors.\n\n3. **Business Logic**:  \n- Provides a mechanism to convert repository-related text data into vector embeddings, enabling downstream applications such as semantic search, recommendation, or similarity analysis within GitHub repositories.  \n- The `/repository/{owner}/{repo}/documents` endpoint suggests functionality to retrieve documents from a repository, supporting data exploration or indexing workflows.\n\n4. **Dependencies**:  \n- An `embedding_service` module or object responsible for generating embeddings and providing model metadata.  \n- A web framework router (likely FastAPI) for defining HTTP endpoints.  \n- A logger for error tracking.  \n- HTTPException class for standardized API error responses.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:39.708822",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_20": {
      "chunk_id": "vector_db_api.py:chunk_20",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "63a836252ea1bff2c49e956a9c5e44a0f4f0a96247fae35c1d3a0ea7f9bfbc38",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet retrieves all document names associated with a specific repository from a vector database collection by filtering on repository metadata.\n\n2. **Technical Details**:  \n- Uses an asynchronous search method (`await vector_db.search`) on a vector database interface.  \n- Constructs a dummy embedding vector (all zeros) to bypass vector similarity and rely solely on metadata filtering.  \n- Attempts two metadata keys (`repo_name` and `repository`) to maximize chances of matching documents.  \n- Uses formatted string to create a repository identifier (`owner/repo`).  \n- Logs the operation for observability.\n\n3. **Business Logic**:  \nEnables clients to query documents related to a particular code repository (e.g., GitHub repo) stored in a vector database, facilitating retrieval of repository-specific data for applications like code search, documentation lookup, or portfolio management.\n\n4. **Dependencies**:  \n- `vector_db`: An asynchronous vector database client or interface supporting search with metadata filters.  \n- `embedding_service`: Provides embedding dimension size; fallback dimension is 768 if not available.  \n- `logger`: For logging informational messages.  \n- `HTTPException`: Likely from a web framework (e.g., FastAPI) to handle HTTP error responses.\n\n5. **Configuration**:  \n- The embedding dimension may be configurable via the `embedding_service`.  \n- The vector database connection and initialization status (`vector_db`) must be configured and available before this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:47.341421",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_22": {
      "chunk_id": "vector_db_api.py:chunk_22",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "7a534187c9f14c70884ad46d80cb601f39e525535ebbf87d3b7e05bc7ab6cf30",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis code snippet performs a fallback search query on a vector database using owner and repository metadata filters if the initial search yields no results, then processes and extracts detailed metadata from the search results into a structured list of document information.\n\n2. **Technical Details**:  \n- Uses asynchronous calls (`await`) to query a vector database (`vector_db.search`) with embedding vectors and metadata filters.  \n- Implements a fallback search strategy by retrying with more specific metadata filters (`owner` and `repo`) if the initial search returns empty.  \n- Iterates over search results, extracting metadata fields safely using `hasattr` and `getattr` to handle optional attributes.  \n- Dynamically adds any additional metadata fields found in the `metadata` object's `__dict__`, excluding predefined keys, allowing extensibility of metadata.  \n- Constructs a list of dictionaries (`documents`) representing each document\u2019s metadata and relevance score.\n\n3. **Business Logic**:  \nThis code supports a business need to retrieve relevant documents or code snippets from a vector-based search engine, particularly in contexts like code search or knowledge management systems where documents are associated with owners and repositories. The fallback ensures better search recall by refining the query with owner/repo filters.\n\n4. **Dependencies**:  \n- An asynchronous vector database client or API (`vector_db`) capable of semantic search with embedding vectors.  \n- The `search` method supports parameters like `collection`, `query_embedding`, `top_k`,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:51.586313",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_24": {
      "chunk_id": "vector_db_api.py:chunk_24",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "e6b3aa052a11ce752eebb65dd7d997d8781f73b8cd16f41f5c45e7ce152e1e59",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis code provides API endpoints to interact with a vector database collection, specifically enabling retrieval of documents from a repository and clearing all documents from a specified collection while preserving its structure.\n\n2. **Technical Details**:  \n- Uses asynchronous FastAPI route handlers (`async def`) for non-blocking I/O operations.  \n- Interacts with a vector database abstraction (`vector_db`) to perform document retrieval and deletion.  \n- Returns structured JSON responses including metadata such as repository name, collection name, document count, and filters attempted during document retrieval.  \n- Logging is used for operational insights and error tracking.  \n- Exception handling wraps database operations to catch and log errors, then raise HTTP exceptions with appropriate status codes.\n\n3. **Business Logic**:  \n- Supports document management within vector database collections, enabling clients to fetch documents for indexing, search, or analysis purposes.  \n- Allows clearing a collection\u2019s documents to facilitate re-indexing or refreshing data without dropping the entire collection, preserving collection schema or metadata.\n\n4. **Dependencies**:  \n- FastAPI for API routing and HTTP exception handling.  \n- An external or internal `vector_db` module or service that provides asynchronous methods like `delete_collection`.  \n- Python\u2019s standard logging module for logging information and errors.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show environment variables or config files, but the presence of `vector_db` suggests it is initialized elsewhere, likely configured via environment variables",
      "embedding_id": null,
      "created_at": "2025-10-22T19:10:59.620081",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_26": {
      "chunk_id": "vector_db_api.py:chunk_26",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "27df9315e8e32cbd9c3f2e7cb11bf88dae3d1689396c1299854fa4ba5d93c37e",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet attempts to clear and then recreate a vector database collection with the same dimensionality, logging and returning the outcome of these operations.\n\n2. **Technical Details**:  \n- Uses an asynchronous call (`await`) to `vector_db.create_collection` to create a collection with a specified name and dimension.  \n- The dimension is dynamically retrieved from an `embedding_service` if available; otherwise, it defaults to 768.  \n- Conditional logic handles success or failure of the collection recreation, logging accordingly.  \n- Raises an HTTPException with a 404 status if the collection does not exist or cannot be cleared.  \n- Uses structured return dictionaries to communicate operation results.\n\n3. **Business Logic**:  \nEnsures that a vector database collection can be reset (cleared and recreated) to maintain data integrity or refresh the dataset, which is critical for applications relying on up-to-date vector embeddings for search, recommendation, or machine learning tasks.\n\n4. **Dependencies**:  \n- `vector_db`: An external or internal vector database interface/service with an asynchronous API.  \n- `embedding_service`: Provides vector dimensionality information.  \n- `logger`: For logging informational and warning messages.  \n- `HTTPException`: Likely from FastAPI or a similar web framework for HTTP error handling.\n\n5. **Configuration**:  \n- The dimension defaults to 768 if `embedding_service` is not provided or unavailable, implying a default embedding size configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:10.302975",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_28": {
      "chunk_id": "vector_db_api.py:chunk_28",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "13e5d8fe3a765bd65ba3bf8a11b71aa1302608b8fcd963ca87122c86eb6a45b7",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint to delete documents from a vector database collection, supporting deletion either by specific document IDs or by all documents associated with a given repository.\n\n2. **Technical Details**:  \n- Uses FastAPI's `@router.delete` decorator to expose a DELETE HTTP endpoint at `/documents`.  \n- Accepts a JSON request body parsed as a Python dictionary.  \n- Conditional logic distinguishes between deletion by document IDs (list of strings) or by repository (owner and repo strings).  \n- Uses structured logging to record deletion operations.  \n- Raises HTTP exceptions to communicate errors back to the client.  \n- Relies on an external `vector_db` object for database operations (not fully shown).  \n\n3. **Business Logic**:  \nEnables clients to manage and clean up vector database collections by removing either specific documents or all documents linked to a particular code repository, facilitating data lifecycle management and repository-based data partitioning.\n\n4. **Dependencies**:  \n- FastAPI for API routing and HTTP exception handling.  \n- A `vector_db` instance (likely a custom or third-party vector database client).  \n- A `logger` for logging errors and informational messages.  \n\n5. **Configuration**:  \n- The default collection name is `\"github_repos\"` if not specified in the request.  \n- No explicit environment variables or config files are shown in this snippet, but `vector_db` initialization likely depends on external configuration.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:21.107409",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_30": {
      "chunk_id": "vector_db_api.py:chunk_30",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "9a3265468354f963b1236edf12f8a3c21c590e4786d8818e7213124449de7898",
      "chunk_index": 30,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet attempts to search for and identify documents in a vector database that are associated with a specific repository, in order to later delete or manage those documents.\n\n2. **Technical Details**:  \n- Uses an asynchronous search method (`await vector_db.search`) on a vector database collection.  \n- Constructs a dummy query embedding vector of zeros with a dimension based on the embedding service or a default of 768.  \n- Applies metadata filtering on the search if the vector DB supports filter-based search (`filter_metadata={\"repo_name\": repo_name}`).  \n- Extracts document IDs from the search results if available.  \n- Uses conditional checks with `hasattr` to adapt to different vector DB implementations or capabilities.\n\n3. **Business Logic**:  \nThe code supports the business need to clean up or manage documents related to a specific code repository, likely as part of a data lifecycle management or repository synchronization process. This ensures that documents tied to a repository can be efficiently found and deleted or updated when the repository changes.\n\n4. **Dependencies**:  \n- An asynchronous vector database client (`vector_db`) with a `search` method.  \n- An embedding service (`embedding_service`) providing the embedding dimension.  \n- A logging utility (`logger`) for informational messages.\n\n5. **Configuration**:  \n- The collection name (`collection_name`) and repository name (`repo_name`) are inputs or environment-specific variables.  \n- The embedding dimension is dynamically fetched from",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:30.108055",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_32": {
      "chunk_id": "vector_db_api.py:chunk_32",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "25f4c32e32e9be80e1eebc8c9438b91c6bc92c79165d8bfb27157e1f7d917461",
      "chunk_index": 32,
      "summary": "1. **Purpose**:  \nThis code snippet handles the deletion of documents from a vector database collection, either by searching documents related to a repository or by directly specifying document IDs.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to perform deletion operations on a vector database.  \n- Conditional logic to determine whether to delete documents based on repository metadata (owner and repo) or explicit document IDs.  \n- Logging is used extensively for tracing operations and warnings.  \n- Returns structured JSON-like dictionaries as responses indicating the outcome of the deletion operation.\n\n3. **Business Logic**:  \nEnables cleanup or management of document data associated with specific repositories in a vector database, supporting scenarios like removing outdated or irrelevant documents either by repository context or by explicit document identifiers.\n\n4. **Dependencies**:  \n- `vector_db`: An asynchronous vector database client or interface with a `delete_documents` method.  \n- `logger`: A logging utility for info and warning messages.  \n- `HTTPException`: Likely from a web framework (e.g., FastAPI) to handle HTTP error responses.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet, but the `collection_name` and repository identifiers (`owner`, `repo_name`) are inputs that likely come from external request parameters or configuration.\n\n6. **Error Handling**:  \n- Catches generic `Exception` during document search and logs a warning but proceeds with deletion attempts regardless.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:36.098073",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_34": {
      "chunk_id": "vector_db_api.py:chunk_34",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "869f2a714b8ac46069b19c643409633313ed9ba59414885995ad22620648cf86",
      "chunk_index": 34,
      "summary": "1. **Purpose**  \nThis code defines an API endpoint to delete documents associated with a specific repository from a vector database. It supports deletion either by repository identifier (owner/repo) or by document IDs.\n\n2. **Technical Details**  \n- Implements an asynchronous HTTP DELETE endpoint using a router (likely FastAPI or similar framework).  \n- Constructs a repository identifier string by concatenating `owner` and `repo`.  \n- Uses conditional logic to differentiate between repository-based deletion and document ID-based deletion, updating the response accordingly.  \n- Logs operations and errors for observability.  \n- Raises HTTP exceptions with appropriate status codes for error signaling.\n\n3. **Business Logic**  \nEnables clients to remove all vector database documents tied to a specific GitHub repository, facilitating data cleanup or synchronization when repositories are deleted or updated. This helps maintain data consistency and relevance in applications relying on repository-based vector embeddings.\n\n4. **Dependencies**  \n- `HTTPException` for HTTP error handling (likely from FastAPI).  \n- `logger` for logging events and errors.  \n- `vector_db` service or client instance for interacting with the vector database (not fully shown but implied).  \n- `router` object for defining API routes (likely FastAPI\u2019s APIRouter).\n\n5. **Configuration**  \n- The endpoint accepts a query parameter `collection` with a default value `\"github_repos\"`, indicating the vector database collection to target.  \n- No explicit environment variables or config files are shown",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:44.638017",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_36": {
      "chunk_id": "vector_db_api.py:chunk_36",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "678f9d2ccf45e1ed0ae33365471e5cdd095fee2c0eacf25f15f037a38fe1e511",
      "chunk_index": 36,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code defines an asynchronous API endpoint to delete all documents associated with a specific repository within a named collection in a vector database. It facilitates bulk removal of repository-related data via an HTTP DELETE request.\n\n2. **Technical Details**:  \n- Uses FastAPI-style async route handling (`@router.delete`) for RESTful API design.  \n- Constructs a repository identifier by concatenating `owner` and `repo` strings.  \n- Employs a vector search approach by creating a dummy vector of zeros matching the embedding dimension to query documents related to the repository.  \n- Relies on an external `embedding_service` to determine vector dimensionality, ensuring compatibility with the vector DB schema.  \n- Logging is used extensively for operational transparency.  \n- The actual deletion logic is delegated to a helper function `delete_repository_documents_full_path` for modularity and consistency.\n\n3. **Business Logic**:  \nEnables clients (e.g., internal tools or external services) to programmatically purge all vectorized documents tied to a specific code repository, supporting data lifecycle management, cleanup, or repository deprecation scenarios in applications like code search, recommendation, or analytics platforms.\n\n4. **Dependencies**:  \n- `vector_db`: A vector database interface/service presumed to support document search and deletion.  \n- `embedding_service`: Provides vector embedding dimensions, likely from an ML model or embedding API.  \n- `FastAPI` or similar async web framework for routing",
      "embedding_id": null,
      "created_at": "2025-10-22T19:11:53.688849",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_38": {
      "chunk_id": "vector_db_api.py:chunk_38",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "71cf82b4683d854a6f1782e55a4dc3671c9e896b49d28604a4dde6a6a37a4edd",
      "chunk_index": 38,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code performs a vector similarity search on a vector database collection, attempting multiple metadata filter variations to retrieve relevant documents associated with a given repository name or owner/repo combination.\n\n2. **Technical Details**:  \n- Uses an asynchronous `search` method on a `vector_db` object, likely an interface to a vector similarity search engine.  \n- Employs a large `top_k=10000` parameter to retrieve up to 10,000 nearest neighbors based on a `dummy_vector` embedding query.  \n- Implements a fallback strategy by sequentially trying different metadata filters (`repo_name`, `repository`, then split `owner` and `repo`) to maximize the chance of finding matching documents.  \n- Uses dictionary-based metadata filters to constrain the search results.\n\n3. **Business Logic**:  \nThe code aims to retrieve all relevant documents from a vector database that are linked to a specific code repository, identified by various possible metadata keys. This supports use cases like code search, repository analysis, or knowledge retrieval where repository context is critical.\n\n4. **Dependencies**:  \n- An asynchronous vector database client or SDK (`vector_db`) with a `search` method supporting collection name, query embeddings, top-k results, and metadata filtering.  \n- A logging utility (`logger`) for informational messages.\n\n5. **Configuration**:  \n- `collection_name`: the target vector database collection, likely configured elsewhere.  \n- `dummy_vector`:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:01.066590",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_40": {
      "chunk_id": "vector_db_api.py:chunk_40",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "e98ab859bf7fd54d73003676e79e42947df143a88c7c0d846e92586b935f706c",
      "chunk_index": 40,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet interacts with a vector database to search for documents within a specified collection and repository, logs metadata about the documents found, and deletes documents if certain conditions are met.\n\n2. **Technical Details**:  \n- Uses asynchronous calls (`await`) to interact with a vector database API (`vector_db`).  \n- Performs a vector similarity search with a query embedding (`dummy_vector`) and retrieves top-k results.  \n- Extracts metadata from search results, specifically document IDs (`doc_id`).  \n- Deletes documents by their IDs from the vector database collection.  \n- Uses structured logging to provide detailed runtime information.  \n- Data structures involved include lists for storing search results and document IDs, and dictionaries for returning status messages.\n\n3. **Business Logic**:  \nThe code supports managing document lifecycle in a vector database for a given repository. It helps identify if documents exist for a repository, provides insights into the collection's content via metadata, and facilitates cleanup by deleting documents, thus maintaining data relevance and integrity.\n\n4. **Dependencies**:  \n- `vector_db`: An external or internal asynchronous vector database client/service with methods like `search` and `delete_documents`.  \n- `logger`: A configured logging instance for info-level logs.  \n- Assumes existence of `dummy_vector` (likely a vector embedding) and variables like `collection_name`, `repo_name`, and `search_results`.\n\n5. **Configuration**:  \n- Collection name and repository",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:10.532748",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_42": {
      "chunk_id": "vector_db_api.py:chunk_42",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "95a6ab0169bf2bb87aff41b959faaaa59257e00dfc7cc0f0a10d826a9793012e",
      "chunk_index": 42,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a FastAPI endpoint `/index-repository` designed to index a local code repository into a vector database using advanced code-intelligence features. It also includes logic to delete documents associated with a repository from the vector database.\n\n2. **Technical Details**:  \n- The endpoint is an asynchronous POST handler (`async def index_repository`) that accepts a request payload of type `IndexRepositoryRequest`.  \n- It interacts with a vector database collection to delete documents by their IDs (`doc_ids`) related to a repository.  \n- Uses structured logging (`logger.info`, `logger.error`) to track success or failure of operations.  \n- Raises HTTP exceptions (`HTTPException`) with appropriate status codes and error details for failure scenarios.  \n- The deletion logic checks if documents exist before attempting deletion and returns structured JSON responses indicating success or absence of documents.\n\n3. **Business Logic**:  \n- Enables indexing of source code repositories into a vector database to facilitate code search, analysis, or intelligence features.  \n- Provides the ability to clean up or refresh repository data by deleting existing documents before re-indexing, ensuring data consistency and relevancy.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and HTTP exception handling.  \n- A vector database client or SDK (not fully shown) to manage document storage and deletion.  \n- A logging framework for operational insights.  \n- Pydantic models (implied by `IndexRepositoryRequest`)",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:16.962168",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_44": {
      "chunk_id": "vector_db_api.py:chunk_44",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "1bc776e952149f591f1db586c5434ea555cf6028e01c599ab34136d4dc1a8690",
      "chunk_index": 44,
      "summary": "**Summary of `interfaces\\vector_db_api.py`**\n\n1. **Purpose**  \n   This code snippet is part of a system that processes and embeds source code repositories into a vector database for enhanced code intelligence. It prepares the environment and validates inputs before orchestrating the embedding process.\n\n2. **Technical Details**  \n   - Uses Python's `pathlib.Path` for robust filesystem path handling.  \n   - Dynamically modifies `sys.path` to include a sibling directory (`code-intelligence`) to import the `EmbeddingOrchestrator` module.  \n   - Validates the existence of the repository path before proceeding.  \n   - Logging is used to track the embedding process start and key parameters.  \n   - The snippet references advanced features like Tree-sitter parsing for semantic chunking, incremental updates with caching, and rate limiting, indicating a sophisticated embedding pipeline (though these are not implemented in the snippet itself).\n\n3. **Business Logic**  \n   Enables automated semantic indexing and embedding of code repositories to support advanced code search, summarization, and intelligence features. This helps developers and organizations quickly understand and navigate large codebases, improving productivity and code quality.\n\n4. **Dependencies**  \n   - Standard Python libraries: `sys`, `pathlib.Path`  \n   - Internal module: `embed_repo.EmbeddingOrchestrator` (likely a custom embedding orchestration library)  \n   - Logging (implied by `logger.info`)  \n   - HTTP exception handling (implied by `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:32.979134",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_46": {
      "chunk_id": "vector_db_api.py:chunk_46",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "e8a26c20d62d5babb0dc504f3fa87b9bf9be640334fa1ba5ff4b79d1a5b856e8",
      "chunk_index": 46,
      "summary": "**Summary: Error Handling in `interfaces\\vector_db_api.py`**\n\n1. **Purpose**:  \n   This error handling code is designed to catch failures related to missing dependencies, specifically the inability to import the `code-intelligence` module, which is critical for embedding operations in the vector database API.\n\n2. **Exception Types**:  \n   - Catches `ImportError` exceptions, which occur if the `code-intelligence` module or its dependencies are not installed or cannot be loaded.\n\n3. **Recovery Strategy**:  \n   - The code does not attempt to retry or recover automatically from the import failure. Instead, it raises an HTTP 503 Service Unavailable error to signal that the service is temporarily unable to perform the requested operation due to missing components.\n\n4. **Logging**:  \n   - Logs the import failure as an error with a clear message including the exception details (`logger.error(f\"\u274c Failed to import code-intelligence: {e}\")`), facilitating monitoring and troubleshooting by developers or system operators.\n\n5. **User Impact**:  \n   - End users receive an HTTP 503 response with a descriptive message indicating that the code-intelligence module is unavailable and needs proper configuration. This prevents silent failures and informs users that the service is temporarily down for this functionality.\n\n6. **Fallback**:  \n   - No fallback or default values are provided in case of this error. The operation is aborted, and the user is explicitly informed of the missing dependency,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:42.466821",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_48": {
      "chunk_id": "vector_db_api.py:chunk_48",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "859dbeff778f418f6dc28293eb26384f4a6dfeb6637f0921a1d203397d88abe1",
      "chunk_index": 48,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/semantic-search` that performs semantic search queries over a collection of indexed repositories, returning the most relevant documents based on the input query and optional filters.\n\n2. **Technical Details**:  \n- Uses an asynchronous FastAPI route handler (`@router.post`) to handle POST requests.  \n- Accepts a `SemanticSearchRequest` object containing query parameters such as `query`, `collection`, `top_k`, `repository`, and `language`.  \n- Constructs a filter dictionary dynamically based on optional repository and language parameters.  \n- Invokes an asynchronous `semantic_search` method on a `query_service` object, which likely implements vector similarity search algorithms (e.g., approximate nearest neighbors) over embedded document vectors.  \n- Transforms the search results into a JSON-serializable dictionary format, including document ID, content snippet, relevance score, and metadata (repository name, file path).\n\n3. **Business Logic**:  \nEnables users or downstream services to perform semantic search queries over code repositories or document collections, facilitating efficient retrieval of relevant code snippets or documents based on natural language queries. This supports use cases like code search, knowledge discovery, and developer productivity tools.\n\n4. **Dependencies**:  \n- `FastAPI` for API routing and HTTP exception handling.  \n- A `query_service` module or class that provides the `semantic_search` asynchronous method (likely backed by a vector database or embedding service).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:12:53.506550",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_50": {
      "chunk_id": "vector_db_api.py:chunk_50",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "9e85dfa06b6cba57031c7fd4d667eb4eab2d6ae19431591ee389dcd39f7421bd",
      "chunk_index": 50,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines an asynchronous API endpoint `/query` that processes intelligent queries combining GitHub data and a vector database using LangGraph orchestration, returning a formatted response optimized for large language models (LLMs).\n\n2. **Technical Details**:  \n- Uses FastAPI's `@router.post` decorator to define an async POST endpoint.  \n- Implements a request-to-internal-query conversion pattern, mapping string query types to an enumerated `QueryType`.  \n- Constructs a `QueryRequest` data structure encapsulating query parameters such as query text, type, repository, and max results.  \n- Uses exception handling to catch and log errors, raising HTTP exceptions with appropriate status codes.  \n- Relies on an orchestrator object (`github_llm_orchestrator`) to perform the actual query processing (not shown in snippet).  \n- The response includes metadata such as language and count of results, formatted for LLM consumption.\n\n3. **Business Logic**:  \nEnables advanced search and summarization capabilities over GitHub repositories by integrating semantic and code search with vector database queries, facilitating developer productivity tools such as repository summaries, file explanations, and intelligent code search.\n\n4. **Dependencies**:  \n- FastAPI for API routing and HTTP exception handling.  \n- A logging framework (`logger`) for error reporting.  \n- Custom types and classes: `GitHubLLMQueryRequest`, `QueryRequest`, `QueryType`, and `github",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:04.637940",
      "status": "summarized"
    },
    "vector_db_api.py:chunk_52": {
      "chunk_id": "vector_db_api.py:chunk_52",
      "file_path": "interfaces\\vector_db_api.py",
      "chunk_hash": "decadb238e159fee6e15429727d7a0f4ee15504811d244326f4fa93453cd5666",
      "chunk_index": 52,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet processes a query request through a language model orchestrator (`github_llm_orchestrator`), formats the response with relevant metadata and truncated source content, and returns a structured JSON-like dictionary. It also handles exceptions by logging errors and raising HTTP exceptions.\n\n2. **Technical Details**:  \n- Uses `await` to asynchronously call `process_query` on `github_llm_orchestrator`, indicating an async I/O operation, likely involving network or compute-bound tasks.  \n- Constructs a dictionary response containing fields such as `query`, `summary`, `beautified_response`, `confidence_score`, and `processing_time_ms`.  \n- Iterates over `response.sources` to create a list of source dictionaries, truncating the `content` to 200 characters for brevity.  \n- Exception handling with a broad `except Exception` clause, logging errors and raising an HTTP 500 error via `HTTPException`.\n\n3. **Business Logic**:  \nThe code supports a business function of querying a language model or knowledge base to retrieve summarized, confidence-scored, and source-backed answers. This is useful in applications like intelligent search, knowledge management, or AI-driven customer support where users need concise and credible responses with traceable sources.\n\n4. **Dependencies**:  \n- `github_llm_orchestrator`: a custom orchestrator module or service that processes queries using language models.  \n- `logger`: a logging utility for error tracking",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:12.556634",
      "status": "summarized"
    },
    "azure_provider.py:chunk_0": {
      "chunk_id": "azure_provider.py:chunk_0",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "c0c94021ac0e834dfe3f2cde754de4964806207fa8e7f901470ddf78b4d74968",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines an Azure cloud provider class that unifies multiple Azure AI services\u2014speech-to-text, text-to-speech, translation, and large language model (LLM) capabilities\u2014under a cloud-agnostic interface for seamless integration in multi-cloud AI orchestration.\n\n2. **Technical Details**  \n- Implements multiple inheritance from abstract base classes/interfaces (`CloudProvider`, `STTProvider`, `TTSProvider`, `TranslationProvider`, `LLMProvider`) to provide a unified API for different AI capabilities.  \n- Uses composition by wrapping Azure-specific service clients (`AzureSpeechService`, `AzureTranslationService`, `AzureModelDeploymentService`) to delegate actual AI operations.  \n- Employs type hinting for method signatures and data structures (`ProviderConfig`, `ProviderCapability`) to enforce configuration and capability contracts.  \n- Uses a logger instance for structured logging and debugging.\n\n3. **Business Logic**  \nEnables businesses to leverage Azure\u2019s AI services through a standardized provider interface, facilitating multi-cloud strategy, reducing vendor lock-in, and simplifying integration of speech, translation, and LLM features into applications such as chatbots, transcription services, and multilingual communication tools.\n\n4. **Dependencies**  \n- Python standard library: `base64` for encoding/decoding operations.  \n- Internal shared modules:  \n  - `shared.azure_services.speech_service.AzureSpeechService` for speech-related AI.  \n  - `shared.azure_services.translation_service.AzureTranslationService`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:23.452529",
      "status": "summarized"
    },
    "azure_provider.py:chunk_2": {
      "chunk_id": "azure_provider.py:chunk_2",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "97ee9a44970a632ccb6c846b3bfb150af4805d90fc845e27d919fbb8d4bf3a63",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an Azure cloud provider implementation that initializes various Azure AI services (speech, translation, and model deployment) and checks the availability of these services based on requested capabilities.\n\n2. **Technical Details**:  \n- The class maintains a list of supported capabilities using an enumeration (`ProviderCapability`).  \n- It instantiates service clients for speech, translation, and model deployment, presumably encapsulating Azure SDK interactions.  \n- The `is_available()` method uses conditional logic to route availability checks to the appropriate service client based on the current capability.  \n- Logging is used to track initialization events.\n\n3. **Business Logic**:  \nThis code enables an orchestration layer to dynamically determine if specific Azure AI services (speech-to-text, text-to-speech, translation, etc.) are operational and ready to be used, supporting multi-capability AI workflows such as transcription, translation, and conversational AI.\n\n4. **Dependencies**:  \n- Azure-specific service classes: `AzureSpeechService`, `AzureTranslationService`, `AzureModelDeploymentService`.  \n- An enumeration `ProviderCapability` defining supported capabilities.  \n- A logging framework (likely Python\u2019s standard `logging` module).  \n- Azure SDKs are implied but not explicitly shown here.\n\n5. **Configuration**:  \n- The snippet does not explicitly show environment variables or config files, but the service classes likely rely on Azure credentials and region settings configured externally (e.g., environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:29.384925",
      "status": "summarized"
    },
    "azure_provider.py:chunk_4": {
      "chunk_id": "azure_provider.py:chunk_4",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "570875ef612b1aa7fce0de2bbbf5ddffb2215edbdfc624b16157020180b41c81",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of an Azure cloud provider implementation that manages and exposes the capabilities of Azure-based AI services such as speech recognition, translation, and language models. It includes functionality to check service availability and perform health checks.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for non-blocking operations, particularly in health checks and transcription.  \n- Encapsulates service availability checks via methods like `is_available()` on service objects (`speech_service`, `translation_service`, `model_service`).  \n- Returns structured dictionaries representing the health status of different Azure services.  \n- Uses enumerations (`ProviderCapability`) to represent different capabilities (e.g., LLM_CHAT, LLM_EMBEDDING).  \n- The code snippet shows conditional logic to determine capability availability and a method to retrieve supported capabilities.\n\n3. **Business Logic**:  \nEnables an orchestration layer to interact with Azure AI services by exposing their capabilities and health status, facilitating dynamic decision-making about which services to use based on availability. This supports business needs such as speech transcription, translation, and AI model inference in a cloud-agnostic orchestration framework.\n\n4. **Dependencies**:  \n- Azure AI services (speech, translation, language models) accessed via service wrapper objects (`speech_service`, `translation_service`, `model_service`).  \n- Likely depends on Azure SDKs or custom wrappers for these services (not shown in snippet).  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:34.242355",
      "status": "summarized"
    },
    "azure_provider.py:chunk_6": {
      "chunk_id": "azure_provider.py:chunk_6",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "a463f6fcbb2248c92301914ff848182d91b274302cf2bc8c86b8ead48644544b",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \n   The provided code snippet is part of an Azure cloud provider implementation for speech-to-text (STT), text-to-speech (TTS), and translation services. However, it does not include explicit error handling logic. The methods shown focus on invoking Azure services to transcribe audio, synthesize speech, and translate text, but do not demonstrate how errors during these operations are caught or managed.\n\n2. **Exception Types**:  \n   No specific exceptions are caught or handled within the shown code. The snippet lacks try-except blocks or any form of exception handling, so exceptions raised by the Azure SDK or network failures would propagate up the call stack.\n\n3. **Recovery Strategy**:  \n   Since no error handling is implemented, there is no recovery or retry mechanism present in this code. Failures during service calls would result in unhandled exceptions unless managed by higher-level components.\n\n4. **Logging**:  \n   There is no logging or monitoring code related to error conditions in the snippet. No error messages are logged, and no telemetry or diagnostic hooks are visible.\n\n5. **User Impact**:  \n   Without error handling, any failure in Azure service calls (e.g., network issues, authentication errors, service outages) would likely cause the calling process to fail or raise exceptions. This could lead to degraded user experience, such as failed transcriptions, missing audio synthesis, or untranslated text, without graceful notification or fallback.\n\n6. **Fallback",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:39.048925",
      "status": "summarized"
    },
    "azure_provider.py:chunk_8": {
      "chunk_id": "azure_provider.py:chunk_8",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "a5940502b8a1cfc2ddb9e1900c006b58ca2e9b1b7a94d8810bc66272a28b5914",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides asynchronous methods to interact with Azure cloud services for language translation, language detection, and chat-based AI completions. It acts as an abstraction layer over Azure's Translator and OpenAI services.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle I/O-bound calls to external Azure services efficiently.  \n- Defines methods returning structured results (`TranslationResult`, `LLMResult`) encapsulating response data.  \n- Utilizes data structures such as dictionaries and lists for input/output (e.g., messages as `List[Dict[str, str]]`).  \n- Implements a service-oriented design pattern where `translation_service` and `model_service` are likely injected dependencies handling API calls to Azure.\n\n3. **Business Logic**:  \nEnables applications to perform multilingual translation and language detection, facilitating globalized user experiences. The chat completion method supports conversational AI features, useful for customer support, virtual assistants, or content generation leveraging Azure OpenAI capabilities.\n\n4. **Dependencies**:  \n- Azure Translator service (via `translation_service`) for translation and language detection.  \n- Azure OpenAI service (via `model_service`) for chat completions.  \n- Custom data models like `TranslationResult` and `LLMResult` for structured responses.  \n- Python async features and typing (`List`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- Likely depends on environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:46.243015",
      "status": "summarized"
    },
    "azure_provider.py:chunk_10": {
      "chunk_id": "azure_provider.py:chunk_10",
      "file_path": "orchestration\\cloud_providers\\implementations\\azure_provider.py",
      "chunk_hash": "d6320b80316763a7a87abbc4c5d2b2e6cd74fc1ecc9fb3c67eafef44eacad773",
      "chunk_index": 10,
      "summary": "**Summary of Error Handling in `azure_provider.py` Code Snippet**\n\n1. **Purpose**  \n   The code snippet primarily handles the scenario where a result object from an Azure OpenAI API call may not be in the expected dictionary format. It ensures that downstream processing can continue by extracting or defaulting key fields such as `content`, `model`, `usage`, and `metadata`. It also explicitly marks the embedding generation method as not implemented, signaling incomplete functionality.\n\n2. **Exception Types**  \n   - The snippet does not explicitly catch any exceptions (no `try-except` blocks).  \n   - Instead, it uses conditional logic (`if`/`else`) to handle cases where `result` might not be a dictionary or lacks expected keys.  \n   - The `generate_embedding` method raises a `NotImplementedError` to indicate unimplemented functionality.\n\n3. **Recovery Strategy**  \n   - When `result` is a dictionary, it extracts values safely using `.get()` with defaults.  \n   - When `result` is not a dictionary (or falsy), it converts `result` to string for `content`, sets `usage` to `None`, and provides minimal `metadata`.  \n   - This approach avoids runtime errors from missing keys or unexpected types, allowing the system to continue operating with partial data.  \n   - For embedding generation, the method explicitly fails fast by raising `NotImplementedError`.\n\n4. **Logging**  \n   - The provided snippet does",
      "embedding_id": null,
      "created_at": "2025-10-22T19:13:52.873580",
      "status": "summarized"
    },
    "facade.py:chunk_0": {
      "chunk_id": "facade.py:chunk_0",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "a3b21c475d665f927c6556557fbd84cb5bceb0519517549fb635419a8bdfdda7",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration/facade.py`:**\n\n---\n\n1. **Purpose**  \n   This module provides a unified facade class, `OrchestrationFacade`, that orchestrates a multi-step pipeline for processing natural language messages. It sequentially parses messages, enriches context, builds prompts, and interacts with a language model agent to generate responses.\n\n2. **Technical Details**  \n   - Implements the *Facade* design pattern to abstract and simplify interaction with multiple subsystems: `MessageParser`, `ContextEnricher`, `PromptBuilder`, and `LangGraphAgent`.  \n   - Uses asynchronous processing (indicated by `await` in usage example) to handle potentially I/O-bound operations such as API calls or database queries.  \n   - Relies on typed data models (`ParsedMessage`, `EnrichedContext`, `FormattedPrompt`, `AgentTask`) to enforce structured data flow between pipeline stages.  \n   - Dependency injection is used for `ServiceManager` and optionally `LLMFactory` to promote modularity and testability.\n\n3. **Business Logic**  \n   The facade addresses the business need to automate complex natural language understanding and response generation workflows, such as analyzing issue descriptions or commands in software repositories. It streamlines the integration of parsing, context enrichment, prompt formulation, and language model interaction to deliver actionable insights or automated responses.\n\n4. **Dependencies**  \n   - Internal modules:  \n     - `orchestration.message_parser.MessageParser`  \n     -",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:04.280508",
      "status": "summarized"
    },
    "facade.py:chunk_2": {
      "chunk_id": "facade.py:chunk_2",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "f7664fcf53b74aba15df2a6a7520afb19f73cb0bb1d5ebcdb517565e0368474a",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines a facade class responsible for orchestrating the processing of user messages through a multi-step pipeline, including parsing, context enrichment, prompt building, and task execution using language model agents.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running operations without blocking.  \n- Employs composition by integrating multiple components: `MessageParser`, `ContextEnricher`, `PromptBuilder`, and `LangGraphAgent`.  \n- Uses dependency injection for `service_manager` and optionally for `llm_factory` (defaulting to `LLMFactory()` if not provided).  \n- Logging is used extensively for observability, including structured logs with metadata about the message and processing parameters.  \n- The method `process_message` accepts flexible keyword arguments (`**kwargs`) to allow extensibility.\n\n3. **Business Logic**:  \nThe code supports a business workflow where raw user messages are processed into actionable tasks or responses by leveraging language models and contextual data enrichment. This is likely part of a conversational AI or automation platform that interprets user intents and executes related tasks.\n\n4. **Dependencies**:  \n- Internal modules/classes: `LLMFactory`, `MessageParser`, `ContextEnricher`, `PromptBuilder`, `LangGraphAgent`.  \n- Logging infrastructure (likely Python\u2019s standard `logging` module or a structured logging library).  \n- Asynchronous runtime (e.g., `asyncio`).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:13.994977",
      "status": "summarized"
    },
    "facade.py:chunk_4": {
      "chunk_id": "facade.py:chunk_4",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "3e804f3a528ffbe785d7d7b8fc8d62ab7079e0fdd0a47ec6aef0994c24e06dd2",
      "chunk_index": 4,
      "summary": "**Summary of `orchestration\\facade.py` code snippet**\n\n---\n\n1. **Purpose**  \nThis asynchronous Python code snippet orchestrates a multi-step message processing workflow: it parses an input message to extract references and then enriches the parsed data with additional context.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`await`) to handle potentially I/O-bound operations without blocking.  \n- Employs a facade-like pattern to encapsulate complex processing steps behind a simplified interface.  \n- Utilizes structured logging with emoji-enhanced messages for clear step-by-step traceability.  \n- Works with custom data structures such as `parsed_message` containing `references` and `enriched_context` containing `context_items`.  \n- Iterates over collections (`references`, `context_items`) to log detailed information about each element.\n\n3. **Business Logic**  \nThe code supports a business process that requires extracting structured references (e.g., identifiers, entities) from unstructured input messages and then enriching these references with additional contextual information, likely to improve downstream decision-making, analytics, or automation workflows.\n\n4. **Dependencies**  \n- An asynchronous parser component (`self.parser`) responsible for parsing raw messages.  \n- An asynchronous enricher component (`self.enricher`) that augments parsed data with context.  \n- A logging framework (`logger`) for detailed operational insights.  \n- The snippet implies use of domain-specific types like `ref.type.value` and `ref.normalized_value`, suggesting custom",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:23.123575",
      "status": "summarized"
    },
    "facade.py:chunk_6": {
      "chunk_id": "facade.py:chunk_6",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "43394e1e05ed4d543c896afd1a33c6bbfcf595726e224b2da66b28a5f7e87100",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet logs detailed information about enriched context items and then asynchronously builds a formatted prompt using a specified template. It is part of a multi-step orchestration process that prepares input data for downstream processing, likely in a conversational AI or prompt engineering pipeline.\n\n2. **Technical Details**:  \n- Uses structured logging to trace the enrichment and prompt-building steps, including metadata like source type, source ID, cache hit status, and data previews.  \n- Iterates over a collection (`enriched_context.context_items`) which appears to be a list of context data objects, each with attributes such as `source_type`, `source_id`, `cache_hit`, and `data`.  \n- Calls an asynchronous method `self.prompt_builder.build()` passing enriched context and template parameters, returning a `formatted_prompt` object with `system_prompt` and `user_prompt` strings.  \n- Calculates the combined length of the generated prompt parts, possibly for validation or logging.\n\n3. **Business Logic**:  \nThe code supports building context-aware prompts by enriching input data and formatting it according to a template. This is critical in applications like chatbots, virtual assistants, or AI content generation where dynamic, context-rich prompts improve response relevance and quality.\n\n4. **Dependencies**:  \n- A `logger` instance for structured logging (likely from Python\u2019s `logging` module or a wrapper).  \n- An asynchronous `prompt_builder` component responsible for constructing prompts from enriched context and templates.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:31.039196",
      "status": "summarized"
    },
    "facade.py:chunk_8": {
      "chunk_id": "facade.py:chunk_8",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "7153536a3c2bdb4c4dddca2d403179f5d142fe338d4d4a9c01a0542d8c660d41",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet logs detailed information about the construction of a prompt and then conditionally plans and executes tasks asynchronously using an agent, based on enriched context and user intent.\n\n2. **Technical Details**:  \n- Uses structured logging to output prompt lengths and previews for debugging and traceability.  \n- Asynchronous programming with `await` to call `self.agent.plan_tasks()`, indicating integration with an async agent/task planner.  \n- Data structures involved include `formatted_prompt` (with `system_prompt` and `user_prompt` strings), `enriched_context` (likely a collection with `context_items`), and a list of `tasks`.  \n- Uses keyword arguments (`kwargs`) to flexibly extract `user_intent` or fallback to a default `message`.  \n- Iterates over planned tasks for further processing (not shown in snippet).\n\n3. **Business Logic**:  \nThe code supports a workflow where user input and contextual data are combined into prompts that guide an AI or automated agent to plan and execute tasks. This is likely part of a system automating decision-making or multi-step operations based on user intent, enhancing efficiency and responsiveness.\n\n4. **Dependencies**:  \n- A logging framework (`logger`) for structured logs.  \n- An asynchronous agent component (`self.agent`) with a `plan_tasks` coroutine method.  \n- Data models or classes for `formatted_prompt` and `enriched_context`.  \n- Possibly an async runtime environment (",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:39.349644",
      "status": "summarized"
    },
    "facade.py:chunk_10": {
      "chunk_id": "facade.py:chunk_10",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "8331e0f8e1ebbe45c20ffc270512b545392722b229f01359f62dc2efb1b5ba81",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet logs and executes a sequence of tasks using an agent, capturing detailed input and output information for each task during orchestration.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to execute tasks sequentially.  \n- Iterates over a list of `tasks`, logging metadata (type, description, parameters) before execution.  \n- Collects results in a list (`results`) after each task execution.  \n- Uses structured logging with emojis and indentation for clarity.  \n- Inspects task results, particularly if they are dictionaries, to log individual key-value pairs.  \n- The `agent.execute(task)` method suggests a command or strategy pattern where the agent encapsulates task execution logic.\n\n3. **Business Logic**:  \nEnables orchestration of multiple discrete tasks, likely representing business operations or workflows, ensuring each task is executed in order with comprehensive logging for auditability and traceability.\n\n4. **Dependencies**:  \n- `logger`: A logging utility, likely Python\u2019s standard `logging` module or a wrapper.  \n- `self.agent`: An external or internal service/component responsible for executing tasks asynchronously.  \n- `tasks`: A list of task objects, each with attributes like `task_type`, `description`, and `parameters`.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are visible in the snippet. Configuration may be external to this code, such as logger setup or agent initialization.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:49.081093",
      "status": "summarized"
    },
    "facade.py:chunk_12": {
      "chunk_id": "facade.py:chunk_12",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "b7f717338fdf3f2449eccac9433e02a47577f720171206306ad945ea54ea65e9",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an orchestration pipeline that logs the execution status of a series of planned tasks, summarizes their outcomes, and returns a structured result containing parsed input, enriched context, task plans, and execution results.\n\n2. **Technical Details**:  \n- Uses list comprehensions to filter and count tasks by status (e.g., counting completed tasks).  \n- Employs structured logging with contextual metadata to provide detailed runtime information.  \n- Truncates task result values to a preview length (150 characters) for concise logging.  \n- Returns a dictionary aggregating multiple related objects and metadata for downstream consumption.\n\n3. **Business Logic**:  \nThe code supports a business process that involves parsing input messages, enriching context, planning tasks, and executing them in sequence. It ensures visibility into task execution success and provides a comprehensive summary of the orchestration pipeline's results, which is critical for monitoring and auditing automated workflows.\n\n4. **Dependencies**:  \n- A `logger` instance for structured logging (likely from Python\u2019s `logging` module or a wrapper).  \n- Data structures such as `parsed_message`, `enriched_context`, `tasks`, and `results` which appear to be custom domain objects or models defined elsewhere in the orchestration system.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are visible in this snippet. Configuration might be external to this code, such as logging settings or orchestration parameters.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T19:14:59.015876",
      "status": "summarized"
    },
    "facade.py:chunk_14": {
      "chunk_id": "facade.py:chunk_14",
      "file_path": "orchestration\\facade.py",
      "chunk_hash": "644abea71e3df9934be038f953c16e56f58b3b243f47cbfa3924e7208b66c8d9",
      "chunk_index": 14,
      "summary": "**Summary of `orchestration\\facade.py`**\n\n---\n\n1. **Purpose**  \nThis code defines an asynchronous facade class that orchestrates a multi-step message processing pipeline, including parsing, enriching, prompt building, and task execution. It modularizes each step to allow independent invocation and customization.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle potentially I/O-bound operations efficiently.  \n- Implements a facade design pattern to provide a simplified interface over complex subsystems: parser, enricher, prompt builder, and agent executor.  \n- Supports partial execution of pipeline steps (`parse_only`, `enrich_only`, `build_prompt_only`, `execute_task_only`) enabling flexible workflow composition.  \n- Uses method overloading with default parameters and variable keyword arguments (`**kwargs`) for extensibility.  \n- Caching mechanism hinted via `clear_cache()` method on the enricher component, suggesting internal state or memoization.\n\n3. **Business Logic**  \nThe code supports a business workflow where incoming messages are processed through parsing, contextual enrichment, prompt formatting, and task execution\u2014likely in an AI or automation context (e.g., chatbot orchestration, automated agent workflows). It enables modular processing to improve maintainability and customization for different message types or business rules.\n\n4. **Dependencies**  \n- Internal components/interfaces: `parser`, `enricher`, `prompt_builder`, `agent` (likely classes or services defined elsewhere in the codebase).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:07.276767",
      "status": "summarized"
    },
    "repository_registry.py:chunk_0": {
      "chunk_id": "repository_registry.py:chunk_0",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "15e524e07db2ee5a4819cc41e453b5355616d45c2e961c6a860129ad04a3e147",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a `RepositoryRegistry` class that maintains a registry of known GitHub repositories and provides intelligent, fuzzy matching capabilities to resolve partial or case-insensitive repository names to their full owner/repo paths.\n\n2. **Technical Details**  \n- Uses Python dictionaries (`Dict[str, str]`) to store known repositories and cache mappings from repo names to full paths.  \n- Employs fuzzy string matching via `difflib.SequenceMatcher` to score similarity between input repo names and known repos for partial or approximate matches.  \n- Implements case-insensitive matching by normalizing repo names.  \n- Contains a cache rebuild mechanism (`_rebuild_cache`) to optimize lookup performance.  \n- Uses standard logging for traceability.\n\n3. **Business Logic**  \nSolves the problem of identifying and resolving repository names that may be incomplete, misspelled, or case-variant in user inputs or integrations. This improves user experience and integration reliability by automatically matching partial repo names to known repositories, reducing manual errors and lookup failures.\n\n4. **Dependencies**  \n- Standard Python libraries: `logging`, `typing` (for type hints), `difflib` (for fuzzy matching), and `re` (likely for regex operations, though not fully shown here).  \n- No external third-party libraries are used in the provided snippet.\n\n5. **Configuration**  \n- Known repositories are intended to be populated from external sources such as user configurations or an \"IntegrationsHub",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:19.707136",
      "status": "summarized"
    },
    "repository_registry.py:chunk_2": {
      "chunk_id": "repository_registry.py:chunk_2",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "4c92f6e062417022a158a343c44c0475bf8bc0385b90b033a7f708b036c1c497",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code manages a registry of known GitHub repositories by allowing registration from URLs or owner/repo pairs, maintaining an internal cache for efficient lookup and enabling repository search by partial names.\n\n2. **Technical Details**:  \n- Uses a dictionary `_known_repos` keyed by lowercase repository names to store full repository paths.  \n- Employs regex matching to parse GitHub URLs and extract owner/repo components.  \n- Implements a cache rebuild method `_rebuild_cache` to maintain a lookup dictionary `_repo_name_to_full` for quick access.  \n- Supports bulk registration by iterating over a list of repository dictionaries.  \n- The `find_repository` method (partially shown) suggests use of fuzzy matching or threshold-based search for partial name resolution.  \n\n3. **Business Logic**:  \nFacilitates centralized management and lookup of GitHub repositories within an orchestration or message parsing system, enabling components to reference repositories by partial or full names reliably and register new repositories dynamically.\n\n4. **Dependencies**:  \n- Python standard library modules: `re` for regex operations, `logging` for logging info messages.  \n- Type hints from `typing` module (`List`, `Dict`, `Optional`).  \n- Presumably a logger instance (`logger`) configured elsewhere in the application.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in the snippet. Configuration likely involves initializing the registry with known repositories and setting logging levels externally",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:31.827263",
      "status": "summarized"
    },
    "repository_registry.py:chunk_4": {
      "chunk_id": "repository_registry.py:chunk_4",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "1930339448d3ff68c9e9a44531448b567b7d057c27dbbb41778aff892523a51e",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet implements a method to find a repository by a partial name using exact and fuzzy matching techniques, returning detailed match information including confidence scores.\n\n2. **Technical Details**:  \n- Uses a dictionary `_repo_name_to_full` for exact name lookups (mapping lowercase repo names to full repository paths).  \n- Iterates over `_known_repos` dictionary to perform fuzzy matching by calculating similarity scores between the partial input and known repository names.  \n- Applies a similarity threshold and boosts similarity if the partial name is a substring of the repository name.  \n- Returns a dictionary containing owner, repository name, full path, confidence score, and match type.  \n- Uses string normalization (lowercasing and trimming) to improve matching accuracy.  \n- Relies on a helper method `_calculate_similarity` (likely implementing a string similarity algorithm such as Levenshtein or SequenceMatcher).\n\n3. **Business Logic**:  \nEnables flexible repository identification from partial or approximate user input, improving user experience in systems where exact repository names may not be known or typed correctly. This supports workflows like automated code analysis, CI/CD orchestration, or repository metadata extraction.\n\n4. **Dependencies**:  \n- Internal dictionaries `_repo_name_to_full` and `_known_repos` presumably populated elsewhere in the class or module.  \n- A logging utility (`logger`) for informational output.  \n- A similarity calculation method `_calculate_similarity` (implementation not shown).  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:40.668609",
      "status": "summarized"
    },
    "repository_registry.py:chunk_6": {
      "chunk_id": "repository_registry.py:chunk_6",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "ace2096602fddda7da3ef7811b3c99d20cd7a2d090d73bb56d4529adad2943ea",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a repository registry extractor that performs fuzzy matching to identify the best matching repository given a partial repository name. It calculates similarity scores between strings to find the closest repository match above a defined threshold.\n\n2. **Technical Details**:  \n- Uses a fuzzy matching approach based on multiple string similarity strategies: sequence matching, substring matching, token matching (handling delimiters like dashes, underscores, spaces), and compound word matching.  \n- Normalizes input strings by removing spaces, dashes, and underscores and converting to lowercase before comparison.  \n- Maintains a running best similarity score (`best_score`) and updates the best match dictionary when a higher similarity above the threshold is found.  \n- Logs the matching result with confidence scores using structured logging (`logger.info` and `logger.debug`).  \n- The method `_calculate_similarity` encapsulates the similarity calculation logic.\n\n3. **Business Logic**:  \nEnables robust identification of repository names from partial or imprecise inputs, improving user experience or automation workflows that rely on repository lookup. This is useful in scenarios like code orchestration, dependency resolution, or analytics where exact repository names may not be known or consistently formatted.\n\n4. **Dependencies**:  \n- Uses a `logger` for logging informational and debug messages (likely Python\u2019s standard `logging` module or a wrapper).  \n- The snippet does not show external libraries explicitly, but fuzzy matching often relies on libraries like `difflib",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:48.094756",
      "status": "summarized"
    },
    "repository_registry.py:chunk_8": {
      "chunk_id": "repository_registry.py:chunk_8",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "0de5bc1cd0a63bfd9cc21a9f31ad1880b82dd0bdad64b2135de97621ec505ce5",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet implements a string similarity scoring mechanism to compare two repository names or identifiers, normalizing and tokenizing them to determine how closely they match.\n\n2. **Technical Details**:  \n- Uses string normalization by removing spaces, hyphens, and underscores for exact matching.  \n- Employs `SequenceMatcher` from Python\u2019s `difflib` module to compute a basic sequence similarity ratio.  \n- Tokenizes strings by splitting on hyphens, underscores, and whitespace, then calculates token overlap ratio.  \n- Adds a substring presence bonus score if one string is contained within the other.  \n- Begins logic for compound word matching by checking if a multi-token repository name contains tokens from the other string.  \n- Uses sets for token comparison to efficiently compute intersections.\n\n3. **Business Logic**:  \nDesigned to robustly match user input or external references to registered repository names despite variations in formatting (e.g., \"market data\" vs. \"market-data\" vs. \"marketdata\"). This improves repository lookup accuracy in an orchestration or message parsing context where repository names may be input inconsistently.\n\n4. **Dependencies**:  \n- Python standard library: `difflib.SequenceMatcher` for sequence similarity.  \n- `re` module for regular expression-based tokenization.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. Behavior appears hardcoded.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:15:57.867591",
      "status": "summarized"
    },
    "repository_registry.py:chunk_10": {
      "chunk_id": "repository_registry.py:chunk_10",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "ccf861c60c07c079fa542d3208193a07c24e851a8f7e150f60eb8f11090a2bec",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a repository registry system that matches user input strings against registered repository names to determine similarity scores, manages the collection of known repositories, and supports clearing and loading repository data.\n\n2. **Technical Details**:  \n- Uses tokenization and normalization of input strings to identify \"significant tokens\" (tokens longer than 2 characters).  \n- Implements a compound matching algorithm that checks if all significant tokens from a registered repository appear in the user input, boosting the confidence score if true.  \n- Combines multiple scoring metrics (`seq_score`, `token_score`, `substring_score`) with weighted averages when compound matching fails.  \n- Maintains an internal dictionary `_known_repos` to store repository identifiers and their names.  \n- Provides methods to retrieve all registered repositories (`get_all_repositories`), clear the registry (`clear`), and load repositories from a configuration (`load_from_config`).  \n- Uses logging to record significant state changes (e.g., clearing the registry).\n\n3. **Business Logic**:  \nEnables robust identification and matching of repository names from user inputs, improving the accuracy of repository recognition in orchestration or automation workflows. This helps in scenarios like routing commands, fetching repository-specific data, or triggering repository-related processes based on user queries.\n\n4. **Dependencies**:  \n- Python standard libraries (e.g., `logging` for `logger.info`).  \n- Likely depends on other parts of the system for tokenization",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:07.303437",
      "status": "summarized"
    },
    "repository_registry.py:chunk_12": {
      "chunk_id": "repository_registry.py:chunk_12",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "acebbe4af96a8b96aa9f682d51a79b4cd2cc4ee3b3abf4e90a22b571795f5bda",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code manages a registry of repositories by loading repository data from configuration, registering repositories, and providing lookup and suggestion capabilities for repository owners.\n\n2. **Technical Details**:  \n- Uses internal data structures such as `_known_repos` (likely a list or dict) and `_repo_name_to_full` (a dictionary mapping repository names to full details) to store repository information.  \n- Supports loading repositories from a config that can be either a list or a dictionary, handling both bulk registration and individual registration.  \n- Implements Python special methods `__len__` and `__contains__` to allow intuitive usage of the registry object (e.g., `len(registry)` and `repo_name in registry`).  \n- Provides a method `suggest_owner` that attempts to find and return the owner of a given repository name, returning `None` if not found.  \n- Uses a singleton pattern with a global instance `_global_registry` and accessor `get_global_registry()` to provide a shared registry instance.\n\n3. **Business Logic**:  \nEnables centralized management and lookup of repository ownership information, which is critical for orchestrating workflows, permissions, or integrations that depend on knowing repository owners within an organization or system.\n\n4. **Dependencies**:  \nNo explicit external libraries or services are shown in the snippet. It likely depends on standard Python data structures and possibly other parts of the `RepositoryRegistry` class not shown here.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:12.215578",
      "status": "summarized"
    },
    "repository_registry.py:chunk_14": {
      "chunk_id": "repository_registry.py:chunk_14",
      "file_path": "orchestration\\message_parser\\extractors\\repository_registry.py",
      "chunk_hash": "aa87286bc1d77dce43dfd3666e24bf293737c6d797a9a932bd9160840ed3a7aa",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**  \nThis code snippet initializes and manages a global repository registry by preloading it with a set of default repositories commonly referenced within the system.\n\n2. **Technical Details**  \n- Uses a singleton-like pattern with a global registry instance accessed via `get_global_registry()`.  \n- Defines a function `initialize_default_repositories()` that registers a list of default repositories in bulk using `registry.bulk_register()`.  \n- The default repositories are represented as dictionaries containing `owner` and `repo` keys.  \n- Logging is used to confirm successful initialization.  \n- The initialization function is called automatically at module load time to ensure the registry is populated immediately.\n\n3. **Business Logic**  \nThis code supports a business need to maintain a centralized and consistent repository registry, which likely facilitates repository lookup, validation, or orchestration tasks in a larger system managing multiple code repositories or data sources.\n\n4. **Dependencies**  \n- Assumes existence of `_global_registry` and `get_global_registry()` function elsewhere in the codebase.  \n- Uses a `logger` object for logging informational messages.  \n- Relies on the `bulk_register` method of the registry object to add repositories efficiently.\n\n5. **Configuration**  \n- The list of default repositories is hardcoded but can be overridden by user configuration (implied by the comment).  \n- No explicit environment variables or external config files are referenced in this snippet.\n\n6. **Error Handling**  \n- No explicit error handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:19.870227",
      "status": "summarized"
    },
    "intent_classifier.py:chunk_0": {
      "chunk_id": "intent_classifier.py:chunk_0",
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "chunk_hash": "31e70190da1fb644f5125792c44b5ee116d6c2e522f4fcdd905fa556ca929d6b",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module implements an intent classifier for a voice assistant, leveraging a large language model (LLM) to interpret user speech input and determine the appropriate orchestration workflow to handle the request.\n\n2. **Technical Details**  \n- Uses a Pydantic `BaseModel` (`Intent`) to define a structured representation of classified intents, including intent type, confidence score, extracted entities, and target orchestration.  \n- The `IntentClassifier` class encapsulates the classification logic and interacts asynchronously with a resilient LLM orchestrator (`ResilientLLMOrchestrator`) to process user input and conversation context.  \n- Intent types are predefined as categorical strings (`commit`, `github_query`, `general`, `help`), supporting domain-specific routing.  \n- Logging is used for lifecycle events (e.g., initialization).\n\n3. **Business Logic**  \nThe code addresses the business need to accurately interpret voice commands related to software development workflows (e.g., committing code, querying GitHub repositories) and general assistant queries, enabling seamless, context-aware voice interactions that route requests to specialized orchestration handlers.\n\n4. **Dependencies**  \n- `pydantic` for data validation and structured intent modeling.  \n- `shared.llm_providers.resilient_orchestrator.ResilientLLMOrchestrator` for robust interaction with underlying LLM services.  \n- Standard Python libraries: `logging`, `typing` for type annotations.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:29.407596",
      "status": "summarized"
    },
    "intent_classifier.py:chunk_2": {
      "chunk_id": "intent_classifier.py:chunk_2",
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "chunk_hash": "716655361315993f94546a2069258a3cea6e19aac22acc34cd85fa3f39e1a025",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method classifies the user's spoken input into an intent type by leveraging a large language model (LLM). It returns an Intent object containing the intent type, confidence score, and any extracted entities to guide downstream voice assistant actions.\n\n2. **Technical Details**:  \n- Uses prompt engineering to build a classification prompt combining the current user input and conversation history.  \n- Calls an LLM's `generate` method asynchronously with controlled parameters (`max_tokens=200`, `temperature=0.3`) to produce consistent intent classification results.  \n- Parses the LLM's textual response into a structured Intent object via a helper method.  \n- Logging is used for traceability of classification attempts and outcomes.  \n- Implements a try-except block to handle runtime exceptions during LLM invocation or parsing.\n\n3. **Business Logic**:  \nEnables a voice assistant to understand user intents accurately by interpreting transcribed speech within conversational context. This classification is critical for routing user requests to appropriate business workflows or services, improving user experience and operational efficiency.\n\n4. **Dependencies**:  \n- An LLM interface (`self.llm`) capable of asynchronous text generation.  \n- A logger for info and error messages.  \n- Custom `Intent` data structure or class for encapsulating classification results.  \n- Internal helper methods `_build_classification_prompt` and `_parse_intent_response`.\n\n5. **Configuration**:  \n- LLM generation parameters such as",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:41.094541",
      "status": "summarized"
    },
    "intent_classifier.py:chunk_4": {
      "chunk_id": "intent_classifier.py:chunk_4",
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "chunk_hash": "387554345fbf5dd6dda8338ac14ede009d1090b5f405ec032c42dd2de9390763",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet defines a method to construct a prompt string for a large language model (LLM) that classifies user intents in a voice-controlled AI assistant. It guides the LLM to categorize user input into predefined intent types and extract relevant entities.\n\n2. **Technical Details**:  \n- The method `_build_classification_prompt` takes user input and optional conversation history as parameters and returns a formatted prompt string.  \n- The prompt instructs the LLM to classify intents into four categories (`commit`, `github_query`, `general`, `help`) and extract entities (`repository`, `branch`, `action`).  \n- The prompt enforces a strict response format for downstream parsing.\n\n3. **Business Logic**:  \n- Enables the voice assistant to understand and categorize user commands related to software development workflows, particularly GitHub operations and general queries.  \n- Facilitates accurate intent recognition to trigger appropriate assistant actions, improving user experience and operational efficiency.\n\n4. **Dependencies**:  \n- Implicit dependency on a large language model API or service (e.g., OpenAI GPT) to process the prompt and generate intent classifications.  \n- No explicit external libraries shown in the snippet.\n\n5. **Configuration**:  \n- No environment variables or configuration files are referenced in this snippet.  \n- The prompt content itself acts as a static configuration for the classification behavior.\n\n6. **Error Handling**:  \n- No explicit error handling or exception management is present in this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:16:51.035324",
      "status": "summarized"
    },
    "intent_classifier.py:chunk_6": {
      "chunk_id": "intent_classifier.py:chunk_6",
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "chunk_hash": "820960347e2b55c51fa0c1627f1c5d70ead00207c8b2eabfa0b74d59433dcd97",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \n   The error handling in this code focuses on safely parsing the response from a large language model (LLM) that classifies user intents. It aims to handle malformed or unexpected response formats, particularly when extracting confidence scores.\n\n2. **Exception Types**:  \n   - Catches `ValueError` exceptions that may occur when converting the confidence score string to a float.\n\n3. **Recovery Strategy**:  \n   - If a `ValueError` occurs during confidence parsing, the code recovers by assigning a default confidence value of `0.7`.  \n   - Other parsing steps do not explicitly handle exceptions, implying reliance on the input format or upstream validation.\n\n4. **Logging**:  \n   - There is no explicit error logging or monitoring in the provided snippet. Errors during parsing are silently handled without logging.\n\n5. **User Impact**:  \n   - Users are unlikely to experience direct errors or interruptions due to parsing issues.  \n   - However, if the confidence score is malformed, the system defaults to a moderate confidence (0.7), which may affect downstream decision-making or intent handling subtly.\n\n6. **Fallback**:  \n   - Default intent type is set to `\"general\"`.  \n   - Default confidence is set to `0.7` if parsing fails.  \n   - Entities dictionary is initialized empty and populated only if valid data is found.  \n   - This approach ensures graceful degradation when the LLM response is incomplete",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:00.894073",
      "status": "summarized"
    },
    "intent_classifier.py:chunk_8": {
      "chunk_id": "intent_classifier.py:chunk_8",
      "file_path": "orchestration\\voice_assistant\\intent_classifier.py",
      "chunk_hash": "78f06410b11082716ae0492d5b72c2ef5592071a24d0ab1e7aaee55c425c0f6a",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet processes parsed intent data from a voice assistant input, extracting relevant entities and mapping the detected intent type to a corresponding orchestration workflow for further handling.\n\n2. **Technical Details**:  \n- Uses string parsing to extract entities such as \"branch\" and \"action\" from input lines.  \n- Employs a dictionary (`orchestration_map`) to map intent types (e.g., \"commit\", \"github_query\") to specific orchestration workflows.  \n- Returns an `Intent` object encapsulating the intent type, confidence score, extracted entities, and the selected orchestration.\n\n3. **Business Logic**:  \nEnables the voice assistant to classify user intents and route them to appropriate backend workflows, such as committing code changes or querying GitHub, thereby automating and streamlining user requests in a development or DevOps context.\n\n4. **Dependencies**:  \n- Assumes existence of an `Intent` class or data structure (likely a custom model) to represent the intent object.  \n- No explicit external libraries or services are referenced in this snippet.\n\n5. **Configuration**:  \n- The orchestration mapping is hardcoded within the method, with no external configuration or environment variables influencing behavior in this snippet.\n\n6. **Error Handling**:  \n- No explicit error handling is present; the code assumes well-formed input lines and valid intent types.  \n- Default orchestration is set to `\"general_llm\"` if",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:08.540341",
      "status": "summarized"
    },
    "session_manager.py:chunk_0": {
      "chunk_id": "session_manager.py:chunk_0",
      "file_path": "orchestration\\voice_assistant\\session_manager.py",
      "chunk_hash": "2c758adff6ad0672ac8c7deef5bc8363586bf6a6ea51cc46ec861731d7c8b6c7",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code implements a session manager for a voice assistant application, maintaining conversation context and history across multiple user interactions within individual sessions.\n\n2. **Technical Details**  \n- Uses Pydantic `BaseModel` classes (`ConversationTurn` and `VoiceSession`) for structured data validation and management of conversation turns and sessions.  \n- Stores sessions in an in-memory dictionary keyed by `session_id`.  \n- Tracks conversation turns with metadata such as role, content, timestamp, intent, and orchestration used.  \n- Manages session lifecycle with timestamps (`created_at`, `last_activity`) and a configurable session timeout (`session_timeout`).  \n- Designed for context retention by storing arbitrary context data in a dictionary within each session.\n\n3. **Business Logic**  \nEnables the voice assistant to maintain conversational context over multiple turns per user session, improving user experience by remembering past interactions, intents, and relevant context, which is critical for natural and coherent multi-turn dialogues.\n\n4. **Dependencies**  \n- Standard Python libraries: `logging`, `datetime`, `typing`  \n- Third-party library: `pydantic` for data modeling and validation\n\n5. **Configuration**  \n- Session timeout duration is configurable via the `session_timeout_minutes` parameter in the `SessionManager` constructor (default 30 minutes).  \n- No environment variables or external config files are referenced in the provided code snippet.\n\n6. **Error Handling**  \n- No explicit error handling or exception management is",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:13.164531",
      "status": "summarized"
    },
    "session_manager.py:chunk_2": {
      "chunk_id": "session_manager.py:chunk_2",
      "file_path": "orchestration\\voice_assistant\\session_manager.py",
      "chunk_hash": "cd4ff1af09e9de1ee02ccce6b73b7f94c2aacfaf8a1af74c556c5a3fb21304a5",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code manages voice conversation sessions by creating, retrieving, and validating session lifecycles within a voice assistant orchestration system.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.sessions`) to store active `VoiceSession` objects keyed by `session_id`.  \n- Each session tracks creation and last activity timestamps (`created_at`, `last_activity`).  \n- Implements session expiration logic by comparing the current time with the last activity timestamp against a configured timeout (`self.session_timeout`).  \n- Provides methods to create new sessions, retrieve existing sessions, and a combined method to get or create sessions as needed.\n\n3. **Business Logic**:  \nEnsures that voice assistant conversations are stateful and session-based, allowing the system to maintain context across interactions while automatically expiring inactive sessions to free resources and maintain relevance.\n\n4. **Dependencies**:  \n- `datetime` module for timestamp management.  \n- `VoiceSession` class (likely a custom data model representing a voice conversation session).  \n- `logger` for logging informational and warning messages.  \n- Optional typing (`Optional[str]`) indicating use of Python\u2019s `typing` module.\n\n5. **Configuration**:  \n- `self.session_timeout` controls session expiration duration; likely set during `SessionManager` initialization or via configuration files/environment variables (not shown in snippet).  \n- Session IDs and optional user IDs are passed as parameters to manage session uniqueness and user association.\n\n6.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:22.958752",
      "status": "summarized"
    },
    "session_manager.py:chunk_4": {
      "chunk_id": "session_manager.py:chunk_4",
      "file_path": "orchestration\\voice_assistant\\session_manager.py",
      "chunk_hash": "ba3771ebcbdc57f09d504b5288b823f72e73179236b7e9731fbcbebf73febd2f",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code manages conversation sessions for a voice assistant by creating sessions, adding conversational turns, and retrieving recent conversation history to maintain context.\n\n2. **Technical Details**:  \n- Uses a session management pattern where each session holds a list of `ConversationTurn` objects representing individual dialogue exchanges.  \n- Each turn records metadata such as role (user or assistant), content, timestamp, intent, and orchestration method used.  \n- Conversation history retrieval slices the last N turns to provide recent context in a structured format suitable for language model consumption.  \n- Uses Python data structures like lists and dictionaries to store and format conversation data.\n\n3. **Business Logic**:  \nEnables the voice assistant to maintain conversational context across multiple turns, improving interaction quality by tracking dialogue history and user intents. This supports personalized and coherent multi-turn conversations in the voice assistant application.\n\n4. **Dependencies**:  \n- `datetime` module for timestamps.  \n- `logger` for logging informational and error messages.  \n- `ConversationTurn` data structure/class (likely a custom or imported class).  \n- Optional typing hints (`Optional`, `List`, `Dict`) from `typing` module.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in the snippet. Logging configuration and session storage mechanisms are assumed to be set up elsewhere in the application.\n\n6. **Error Handling**:  \n- Checks if a session exists before adding a turn or retrieving history.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:30.859362",
      "status": "summarized"
    },
    "session_manager.py:chunk_6": {
      "chunk_id": "session_manager.py:chunk_6",
      "file_path": "orchestration\\voice_assistant\\session_manager.py",
      "chunk_hash": "995ffc3c94bcc666f635d69590839b984fd8592a3c475fff56982858659adf58",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code manages session context and lifecycle for a voice assistant application, allowing updates and retrieval of session-specific data and cleaning up expired sessions to maintain resource efficiency.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.sessions`) to store session objects keyed by `session_id`.  \n- Each session contains a `context` dictionary for arbitrary key-value pairs relevant to the session state.  \n- `update_context` modifies the session context by adding or updating key-value pairs.  \n- `get_context` retrieves values from the session context with an optional default fallback.  \n- `cleanup_expired_sessions` iterates over all sessions, compares their `last_activity` timestamps against a configured timeout (`self.session_timeout`), and deletes expired sessions.  \n- Logging is used to track context updates and session cleanup operations.\n\n3. **Business Logic**:  \nSupports maintaining conversational state and relevant metadata (e.g., detected repository, last commit) per user session in a voice assistant, enabling personalized and context-aware interactions. Cleaning up expired sessions prevents stale data accumulation and optimizes memory usage.\n\n4. **Dependencies**:  \n- Python standard library: `datetime` for time comparisons.  \n- A `logger` instance for info-level logging (likely from Python\u2019s `logging` module or a custom logger).  \n- Presumably, a `Session` class or similar data structure managing `context` and `last_activity` attributes (not shown in snippet).\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:41.681617",
      "status": "summarized"
    },
    "confluence_client.py:chunk_0": {
      "chunk_id": "confluence_client.py:chunk_0",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "4683bf459fa5cc61445b74fffabbb66a332325cdda3774de92480c74b8e9800b",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\clients\\confluence_client.py`:**\n\n1. **Purpose**  \n   This module defines a `ConfluenceClient` class that encapsulates interaction with Atlassian Confluence, providing an authenticated client for both the official Python SDK (`atlassian-python-api`) and direct REST API calls.\n\n2. **Technical Details**  \n   - Uses the `Confluence` class from the `atlassian` Python package to interact with Confluence.  \n   - Stores credentials and constructs a Basic Authentication header manually (Base64-encoded email:api_token) for direct HTTP requests.  \n   - Initialization pattern: credentials and client setup occur in a private `_initialize_client` method called during instantiation.  \n   - Uses Python typing hints (`Optional`, `Dict`, `Any`, `List`) for clarity and potential static analysis.  \n   - Logging is integrated for warning about missing configuration.  \n   - Imports `aiohttp` and `asyncio` suggesting potential asynchronous HTTP operations (though not shown in the snippet).  \n\n3. **Business Logic**  \n   Enables secure, authenticated access to Confluence resources, likely to automate content retrieval, updates, or integration with other business systems that rely on Confluence as a knowledge base or documentation platform.\n\n4. **Dependencies**  \n   - `atlassian` Python SDK for Confluence API abstraction.  \n   - `aiohttp` and `asyncio` for asynchronous HTTP calls (implied usage).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:17:52.085941",
      "status": "summarized"
    },
    "confluence_client.py:chunk_2": {
      "chunk_id": "confluence_client.py:chunk_2",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "5404beb23f1de674e45e4c5f93580a6600dd08b5078bba554d417cee57f5412d",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines a client wrapper for interacting with Atlassian Confluence via the `atlassian-python-api` library, enabling retrieval of Confluence pages and managing authentication headers.\n\n2. **Technical Details**:  \n- Uses the `Confluence` class from `atlassian-python-api` to create a client instance.  \n- Implements a method `_get_headers` to generate HTTP headers with Basic Authentication for API requests.  \n- Provides an asynchronous method `get_page` to fetch a Confluence page by its ID, expanding specific fields (`body.storage`, `version`).  \n- Uses a boolean check `is_configured` to verify if authentication credentials are set.  \n- Exception handling around client initialization to safely fallback if connection setup fails.\n\n3. **Business Logic**:  \nFacilitates integration with Confluence to programmatically access page content and metadata, supporting business workflows that require automated documentation retrieval, content synchronization, or knowledge management.\n\n4. **Dependencies**:  \n- `atlassian-python-api` library for Confluence API interactions.  \n- `settings` module or object providing configuration values (`confluence_url`, `confluence_email`, `confluence_api_token`).  \n- `logger` for logging informational and error messages.\n\n5. **Configuration**:  \n- Requires environment or configuration settings for:  \n  - `confluence_url`: Base URL of the Confluence instance.  \n  - `confluence_email`:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:02.824427",
      "status": "summarized"
    },
    "confluence_client.py:chunk_4": {
      "chunk_id": "confluence_client.py:chunk_4",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "243590286c8e6dacb0405fae04f565098e80fd77b78c76256b9ef46279b5c2f3",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides asynchronous and synchronous client methods to interact with Confluence pages, specifically to create, retrieve, and update pages within a Confluence space.\n\n2. **Technical Details**:  \n- Uses an asynchronous method (`async def create_page`) for creating pages, indicating integration with async workflows.  \n- Employs dictionary data structures to represent Confluence page attributes such as `id`, `title`, `content`, `version`, and `url`.  \n- Uses formatted strings (f-strings) to construct URLs dynamically based on page and space identifiers.  \n- Implements basic error handling with try-except blocks to catch and log exceptions during API calls.  \n- The client object (`self.client`) is used to interact with Confluence, presumably wrapping REST API calls or SDK methods.\n\n3. **Business Logic**:  \nEnables automated management of Confluence content, allowing business applications to programmatically create, update, and retrieve documentation or knowledge base pages. This supports workflows such as content synchronization, documentation automation, or integration with other business tools.\n\n4. **Dependencies**:  \n- A Confluence client library or SDK (not explicitly shown but implied by `self.client.create_page`).  \n- A logger instance (`logger`) for error and info logging.  \n- A `settings` module or object providing configuration such as `confluence_url`.  \n- Python standard libraries for async support and exception handling.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:12.472306",
      "status": "summarized"
    },
    "confluence_client.py:chunk_6": {
      "chunk_id": "confluence_client.py:chunk_6",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "0b02f3bd723f418d18f74fa407c7616a82059780b4f41129f8e4bb89bab67ecf",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code provides client methods to interact with Confluence pages, specifically to update a page's content and to search for pages using Confluence Query Language (CQL).\n\n2. **Technical Details**:  \n- Uses a client object (likely a Confluence REST API wrapper) to fetch and update pages.  \n- Retrieves the current page version to increment it before updating, ensuring version consistency.  \n- Implements a search method that executes a CQL query with a configurable limit and parses results into a simplified list of dictionaries containing page id, title, and space key.  \n- Uses try-except blocks for error handling and logging.  \n- Data structures include dictionaries for page metadata and lists to aggregate search results.\n\n3. **Business Logic**:  \nEnables automated management of Confluence content by allowing programmatic updates to pages and searching for relevant pages. This supports workflows such as content synchronization, documentation updates, or content discovery within an organization\u2019s Confluence instance.\n\n4. **Dependencies**:  \n- A Confluence client library (not explicitly named here, but likely Atlassian\u2019s Python API or a similar wrapper).  \n- A logger instance for info and error logging.  \n- Python standard libraries for typing (List, Dict, Any).\n\n5. **Configuration**:  \n- The client instance (`self.client`) must be initialized and authenticated outside these methods.  \n- No explicit environment variables or config files shown, but authentication and API endpoint configuration are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:18.293800",
      "status": "summarized"
    },
    "confluence_client.py:chunk_8": {
      "chunk_id": "confluence_client.py:chunk_8",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "7a8583f8a43325404e72896cbf88795cd708f4a26b8c1723d8aded184aeb6013",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code provides a client interface to interact with Atlassian Confluence, enabling operations such as searching pages, adding labels to pages, and retrieving space information.\n\n2. **Technical Details**:  \n- The code uses a client object (likely a wrapper around Confluence REST API) to perform operations.  \n- Methods include iterating over lists (e.g., labels) to apply changes, and list/dictionary comprehensions to transform API responses.  \n- Uses standard Python typing hints (`List`, `Dict`, `Optional`) for method signatures.  \n- Logging is employed for both successful operations and error conditions.  \n- Exception handling is done broadly with `except Exception as e` to catch all errors during API calls.\n\n3. **Business Logic**:  \n- Facilitates content management within Confluence by allowing automated tagging (labels) of pages, which can improve content categorization and retrieval.  \n- Enables retrieval of all accessible spaces and specific space information, supporting navigation and management of Confluence spaces within an organization.\n\n4. **Dependencies**:  \n- A Confluence client library or SDK (not explicitly shown but implied by `self.client` usage).  \n- Python standard libraries such as `logging`.  \n- Typing module for type annotations (`List`, `Dict`, `Any`, `Optional`).  \n- Possibly external configuration or authentication modules to initialize `self.client`.\n\n5. **Configuration**:  \n- The snippet does not show explicit configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:26.568349",
      "status": "summarized"
    },
    "confluence_client.py:chunk_10": {
      "chunk_id": "confluence_client.py:chunk_10",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "04eb8edae38f57c1c3e25bd490dacf3f751829973470880f296fae577e7f9f20",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code provides a client interface to interact with Confluence spaces and pages, enabling retrieval of space details, listing pages within a space, and deleting pages.\n\n2. **Technical Details**:  \n- Uses a client object (`self.client`) to communicate with the Confluence API.  \n- Methods return structured dictionaries or lists of dictionaries representing Confluence entities (spaces and pages).  \n- Employs exception handling to catch and log errors during API calls.  \n- Uses list comprehensions to transform API responses into simplified data structures.  \n- Relies on standard Python data types: dictionaries and lists with type hints (`List[Dict[str, Any]]`).\n\n3. **Business Logic**:  \nSupports content management workflows by allowing applications to programmatically access Confluence space metadata, enumerate pages for display or processing, and delete pages as part of content lifecycle management or cleanup operations.\n\n4. **Dependencies**:  \n- An external Confluence client library or wrapper (`self.client`) that provides methods like `get_space`, `get_all_pages_from_space`, and `remove_page`.  \n- A logging facility (`logger`) for error and info messages.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show configuration, but `self.client` likely requires authentication and endpoint configuration, typically set via environment variables or config files external to this snippet.\n\n6. **Error Handling**:  \n- Catches all exceptions (`Exception`) during API calls.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:35.535109",
      "status": "summarized"
    },
    "confluence_client.py:chunk_12": {
      "chunk_id": "confluence_client.py:chunk_12",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "9b2f0f988324b0c257717d9996dcb21364e31f9582f04be3949eee45f2a378e4",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis Python code provides synchronous and asynchronous methods to test connectivity to a Confluence instance, ensuring that the client can successfully authenticate and communicate with the Confluence API.\n\n2. **Technical Details**:  \n- Implements both synchronous (`test_connection`) and asynchronous (`test_connection_async`) connection tests.  \n- The synchronous method uses a client object's `get_current_user()` method to verify connectivity.  \n- The asynchronous method uses `aiohttp` to send an HTTP GET request to the Confluence REST API endpoint for spaces (`/wiki/rest/api/space`).  \n- Uses async context managers (`async with`) for HTTP session and request handling.  \n- Logging is used for error reporting and informational messages.  \n- Checks for client configuration before attempting connection tests.\n\n3. **Business Logic**:  \nEnsures that the application can reliably connect to a Confluence server, which is critical for any features depending on Confluence data (e.g., documentation retrieval, collaboration tools). This validation helps prevent runtime failures due to misconfiguration or network issues.\n\n4. **Dependencies**:  \n- `aiohttp` for asynchronous HTTP requests.  \n- A Confluence client object (likely a wrapper around Confluence REST API).  \n- A logger instance for logging errors and info messages.\n\n5. **Configuration**:  \n- Requires Confluence credentials and site URL to be configured (implied by `self.is_configured()` and `self.site_url`).  \n- Headers for authentication are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:44.298100",
      "status": "summarized"
    },
    "confluence_client.py:chunk_14": {
      "chunk_id": "confluence_client.py:chunk_14",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "e3f76c17a63bdc9134af74ffb4faaed5018d9a6d59336d5452ceec78f7806083",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods within a Confluence client class to test the connection to a Confluence site and to retrieve a list of Confluence spaces via the Confluence REST API.\n\n2. **Technical Details**:  \n- Uses asynchronous programming with `async`/`await` and `aiohttp` for non-blocking HTTP requests.  \n- Constructs REST API URLs dynamically based on the configured Confluence site URL.  \n- Uses HTTP GET requests with custom headers for authentication or content-type.  \n- Parses JSON responses to extract relevant data (`results` list of spaces).  \n- Logging is used extensively for error reporting.  \n- Returns `None` or `False` to indicate failure states, and valid data on success.\n\n3. **Business Logic**:  \nEnables integration with Atlassian Confluence by programmatically verifying connectivity and retrieving metadata about available spaces. This supports business workflows that require automated access to Confluence content structure, such as documentation management, content synchronization, or analytics.\n\n4. **Dependencies**:  \n- `aiohttp` for asynchronous HTTP client sessions.  \n- `logger` (likely from Python\u2019s `logging` module) for error logging.  \n- The class likely depends on internal methods like `is_configured()` and `_get_headers()` for configuration validation and authentication headers.\n\n5. **Configuration**:  \n- `self.site_url`: Base URL of the Confluence site, presumably set via environment variables or configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:18:51.457890",
      "status": "summarized"
    },
    "confluence_client.py:chunk_16": {
      "chunk_id": "confluence_client.py:chunk_16",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "14e5fce346dc347941ba0d312cd0457c014b853f99a8d6915fbf24bb8fc8fab4",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis Python method `_markdown_to_storage` converts a markdown-formatted string into Confluence's storage format (an XML-like markup) to enable proper rendering of markdown content within Confluence pages.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.sub`) to identify and replace markdown syntax with corresponding Confluence storage format tags.  \n- Converts markdown headers (`#`, `##`, `###`, `####`) into `<h1>` to `<h4>` HTML tags.  \n- Converts fenced code blocks (```lang ... ```) into Confluence's `<ac:structured-macro>` code block macros, embedding the language parameter and code content inside CDATA sections.  \n- Converts markdown bold (`**text**`) and italic (`*text*`) syntax into `<strong>` and `<em>` HTML tags respectively.  \n- The code uses a nested function `replace_code_block` as a callback for regex substitution to handle multi-line code blocks with optional language specifiers.  \n- The method processes the markdown string sequentially applying transformations.\n\n3. **Business Logic**:  \nEnables users or systems to write content in markdown format and automatically convert it to a format compatible with Confluence\u2019s rich text editor and storage system. This facilitates easier content creation, migration, or integration workflows where markdown is preferred but Confluence storage format is required.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regular expressions.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:02.600791",
      "status": "summarized"
    },
    "confluence_client.py:chunk_18": {
      "chunk_id": "confluence_client.py:chunk_18",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "a32ce2e6c73dcd22ac9dfe318e5ef118e85d27a25795d53f9e99763f3a0ba58f",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a Confluence client that asynchronously creates a new Confluence page by converting markdown content into Confluence's storage format and then posting it via the Confluence REST API v1.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.sub`) to transform markdown-style bullet lists (`* item`) into Confluence storage format HTML lists (`<ul><li>item</li></ul>`), merging adjacent lists and converting double line breaks into paragraph tags (`<p>`).  \n- Asynchronous method `create_page_async` constructs a JSON payload with page metadata and content, then sends it to the Confluence REST API endpoint for content creation.  \n- Utilizes Python async/await syntax for non-blocking HTTP requests (implied by async method).  \n- Encapsulates HTTP headers and authentication logic in a helper method `_get_headers()`.  \n- Checks configuration readiness via `is_configured()` before proceeding.\n\n3. **Business Logic**:  \nEnables automated creation of Confluence pages from markdown content, facilitating content management workflows such as documentation publishing, knowledge base updates, or collaborative content generation within an enterprise environment.\n\n4. **Dependencies**:  \n- Python standard library `re` for regex operations.  \n- Async HTTP client (not shown but implied, e.g., `aiohttp` or `httpx`) for making asynchronous REST API calls.  \n- Logging module (`logger`) for error reporting",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:08.777754",
      "status": "summarized"
    },
    "confluence_client.py:chunk_20": {
      "chunk_id": "confluence_client.py:chunk_20",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "fa695da008a267fa41a18364995236f86de36823a590e39095bf8ba3cc158333",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet creates a new page in a Confluence space by sending a POST request with page content and metadata to the Confluence REST API, then processes and returns the created page details.\n\n2. **Technical Details**:  \n- Uses asynchronous HTTP requests via `aiohttp.ClientSession` to interact with the Confluence API.  \n- Constructs a JSON payload including page title, content (in Confluence storage format), and optionally a parent page ID to nest the new page.  \n- Parses JSON response to extract page ID, title, URL, and space key.  \n- Uses structured logging to record success or failure of the page creation operation.\n\n3. **Business Logic**:  \nEnables automated creation and hierarchical organization of Confluence pages within a specified space, facilitating content management workflows such as documentation publishing, knowledge base updates, or collaborative content generation.\n\n4. **Dependencies**:  \n- `aiohttp` for asynchronous HTTP client functionality.  \n- `logger` (likely Python\u2019s `logging` module or a configured logger) for logging operations.  \n- Confluence REST API as the external service endpoint.\n\n5. **Configuration**:  \n- `self.site_url` and `space_key` are used to build API URLs and identify the Confluence space; these are presumably set elsewhere in the class or configuration.  \n- `headers` likely include authentication tokens or API keys (not shown in snippet).  \n- `parent_id` is",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:14.194601",
      "status": "summarized"
    },
    "confluence_client.py:chunk_22": {
      "chunk_id": "confluence_client.py:chunk_22",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "46be63d3f2f3791a74de8b632be57ef4b4313ed22539c73aa00562d25a3f677f",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis Python code defines an asynchronous method to update an existing Confluence page by sending a REST API request to the Confluence server, converting markdown content to Confluence storage format, and incrementing the page version.\n\n2. **Technical Details**:  \n- Uses asynchronous programming with `async`/`await` and `aiohttp` for non-blocking HTTP requests.  \n- Constructs a JSON payload conforming to Confluence's REST API schema, including page metadata and content in storage format.  \n- Converts markdown content to Confluence's storage format via a helper method `_markdown_to_storage`.  \n- Uses a versioning scheme by incrementing the current version number to avoid conflicts.  \n- Employs structured logging for error reporting.  \n- Checks configuration state before proceeding (`is_configured()`).\n\n3. **Business Logic**:  \nEnables automated, programmatic updates to Confluence documentation pages, facilitating continuous content management, collaboration, and integration with other tools or workflows that generate or modify documentation.\n\n4. **Dependencies**:  \n- `aiohttp` for asynchronous HTTP client sessions.  \n- A logger instance (likely from Python\u2019s `logging` module).  \n- Internal helper methods such as `_get_headers()`, `_markdown_to_storage()`, and `is_configured()`.  \n- Confluence REST API endpoint (`/wiki/rest/api/content/{page_id}`).\n\n5. **Configuration**:  \n- `self.site_url` holds the base",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:23.177238",
      "status": "summarized"
    },
    "confluence_client.py:chunk_24": {
      "chunk_id": "confluence_client.py:chunk_24",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "fdf291e1d99f1fdaaa43cf039848a989f4395e6102e12739828fd8b610ec8c65",
      "chunk_index": 24,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous client for interacting with Confluence's REST API, specifically to update and retrieve Confluence pages by their IDs.\n\n2. **Technical Details**:  \n- Uses asynchronous programming with `async/await` to perform non-blocking HTTP requests.  \n- Parses JSON responses from Confluence API to extract page details such as ID, title, URL, and version.  \n- Constructs page URLs dynamically using base site URL and API response links.  \n- Uses structured logging to record success or failure of operations.  \n- Returns structured dictionaries representing page metadata or `None` on failure.\n\n3. **Business Logic**:  \nEnables automated management of Confluence content, such as updating page content and retrieving page information, which supports workflows that require programmatic documentation updates or content synchronization in enterprise environments.\n\n4. **Dependencies**:  \n- An asynchronous HTTP client library (likely `aiohttp` or similar) for making API calls.  \n- A logging framework (`logger`) for capturing operational events.  \n- Internal methods like `self.is_configured()` and `self._get_headers()` suggest dependency on configuration management and authentication handling within the client class.\n\n5. **Configuration**:  \n- Requires `self.site_url` to be set, representing the base URL of the Confluence instance.  \n- Authentication headers are dynamically generated, possibly from stored credentials or tokens.  \n- The client must be properly configured before making",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:34.316076",
      "status": "summarized"
    },
    "confluence_client.py:chunk_26": {
      "chunk_id": "confluence_client.py:chunk_26",
      "file_path": "shared\\clients\\confluence_client.py",
      "chunk_hash": "f55f095d1ea4bda583cd49fa8794233c31d05361b0198ba19e50e7a223a95e19",
      "chunk_index": 26,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet fetches metadata (ID, title, version) of a Confluence page by making an HTTP GET request to a Confluence API endpoint.\n\n2. **Technical Details**:  \n- Uses `aiohttp` for asynchronous HTTP client session management and requests.  \n- Parses JSON response to extract specific fields: `\"id\"`, `\"title\"`, and `\"version\"` (with a default version number fallback).  \n- Implements async context managers (`async with`) to ensure proper resource cleanup.  \n- Uses Python dictionary `.get()` method with nested `.get()` for safe extraction of optional fields.\n\n3. **Business Logic**:  \nEnables retrieval of Confluence page metadata, likely to support documentation management, content synchronization, or display of page details within a larger application or workflow.\n\n4. **Dependencies**:  \n- `aiohttp` for asynchronous HTTP requests.  \n- A `logger` instance (likely from Python\u2019s `logging` module) for error logging.  \n- Presumably a `ConfluenceClient` class that encapsulates this method (not fully shown).\n\n5. **Configuration**:  \n- `api_url` and `headers` (likely including authentication tokens) are passed or configured externally to target the correct Confluence API endpoint.  \n- No explicit environment variables or config files shown in snippet, but these are typically required for API URLs and credentials.\n\n6. **Error Handling**:  \n- Checks HTTP",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:39.980784",
      "status": "summarized"
    },
    "grafana_client.py:chunk_0": {
      "chunk_id": "grafana_client.py:chunk_0",
      "file_path": "shared\\clients\\grafana_client.py",
      "chunk_hash": "ece40e2596d07e34a5aa89d86794cd776fd069d1d035c85a43b189bb71f818f1",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\clients\\grafana_client.py` Monitoring/Observability Configuration**\n\n1. **Purpose**  \n   This module implements a client for querying metrics from a Grafana instance programmatically. It is designed to interact with Grafana\u2019s HTTP API to retrieve time-series metric data over a specified time range. The client supports asynchronous requests using `aiohttp` and authenticates via an API key.\n\n2. **Metrics**  \n   The client itself does not define or collect metrics but provides a method `query_metrics` to query arbitrary Prometheus-style metric queries (`query` parameter) from Grafana\u2019s datasource proxy API. The actual metrics depend on the queries passed to this method. Examples might include CPU usage, request latency, error rates, etc., but these are not hardcoded here.\n\n3. **Alerts**  \n   There are no alert rules or thresholds defined within this client code. Alerting would be configured separately in Grafana or Prometheus. This client is purely for querying metric data, not managing alerting logic.\n\n4. **Dashboards**  \n   No dashboards or visualization configurations are included or managed by this client. Dashboards would be created and maintained within the Grafana UI or via Grafana provisioning, independent of this code.\n\n5. **Targets**  \n   The client queries metrics via Grafana\u2019s datasource proxy endpoint `/api/datasources/proxy/1/api/v1/query_range`. The target datasource ID is hardcoded as `1`, which typically",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:49.204833",
      "status": "summarized"
    },
    "grafana_client.py:chunk_2": {
      "chunk_id": "grafana_client.py:chunk_2",
      "file_path": "shared\\clients\\grafana_client.py",
      "chunk_hash": "a0e249412b042d72aa0484564ad70173713b8f896fec3c9d458cc0d9e08d9815",
      "chunk_index": 2,
      "summary": "**Summary of `shared\\clients\\grafana_client.py` (Grafana Client Integration)**\n\n1. **Purpose**  \n   This Python module provides an asynchronous client interface to query metrics and retrieve alert information from a Grafana server via its HTTP API. It is designed to facilitate programmatic access to Grafana\u2019s monitoring data and alert states for integration into other systems or dashboards.\n\n2. **Metrics**  \n   The code snippet shows a method (partially visible) that queries Grafana for metrics data using a specified query string. Although the exact metrics are not detailed here, the client expects to receive JSON-formatted metric data from Grafana\u2019s query API endpoint. The metrics could be any time-series data Grafana is configured to visualize, typically sourced from Prometheus or other data sources.\n\n3. **Alerts**  \n   The `get_alerts` async method fetches alert objects from Grafana\u2019s `/api/alerts` endpoint, filtered by alert state (e.g., \"all\", \"alerting\", \"ok\"). It returns a list of alert dictionaries representing current alert statuses. The code logs the number of alerts retrieved or errors if the request fails. Alert rules and thresholds themselves are managed within Grafana and are not defined in this client code.\n\n4. **Dashboards**  \n   There is no direct dashboard configuration or visualization logic in this client code. The client is focused on data retrieval; dashboard creation and graphing are handled within Grafana\u2019s UI or other tooling.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:19:58.981890",
      "status": "summarized"
    },
    "grafana_client.py:chunk_4": {
      "chunk_id": "grafana_client.py:chunk_4",
      "file_path": "shared\\clients\\grafana_client.py",
      "chunk_hash": "b194831c47abed15bbec2014be596d1565f9422b5afcf090f8756fa2ac05440a",
      "chunk_index": 4,
      "summary": "**Summary of `shared\\clients\\grafana_client.py` (Grafana Client Integration)**\n\n1. **Purpose**  \n   This configuration provides an asynchronous Python client interface to interact with a Grafana server. It enables programmatic retrieval of dashboards by UID and creation of annotations on Grafana dashboards. The client uses API keys for authentication and performs HTTP requests to Grafana\u2019s REST API endpoints.\n\n2. **Metrics**  \n   The code itself does not collect or track metrics directly. Instead, it interacts with Grafana, which is a visualization and dashboarding tool that aggregates metrics from various sources. Metrics management is external to this client.\n\n3. **Alerts**  \n   There are no alert rules or thresholds defined in this client code. Alerting configuration would typically be managed within Grafana or the underlying monitoring system (e.g., Prometheus), not via this client.\n\n4. **Dashboards**  \n   The client supports fetching complete dashboard JSON objects from Grafana by UID, enabling external services or automation scripts to retrieve dashboard configurations. This facilitates dashboard management, backup, or dynamic display in other tools.\n\n5. **Targets**  \n   The client targets the Grafana server API endpoints:  \n   - `/api/dashboards/uid/{uid}` for dashboard retrieval  \n   - `/api/annotations` for creating annotations  \n   The monitored services or endpoints are not specified here; this client acts as a conduit to Grafana\u2019s API.\n\n6. **Retention**  \n   Data retention",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:04.367936",
      "status": "summarized"
    },
    "grafana_client.py:chunk_6": {
      "chunk_id": "grafana_client.py:chunk_6",
      "file_path": "shared\\clients\\grafana_client.py",
      "chunk_hash": "b030a03b6efbc49b38300650c32cf5b543a5336ee5bc23e23fed8a382e663c74",
      "chunk_index": 6,
      "summary": "**Summary of `shared\\clients\\grafana_client.py` Monitoring/Observability Configuration**\n\n1. **Purpose**  \n   This configuration defines an asynchronous Python client (`GrafanaClient`) for creating annotations in Grafana dashboards. Annotations are time-stamped notes or markers on Grafana graphs used to highlight events or incidents. The client sends HTTP POST requests to the Grafana API to create these annotations programmatically, aiding in correlating events with metrics visually.\n\n2. **Metrics**  \n   The provided code snippet does not directly collect or track metrics. Instead, it focuses on creating annotations related to events or incidents that can be overlaid on existing Grafana metrics dashboards.\n\n3. **Alerts**  \n   There are no alert rules or thresholds defined within this code. Alerting would be configured separately in Grafana or Prometheus. This client\u2019s role is limited to adding contextual annotations that can help interpret alerts or metric anomalies.\n\n4. **Dashboards**  \n   The client interacts with Grafana dashboards by adding annotations. These annotations appear as markers or notes on time-series graphs, providing additional context to the visualized data. The code itself does not define dashboards or visualizations.\n\n5. **Targets**  \n   The code does not specify monitored services or endpoints. It acts as a generic client to post annotations to Grafana, which could be used by any service or monitoring system that wants to mark events on dashboards.\n\n6. **Retention**  \n   Data retention and storage policies are managed",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:12.127658",
      "status": "summarized"
    },
    "confluence_service.py:chunk_0": {
      "chunk_id": "confluence_service.py:chunk_0",
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "chunk_hash": "58c1d90b374aebc96ab1e7ea99b68fc0781629057d2916bd34c781b9b0423ac5",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module implements a Confluence integration service as part of a shared services architecture, enabling asynchronous connection and interaction with Atlassian Confluence via a standardized service interface.\n\n2. **Technical Details**  \n- Implements a `ConfluenceService` class inheriting from a generic `BaseService` base class, following an object-oriented design pattern for service abstraction.  \n- Uses asynchronous programming (`async def connect`) to support non-blocking connection attempts.  \n- Dynamically imports the `Confluence` client from the `atlassian` Python SDK within the connection method to potentially reduce startup overhead or handle optional dependencies.  \n- Validates configuration presence before initializing the client.  \n- Tests connectivity by fetching a limited list of Confluence spaces (`get_all_spaces(limit=1)`) as a lightweight health check.\n\n3. **Business Logic**  \nFacilitates secure and reliable integration with Atlassian Confluence to enable downstream features such as content retrieval, knowledge base access, or LLM (Large Language Model) wrapper support for enterprise collaboration and documentation workflows.\n\n4. **Dependencies**  \n- `atlassian` Python SDK for Confluence API interaction.  \n- Internal shared modules: `shared.services.base` (for base service abstractions), `shared.logger` (for logging), and `shared.config.settings` (for configuration management).  \n- Standard Python libraries: `os`, `typing`.\n\n5. **Configuration**  \nRelies on environment or configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:26.170079",
      "status": "summarized"
    },
    "confluence_service.py:chunk_2": {
      "chunk_id": "confluence_service.py:chunk_2",
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "chunk_hash": "a98f5c5f92af8bc60c825906ed0e9fefe19e5c52f4373965531c14cc926cc2dc",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous service methods to manage and interact with a Confluence instance, including connecting, disconnecting, testing the connection, and executing various Confluence-related actions such as creating or updating pages.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to allow non-blocking I/O operations.  \n- Employs a command pattern-like dispatch in the `execute` method, mapping action strings to internal handler methods (`_create_page`, `_update_page`, etc.).  \n- Uses a dictionary to return structured results indicating success or failure, along with relevant data or error messages.  \n- Maintains internal state with attributes like `_client` (likely a Confluence API client) and `status` (using an enum `ServiceStatus`).\n\n3. **Business Logic**:  \nEnables integration with Confluence to automate content management tasks such as creating, updating, retrieving pages, listing spaces, and searching content. This supports business workflows that require dynamic interaction with Confluence documentation or knowledge bases.\n\n4. **Dependencies**:  \n- A Confluence client library (not explicitly shown but implied by `_client.get_all_spaces()`).  \n- `ServiceStatus` enum for managing connection states.  \n- Python standard libraries for async programming and exception handling.  \n- Possibly other internal modules providing the implementations of `_create_page`, `_update_page`, etc.\n\n5. **Configuration**:  \n- The snippet does not show explicit configuration,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:35.711690",
      "status": "summarized"
    },
    "confluence_service.py:chunk_4": {
      "chunk_id": "confluence_service.py:chunk_4",
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "chunk_hash": "091016308924bef4d33df72f64abd3dbd7aae9f863a0293c6d43a2a921197bb3",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides asynchronous service methods to interact with a Confluence instance, specifically enabling capabilities such as creating and updating Confluence pages programmatically.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async`/`await`) to handle potentially long-running I/O operations without blocking.  \n- Implements an internal dispatch mechanism where an action string maps to a handler method (e.g., `_create_page`).  \n- Uses Python dictionaries for structured responses indicating success or failure, including relevant data or error messages.  \n- The `_create_page` method calls a synchronous client method (`self._client.create_page`) to create a page, wrapping it in an async method for integration consistency.\n\n3. **Business Logic**:  \nEnables automated management of Confluence content, such as creating and updating pages within specified spaces. This supports business workflows requiring dynamic documentation updates, content collaboration, or integration of Confluence content with other systems.\n\n4. **Dependencies**:  \n- A Confluence client library (likely a REST API client) referenced as `self._client` which provides methods like `create_page`.  \n- Python standard libraries for typing (`List`, `Dict`, `Optional`, `Any`).  \n- Asyncio or an async framework to support asynchronous method execution.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show configuration, but `self._client` likely requires configuration such as Confluence base URL, authentication tokens,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:44.707431",
      "status": "summarized"
    },
    "confluence_service.py:chunk_6": {
      "chunk_id": "confluence_service.py:chunk_6",
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "chunk_hash": "c956c9f3079f72a321d914d14f2b7713162cf934384e302f39bf9ee4fe933d8c",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous service methods to interact with Atlassian Confluence, specifically for updating pages, retrieving page details, and listing spaces within a Confluence instance.\n\n2. **Technical Details**:  \n- Uses asynchronous functions (`async def`) for potentially non-blocking I/O operations.  \n- Interacts with a Confluence client object (`self._client`) that abstracts API calls to Confluence REST endpoints.  \n- Returns structured dictionaries indicating success status and relevant data or error messages.  \n- Employs try-except blocks for exception handling around API calls.  \n- Uses dictionary data structures to encapsulate response data such as page ID, version, title, content, and spaces list.\n\n3. **Business Logic**:  \nEnables integration with Confluence to programmatically manage documentation or knowledge base content by updating pages, retrieving page content and metadata, and enumerating available spaces. This supports automation or synchronization of content between internal systems and Confluence, improving content management workflows.\n\n4. **Dependencies**:  \n- A Confluence client library (likely a wrapper around Atlassian Confluence REST API).  \n- Python standard libraries for async programming and exception handling.  \n- Typing module for type hints (`Dict[str, Any]`).\n\n5. **Configuration**:  \n- The Confluence client (`self._client`) is presumably configured elsewhere with authentication credentials, base URL, and other connection settings.  \n- No explicit environment variables or config",
      "embedding_id": null,
      "created_at": "2025-10-22T19:20:56.055400",
      "status": "summarized"
    },
    "confluence_service.py:chunk_8": {
      "chunk_id": "confluence_service.py:chunk_8",
      "file_path": "shared\\services\\integrations\\confluence_service.py",
      "chunk_hash": "fef94c2499ee0afb616a695d806c59dcbe5e95fc8581e454151b30af8c4abf1a",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines asynchronous methods within a Confluence integration service to fetch Confluence spaces and perform text-based searches on Confluence content.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) for non-blocking I/O operations.  \n- Interacts with a Confluence client (`self._client`) to execute API calls.  \n- Processes JSON-like dictionary responses, extracting relevant fields (`key`, `name` for spaces; `id`, `title` for search results).  \n- Uses list comprehensions to transform API results into simplified lists of dictionaries.  \n- Employs try-except blocks to catch and handle exceptions gracefully.\n\n3. **Business Logic**:  \nEnables retrieval of Confluence spaces and search results to support features like content discovery, navigation, or integration of Confluence data into other business applications or workflows.\n\n4. **Dependencies**:  \n- A Confluence client library or wrapper (`self._client`) that exposes methods like `.cql()` for querying Confluence via CQL (Confluence Query Language).  \n- Python standard libraries for async programming and exception handling.\n\n5. **Configuration**:  \n- Likely requires configuration of the Confluence client with credentials, base URL, and other connection parameters (not shown in the snippet).  \n- Query limits are configurable via method parameters (default limit=10).\n\n6. **Error Handling**:  \n- Catches all exceptions generically (`except Exception",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:07.296634",
      "status": "summarized"
    },
    "github_service.py:chunk_0": {
      "chunk_id": "github_service.py:chunk_0",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "8393f55824d5e738196b99e95329c8515631333e06b8b78f628e724ad0e01602",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\services\\integrations\\github_service.py`**\n\n1. **Purpose**  \n   This module implements a GitHub integration service as part of a larger application architecture, enabling asynchronous connection management to the GitHub API using a personal access token.\n\n2. **Technical Details**  \n   - Implements a `GitHubService` class inheriting from a generic `BaseService` class, following an object-oriented design pattern for service abstraction.  \n   - Uses asynchronous methods (`async def`) for connection handling, suggesting integration in an async event loop environment.  \n   - Utilizes the official `PyGithub` library (`github.Github`) to interact with GitHub\u2019s REST API.  \n   - Employs internal state management methods (`_set_connected()`, `_set_error()`) presumably defined in `BaseService` to track connection status and errors.  \n   - Logging is integrated via a shared logger instance for audit and debugging.\n\n3. **Business Logic**  \n   The service facilitates secure and managed access to GitHub repositories and user data by authenticating with a token. This enables higher-level business processes such as repository management, issue tracking, or CI/CD pipeline integrations that require GitHub API access.\n\n4. **Dependencies**  \n   - `PyGithub` library for GitHub API interaction (imported dynamically inside the method).  \n   - `shared.services.base` module providing base service classes and status management.  \n   - `shared.logger` for consistent logging across",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:16.199259",
      "status": "summarized"
    },
    "github_service.py:chunk_2": {
      "chunk_id": "github_service.py:chunk_2",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "bc3fb8a9cdc189c925c5bb13a8892ceb05bfdc93ede536376241c5dbde8407c7",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a GitHub integration service that manages connection status, tests connectivity to GitHub, and executes various GitHub-related actions asynchronously.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running GitHub API calls without blocking.  \n- Implements a command pattern via a dictionary (`actions`) mapping string action names to handler methods, enabling extensible and organized action execution.  \n- Maintains an internal client object (`self._client`) for GitHub API interactions, with explicit connection management (closing and nullifying the client).  \n- Returns structured dictionaries indicating success or failure, including relevant data or error messages.\n\n3. **Business Logic**:  \nEnables a business application to interact programmatically with GitHub repositories and user data, supporting operations like repository retrieval, issue and pull request creation, and file management. This facilitates automation and integration of GitHub workflows into the business\u2019s software ecosystem.\n\n4. **Dependencies**:  \n- Implicitly depends on a GitHub client library (likely `PyGithub` or similar) for `self._client.get_user()` and other GitHub API calls.  \n- Uses Python\u2019s asynchronous features (`async/await`).  \n- Uses a `ServiceStatus` enum or class for connection status management.\n\n5. **Configuration**:  \n- The snippet does not explicitly show configuration, but the presence of `self._client` implies prior setup with authentication",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:24.753990",
      "status": "summarized"
    },
    "github_service.py:chunk_4": {
      "chunk_id": "github_service.py:chunk_4",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "b9ed626cb43a8737b4670938c8281235c2e67b43b5850f865ed1a5646dea519b",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods within a GitHub integration service to retrieve GitHub capabilities and perform repository-related actions such as fetching repository details and listing repositories.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to allow non-blocking I/O operations.  \n- Returns data in dictionary structures with success flags and relevant information.  \n- Employs try-except blocks for error handling around GitHub API calls.  \n- Uses optional parameters (e.g., `user: Optional[str]`) to modify behavior dynamically.  \n- Likely relies on an instance variable `_client` that abstracts GitHub API interactions (probably from a GitHub SDK like PyGithub).\n\n3. **Business Logic**:  \nEnables integration with GitHub to support business workflows involving repository management, issue tracking, pull requests, and other GitHub features. This facilitates automation and data retrieval for applications that need to interact with GitHub repositories and user data.\n\n4. **Dependencies**:  \n- A GitHub API client library (e.g., PyGithub) accessed via `self._client`.  \n- Python's `asyncio` for asynchronous method definitions.  \n- Typing module for type hints (`List`, `Dict`, `Any`, `Optional`).\n\n5. **Configuration**:  \n- The code snippet does not explicitly show configuration, but `_client` likely requires authentication tokens or credentials configured elsewhere (environment variables or config files) to connect to Git",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:34.191708",
      "status": "summarized"
    },
    "github_service.py:chunk_6": {
      "chunk_id": "github_service.py:chunk_6",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "b401eb61f663564108fc998e4f7970bff12b9c05a29de252e2cfbe6a72d5b195",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous methods to interact with GitHub repositories, specifically to create issues and pull requests programmatically via a GitHub client.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) to enable non-blocking calls, likely within an async event loop.  \n- Interacts with GitHub repositories through a client object (`self._client`), presumably an instance of a GitHub API wrapper (e.g., PyGithub).  \n- Uses try-except blocks to catch and handle exceptions during API calls.  \n- Returns structured dictionaries indicating success or failure along with relevant metadata (issue/PR number and URL).  \n- Limits repository listing to the first 20 items (seen in the snippet for repos).\n\n3. **Business Logic**:  \nEnables automation of GitHub workflows by programmatically creating issues and pull requests, which can be used for bug tracking, feature requests, or code review processes within a software development lifecycle.\n\n4. **Dependencies**:  \n- A GitHub API client library (likely PyGithub or similar) for repository and issue/PR management.  \n- Python's `asyncio` for asynchronous execution.  \n- Standard Python exception handling.\n\n5. **Configuration**:  \n- The GitHub client (`self._client`) likely requires authentication tokens or credentials configured elsewhere (not shown).  \n- Repository names and branch names are passed as parameters, implying dynamic configuration per call.\n\n6. **Error Handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:43.209682",
      "status": "summarized"
    },
    "github_service.py:chunk_8": {
      "chunk_id": "github_service.py:chunk_8",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "0a319c684ebdc1d62b9af6ba6ef01c09ff3f9565d19a30594aeadcdd23b99cc2",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides asynchronous methods to interact with GitHub repositories, specifically to retrieve file contents and commit changes to files within a repository.\n\n2. **Technical Details**:  \n- Uses asynchronous functions (`async def`) to allow non-blocking I/O operations.  \n- Interacts with GitHub repositories via a client object (`self._client`), presumably an instance of a GitHub API client (e.g., PyGithub).  \n- Retrieves file contents using `repo.get_contents()` and decodes the content from base64 to UTF-8.  \n- Commits changes by either updating an existing file (if found) or presumably creating a new file (code snippet incomplete).  \n- Returns structured dictionaries indicating success or failure, including content, SHA hashes, and error messages.\n\n3. **Business Logic**:  \nEnables automated management of files within GitHub repositories, supporting workflows such as CI/CD pipelines, content synchronization, or configuration management by programmatically reading and updating repository files.\n\n4. **Dependencies**:  \n- A GitHub API client library (likely PyGithub or similar) for repository interactions.  \n- Python's `asyncio` for asynchronous execution.  \n- Standard Python types (`Dict`, `Any`) for type hinting.\n\n5. **Configuration**:  \n- Repository names, file paths, branch names, and commit messages are passed as parameters.  \n- The GitHub client (`self._client`) is assumed to be",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:48.114303",
      "status": "summarized"
    },
    "github_service.py:chunk_10": {
      "chunk_id": "github_service.py:chunk_10",
      "file_path": "shared\\services\\integrations\\github_service.py",
      "chunk_hash": "11bc254c4fc34d9f527da04228d9dcfa56e2dc60eff84475104f21af75779275",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet attempts to update a file in a GitHub repository branch; if the file does not exist, it creates the file instead. It returns a structured response indicating success or failure along with commit details.\n\n2. **Technical Details**:  \n- Uses a try-except block to attempt updating a file via `repo.update_file()`.  \n- If an exception occurs (likely due to the file not existing), it falls back to creating the file using `repo.create_file()`.  \n- Returns a dictionary containing success status, the action performed (\"updated\" or \"created\"), and commit metadata (SHA and URL).  \n- The `result` object is expected to have a nested `commit` attribute with `sha` and `html_url` properties.\n\n3. **Business Logic**:  \nEnables seamless content management on a GitHub repository by abstracting the complexity of checking file existence before updating or creating files. This supports workflows that programmatically maintain repository content, such as CI/CD pipelines, documentation updates, or configuration management.\n\n4. **Dependencies**:  \n- Likely depends on the PyGithub library or a similar GitHub API wrapper, as indicated by methods like `create_file()` and `update_file()`.  \n- Requires a `repo` object representing a GitHub repository.\n\n5. **Configuration**:  \n- Assumes authentication and repository context are configured elsewhere (e.g., via GitHub tokens, environment variables).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:21:58.556593",
      "status": "summarized"
    },
    "vector_query_service.py:chunk_0": {
      "chunk_id": "vector_query_service.py:chunk_0",
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "chunk_hash": "b7ba6de3fc0e7563e2cb7cd6e97c388f50f95ffb74419679e0a3e3a2f678d804",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module implements a `VectorQueryService` class that enables semantic search capabilities by querying a vector database using embeddings generated from natural language queries.\n\n2. **Technical Details**:  \n- Utilizes asynchronous programming (`async def semantic_search`) to perform non-blocking vector search operations.  \n- Integrates two main components: a `VectorDBProvider` for vector storage and retrieval, and an `EmbeddingService` to convert text queries into vector embeddings.  \n- The service supports filtering and configurable result count (`top_k`).  \n- Uses Python typing hints for clarity and maintainability (`List`, `Dict`, `Optional`).  \n- Logging is integrated for observability (`logger.info`).\n\n3. **Business Logic**:  \nEnables enhanced search functionality over indexed repositories (e.g., GitHub repos) by allowing users to perform semantic searches that go beyond keyword matching, improving relevance and user experience in code or document discovery platforms.\n\n4. **Dependencies**:  \n- Internal modules:  \n  - `VectorDBProvider` and `VectorSearchResult` from `..base` (likely abstracting vector DB operations and result representation).  \n  - `EmbeddingService` from `..embedding_service` (handles embedding generation).  \n- Standard Python libraries: `logging`, `typing`.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in the snippet.  \n- The `collection` parameter defaults to `\"github_repos\"",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:06.488888",
      "status": "summarized"
    },
    "vector_query_service.py:chunk_2": {
      "chunk_id": "vector_query_service.py:chunk_2",
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "chunk_hash": "7f6c14614f88c449050caa9154c98ca45c53f6d18ecebadc1685709b24be7883",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet performs a semantic search on a vector database by generating an embedding for a user query and then retrieving the top K most relevant results from a specified collection, optionally filtered by metadata.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) for non-blocking calls to embedding generation and vector search services.  \n- Employs vector embeddings to represent textual queries in a high-dimensional space for similarity search.  \n- Logs detailed timing and operational metrics for each step (embedding generation, search).  \n- Likely uses a vector search algorithm (e.g., approximate nearest neighbors) abstracted behind `self.vector_db.search`.  \n- Uses structured logging with emojis and formatted messages for readability and monitoring.\n\n3. **Business Logic**:  \nEnables semantic search functionality within an application, allowing users to retrieve contextually relevant documents or items from large datasets based on natural language queries, improving search accuracy beyond keyword matching.\n\n4. **Dependencies**:  \n- `time` module for performance measurement.  \n- `self.embedding_service` for generating query embeddings (likely an external ML model or API).  \n- `self.vector_db` for performing vector similarity search (could be a vector database like Pinecone, FAISS, or similar).  \n- `logger` for structured logging (not shown but assumed imported/configured elsewhere).\n\n5. **Configuration**:  \n- Parameters such as `collection` (target dataset), `top_k",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:18.648131",
      "status": "summarized"
    },
    "vector_query_service.py:chunk_4": {
      "chunk_id": "vector_query_service.py:chunk_4",
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "chunk_hash": "44f10550826d557a235a6260d44eb7484818d864fc5c4cfb02d3c141146589ff",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet performs a semantic vector search query against a vector database, logs detailed timing and result information, and returns the search results or an empty list if an error occurs.\n\n2. **Technical Details**:  \n- Uses time measurements to capture embedding generation and search execution durations in milliseconds.  \n- Logs the number of documents found and details of the top 3 results, including repository name, file path, and similarity score.  \n- Employs exception handling to catch and log any errors during the search process.  \n- Results appear to be objects with metadata attributes and a similarity score, indicating use of structured result objects from a vector search library or custom data class.\n\n3. **Business Logic**:  \nEnables semantic search functionality over a document repository or codebase, allowing users or systems to retrieve the most relevant documents/files based on vector similarity, which supports enhanced search experiences such as code search, knowledge retrieval, or content recommendation.\n\n4. **Dependencies**:  \n- A vector database or vector search service (not explicitly shown but implied).  \n- A logging framework (`logger`) for info and error logging.  \n- Python standard library `time` module for performance measurement.\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown in this snippet.  \n- Likely depends on external configuration for vector DB connection and search parameters (e.g., `filters` passed as `filter_metadata`).\n\n6. **Error Handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:27.542730",
      "status": "summarized"
    },
    "vector_query_service.py:chunk_6": {
      "chunk_id": "vector_query_service.py:chunk_6",
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "chunk_hash": "06a717ad045d04894f2f585410bab46d7d3da576eb9b147f86415a7149e924f6",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code provides asynchronous search functionalities within a vector database service, enabling semantic search queries scoped by repository name or programming language.\n\n2. **Technical Details**:  \n- Implements async methods (`search_by_repository`, `search_by_language`) that perform filtered semantic searches on a vector database collection.  \n- Uses a filtering mechanism (dictionary-based filters) to scope searches to specific repositories or languages.  \n- Relies on an underlying `semantic_search` method (not shown) that likely performs vector similarity search and returns a list of `VectorSearchResult` objects.  \n- Uses Python type hints and async/await for concurrency.\n\n3. **Business Logic**:  \nEnables developers or automated systems to perform targeted semantic code searches within large codebases, filtered by repository or programming language, facilitating efficient code discovery, reuse, or analysis.\n\n4. **Dependencies**:  \n- Assumes existence of a `semantic_search` async method within the same class or inherited.  \n- Uses a `logger` for informational logging.  \n- Returns `VectorSearchResult` objects, implying a data model defined elsewhere.  \n- Likely depends on an async vector database client or service (not shown).\n\n5. **Configuration**:  \n- Default collection name is `\"github_repos\"`, configurable via method parameters.  \n- `top_k` parameter controls the number of search results returned.  \n- No explicit environment variables or config files shown, but collection names and logging imply external",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:39.039818",
      "status": "summarized"
    },
    "vector_query_service.py:chunk_8": {
      "chunk_id": "vector_query_service.py:chunk_8",
      "file_path": "shared\\vector_db\\services\\vector_query_service.py",
      "chunk_hash": "49abfe51c81621c4713101d23628f8f7dab850e09e0dda19b72bb143f0689d85",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a vector query service that performs semantic search operations on document collections, including filtering search results by language and retrieving documents similar to a given document ID.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking search operations.  \n- Implements a `semantic_search` method call with filters to refine results by language.  \n- Defines a placeholder method `get_similar_documents` intended to find documents similar to a specified document ID, returning a list of `VectorSearchResult` objects.  \n- Uses a dictionary (`filters`) to apply search constraints.  \n- Logging is used to indicate unimplemented features.\n\n3. **Business Logic**:  \n- Enables users or systems to perform semantic searches within document collections, filtered by language, which is useful for multilingual content retrieval.  \n- Plans to support document-to-document similarity searches, which can help in recommendation systems, content discovery, or duplicate detection within collections such as GitHub repositories.\n\n4. **Dependencies**:  \n- Likely depends on an asynchronous vector search backend or service (not shown in snippet).  \n- Uses a logger for warnings (implies a configured logging framework).  \n- Uses type hinting with `List` and a custom `VectorSearchResult` type, indicating dependencies on typing and domain-specific data models.\n\n5. **Configuration**:  \n- Default collection name is `\"github_repos\"` for similarity searches",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:47.731638",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_0": {
      "chunk_id": "Sidebar.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "af886005cfbf1ceb6c127897937b4965ef9778b39fc7c314f00a0b17a1b23bfc",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component implements a sidebar navigation menu for a frontend application, allowing users to switch between different functional tabs and manage conversation history related to the \"LLM Testing\" tab.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`) for state management and side effects.  \n- Maintains local state for conversations (an array of conversation objects), visibility of conversation history, and the currently selected conversation ID.  \n- Defines a static menu with tab identifiers, labels, and icons imported from the `lucide-react` icon library.  \n- Implements a side effect to load conversations when the active tab changes to 'llm' and listens for conversation save events to refresh the list.  \n- Uses TypeScript interfaces for strong typing of props (`SidebarProps`) and conversation data (`Conversation`).  \n\n3. **Business Logic**:  \nEnables users to navigate between different application modules (Voice Assistant, LLM Testing, Integrations Hub, Doc Orchestrator) and manage conversation histories specifically for the LLM Testing feature, supporting workflows that involve reviewing or continuing past conversations.\n\n4. **Dependencies**:  \n- `lucide-react`: For SVG icon components.  \n- React core (`useState`, `useEffect`).  \n- Local app types (`Tab` from `../../App`).  \n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are visible in this snippet. Configuration likely depends on props passed",
      "embedding_id": null,
      "created_at": "2025-10-22T19:22:56.473538",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_2": {
      "chunk_id": "Sidebar.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "83015e423435d2ae6d849b6b6f09282b6bdc0b7628bc1c823b16c6f6965b4a78",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component code manages the sidebar functionality for a chat application, specifically handling the loading, deletion, and selection of chat conversations.\n\n2. **Technical Details**:  \n- Uses React hooks (`useEffect`) to add and clean up event listeners for a custom event `conversationSaved`.  \n- Asynchronous functions (`loadConversations`, `deleteConversation`) perform REST API calls to fetch and delete conversations.  \n- State management via React state setters (`setConversations`, `setCurrentConversationId`).  \n- Event-driven architecture using `window.dispatchEvent` and `window.addEventListener` for inter-component communication with custom events like `clearChat` and `loadConversation`.  \n- Confirmation dialog (`confirm`) to prevent accidental deletion.  \n- Stops event propagation on delete button clicks to avoid triggering parent click handlers.\n\n3. **Business Logic**:  \nEnables users to manage their chat conversations by loading the list of conversations, selecting a conversation to view, and deleting conversations with user confirmation. Ensures UI consistency by clearing the chat view when the current conversation is deleted.\n\n4. **Dependencies**:  \n- React and React DOM for component and event handling.  \n- Browser Fetch API for HTTP requests to backend endpoints (`/api/chat/conversations`).  \n- Browser native event system for custom events.\n\n5. **Configuration**:  \n- Uses an environment variable `conversationId` (likely for identifying or initializing the current conversation context).  \n- API endpoints are",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:03.704838",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_4": {
      "chunk_id": "Sidebar.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "9d8726c8eb62a89ba6317fa383f90e65de36a5b1fa7b32bf2a58df2c996e8668",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React functional component renders a sidebar layout for a frontend application, providing navigation tabs and controls to manage chat conversations, including starting a new chat and switching between conversation tabs.\n\n2. **Technical Details**:  \n- Utilizes React hooks (`useState` or similar implied) to manage state such as `currentConversationId` and `activeTab`.  \n- Uses event dispatching (`window.dispatchEvent` with `CustomEvent`) to communicate state changes like clearing the chat.  \n- Renders UI elements with Tailwind CSS utility classes for styling and layout.  \n- Maps over a `menuItems` array to dynamically generate navigation buttons with icons and active state styling.  \n- Employs JSX for declarative UI rendering.\n\n3. **Business Logic**:  \nEnables users to navigate between different conversation tabs and start new chat sessions within an AI development assistant interface, facilitating multi-conversation management and improving user workflow efficiency.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Custom icon component `Brain` (likely an SVG or React component)  \n- Possibly a `menuItems` data structure imported or defined elsewhere containing tab metadata and icons\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration files are referenced in this snippet. Styling and behavior are controlled via component props and internal state.\n\n6. **Error Handling**:  \nNo explicit error handling or exception management is present",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:10.512270",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_6": {
      "chunk_id": "Sidebar.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "c1dc7b616fef8076b007af01f511a524ebc48b47953ca0a943f1c86444a7cd98",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component snippet renders part of a sidebar UI, including navigation buttons with active state styling and a conditional \"Chat History\" section that appears when the \"llm\" tab is active. It allows users to start a new chat or toggle the visibility of recent conversations.\n\n2. **Technical Details**:  \n- Uses conditional rendering (`activeTab === 'llm'`) to display UI elements based on application state.  \n- Applies dynamic CSS classes based on active states (`isActive`) for styling buttons and icons.  \n- Utilizes React event handlers (`onClick`) to trigger state changes such as starting a new chat (`startNewChat`) and toggling chat history visibility (`setShowHistory`).  \n- Employs JSX syntax with Tailwind CSS utility classes for styling.  \n- Uses icon components (`MessageSquarePlus`, `ChevronDown`, `ChevronRight`) likely imported from an icon library.\n\n3. **Business Logic**:  \nEnables users to navigate through different sidebar options and manage chat sessions when interacting with a language model testing feature (\"llm\"). It supports initiating new conversations and reviewing recent chat history, enhancing user productivity and session management.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Icon components (possibly from a library like `lucide-react` or similar)  \n- State management hooks (`useState` or context, inferred from `setShowHistory` and `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:17.420878",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_8": {
      "chunk_id": "Sidebar.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "ced05a4396f1ef72d02fe26bce3758c641f305cc13c1a9da11a841b8e0a07387",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a sidebar section displaying a list of past conversations (history). It allows users to view and select conversations, highlighting the currently active one.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX for UI rendering.  \n- Conditional rendering with `showHistory` boolean to toggle visibility of the conversation list.  \n- Maps over an array `conversations` to dynamically generate conversation items.  \n- Uses event handlers (`onClick`) to trigger loading a selected conversation via `loadConversation(conv.id)`.  \n- Applies conditional CSS classes to highlight the active conversation (`currentConversationId === conv.id`).  \n- Utilizes utility-first CSS classes (likely Tailwind CSS) for styling and layout.  \n- Displays formatted dates using JavaScript's `Date` object and `toLocaleDateString()` method.  \n- Includes an icon component `<Clock />` for visual indication of the conversation timestamp.\n\n3. **Business Logic**:  \nEnables users to access and manage their conversation history efficiently, improving user experience by allowing quick navigation between past interactions. This supports features like session continuity, reference to previous chats, or audit trails.\n\n4. **Dependencies**:  \n- React (JSX, hooks implied).  \n- Tailwind CSS (inferred from class names like `bg-primary-50`, `hover:bg-gray-50`).  \n- A custom or third-party `<Clock />` icon component.  \n- Possibly a state",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:25.566373",
      "status": "summarized"
    },
    "Sidebar.tsx:chunk_10": {
      "chunk_id": "Sidebar.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Layout\\Sidebar.tsx",
      "chunk_hash": "9222388347e68b68d9ef844a79d11bd714a38369b1de81f6fa5fa1ba119a4524",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component renders a sidebar UI element that displays a list of conversations with the ability to delete individual conversations. It also shows a status section indicating the system is running and the integration of Together AI with Azure OpenAI.\n\n2. **Technical Details**:  \n- Uses React functional component with JSX for UI rendering.  \n- Iterates over a `conversations` array to dynamically render conversation items.  \n- Each conversation item includes a delete button with an `onClick` handler invoking `deleteConversation` passing the conversation ID and event.  \n- Conditional rendering is used to display a placeholder message when no conversations exist.  \n- Tailwind CSS classes are applied for styling and hover effects (e.g., opacity transitions on the delete button).  \n- The component structure includes semantic HTML elements like `<nav>` and `<aside>` for accessibility.\n\n3. **Business Logic**:  \nEnables users to view and manage (specifically delete) their conversation history within the application, supporting user interaction with AI-driven chat or messaging features. The status section informs users about the operational state and AI service integration, enhancing transparency.\n\n4. **Dependencies**:  \n- React (functional components and hooks implied).  \n- Tailwind CSS for styling.  \n- An icon component `Trash2` (likely from a library such as `react-feather` or similar).  \n- External AI services referenced in the status text: Together AI and Azure OpenAI (though not directly invoked",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:33.345743",
      "status": "summarized"
    },
    "http_api.py:chunk_0": {
      "chunk_id": "http_api.py:chunk_0",
      "file_path": "interfaces\\http_api.py",
      "chunk_hash": "6c5e77def8fc48911f66780bd7a28d6b853a1a0a2131e757af530fd54daaa0a4",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines the main HTTP API application for a modular FastAPI-based backend, consolidating multiple endpoint modules and initializing critical services like a vector database on startup. It replaces a previous monolithic API file with a more maintainable, modular architecture.\n\n2. **Technical Details**  \n- Uses FastAPI framework to create an asynchronous web application.  \n- Employs a factory pattern via `create_app()` to instantiate the FastAPI app, promoting modularity and testability.  \n- Registers multiple routers imported from various interface modules, each encapsulating domain-specific endpoints (e.g., services, vector DB, translation, AI, code intelligence).  \n- Implements an asynchronous startup event handler to initialize the vector database, ensuring the system is ready before serving requests.  \n- Uses structured logging via a shared logger utility for observability.\n\n3. **Business Logic**  \nThe application serves as a unified API gateway that integrates diverse AI, translation, vector search, and service endpoints, enabling clients to access complex backend capabilities through a single HTTP interface. This modular approach supports scalable development and deployment of AI-powered business features such as document analysis, chat, voice, and code intelligence.\n\n4. **Dependencies**  \n- **FastAPI**: Web framework for building APIs.  \n- **interfaces.api.core**: Provides `create_app()` factory function.  \n- **Multiple interface modules**: Each provides routers for specific domain endpoints (e.g., services_api, vector_db_api, translation_api",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:37.999409",
      "status": "summarized"
    },
    "http_api.py:chunk_2": {
      "chunk_id": "http_api.py:chunk_2",
      "file_path": "interfaces\\http_api.py",
      "chunk_hash": "f964609bbb50279da7d53c628ce9842403beade3718f083fc478253420a40ca9",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet finalizes the initialization of a vector database and sets up a modular HTTP API by including multiple routers corresponding to different functional areas of the application. It logs the successful setup of the vector DB and the registration of various API endpoints.\n\n2. **Technical Details**:  \n- Uses a modular design pattern by organizing API endpoints into separate routers (e.g., `basic_endpoints.router`, `llm_endpoints.router`).  \n- Employs a try-except block to handle exceptions during vector DB initialization.  \n- Utilizes a logger for structured logging of system status and endpoint registration.  \n- The `app.include_router()` method suggests the use of a web framework like FastAPI or similar, which supports router modularization.\n\n3. **Business Logic**:  \nThe code supports a business need to provide a scalable and maintainable HTTP API that exposes various services such as language model testing, document generation, chat, voice processing, code intelligence, and vector database operations. This modular API structure enables rapid development and integration of AI-driven features and services.\n\n4. **Dependencies**:  \n- A web framework that supports routers (likely FastAPI or Starlette).  \n- A vector database service or client (not shown but implied by vector DB initialization).  \n- Multiple internal modules providing routers: `basic_endpoints`, `llm_endpoints`, `test_endpoints`, `doc_endpoints`, `analysis_endpoints`, `chat_endpoints`, `commit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:23:48.828245",
      "status": "summarized"
    },
    "http_api.py:chunk_4": {
      "chunk_id": "http_api.py:chunk_4",
      "file_path": "interfaces\\http_api.py",
      "chunk_hash": "c5753db14ce37b233782c9707d13a90a65d9e93da61de77fbdc07c976bee6ea3",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet logs the available HTTP API endpoints and their respective functional areas for an application, serving as a runtime informational message to indicate which API routes are supported.\n\n2. **Technical Details**:  \n- Uses a logger (likely from Python\u2019s standard `logging` module or a similar logging framework) to output informational messages.  \n- No algorithms, data structures, or design patterns are implemented here; it is purely declarative logging.\n\n3. **Business Logic**:  \n- The logged endpoints correspond to various business capabilities such as analysis, chat management, commit workflows, voice assistant features, service management, vector database interactions, translation services, Azure cloud testing, unified AI operations, and code intelligence.  \n- This helps developers or operators understand the scope of the API surface exposed by the application.\n\n4. **Dependencies**:  \n- Implicit dependency on a configured logging system (`logger`).  \n- The actual API implementations for these endpoints would depend on web frameworks (e.g., Flask, FastAPI) and other service modules, but none are shown here.\n\n5. **Configuration**:  \n- No explicit configuration or environment variables are referenced in this snippet.  \n- The logging behavior (level, format, output destination) would be configured elsewhere in the application.\n\n6. **Error Handling**:  \n- No error handling is present or required in this logging-only snippet.\n\n7. **API/Interface**:  \n- The snippet documents the following API",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:02.068151",
      "status": "summarized"
    },
    "approval_system.py:chunk_0": {
      "chunk_id": "approval_system.py:chunk_0",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "de0f0986399e38c9aa9d3a88c1ef6fcfe1304b76f28178e1563ec56e134751f8",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a UI approval system for GitHub commits and other write operations, requiring explicit user confirmation before executing potentially destructive actions.\n\n2. **Technical Details**:  \n- Uses Python `dataclasses` to model an `ApprovalRequest` entity encapsulating details of the approval needed.  \n- Defines an `ApprovalStatus` enum to represent the lifecycle states of an approval request (`PENDING`, `APPROVED`, `REJECTED`, `EXPIRED`).  \n- Includes serialization logic (`to_dict`) for converting approval requests into JSON-compatible dictionaries, facilitating communication with UI components.  \n- Uses timestamps (`created_at`, `expires_at`) to manage approval validity windows.\n\n3. **Business Logic**:  \nEnsures that any critical write operation (e.g., GitHub commits) undergoes explicit user approval to prevent accidental or unauthorized destructive changes, thereby enforcing operational safety and auditability.\n\n4. **Dependencies**:  \n- Standard Python libraries: `logging`, `uuid`, `dataclasses`, `datetime`, `enum`, and typing modules (`Dict`, `Any`, `Optional`).  \n- No external third-party libraries are referenced in the provided snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or configuration files are referenced in the snippet.  \n- Logging is set up via Python\u2019s standard `logging` module, presumably configured elsewhere in the application.\n\n6. **Error Handling**:  \n- The snippet does not explicitly show error handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:10.965259",
      "status": "summarized"
    },
    "approval_system.py:chunk_2": {
      "chunk_id": "approval_system.py:chunk_2",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "bb8b9828154fa57412c3d6df8090da7e7b64733c0beb308c197fad04fd001ff6",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines an `ApprovalManager` class responsible for managing approval requests related to write operations, such as commits. It tracks pending approvals, their expiration, and user association.\n\n2. **Technical Details**:  \n- Uses a dictionary (`pending_approvals`) keyed by a string ID to store `ApprovalRequest` objects representing individual approval requests.  \n- The class constructor accepts an expiration time (in minutes) to automatically expire approval requests.  \n- Methods include creation of new approval requests with metadata such as operation type, title, description, template data, and optional user ID.  \n- Uses ISO 8601 formatting for expiration timestamps (`expires_at.isoformat()`).  \n- Logging is integrated for lifecycle events (e.g., initialization).\n\n3. **Business Logic**:  \n- Facilitates controlled write operations by requiring approvals, ensuring that changes (e.g., GitHub commits) are authorized before execution.  \n- Helps enforce governance and auditability in workflows that modify critical systems or data.\n\n4. **Dependencies**:  \n- Relies on Python standard libraries (`datetime`, `typing` for `Dict`, `Any`, `Optional`).  \n- Uses a logging utility (`logger`) presumably configured elsewhere in the application.  \n- References an `ApprovalRequest` class (not fully shown) which encapsulates individual approval details.\n\n5. **Configuration**:  \n- The expiration duration for approval requests is configurable via the `expiration_minutes` parameter in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:20.963947",
      "status": "summarized"
    },
    "approval_system.py:chunk_4": {
      "chunk_id": "approval_system.py:chunk_4",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "2404d26b55fb222aad802a196d325f1b145df412a7617fe1ef3b2055d7a417e2",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code manages approval requests within a workflow system by creating new approval requests and retrieving existing ones while handling expiration logic.\n\n2. **Technical Details**:  \n- Uses `uuid.uuid4()` to generate unique request IDs.  \n- Utilizes `datetime.utcnow()` and `timedelta` to set creation and expiration timestamps.  \n- Stores approval requests in an in-memory dictionary `self.pending_approvals` keyed by request ID.  \n- Defines an `ApprovalRequest` data structure with fields like `id`, `operation_type`, `status`, timestamps, and user info.  \n- Implements status management with an enum-like `ApprovalStatus` (e.g., PENDING, EXPIRED).  \n- Logging is used for audit trail and operational visibility.\n\n3. **Business Logic**:  \nThe code supports a business process requiring explicit approval for certain operations. It tracks pending approvals, enforces expiration of stale requests, and provides retrieval of current approval status to ensure timely decision-making and compliance.\n\n4. **Dependencies**:  \n- Python standard libraries: `uuid` for ID generation, `datetime` for time management.  \n- Custom classes/enums: `ApprovalRequest`, `ApprovalStatus`.  \n- Logging module for info-level logs.\n\n5. **Configuration**:  \n- `self.expiration_minutes` controls how long an approval request remains valid before expiring. This is likely set via constructor or external configuration.  \n- No explicit environment variables or config",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:25.661564",
      "status": "summarized"
    },
    "approval_system.py:chunk_6": {
      "chunk_id": "approval_system.py:chunk_6",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "eea51e88963480880c96e6e8109fec6565c5ce236f0561ec47f044ce352fbdea",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an approval system within an orchestration workflow. It provides functionality to approve an approval request by updating its status and optionally modifying its associated template data.\n\n2. **Technical Details**:  \n- The code defines a method `approve_request` that takes a `request_id` and optional `updated_template_data`.  \n- It retrieves an `ApprovalRequest` object via `get_approval_request(request_id)`.  \n- It checks the request\u2019s existence and status before approving.  \n- If valid, it updates the request\u2019s status to `APPROVED` and merges any updated template data into the existing data dictionary.  \n- Uses logging for audit and traceability of actions.  \n- The method returns the updated `ApprovalRequest` object or `None` if the request is not found or expired.\n\n3. **Business Logic**:  \n- Ensures that only valid, non-expired approval requests can be approved.  \n- Allows users to modify the template data associated with the approval request during approval, supporting dynamic updates.  \n- Supports workflow governance by tracking approval status changes and preventing invalid state transitions (e.g., approving expired requests).\n\n4. **Dependencies**:  \n- Relies on an `ApprovalRequest` data model and `ApprovalStatus` enum (likely defined elsewhere in the codebase).  \n- Uses Python\u2019s standard `logging` module for logging warnings and info messages.  \n- Uses typing hints such as `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:34.986742",
      "status": "summarized"
    },
    "approval_system.py:chunk_8": {
      "chunk_id": "approval_system.py:chunk_8",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "1aed5b67b9581c3dee55e72da112d4b6612d5c09a33f6187c2ef8173dcdc6f7b",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an approval system within a commit workflow orchestration module. It manages approval requests by allowing rejection of requests and listing pending approval requests, optionally filtered by user.\n\n2. **Technical Details**:  \n- Uses class methods (likely within an approval system class) to manipulate `ApprovalRequest` objects stored in a dictionary (`self.pending_approvals`).  \n- Implements status management via an enum or constant class `ApprovalStatus` with states such as `PENDING`, `REJECTED`, and `EXPIRED`.  \n- Uses timestamps (`datetime.utcnow()`) to check and update expiration status of requests.  \n- Logging is used extensively for audit trails and operational visibility.  \n- The `list_pending_requests` method filters requests by status, expiration, and optionally by user ID.\n\n3. **Business Logic**:  \n- Enables workflow governance by allowing authorized users or systems to reject approval requests with optional reasons, ensuring accountability.  \n- Maintains an up-to-date list of actionable approval requests, automatically expiring outdated requests to prevent stale approvals.  \n- Supports user-specific views of pending approvals, facilitating personalized task management.\n\n4. **Dependencies**:  \n- Python standard library modules: `datetime` for time operations.  \n- A logging framework (likely Python\u2019s built-in `logging` module).  \n- Custom types or enums: `ApprovalRequest`, `ApprovalStatus`.  \n- The method `get_approval_request` suggests internal",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:44.942623",
      "status": "summarized"
    },
    "approval_system.py:chunk_10": {
      "chunk_id": "approval_system.py:chunk_10",
      "file_path": "orchestration\\commit_workflow\\approval_system.py",
      "chunk_hash": "3e6a0a18d49515544d66205a00e391719d4f70c54ce3c6f4161a43305f4f851e",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code manages approval requests within a workflow system, specifically handling the cleanup of expired approval requests and providing a singleton instance of an approval manager.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.pending_approvals`) keyed by request IDs to store pending approval requests.  \n- Iterates over these requests to identify and remove those that have expired based on their `expires_at` timestamp compared to the current UTC time.  \n- Implements a singleton pattern for the `ApprovalManager` instance via a module-level variable `_approval_manager` and a factory function `get_approval_manager()`.  \n- Logging is used to record cleanup operations.\n\n3. **Business Logic**:  \nEnsures that approval requests which are no longer valid (expired) are removed from the system to prevent stale or outdated approvals from blocking or interfering with workflow progression.\n\n4. **Dependencies**:  \n- Python standard library: `datetime` for time comparisons.  \n- A logger instance (`logger`) presumably from a logging framework (e.g., Python\u2019s `logging` module).  \n- The `ApprovalManager` class, which is defined elsewhere in the codebase.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in this snippet. The expiration logic depends on timestamps within the approval request objects.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. It assumes that `self.pending_approvals` and request",
      "embedding_id": null,
      "created_at": "2025-10-22T19:24:53.814214",
      "status": "summarized"
    },
    "github_operations.py:chunk_0": {
      "chunk_id": "github_operations.py:chunk_0",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "8c236895e0eb1a59646bfcd20c43b35b3b06b507875d7c5f809768d2543854ca",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module provides utilities for interacting with GitHub repositories using the PyGithub library, focusing on automating branch name generation from commit messages and encapsulating GitHub operations such as commits, pull requests, and repository management.\n\n2. **Technical Details**  \n- Implements a function `generate_branch_name` that sanitizes and formats commit messages into standardized branch names using regex substitutions and string manipulations.  \n- Uses datetime to append a timestamp to branch names for uniqueness and traceability.  \n- Defines a `GitHubOperations` class (partially shown) intended to encapsulate GitHub API interactions via the PyGithub client, likely following an object-oriented design pattern to group related operations.  \n- Logging is set up for diagnostic and operational traceability.\n\n3. **Business Logic**  \nAutomates the process of creating meaningful, consistent, and traceable Git branch names derived from commit messages, which supports streamlined development workflows and better branch management. The class is designed to facilitate automated GitHub repository operations, reducing manual overhead and potential errors in managing commits and pull requests.\n\n4. **Dependencies**  \n- `PyGithub` library (`github` module) for GitHub API interactions.  \n- Standard Python libraries: `logging`, `re` (regex), `datetime`, and `typing` for type hints.\n\n5. **Configuration**  \n- No explicit environment variables or config files are shown in the snippet; however, authentication and repository details are likely managed externally or within",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:00.829463",
      "status": "summarized"
    },
    "github_operations.py:chunk_2": {
      "chunk_id": "github_operations.py:chunk_2",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "fb3cba3a8c7f5d6cc2cc3bce7cc0c7038218918213b515c08a92d8e75c9006ac",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python class manages GitHub repository operations, specifically enabling the creation of new branches from a base branch using a centralized GitHub client.\n\n2. **Technical Details**:  \n- Utilizes the PyGithub library to interact with GitHub repositories.  \n- The class is initialized with an optional PyGithub client instance, promoting reuse of a centralized GitHub client (likely from a wrapper class named `GitHubWrapper`).  \n- Implements a private method `_create_branch` that creates a new Git reference (branch) from an existing branch by fetching the base branch commit SHA and creating a new git ref pointing to it.  \n- Uses logging to track operation success or warn about missing clients.\n\n3. **Business Logic**:  \n- Facilitates automated Git operations within a larger orchestration or CI/CD workflow, enabling dynamic branch creation for features, fixes, or deployment workflows.  \n- Helps maintain consistent branching strategies by programmatically managing branches, reducing manual errors and improving developer productivity.\n\n4. **Dependencies**:  \n- PyGithub library (`Github` class and repository objects).  \n- A centralized GitHub client wrapper (`GitHubWrapper`) providing the `Github` client instance.  \n- Python standard logging module (implied by `logger` usage).\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown in the snippet.  \n- Assumes external configuration or authentication is handled when initializing the centralized GitHub client passed into this class",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:08.023534",
      "status": "summarized"
    },
    "github_operations.py:chunk_4": {
      "chunk_id": "github_operations.py:chunk_4",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "e44612aec57802859139b4ca6d47b42015da6fa964acfeb08da2d7d1cd3ee8e5",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages failures related to GitHub branch creation operations within a commit workflow. It specifically addresses errors that occur when attempting to create a branch, ensuring the workflow can continue smoothly if the branch already exists or if other GitHub API errors arise.\n\n2. **Exception Types**:  \n   - Catches `GithubException`, which is a specific exception type from the GitHub API client library indicating API request failures.\n\n3. **Recovery Strategy**:  \n   - If the exception status code is `422` (Unprocessable Entity), which typically means the branch already exists, the code treats this as a non-fatal condition and returns `True` to indicate success, allowing the workflow to proceed without interruption.  \n   - For other `GithubException` errors, it logs the error and returns `False`, signaling failure without retry logic in this snippet.\n\n4. **Logging**:  \n   - Uses `logger.info` to log informational messages when the branch already exists, providing visibility into expected, non-error conditions.  \n   - Uses `logger.error` to log unexpected failures during branch creation, aiding in monitoring and troubleshooting.\n\n5. **User Impact**:  \n   - End users are shielded from errors caused by attempting to create an already existing branch, preventing unnecessary failures.  \n   - Other errors result in a failure response, which may propagate to the user or calling process, potentially requiring user intervention or retries.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:13.691613",
      "status": "summarized"
    },
    "github_operations.py:chunk_6": {
      "chunk_id": "github_operations.py:chunk_6",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "e76d54e845b212bf542d502ddf37c8401ce8ebe5db38dded39e1d740ed9c1d8a",
      "chunk_index": 6,
      "summary": "**Summary of Error Handling in `github_operations.py` Commit Workflow**\n\n1. **Purpose**  \n   This code handles errors related to committing multiple files to a GitHub repository branch. It specifically manages failures in:  \n   - GitHub client initialization  \n   - Branch creation (if requested)  \n   - File retrieval and update operations on GitHub  \n\n2. **Exception Types**  \n   - `GithubException`: Catches exceptions thrown by GitHub API calls, such as when a file is not found (HTTP 404) or other API errors.  \n   - Implicitly handles errors from branch creation method `_create_branch` via boolean return values.  \n\n3. **Recovery Strategy**  \n   - If the GitHub client is not initialized, the method immediately returns a failure response without proceeding.  \n   - When creating a branch, if `_create_branch` returns `False`, the method returns an error indicating branch creation failure.  \n   - For each file update, if a `GithubException` with status 404 occurs (file not found), the code presumably attempts to handle it differently (code snippet incomplete), likely by creating the file instead of updating. Other exceptions are not explicitly handled here and may propagate.  \n\n4. **Logging**  \n   - Logs an informational message before committing files, including the number of files, repository, and branch.  \n   - Logs a success message for each file successfully updated (`\u2705 Updated: {file_path}`).  \n   - Error logging for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:21.126563",
      "status": "summarized"
    },
    "github_operations.py:chunk_8": {
      "chunk_id": "github_operations.py:chunk_8",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "74cd61c9c279e14e8f9fba87f85c7b88804b96c9040fa1d28c727d2c5ce0da72",
      "chunk_index": 8,
      "summary": "**Summary of `orchestration/commit_workflow/github_operations.py`**\n\n1. **Purpose**  \nThis code snippet handles committing one or more files to a specified branch in a GitHub repository, logging the operation, and returning metadata about the commit and branch.\n\n2. **Technical Details**  \n- Uses the GitHub API (likely via a Python client such as PyGithub) to create files in a repository branch.  \n- Checks if files exist before creation; if not, raises an exception to trigger error handling.  \n- Retrieves the latest commit object from the branch after file creation to extract commit SHA and URLs.  \n- Constructs URLs for the commit and branch for easy access.  \n- Returns a structured dictionary summarizing the commit operation.  \n- Uses logging to track success and failure states.\n\n3. **Business Logic**  \nEnables automated workflows or orchestration systems to programmatically commit changes to GitHub repositories, supporting CI/CD pipelines, content updates, or configuration management without manual intervention.\n\n4. **Dependencies**  \n- GitHub API client library (e.g., PyGithub) for repository and branch operations.  \n- `logger` for logging informational and error messages.  \n- External GitHub service (GitHub.com or GitHub Enterprise).\n\n5. **Configuration**  \n- Repository name, branch name, base branch, commit message, and file contents are passed as parameters or configured externally.  \n- Authentication tokens or credentials for GitHub API access are assumed to be configured",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:31.442854",
      "status": "summarized"
    },
    "github_operations.py:chunk_10": {
      "chunk_id": "github_operations.py:chunk_10",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "4e1df3584a4384eb9a9391d06b12a73d0bd9dbe3e16aa4757bba1497ec85def0",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method creates a pull request (PR) on a specified GitHub repository, allowing automated or programmatic management of code changes and collaboration workflows.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to enable non-blocking I/O operations, likely integrating with an async GitHub client library.  \n- Accepts parameters for repository identification, source and target branches, PR metadata (title, description), and optional lists for reviewers, assignees, and labels.  \n- Returns a dictionary indicating success or failure along with PR details or error messages.  \n- Utilizes logging for operational transparency.  \n- Interacts with GitHub\u2019s API through a client object (`self.client.get_repo(repository)`), suggesting an object-oriented design encapsulating GitHub operations.\n\n3. **Business Logic**:  \nAutomates the creation of pull requests to streamline code review and integration processes in software development workflows. This supports continuous integration/continuous deployment (CI/CD) pipelines by programmatically managing PR lifecycle events, reducing manual intervention and accelerating development cycles.\n\n4. **Dependencies**:  \n- A GitHub client library (likely `PyGithub` or similar) for API interactions.  \n- Python standard libraries such as `asyncio` for asynchronous support.  \n- Logging module for event tracking.  \n- Typing module for type hints (`Optional`, `List`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- Requires initialization",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:35.583015",
      "status": "summarized"
    },
    "github_operations.py:chunk_12": {
      "chunk_id": "github_operations.py:chunk_12",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "8e7f4768da0fce3990aa0a43e751ccb50deee50dae3b377abf0b5bcd15e527ff",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Python module that automates the creation of GitHub pull requests (PRs) within a repository, including setting reviewers, assignees, and labels, and returns structured information about the created PR.\n\n2. **Technical Details**:  \n- Uses an object-oriented approach, likely within a class managing GitHub operations.  \n- Interacts with GitHub's API through a repository object (`repo`) to create PRs (`create_pull`).  \n- Conditionally adds reviewers (`create_review_request`), assignees (`add_to_assignees`), and labels (`add_to_labels`) to the PR.  \n- Uses structured dictionaries to return success or failure responses.  \n- Employs logging for informational and error messages.  \n- The snippet shows part of an asynchronous method `commit_and_create_pr`, indicating async operations for committing files and creating PRs.\n\n3. **Business Logic**:  \nAutomates the workflow of committing code changes and opening pull requests on GitHub, streamlining code review and collaboration processes in software development teams. This reduces manual steps and enforces consistent PR metadata (reviewers, assignees, labels).\n\n4. **Dependencies**:  \n- Likely depends on `PyGithub` or a similar GitHub API client library for repository and PR operations.  \n- Uses Python's standard `logging` module for logging.  \n- Async functionality suggests use of `asyncio` or an async-compatible",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:44.387187",
      "status": "summarized"
    },
    "github_operations.py:chunk_14": {
      "chunk_id": "github_operations.py:chunk_14",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "08a454649639350eaa9b032849a397fab181e0e853503f38c5439c4cacf71867",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method orchestrates a combined workflow to commit files to a GitHub repository branch and subsequently create a pull request (PR) from that branch to a target branch, streamlining code changes and review initiation in one operation.\n\n2. **Technical Details**:  \n- The method uses asynchronous programming (`async/await`) to perform GitHub operations without blocking.  \n- It internally calls two separate async methods: `commit_files` (to commit changes) and `create_pull_request` (to open a PR).  \n- The method accepts optional parameters for PR metadata such as description, reviewers, assignees, labels, and draft status.  \n- Returns a dictionary containing the success status and details from both commit and PR operations.  \n- Uses structured logging to track workflow progress.\n\n3. **Business Logic**:  \nAutomates the developer workflow of pushing code changes and initiating code review via PRs, reducing manual steps and potential errors. This supports continuous integration and collaborative development practices by integrating commit and PR creation into a single seamless process.\n\n4. **Dependencies**:  \n- Presumably depends on GitHub API client libraries or internal wrappers for `commit_files` and `create_pull_request` methods.  \n- Uses Python's `asyncio` for asynchronous execution.  \n- Uses a logger instance for logging (likely Python\u2019s standard `logging` module or a configured logger).\n\n5. **Configuration**:  \n- Default target branch is set",
      "embedding_id": null,
      "created_at": "2025-10-22T19:25:53.622189",
      "status": "summarized"
    },
    "github_operations.py:chunk_16": {
      "chunk_id": "github_operations.py:chunk_16",
      "file_path": "orchestration\\commit_workflow\\github_operations.py",
      "chunk_hash": "7167bc7cf08603ce4298fa86a478164b185386665f18d6c47032ce914470b46c",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet constructs and returns a dictionary summarizing the results of a GitHub commit and pull request (PR) operation, indicating success status and relevant metadata such as commit SHA, URLs, PR number, and error information if applicable.\n\n2. **Technical Details**:  \n- Uses Python dictionary unpacking (`**commit_result`) to merge commit-related data into the result.  \n- Returns structured JSON-like dictionaries representing operation outcomes.  \n- Conditional logic (implied from partial snippet) differentiates between success and failure states for PR creation.\n\n3. **Business Logic**:  \nFacilitates automated workflows for committing code changes and creating pull requests on GitHub repositories, enabling continuous integration or deployment pipelines to programmatically manage code updates and review processes.\n\n4. **Dependencies**:  \n- Likely depends on GitHub API client libraries or custom modules to perform commit and PR operations (not shown in snippet).  \n- Uses standard Python data structures; no explicit external libraries visible in snippet.\n\n5. **Configuration**:  \n- Repository and branch names are passed as parameters or context variables (implied).  \n- May rely on environment variables or config files for GitHub authentication tokens and repository settings (not shown).\n\n6. **Error Handling**:  \n- Captures PR creation errors in the `\"pr_error\"` field when `\"pr_created\"` is `False`.  \n- Returns a success flag (`\"success\": True`) only when both commit and PR",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:01.962044",
      "status": "summarized"
    },
    "context_extractor.py:chunk_0": {
      "chunk_id": "context_extractor.py:chunk_0",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "97a7ed4d55d8d088ed71b164b5ee9dfc07b69e30cf576f4f60fb4e54c455d6fe",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines a `ConversationContextExtractor` class responsible for extracting structured context information\u2014such as repository references, file paths, and code entities\u2014from conversation history text. It aims to parse and identify relevant technical context embedded in natural language dialogue.\n\n2. **Technical Details**  \n- Uses regular expressions extensively to identify patterns related to repositories (e.g., GitHub repo names and URLs), file paths, and code entities (functions, classes, methods).  \n- Patterns are organized into class-level lists (`REPO_PATTERNS`, `FILE_PATTERNS`, `CODE_ENTITY_PATTERNS`) for modularity and ease of maintenance.  \n- The class likely processes conversation messages (instances of `ConversationMessage`) and produces structured context objects (`ConversationContext`) tagged with types (`ContextType`).  \n- Logging is set up for debugging and traceability.  \n- The code snippet shows partial regex patterns but implies a pattern-matching algorithm scanning conversation text for relevant context.\n\n3. **Business Logic**  \nThis extractor supports applications that need to understand and leverage technical context from user conversations, such as developer assistants, code review bots, or automated documentation tools. By extracting references to repos, files, and code entities, it enables downstream components to provide more accurate, context-aware responses or actions.\n\n4. **Dependencies**  \n- Standard Python libraries: `re` for regex, `logging` for diagnostics, `typing` for type hints.  \n- Internal module imports: `.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:06.553038",
      "status": "summarized"
    },
    "context_extractor.py:chunk_2": {
      "chunk_id": "context_extractor.py:chunk_2",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "b56ca4ad15daccabe78c1698f1654ba490e22e82b282ec1ea1ada1831672b493",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a context extraction utility designed to analyze conversation history and identify relevant contextual information based on predefined topic keywords and code patterns. It aims to structure unstructured conversation data into a meaningful context representation.\n\n2. **Technical Details**:  \n- Uses regular expressions (regex) to detect code constructs such as class definitions.  \n- Maintains a dictionary of topic keywords grouped by domain areas (e.g., authentication, API, database).  \n- Implements a class method `extract_context` which takes a list of conversation messages and optionally a current query, then processes these inputs to extract a structured `ConversationContext` object.  \n- Likely uses pattern matching and keyword scanning algorithms to map conversation content to topics.\n\n3. **Business Logic**:  \nThe code addresses the need to understand and categorize user conversations in software development or support scenarios, enabling better contextual awareness for automated assistants, chatbots, or analytics tools. This helps in tailoring responses, improving search relevance, or guiding users effectively based on the conversation context.\n\n4. **Dependencies**:  \n- Python standard libraries such as `re` for regex (implied by regex usage).  \n- Typing hints (`List`, `Dict`, `Any`, `Optional`) from the `typing` module.  \n- A custom or external `ConversationContext` class/type used as the return type, which encapsulates the extracted context.\n\n5. **Configuration**:  \n- No explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:15.232534",
      "status": "summarized"
    },
    "context_extractor.py:chunk_5": {
      "chunk_id": "context_extractor.py:chunk_5",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "90c16677ee33df2859ba1819f35252faf7b2001a56ba1ad1fb52cc7c746a36d7",
      "chunk_index": 5,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a context extraction process that updates a context object by extracting and appending unique repositories, files, code entities, and topics from given content, while also processing an optional current query. It ensures the context lists do not grow indefinitely by limiting their sizes.\n\n2. **Technical Details**:  \n- Uses list data structures (`context.repositories_mentioned`, `context.files_mentioned`, `context.code_entities`, `context.topics`) to store extracted elements.  \n- Employs membership checks (`if item not in list`) to avoid duplicates before appending new elements.  \n- Invokes class methods (`cls._extract_code_entities`, `cls._extract_topics`, `cls._update_context_from_current_query`) to modularize extraction and update logic.  \n- Truncates lists to fixed sizes using slicing to maintain a bounded context size (e.g., last 5 repositories, last 10 files/entities).  \n- Uses logging (`logger.info`) to record extraction events with emoji-enhanced messages for clarity.\n\n3. **Business Logic**:  \nThe code supports maintaining an up-to-date, concise context of relevant code artifacts and topics related to a software project or query. This is likely used to enhance developer tooling, code search, or automated assistance by tracking recent and relevant entities without overwhelming the system with stale or redundant data.\n\n4. **Dependencies**:  \n- A `logger` instance for logging informational messages.  \n- Class",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:27.392244",
      "status": "summarized"
    },
    "context_extractor.py:chunk_7": {
      "chunk_id": "context_extractor.py:chunk_7",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "296eb292a4e6455579d4f8cdf2456f6dcaeb39a17e2e781859c5c5e35f09f1aa",
      "chunk_index": 7,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a context extraction module that processes text to identify and extract references to code repositories and file paths, refining the context for further orchestration tasks.\n\n2. **Technical Details**:  \n- Uses class methods to encapsulate functionality for extracting repositories and file paths from input text.  \n- Employs regular expressions (`re.finditer`) with predefined patterns (`REPO_PATTERNS`, `FILE_PATTERNS`) to locate relevant substrings.  \n- Applies filtering logic to validate repository format (must be \"owner/repo\") and to exclude false positives in file paths (e.g., URLs or email-like strings).  \n- Uses sets to remove duplicate entries before returning results.  \n- Logs completion of context extraction with a summary method on the `context` object.\n\n3. **Business Logic**:  \nEnables automated identification of relevant code repositories and file paths mentioned in textual data, which is critical for orchestrating workflows such as code analysis, dependency tracking, or automated code review processes.\n\n4. **Dependencies**:  \n- Python standard library modules: `re` for regular expressions, `logging` (implied by `logger.info`).  \n- The `context` object and its methods (e.g., `get_context_summary`) are part of the broader orchestration framework but not shown here.\n\n5. **Configuration**:  \n- The regex patterns `REPO_PATTERNS` and `FILE_PATTERNS`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:37.293612",
      "status": "summarized"
    },
    "context_extractor.py:chunk_9": {
      "chunk_id": "context_extractor.py:chunk_9",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "81eaf97485acbfae92e1d85c1cffe71854c6d006691a965f1867c857693d59b6",
      "chunk_index": 9,
      "summary": "1. **Purpose**:  \nThis code provides utility methods to extract meaningful entities such as code constructs (functions, classes) and topical keywords from a given text input, and to update a conversational context based on the current query.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.finditer`) to identify code entities matching predefined patterns (`CODE_ENTITY_PATTERNS`).  \n- Filters extracted entities by length and excludes common stopwords to improve relevance.  \n- Performs keyword matching against a dictionary (`TOPIC_KEYWORDS`) to identify relevant topics within the text.  \n- Uses class methods and class-level constants for pattern and keyword definitions, indicating a design that centralizes configuration and extraction logic.  \n- The `_update_context_from_current_query` method suggests integration with a `ConversationContext` object to maintain or modify state based on input queries.\n\n3. **Business Logic**:  \nEnables automated extraction of technical concepts and thematic topics from user queries or documentation text, facilitating enhanced context awareness in conversational AI or code orchestration systems. This supports better understanding and handling of developer intents or codebase discussions.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regex operations.  \n- A `ConversationContext` class or type, likely defined elsewhere in the codebase, representing the state of a conversation or session.\n\n5. **Configuration**:  \n- Class-level constants `CODE_ENTITY_PATTERNS` and `TOPIC_KEYWORDS` are expected to be defined",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:43.384022",
      "status": "summarized"
    },
    "context_extractor.py:chunk_11": {
      "chunk_id": "context_extractor.py:chunk_11",
      "file_path": "orchestration\\context_manager\\context_extractor.py",
      "chunk_hash": "2f07d22ad3f7f235637d5f395e73fdcad8dfe94a976020549c8d746ccc94f168",
      "chunk_index": 11,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet updates the current repository context based on repositories extracted from a given query. It ensures that the most recently mentioned repository is set as the current one and tracks all repositories mentioned so far.\n\n2. **Technical Details**:  \n- Uses a class method `_extract_repositories(query)` to parse and extract repository identifiers from the input query.  \n- Updates a `context` object by setting `current_repository` to the first extracted repository.  \n- Maintains a list `repositories_mentioned` within the context to keep track of all unique repositories referenced.  \n- Uses simple list operations (`append`, membership check) for managing repositories.  \n- Logs the update event using a `logger` with an informational message.\n\n3. **Business Logic**:  \nThis code supports a system that manages or orchestrates operations across multiple code repositories. By tracking which repositories are mentioned in user queries or commands, it maintains state about the current focus repository and a history of repositories referenced, enabling context-aware processing or automation workflows.\n\n4. **Dependencies**:  \n- Relies on a class method `_extract_repositories` defined elsewhere in the class/module.  \n- Uses a `logger` object for logging informational messages.  \n- Depends on a `context` object that holds state related to repositories (likely a custom context manager or state container).\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in this snippet.  \n- Logging",
      "embedding_id": null,
      "created_at": "2025-10-22T19:26:52.656793",
      "status": "summarized"
    },
    "context_manager.py:chunk_0": {
      "chunk_id": "context_manager.py:chunk_0",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "b272905a3e4f6afa3e3672fa153bef02a08408acc0ef85c36631cb85b4fcd7e4",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines a `ConversationContextManager` class responsible for managing and injecting conversational context into user queries to enable more intelligent, multi-turn dialogue interactions.\n\n2. **Technical Details**  \n- Uses a composition pattern by instantiating a `ConversationContextExtractor` to handle context extraction logic.  \n- The main method `augment_query_with_context` takes the current query and conversation history, then augments the query by injecting relevant context extracted from prior messages.  \n- Data structures include lists of dictionaries representing conversation history and a custom `ConversationContext` model to encapsulate extracted context details.  \n- Logging is used for tracing key operations.\n\n3. **Business Logic**  \nEnables enhanced user experience in conversational AI or chatbot systems by maintaining context across multiple turns, allowing queries to be interpreted with awareness of prior interactions. This supports more natural and accurate responses in multi-turn conversations.\n\n4. **Dependencies**  \n- Python standard library: `logging`, `typing` (List, Dict, Any, Optional)  \n- Internal modules:  \n  - `.context_extractor` providing `ConversationContextExtractor` for extracting context from conversation history  \n  - `.models` providing the `ConversationContext` data model\n\n5. **Configuration**  \nNo explicit environment variables or configuration files are referenced in the provided snippet. Logging configuration is assumed to be handled externally.\n\n6. **Error Handling**  \nNo explicit error handling or exception management is shown in the snippet. Potential errors during context",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:02.005709",
      "status": "summarized"
    },
    "context_manager.py:chunk_2": {
      "chunk_id": "context_manager.py:chunk_2",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "124fbf1acdd12cf72d70ec7576cdbe459b74329edb5d964ff35049dcf0167979",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code manages the augmentation of user queries by extracting relevant conversational context and deciding whether to enhance the query with that context before further processing.\n\n2. **Technical Details**:  \n- Uses a context extractor (`self.extractor.extract_context`) to obtain relevant conversation history context.  \n- Implements a decision function `_needs_context_augmentation` to determine if query augmentation is necessary, optionally forced by a flag.  \n- If augmentation is needed, it constructs an augmented query via `_build_augmented_query`.  \n- Uses logging to trace decisions and show before/after states of the query augmentation.  \n- The `ConversationContext` data structure is used to represent extracted context, likely a domain-specific object encapsulating conversation state.\n\n3. **Business Logic**:  \nEnhances user queries with relevant prior conversation context to improve the accuracy and relevance of downstream processing (e.g., search, chatbot responses). This ensures that queries are complete and context-aware, addressing issues where users provide incomplete or ambiguous inputs.\n\n4. **Dependencies**:  \n- A custom `extractor` module or class responsible for extracting context from conversation history.  \n- A `ConversationContext` type, likely defined elsewhere in the codebase.  \n- Standard Python logging (`logger`) for informational output.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in the snippet. The behavior can be influenced by the `force_context` boolean flag passed to the method, which forces augmentation",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:07.909336",
      "status": "summarized"
    },
    "context_manager.py:chunk_4": {
      "chunk_id": "context_manager.py:chunk_4",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "e161fe12c876d69e6150edbff4196f63e72050a99ff4bce1c5131292a6050fac",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet determines whether a user query should be augmented with repository context based on the presence or absence of explicit repository references and the nature of the query as a follow-up question.\n\n2. **Technical Details**:  \n- Converts the query string to lowercase for case-insensitive matching.  \n- Checks for explicit repository keywords (`'repo'`, `'repository'`, `'github.com'`) and the presence of a full repository path (indicated by `'/'`).  \n- Uses membership tests (`any()`) over predefined keyword lists to identify if the query is a follow-up or references code elements.  \n- Relies on a `context` object method `has_repository_context()` to verify if repository context is already available.  \n- Employs simple string containment checks as heuristics to classify the query type.\n\n3. **Business Logic**:  \nThe code supports an intelligent query augmentation mechanism in a system that interacts with code repositories. It ensures that follow-up questions or queries lacking explicit repository references are enriched with repository context to improve the relevance and accuracy of responses, likely in a developer assistant or code search tool.\n\n4. **Dependencies**:  \n- Uses a `context` object, presumably part of the larger orchestration framework, which provides the method `has_repository_context()`.  \n- No external libraries or services are explicitly referenced in this snippet.\n\n5. **Configuration**:  \n- No environment variables or configuration files are referenced or required in this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:17.343818",
      "status": "summarized"
    },
    "context_manager.py:chunk_6": {
      "chunk_id": "context_manager.py:chunk_6",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "2f4aed551a36b66c3938dd31f227197189f353215dca25309bcd965a8e7e04c5",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a context manager module designed to determine whether a user query requires augmentation with additional repository or conversation context before processing, particularly in scenarios involving code-related queries or follow-up questions.\n\n2. **Technical Details**:  \n- The code uses keyword matching to detect if a query is related to code by checking for presence of specific keywords (e.g., 'file', 'code', 'implementation').  \n- It checks for follow-up indicators (not fully shown here) and repository context availability via methods like `context.has_repository_context()`.  \n- Logical conditions combine these checks to decide if query augmentation is necessary.  \n- Logging statements provide traceability for decisions made during query evaluation.  \n- The method `_build_augmented_query` (partially shown) suggests a design where the original query is prepended with contextual information to enrich the input for downstream processing.\n\n3. **Business Logic**:  \nThe code addresses the problem of improving query understanding in conversational AI or code search tools by augmenting ambiguous or context-dependent queries with relevant repository or conversation context. This ensures more accurate and relevant responses, especially when users ask follow-up questions or short queries that lack explicit repository references.\n\n4. **Dependencies**:  \n- Uses a `logger` for informational logging (likely Python\u2019s standard `logging` module or a configured logger).  \n- Relies on a `ConversationContext` object that provides methods like `has_repository_context()`.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:25.304130",
      "status": "summarized"
    },
    "context_manager.py:chunk_8": {
      "chunk_id": "context_manager.py:chunk_8",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "f22e18f1fa64e9d7b17d2983fd55e23abe060bee6a792e4b4c8a28febc253f69",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet augments a user query by prepending relevant contextual information extracted from a given context object, such as the current repository and recently mentioned files, to improve the clarity and specificity of the query.\n\n2. **Technical Details**:  \n- The code constructs a list of context parts conditionally based on the presence of repository and file context.  \n- It checks if the current repository is already mentioned in the query to avoid redundancy.  \n- It uses simple string operations (e.g., `lower()`, `in`) and list slicing (`[-2:]`) to extract recent files.  \n- The augmented query is formed by joining context parts with commas and appending the original query.  \n- The method `has_file_context()` and attribute `files_mentioned` suggest the context object encapsulates state and helper methods related to file references.\n\n3. **Business Logic**:  \nThe code enhances user queries by embedding relevant contextual metadata, which likely helps downstream systems (e.g., search engines, code analysis tools, or chatbots) to better understand and respond to queries within the scope of a specific code repository and recently referenced files. This improves accuracy and relevance in developer tooling or knowledge management scenarios.\n\n4. **Dependencies**:  \n- The snippet references a `context` object with attributes and methods (`current_repository`, `has_file_context()`, `files_mentioned`), implying a dependency on a custom context management module or class.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:29.120209",
      "status": "summarized"
    },
    "context_manager.py:chunk_10": {
      "chunk_id": "context_manager.py:chunk_10",
      "file_path": "orchestration\\context_manager\\context_manager.py",
      "chunk_hash": "413bc93bdfa3e04b5e99c0ee5f24565f53627bba995b149ddb4172c5d077e73d",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet defines a method that takes a conversation history as input and returns a summarized context string extracted from that conversation.\n\n2. **Technical Details**:  \n- Utilizes an `extractor` object with a method `extract_context` to process the conversation history.  \n- The extracted context object then provides a summary via `get_context_summary()`.  \n- The code implies a separation of concerns: extraction logic is encapsulated in the `extractor`, while this method acts as a facade or orchestrator.\n\n3. **Business Logic**:  \n- Supports conversational AI or chatbot systems by summarizing past conversation messages into a concise context summary.  \n- Helps maintain context awareness in multi-turn dialogues, improving response relevance and user experience.\n\n4. **Dependencies**:  \n- Depends on an `extractor` component/module, likely part of the same codebase or a specialized NLP library.  \n- No explicit external libraries shown in this snippet.\n\n5. **Configuration**:  \n- No direct configuration or environment variables referenced in this snippet.  \n- Configuration might be required for the `extractor` component elsewhere.\n\n6. **Error Handling**:  \n- No explicit error handling shown; assumes `extractor.extract_context` and `context.get_context_summary()` succeed or handle their own exceptions.\n\n7. **API/Interface**:  \n- Appears to be a method (likely within a class) that accepts `conversation_history` as input and returns",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:38.030662",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_0": {
      "chunk_id": "query_orchestrator.py:chunk_0",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "4542840a8f14c60ae6bcc069c5170ec04c4559ef6ec93cbac148032383e3a5cc",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration/github_llm/query_orchestrator.py`**\n\n---\n\n1. **Purpose**  \nThis module defines a `GitHubLLMOrchestrator` class that orchestrates queries across multiple data sources, specifically a vector database and the GitHub API, and then formats the aggregated responses for consumption. It leverages a LangGraph-style workflow to integrate and manage these heterogeneous data sources.\n\n2. **Technical Details**  \n- The orchestrator uses dependency injection to accept instances of `VectorQueryService` (for vector DB queries), `GitHubWrapper` (for GitHub API interactions), and `ResponseBeautifier` (for formatting responses).  \n- The design follows an orchestration pattern, coordinating multiple services to fulfill a single query request.  \n- Data models such as `QueryRequest`, `QueryResponse`, `SourceResult`, and `QueryType` are used to structure input and output data, ensuring type safety and clarity.  \n- Logging is set up for operational visibility, and standard Python typing hints improve code maintainability.\n\n3. **Business Logic**  \nThe orchestrator addresses the business need to provide enriched, multi-source query results by combining semantic search capabilities (via vector DB) with real-time or metadata information from GitHub repositories. This enables enhanced developer tooling, knowledge discovery, or analytics platforms that rely on both historical indexed data and live GitHub data.\n\n4. **Dependencies**  \n- Internal modules:  \n  - `shared.vector_db.services.vector",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:44.126737",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_2": {
      "chunk_id": "query_orchestrator.py:chunk_2",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "a1f633eb97754e5706346e5afd049305c4a79640d71012c2e4d53c2783527d72",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a GitHub-LLM Orchestrator that processes user queries by orchestrating multiple data sources using a LangGraph-style approach, with detailed logging for traceability and performance monitoring.\n\n2. **Technical Details**:  \n- The method `process_query` is asynchronous (`async def`), indicating non-blocking I/O operations likely involving network or disk access.  \n- It uses structured logging to capture query metadata and orchestration steps.  \n- Implements a query planning step (`_plan_query`) to decide which data sources to query based on the input request.  \n- Measures execution time for query planning in milliseconds for performance insights.  \n- Uses a `QueryRequest` input data structure and returns a `QueryResponse`, suggesting typed request/response models.  \n- The design follows an orchestration pattern where multiple data sources or services are coordinated to fulfill a query.\n\n3. **Business Logic**:  \nThe code supports a business need to intelligently route and process user queries against GitHub repositories and potentially other vector search sources. It enables filtering by repository, choosing between direct GitHub queries or vector-based semantic search, thus improving the relevance and efficiency of code or data retrieval in developer tools or analytics platforms.\n\n4. **Dependencies**:  \n- `time` module for performance timing.  \n- `logger` for structured logging (likely Python\u2019s `logging` module or a wrapper).  \n- Custom types `QueryRequest` and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:27:51.985734",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_4": {
      "chunk_id": "query_orchestrator.py:chunk_4",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "4ee749cae4513420228269e830aa9ee15257e09db2b4f6bd617d9ba94f9f46fc",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet orchestrates a multi-step process to query multiple data sources in parallel, synthesize the retrieved results, and generate a summary based on a user request.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to perform parallel querying of multiple sources, improving responsiveness.  \n- Measures execution time for each step (querying, synthesis, summary generation) using `time.time()` for performance logging.  \n- The results from sources are collected into a list (`source_results`), then combined and ranked via `_synthesize_results()`.  \n- The final step generates a textual summary from the synthesized results using `_generate_summary()`.  \n- Logging is extensively used to track progress, performance, and intermediate data characteristics (e.g., relevance scores).\n\n3. **Business Logic**:  \nEnables efficient aggregation and summarization of information from diverse data sources (likely code repositories or knowledge bases) to provide concise, relevant answers or insights to end-users, supporting decision-making or knowledge discovery workflows.\n\n4. **Dependencies**:  \n- Python `asyncio` for asynchronous calls (implied by `await`).  \n- `time` module for timing operations.  \n- A `logger` instance for structured logging (likely from Python\u2019s `logging` module).  \n- Internal methods `_query_sources()`, `_synthesize_results()`, and `_generate_summary()` which encapsulate source querying, result processing, and summarization logic respectively.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:01.403031",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_6": {
      "chunk_id": "query_orchestrator.py:chunk_6",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "a088542efcc341babb3e47e7dce9185001cc6456ed16c0fd4b43b06a6b9e64a7",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a query orchestration process that formats and enriches a response generated from multiple data sources, preparing it for consumption by a large language model (LLM). It logs processing steps, beautifies the response, calculates a confidence score, and packages the final response with metadata.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to perform the beautification step, indicating non-blocking I/O or CPU-bound operations handled asynchronously.  \n- Measures elapsed time for beautification and overall processing using `time.time()`.  \n- Constructs a `QueryResponse` data structure (likely a class or dataclass) encapsulating the original query, query type, synthesized source data, summary, beautified response, confidence score, processing time, and metadata.  \n- The beautification method `_beautify_response` likely formats or enhances raw data for better LLM input.  \n- Confidence is computed via `_calculate_confidence`, presumably analyzing the synthesized data quality or relevance.\n\n3. **Business Logic**:  \nThe code supports a business need to aggregate and refine information from multiple sources, summarize it, and present it in a polished format suitable for AI-driven language models. This enables delivering high-quality, confidence-scored answers to user queries, improving user trust and engagement in applications like intelligent assistants or knowledge retrieval systems.\n\n4. **Dependencies**:  \n- Python standard library modules: `time` for timing operations, and",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:07.720281",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_8": {
      "chunk_id": "query_orchestrator.py:chunk_8",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "306c391e0af9ebda1666dd0fa085eda0f4a621a0f0a6c7bcf12d2f9f1f750b3d",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a GitHub LLM (Large Language Model) orchestration module that manages the end-to-end process of handling a query request, including planning, querying, synthesizing, summarizing, and beautifying the response, while logging detailed timing and confidence metrics.\n\n2. **Technical Details**:  \n- The code collects timing metrics for different stages of the orchestration pipeline: planning, querying, synthesis, summary generation, and beautification.  \n- It uses structured logging to output these metrics along with a confidence score and total processing time.  \n- The snippet includes a private method `_plan_query` that determines which data sources to query based on the request type, returning a list of source identifiers.  \n- Data structures used include dictionaries for timing breakdown and lists for source identifiers.\n\n3. **Business Logic**:  \n- The orchestration facilitates efficient and transparent querying of GitHub-related data through an LLM, enabling business users or developers to get synthesized and summarized insights from multiple sources.  \n- The timing and confidence logs help in monitoring and improving the quality and performance of the query responses.\n\n4. **Dependencies**:  \n- The code references a `logger` for logging, likely from Python\u2019s standard `logging` module or a configured logging framework.  \n- It depends on a `QueryRequest` type hint, suggesting integration with a request model defined elsewhere in the codebase.  \n- The orchestration likely interacts",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:18.293029",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_10": {
      "chunk_id": "query_orchestrator.py:chunk_10",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "bf07a2b4d245141276c884c7ca0bcf6d68c77cd180741df7a150578058c0dcad",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code orchestrates querying multiple data sources asynchronously based on a query request, specifically integrating vector database search and direct GitHub API queries to aggregate relevant results.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to concurrently query different sources.  \n- Maintains a list of source identifiers (`sources`) to dynamically determine which backends to query.  \n- Aggregates results from multiple sources into a combined list.  \n- Encapsulates querying logic into private methods (`_query_vector_db`, `_query_github_api`).  \n- Uses conditional checks to verify availability of services (`self.vector_service`, `self.github_client`) before querying.\n\n3. **Business Logic**:  \nEnables flexible and extensible querying of code-related data by combining semantic vector search with direct GitHub API access, supporting richer and more relevant search results for developer tools or knowledge management platforms.\n\n4. **Dependencies**:  \n- An asynchronous vector search service (`self.vector_service`) likely backed by a vector database or embedding index.  \n- A GitHub API client (`self.github_client`) for direct repository or code search.  \n- Data models such as `QueryRequest` and `SourceResult` (likely custom classes or Pydantic models).\n\n5. **Configuration**:  \n- The availability of `vector_service` and `github_client` is presumably configured during class instantiation or via dependency injection.  \n- No explicit environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:25.658305",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_12": {
      "chunk_id": "query_orchestrator.py:chunk_12",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "9216b424c9a1afc664ac034692b91a5ae18ca38ad73116573531e40256f92b0b",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet performs a semantic search query against a vector database, applying optional filters based on repository and programming language, then transforms the raw vector search results into a standardized `SourceResult` format for downstream consumption.\n\n2. **Technical Details**:  \n- Uses a dictionary (`filters`) to dynamically build search constraints.  \n- Calls an asynchronous method `semantic_search` on a `vector_service` to retrieve top-k relevant results based on a natural language query.  \n- Iterates over the vector search results to map them into `SourceResult` objects, extracting and restructuring metadata such as document ID, repository name, file path, and language.  \n- Employs structured logging to record the number of results returned.  \n- The code is wrapped in a try-except block (though the except block is incomplete in the snippet).\n\n3. **Business Logic**:  \nEnables efficient retrieval of code or document snippets relevant to a user query within specified repositories or languages, supporting developer productivity tools such as code search, knowledge discovery, or automated code review assistance.\n\n4. **Dependencies**:  \n- `vector_service`: An external or internal service providing semantic vector search capabilities.  \n- `SourceResult`: A data structure or class used to standardize search results.  \n- `logger`: Logging utility for operational insights.  \n- The code likely depends on asynchronous frameworks (e.g., `asyncio`) and possibly vector database clients.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:33.682299",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_14": {
      "chunk_id": "query_orchestrator.py:chunk_14",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "bb66dac7aab320fefe3dc5dd81ea8df41bc77af6e138c8ede44af44f8b8f0adb",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a query orchestrator module designed to aggregate and process search results from multiple sources, specifically a vector database and the GitHub API, to provide ranked and synthesized results for a given query request.\n\n2. **Technical Details**:  \n- Implements asynchronous querying of the GitHub API (though currently a stub).  \n- Uses sorting algorithms to rank results based on a `relevance_score` attribute.  \n- Applies result deduplication and limits output to a maximum number specified in the request.  \n- Utilizes structured data types such as `List[SourceResult]` and `QueryRequest` for input/output consistency.  \n- Logging is used for tracing execution and error reporting.\n\n3. **Business Logic**:  \nThe code supports a business need to retrieve, combine, and rank relevant information from different data sources (vector DB and GitHub API) to answer user queries effectively, enhancing search quality and user experience in applications that rely on code or repository data.\n\n4. **Dependencies**:  \n- Likely depends on an asynchronous HTTP client or SDK for GitHub API calls (not shown, as the method is not implemented).  \n- Uses a logging framework (`logger`) for error and info messages.  \n- Custom data types `QueryRequest` and `SourceResult` are used, presumably defined elsewhere in the codebase.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:43.156366",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_16": {
      "chunk_id": "query_orchestrator.py:chunk_16",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "faf3e37dae95572c074433fb8d77665c4ba145b98745fdb1acf76c1a2cbbc397",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a query orchestration module that generates a textual summary of search results and optionally beautifies the response using an external beautifier service.\n\n2. **Technical Details**:  \n- The `generate_summary` method constructs a summary string listing up to the top 3 relevant results, including repository and file path metadata and a relevance score formatted to two decimals.  \n- The `_beautify_response` method is asynchronous and conditionally calls an external beautifier service to enhance the summary output. It uses Python's async/await syntax for non-blocking I/O operations.  \n- Data structures used include lists for accumulating summary parts and dictionaries accessed via `.get()` for metadata extraction.\n\n3. **Business Logic**:  \nThe code addresses the need to provide users with a concise, human-readable summary of search results from a code repository or document search system, improving user experience by highlighting the most relevant results and optionally enhancing readability through beautification.\n\n4. **Dependencies**:  \n- An external beautifier service accessed via `self.beautifier.beautify()` which is awaited asynchronously.  \n- Custom types such as `QueryRequest`, `SourceResult`, and `QueryType` suggest domain-specific models defined elsewhere in the codebase.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are shown in this snippet. The presence of `self.beautifier` implies it is configured or injected elsewhere in the class or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:51.781505",
      "status": "summarized"
    },
    "query_orchestrator.py:chunk_18": {
      "chunk_id": "query_orchestrator.py:chunk_18",
      "file_path": "orchestration\\github_llm\\query_orchestrator.py",
      "chunk_hash": "2f050cd3df436cb82bbc7c99bd5e8f8eb4e8b829288c273d7c2ae2affc1be20f",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a private method `_calculate_confidence` that computes an overall confidence score based on a list of `SourceResult` objects, specifically by averaging the relevance scores of the top three results.\n\n2. **Technical Details**:  \n- Input: A list of `SourceResult` instances, each presumably containing a `relevance_score` attribute.  \n- Algorithm: It extracts the relevance scores of the first three results (top results) and calculates their average. If the input list is empty or has no scores, it returns 0.0.  \n- Data Structures: Uses Python lists and list slicing (`results[:3]`).  \n- Design Pattern: Encapsulated as a private method (indicated by the underscore prefix), suggesting it is an internal helper function within a larger class.\n\n3. **Business Logic**:  \nThe method quantifies the confidence level of query results, likely to determine how reliable or relevant the aggregated search or retrieval results are. This can be used to decide whether to present results to users or trigger fallback mechanisms.\n\n4. **Dependencies**:  \n- Relies on a `SourceResult` type, which is expected to have a `relevance_score` attribute.  \n- Uses standard Python typing (`List`) for type hinting.  \n- No external libraries or services are directly referenced in this snippet.\n\n5. **Configuration**:  \nNo environment variables, configuration files, or external settings influence this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:28:59.591667",
      "status": "summarized"
    },
    "github_extractor.py:chunk_0": {
      "chunk_id": "github_extractor.py:chunk_0",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "6e1d36cb56b639c7055e7b4ac515fd11b2316e52ba8ffd550137bc7983e9085c",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module defines an enhanced GitHub repository extractor that parses user messages to identify GitHub repository references in multiple formats, assigning confidence scores to improve extraction accuracy.\n\n2. **Technical Details**  \n- Uses regular expressions to match various GitHub repository reference formats, including full URLs, short URLs, owner/repo strings, and natural language mentions.  \n- Maintains a prioritized list of regex patterns to apply in order of confidence.  \n- Integrates with a global repository registry (`get_global_registry`) to validate and intelligently match extracted repository names.  \n- Encapsulated in a `GitHubExtractor` class, following an object-oriented design.  \n- Uses Python typing hints for method signatures and data structures.  \n- Logging is set up for debugging and operational insights.\n\n3. **Business Logic**  \nEnables robust extraction of GitHub repository references from unstructured user input, facilitating downstream automation such as issue tracking, repository analytics, or integration workflows that rely on accurate repository identification.\n\n4. **Dependencies**  \n- Python standard libraries: `re` (regex), `logging`  \n- Typing module for type annotations (`List`, `Dict`, `Any`, `Optional`)  \n- Internal modules:  \n  - `orchestration.shared.models` for `Reference` and `ReferenceType` data models  \n  - `orchestration.message_parser.extractors.repository_registry` for accessing a global repository registry\n\n5. **Configuration**  \nNo explicit environment variables",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:06.827229",
      "status": "summarized"
    },
    "github_extractor.py:chunk_2": {
      "chunk_id": "github_extractor.py:chunk_2",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "ce72091911802fdfa3457387b17c4202d3347645b61610c80b56b2746e5e3754",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines regular expression patterns to extract and identify GitHub repository references and URLs from text. It is part of a message parsing system that detects various GitHub URL formats and repository mentions.\n\n2. **Technical Details**:  \n- Uses Python's `re` module to compile multiple regex patterns targeting different GitHub URL structures: full URLs, short URLs (without protocol), and owner/repository name mentions with contextual keywords.  \n- Each pattern is associated with a confidence score indicating the likelihood that a matched string is a valid GitHub reference.  \n- Patterns capture components such as repository owner, repository name, issue or pull request numbers, branches, and file paths.  \n- The regexes are case-insensitive (`re.IGNORECASE`) to handle varied input text.\n\n3. **Business Logic**:  \n- Enables automated extraction of GitHub repository references from unstructured text (e.g., chat messages, comments, or logs).  \n- Facilitates linking, tracking, or further processing of GitHub resources within a larger orchestration or integration platform, improving developer productivity and traceability.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regular expressions.  \n- No external third-party libraries are evident in the snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or configuration files are referenced in the snippet.  \n- Confidence scores are hardcoded alongside regex patterns, potentially configurable elsewhere in the full code",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:12.442533",
      "status": "summarized"
    },
    "github_extractor.py:chunk_4": {
      "chunk_id": "github_extractor.py:chunk_4",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "d98272ba58db9b78a6a274b4c4c999b0952d1be59e17fe91f356d95e683ead52",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a GitHub repository reference extractor that parses user messages to identify and extract GitHub repository mentions in various textual formats.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.compile`) to define multiple patterns for detecting GitHub repository references, including standard `owner/repo` formats and `@owner/repo` mention formats.  \n- Each pattern is associated with a confidence score indicating the likelihood that a matched string is a valid GitHub repository reference.  \n- Maintains lists of GitHub-related keywords to boost confidence in detection and a set of invalid owner names to filter out false positives.  \n- The main extraction method `extract` takes a message string and returns a list of `Reference` objects representing identified GitHub repositories.\n\n3. **Business Logic**:  \nEnables automated identification and extraction of GitHub repository references from user-generated text, facilitating features such as linking, tracking, or analytics of repository mentions in communication platforms or orchestration tools.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regular expressions.  \n- Custom `Reference` class (likely defined elsewhere in the codebase) to encapsulate extracted repository references.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration files are indicated in the snippet. Confidence thresholds and invalid owner lists are hardcoded within the class.\n\n6. **Error Handling**:  \nThe snippet does not explicitly show",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:22.259676",
      "status": "summarized"
    },
    "github_extractor.py:chunk_6": {
      "chunk_id": "github_extractor.py:chunk_6",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "ad412486ee31a167edc398f64842847af3478d9027b0d06fa2217c18c789f519",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet extracts GitHub-related references from a given text message by searching for predefined keyword contexts and applying multiple regex patterns to identify and parse GitHub entities such as repositories, issues, or pull requests.\n\n2. **Technical Details**:  \n- Uses a list of regex pattern configurations (`self.patterns`), each with a name, regex pattern, and confidence score, to iteratively search the message.  \n- Employs a set (`seen_repos`) to track unique repositories and a list (`references`) to accumulate extracted references.  \n- Checks for GitHub-related keywords (`self.github_keywords`) in the message to determine if GitHub context is present before pattern matching.  \n- Uses Python\u2019s `re.finditer` to find all non-overlapping matches per pattern.  \n- Calls an internal method `_create_reference` to transform regex matches into structured reference objects, presumably enriching them with metadata like confidence scores and pattern source.\n\n3. **Business Logic**:  \nThe code supports automated extraction of GitHub references from arbitrary text inputs, enabling downstream processes such as issue tracking, linking commits or pull requests, or integrating GitHub data into broader orchestration or notification workflows. This helps in contextualizing messages with actionable GitHub entities.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regex operations, `logging` for logging.  \n- Internal components: `self.github_keywords`, `self.patterns`, and `_create_reference`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:31.060506",
      "status": "summarized"
    },
    "github_extractor.py:chunk_8": {
      "chunk_id": "github_extractor.py:chunk_8",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "95bfb8d4ccdd9d4234fe4b66512ed60b7611dfb2490817a83900057fdd9e5476",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a GitHub repository extractor that parses and validates GitHub repository references from a given input, ensuring uniqueness and logging the extraction process.\n\n2. **Technical Details**:  \n- Uses a set (`seen_repos`) to track and avoid duplicate repository references based on a normalized repository identifier.  \n- Applies a validation method (`_validate_reference`) to ensure each extracted reference meets certain criteria before acceptance.  \n- Employs structured logging at different levels (`info`, `debug`, `warning`) to trace successful extractions, validation failures, duplicates, and parsing errors.  \n- Exception handling is used to catch and log any errors during parsing without interrupting the overall extraction flow.  \n- The snippet hints at a subsequent step to detect \"bare\" repository names (repositories without owners) if no references have been found and GitHub context is present.\n\n3. **Business Logic**:  \nThe code supports automated extraction and validation of GitHub repository references from messages or text inputs, which is critical for systems that track, analyze, or integrate with GitHub repositories (e.g., issue trackers, CI/CD pipelines, or analytics platforms). It ensures only valid and unique repositories are processed, improving data quality and downstream reliability.\n\n4. **Dependencies**:  \n- A logger instance (`logger`) for logging activities.  \n- A method `_validate_reference(ref)` presumably defined elsewhere in the class/module for validating repository references.  \n- The code likely depends",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:39.772599",
      "status": "summarized"
    },
    "github_extractor.py:chunk_10": {
      "chunk_id": "github_extractor.py:chunk_10",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "3bdeed4bc28da2d5e81f64cbc100a2a9821ef08cb88c321874645d18a1e20243",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a GitHub repository reference extractor that parses user messages to identify GitHub repository mentions, including both standard \"owner/repo\" formats and bare repository names. It logs the extraction process and returns a list of normalized repository references with confidence scores.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.compile`) to detect keywords related to repositories (e.g., \"repo\", \"repository\", \"project\", \"codebase\") in the input message.  \n- Maintains a list of `Reference` objects representing detected GitHub repositories, each with attributes like `normalized_value` and `confidence`.  \n- Uses a set (`seen_attempts`) to avoid duplicate processing of the same repository references.  \n- Employs logging at various levels (`info`, `warning`) to trace the extraction process and provide user guidance.  \n- The method `_extract_bare_repo_names_with_registry` suggests an intelligent owner matching mechanism, likely involving a registry or database to infer owners for bare repo names.\n\n3. **Business Logic**:  \nThe code addresses the need to automatically detect and normalize GitHub repository references from unstructured user input (e.g., chat messages, comments). This enables downstream systems to link, track, or analyze repositories mentioned by users without requiring strict input formats, improving user experience and data accuracy.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regular expressions, `logging` for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:47.336119",
      "status": "summarized"
    },
    "github_extractor.py:chunk_12": {
      "chunk_id": "github_extractor.py:chunk_12",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "771440fc41a7afe8c9dcfaa7ceae857ff49a6100b2d8cb8665c2118ce6785b29",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a GitHub repository extractor that scans a text message to identify potential GitHub repository owner names following specific keywords. It extracts and normalizes candidate owner names for further processing.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.finditer` and `re.match`) to locate keywords and extract subsequent text segments.  \n- Extracts up to 50 characters following a matched keyword and attempts to capture 1 to 3 words as candidate owner names.  \n- Applies filtering rules to exclude candidates containing slashes (indicating full owner/repo format) or common irrelevant words.  \n- Prepares a list of normalization variations for each candidate to improve matching accuracy.\n\n3. **Business Logic**:  \nThe code aims to accurately identify GitHub repository owners mentioned in free-form text, which is critical for automating repository linking, issue tracking, or analytics in a system that processes user messages or comments referencing GitHub projects.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regular expression operations.  \n- An instance attribute `self.invalid_owners` presumably containing a set of invalid or disallowed owner names.\n\n5. **Configuration**:  \n- The set `self.invalid_owners` is likely configured elsewhere in the class or module, defining disallowed owner names to filter out common or irrelevant terms.  \n- The keyword pattern `repo_keyword_pattern` is defined outside this snippet,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:29:54.722867",
      "status": "summarized"
    },
    "github_extractor.py:chunk_14": {
      "chunk_id": "github_extractor.py:chunk_14",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "dda5b4dbd33504b96c6febbe016a1fd5e5c3f61044fbb6d74679d5f8b9caa707",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet attempts to identify and normalize GitHub repository names from candidate strings by generating variations of the repository name and searching for matches in a repository registry.\n\n2. **Technical Details**:  \n- Generates multiple candidate repository name formats by replacing spaces with no space, hyphens, or underscores.  \n- Uses a set (`seen_attempts`) to avoid redundant lookups for the same repository name variant.  \n- Invokes a fuzzy matching method (`find_repository`) on a `repo_registry` object with a similarity threshold (0.6) to find the best matching repository.  \n- Upon finding a match, constructs a `Reference` object encapsulating metadata such as owner, repo name, and matched pattern type.  \n- Uses logging to trace lookup attempts.\n\n3. **Business Logic**:  \nThe code supports the business need to robustly identify GitHub repositories referenced in text, even when repository names are formatted differently (e.g., spaces replaced by hyphens or underscores). This enables downstream processes to link textual mentions to canonical repository data, improving data integration, analytics, or automation workflows involving GitHub repositories.\n\n4. **Dependencies**:  \n- `repo_registry`: a service or module responsible for repository lookup with fuzzy matching capabilities.  \n- `Reference` and `ReferenceType`: domain models/enums used to represent normalized references.  \n- `logger`: logging utility for informational output.  \n- `keyword_match`: regex match object",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:02.787320",
      "status": "summarized"
    },
    "github_extractor.py:chunk_16": {
      "chunk_id": "github_extractor.py:chunk_16",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "da9cefee001d6233e74e882afae4556714d745e5d76a53751ad1b0f44000349d",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a GitHub URL extractor that processes candidate strings to identify and validate GitHub repository references, assigning confidence scores and metadata to each match or marking them as unknown if no valid match is found.\n\n2. **Technical Details**:  \n- Iterates over candidate variations to find a registry match using confidence and match type metadata.  \n- Constructs `Reference` objects encapsulating details such as match type, confidence, original input, and normalized repository names.  \n- Uses a list (`references`) to accumulate matched or unknown references.  \n- Employs a break statement to stop further attempts once a confident match is found for a candidate.  \n- Checks for duplicates before appending an \"UNKNOWN\" reference for unmatched candidates.  \n- Uses formatted logging to record match results with confidence and type.\n\n3. **Business Logic**:  \nThe code supports automated extraction and normalization of GitHub repository references from unstructured text, enabling downstream processes (e.g., dependency analysis, security scanning, or metadata enrichment) to reliably identify and categorize repository URLs with confidence scoring.\n\n4. **Dependencies**:  \n- Custom classes/enums such as `Reference` and `ReferenceType` (likely defined elsewhere in the codebase).  \n- A `logger` instance for info-level logging.  \n- Presumably, regex match objects (e.g., `keyword_match`) and data structures like `match_info` dicts are provided by other parts of the",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:10.654084",
      "status": "summarized"
    },
    "github_extractor.py:chunk_18": {
      "chunk_id": "github_extractor.py:chunk_18",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "83e7be00a5512f9137ca484f430dd78309ed221f2d73ecdb4dc29ea5f0c8004a",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a GitHub repository name extractor that identifies \"bare\" repository names (i.e., repository names without an owner prefix) from user messages. It generates low-confidence references for these ambiguous repo names and logs warnings prompting the user to specify the owner explicitly.\n\n2. **Technical Details**:  \n- The method `_extract_bare_repo_names` takes a string message and returns a list of `Reference` objects representing detected bare repository names.  \n- Each `Reference` includes metadata such as the repo name, a flag indicating the need for an owner, and a warning message.  \n- Confidence scores are assigned low values (0.3) to reflect ambiguity.  \n- Logging is used to warn about missing owner information and to guide users toward correct formatting.  \n- The code uses a list (`references`) to accumulate results.\n\n3. **Business Logic**:  \n- The extractor addresses the problem of ambiguous repository references in user input where the owner is not specified.  \n- It helps maintain data integrity and accuracy in downstream processes (e.g., linking to GitHub repos) by flagging incomplete repo names and prompting for clarification.  \n- This reduces errors in repository identification and improves user guidance.\n\n4. **Dependencies**:  \n- Uses a `Reference` class or data structure (likely custom or from an internal module) to encapsulate extracted repo information.  \n- Uses a `logger` object for warning messages (",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:21.832228",
      "status": "summarized"
    },
    "github_extractor.py:chunk_20": {
      "chunk_id": "github_extractor.py:chunk_20",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "812217aec20f722eb8d1c63bd67e99ddbf18c598fb5b7132e8452585ca19b437",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis code snippet extracts GitHub repository names from a given text message by identifying repo-like keywords and associated names, normalizing them into a reference format with an unknown owner when the owner is not explicitly mentioned.\n\n2. **Technical Details**:  \n- Uses a compiled regular expression (`bare_repo_pattern`) to match patterns where GitHub-related keywords (\"repo\", \"repository\", \"project\", \"codebase\") appear near candidate repository names.  \n- The regex captures repo names either preceding or following these keywords, allowing flexible phrase structures.  \n- Iterates over all regex matches in the input message.  \n- Filters out matches that contain slashes (indicating full owner/repo format) or are common invalid words (e.g., \"repo\", \"project\").  \n- Constructs a `Reference` object with a normalized value using a placeholder owner `\"UNKNOWN\"` when the owner is not specified.  \n- Uses `ReferenceType.GITHUB_URL` to categorize the reference type.\n\n3. **Business Logic**:  \nThe code addresses the problem of identifying and extracting GitHub repository references from unstructured text inputs (e.g., chat messages, comments) where the repository owner is not explicitly mentioned. This enables downstream systems to recognize and link to repositories even when partial or informal mentions occur, improving traceability and automation in workflows like issue tracking or code review.\n\n4. **Dependencies**:  \n- Python standard library: `re` module for regular expressions.  \n- Custom",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:30.669620",
      "status": "summarized"
    },
    "github_extractor.py:chunk_22": {
      "chunk_id": "github_extractor.py:chunk_22",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "4dfce2dab5456d8db3f5ce8d07320babdcc4caf6e535372619008465611ea52b",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a GitHub repository reference extractor within a message parsing orchestration system. It identifies and parses GitHub repository references from text, creating structured `Reference` objects that capture repository owner and name information.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.Match`) to identify GitHub repository patterns in text.  \n- Extracts groups from regex matches to obtain `owner` and `repo` names.  \n- Implements a method `_create_reference` that constructs a `Reference` object if both owner and repo are present.  \n- Handles cases where only a bare repository name is found (without owner), assigning a low confidence score (0.5) and logging a warning.  \n- Cleans repository names by removing `.git` suffixes if present.  \n- Uses a list (`references`) to accumulate multiple extracted references.  \n- Logging is used for warnings about incomplete or ambiguous repository references.\n\n3. **Business Logic**:  \nThe code solves the problem of reliably extracting GitHub repository references from unstructured text messages or inputs, which is critical for downstream processes such as issue tracking, linking code repositories, or automating workflows that depend on repository metadata. It enforces the business rule that repository references should include an owner to avoid ambiguity.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regular expressions, `logging` for warnings.  \n- Custom or external `Reference`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:38.468332",
      "status": "summarized"
    },
    "github_extractor.py:chunk_24": {
      "chunk_id": "github_extractor.py:chunk_24",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "2b155d3245e0d0882d4afaf7da04e0eb60a275d7ea461591367501faf2b4a7a6",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis code snippet extracts and categorizes metadata from a parsed GitHub URL or reference string, identifying repository details, issue or pull request numbers, branches, and file paths.\n\n2. **Technical Details**:  \n- Uses string manipulation (`rstrip`) to clean repository names.  \n- Utilizes a dictionary (`metadata`) to store extracted attributes dynamically.  \n- Determines the type of GitHub reference by inspecting regex match groups and the matched string content.  \n- Conditional logic differentiates between GitHub URL types: general repo URL, issue, pull request, branch, and file path references.  \n- Relies on a `ReferenceType` enum or constant class to classify the reference type.\n\n3. **Business Logic**:  \nEnables the system to parse GitHub URLs or references embedded in text or data, extracting structured information to support features like linking to issues, PRs, specific branches, or files. This facilitates automation, traceability, or integration with GitHub resources in workflows.\n\n4. **Dependencies**:  \n- Assumes presence of a regex `match` object and `groups` list from prior pattern matching.  \n- Uses a `ReferenceType` enumeration or class (likely defined elsewhere in the codebase).  \n- Standard Python types (`Dict`, `Any`) from `typing` module.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet. Behavior depends on the regex patterns and `ReferenceType",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:46.690217",
      "status": "summarized"
    },
    "github_extractor.py:chunk_26": {
      "chunk_id": "github_extractor.py:chunk_26",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "8ec3c32a2468c62c8e9c4849adeb58f19f72c3c5e3cbcaff829f786a511aafe1",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a GitHub reference extractor that parses and validates GitHub repository references from text, adjusting confidence scores based on contextual cues and ensuring references correspond to valid GitHub repositories.\n\n2. **Technical Details**:  \n- The code adjusts a confidence score (`confidence`) for detected GitHub references based on whether there is contextual evidence (`has_github_context`) and the pattern type (`pattern_name`).  \n- It uses a `Reference` data structure (likely a class or namedtuple) to encapsulate extracted information including type, raw matched text, normalized repository path (`owner/repo`), metadata, and confidence score.  \n- The `_validate_reference` method performs validation by checking metadata fields (`owner`, `repo`) and rejecting references with owners in a predefined invalid list (`self.invalid_owners`).  \n- Logging is used for debug-level tracing of invalid owners.\n\n3. **Business Logic**:  \nThe code aims to reliably extract and validate GitHub repository references from unstructured text, improving the accuracy of downstream processes such as issue tracking, code linking, or automated notifications by ensuring only valid and contextually relevant references are considered.\n\n4. **Dependencies**:  \n- Uses a `Reference` class or data structure (likely defined elsewhere in the codebase).  \n- Uses Python\u2019s standard logging module (`logger.debug`).  \n- Assumes presence of attributes like `self.invalid_owners` which is a collection of disallowed GitHub",
      "embedding_id": null,
      "created_at": "2025-10-22T19:30:54.400011",
      "status": "summarized"
    },
    "github_extractor.py:chunk_28": {
      "chunk_id": "github_extractor.py:chunk_28",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "89739e837bd1ed7173c45adfa86dc625071aaa77a097ba849b0d9cf2bf09c6b8",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis code snippet validates GitHub repository owner and repository name strings to ensure they conform to GitHub's naming rules and additional heuristic checks before further processing.\n\n2. **Technical Details**:  \n- Uses conditional checks on string length to enforce GitHub's character limits for owners (2-39 chars) and repos (1-100 chars).  \n- Applies regular expressions (`re.match`) to validate allowed characters in owner (`[a-zA-Z0-9_-]`) and repo (`[a-zA-Z0-9_.-]`) names.  \n- Checks if the repository name is numeric-only to filter out likely false positives.  \n- Incorporates a confidence threshold (`ref.confidence < 0.8`) to apply stricter validation rules for low-confidence matches (e.g., minimum repo name length).  \n- Uses logging (`logger.debug`) for traceability of validation failures.\n\n3. **Business Logic**:  \nEnsures that extracted GitHub repository references are valid and meaningful before they are used downstream, reducing errors from malformed or spurious data in message parsing or orchestration workflows.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regex matching.  \n- A logging framework (likely Python\u2019s `logging` module) for debug output.  \n- An external or internal `ref` object with a `confidence` attribute, indicating the certainty of the parsed reference.\n\n5. **Configuration**:  \nNo explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:01.705734",
      "status": "summarized"
    },
    "github_extractor.py:chunk_30": {
      "chunk_id": "github_extractor.py:chunk_30",
      "file_path": "orchestration\\message_parser\\extractors\\github_extractor.py",
      "chunk_hash": "6922ef481b7003a72ef46cc541c877066099e5f06f04cfe3233da25c77788603",
      "chunk_index": 30,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a method `extract_repo_info` that parses a GitHub repository reference string (either in \"owner/repo\" format or a full GitHub URL) and extracts the repository owner and name as a dictionary. It returns `None` if the input is invalid or cannot be parsed.\n\n2. **Technical Details**:  \n- The method relies on an internal `extract` function (not shown) that presumably returns a list of match objects containing metadata about the repository.  \n- It accesses the first match's metadata dictionary to retrieve the 'owner' and 'repo' keys.  \n- Uses Python typing hints (`Optional[Dict[str, str]]`) for clarity on input/output types.  \n- Uses a simple conditional check to return either the extracted dictionary or `None`.\n\n3. **Business Logic**:  \n- Facilitates the extraction of GitHub repository information from various input formats, enabling downstream processes (e.g., CI/CD pipelines, analytics, or integrations) to work with normalized repository identifiers.  \n- Helps validate and standardize repository references within an orchestration or message parsing context.\n\n4. **Dependencies**:  \n- Depends on a `self.extract` method, likely part of the same class or module, which performs the actual parsing and metadata extraction.  \n- Uses Python standard logging (`logger.debug`) as seen in the snippet above the method (not fully included here).  \n- Uses Python typing (`Optional`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:08.545803",
      "status": "summarized"
    },
    "formatters.py:chunk_0": {
      "chunk_id": "formatters.py:chunk_0",
      "file_path": "orchestration\\summary_layer\\formatters.py",
      "chunk_hash": "ed1818ad359465b9d3cf8c2ad1d29f7c7f9c19303be918a82e3299959385a598",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a framework for formatting response data into different output formats, specifically Markdown and JSON, enabling flexible presentation of structured content.\n\n2. **Technical Details**  \n- Implements the Strategy design pattern via an abstract base class `ResponseFormatter` with a required `format` method.  \n- Two concrete formatter classes: `MarkdownFormatter` converts a dictionary into a Markdown string with headers, sections, and code blocks; `JSONFormatter` (partially shown) formats the dictionary as pretty-printed JSON.  \n- Uses Python\u2019s `abc` module for abstract base classes and typing annotations for clarity.  \n- The content input is a nested dictionary with optional keys like `title`, `summary`, `sections` (list of dicts), `code`, and `language`.\n\n3. **Business Logic**  \nFacilitates consistent and reusable formatting of response data for different output channels or consumers, such as generating human-readable Markdown reports or machine-readable JSON responses, supporting documentation, reporting, or API response formatting needs.\n\n4. **Dependencies**  \n- Standard Python libraries: `abc` for abstract classes, `typing` for type hints, and `json` for JSON serialization.\n\n5. **Configuration**  \nNo explicit configuration, environment variables, or external settings are referenced or required by this code.\n\n6. **Error Handling**  \n- No explicit error handling is implemented.  \n- Potential errors (e.g., missing keys in content dict) are implicitly handled by using",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:15.992418",
      "status": "summarized"
    },
    "formatters.py:chunk_2": {
      "chunk_id": "formatters.py:chunk_2",
      "file_path": "orchestration\\summary_layer\\formatters.py",
      "chunk_hash": "1b63159d5d582eb844c090de490fcf1187b1b538e74b806c8ff587646e517aea",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines a `PlainTextFormatter` class that formats structured response content (provided as a dictionary) into a human-readable plain text string, organizing titles, summaries, and sections with simple text-based headings and separators.\n\n2. **Technical Details**:  \n- The class `PlainTextFormatter` inherits from a base class `ResponseFormatter` (not shown here).  \n- The `format` method takes a dictionary (`content`) and constructs a list of text parts by extracting keys like `'title'`, `'summary'`, and `'sections'`.  \n- It uses string operations to create underlined titles and section headers by repeating characters (`=` and `-`) matching the length of the title strings.  \n- Sections are iterated over, with default fallbacks for missing titles or content (`'Section'` and empty string).  \n- The final output is a concatenated string with double newlines separating major parts.\n\n3. **Business Logic**:  \nThis formatter converts structured response data into a plain text format suitable for display in environments where rich formatting (like HTML or JSON) is not supported or desired, such as CLI tools, logs, or plain text emails. It enhances readability by visually distinguishing titles and sections.\n\n4. **Dependencies**:  \n- Uses Python standard library only (`json` is referenced in the snippet but not in this class).  \n- Relies on an external base class `ResponseFormatter` which is presumably part of",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:21.166366",
      "status": "summarized"
    },
    "response_formatter.py:chunk_0": {
      "chunk_id": "response_formatter.py:chunk_0",
      "file_path": "orchestration\\voice_assistant\\response_formatter.py",
      "chunk_hash": "8d6ffc5e7d09201596fabdd00e1b32ebd976ac2d0dc9012acb1c7c0dfadec38d",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module provides a class, `VoiceResponseFormatter`, designed to convert orchestration-generated textual responses into concise, voice-friendly, and conversational outputs suitable for voice assistant applications.\n\n2. **Technical Details**  \n- Utilizes an asynchronous method `format_for_voice` to process responses, enabling non-blocking I/O operations likely involving external calls.  \n- Employs a decorator or helper class `ResponseBeautifier` for initial cleanup of raw responses, such as removing markdown or formatting artifacts.  \n- Integrates with a resilient large language model orchestrator (`ResilientLLMOrchestrator`) to summarize or rephrase responses, ensuring they are concise and conversational.  \n- Configurable maximum response length (`max_length`) to control verbosity.  \n- Uses Python\u2019s standard logging for lifecycle and debugging information.\n\n3. **Business Logic**  \nSolves the problem of transforming potentially verbose or poorly formatted orchestration responses into succinct, natural-sounding speech outputs. This improves user experience in voice assistant scenarios by making responses easier to understand and more engaging.\n\n4. **Dependencies**  \n- `ResilientLLMOrchestrator` from `shared.llm_providers.resilient_orchestrator`: likely a wrapper around LLM APIs with retry/resilience logic.  \n- `ResponseBeautifier` from `orchestration.summary_layer.beautifier`: cleans and formats raw text responses.  \n- Standard Python libraries: `logging`, `re`, and `typing.Optional",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:25.798069",
      "status": "summarized"
    },
    "response_formatter.py:chunk_2": {
      "chunk_id": "response_formatter.py:chunk_2",
      "file_path": "orchestration\\voice_assistant\\response_formatter.py",
      "chunk_hash": "90bc1b3b98c1c62114d13767843318f523d9df7e5474bf92557d09dda4c706a9",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code formats textual responses specifically for voice assistants by cleaning, summarizing, and converting them into a conversational style optimized for vocal delivery.\n\n2. **Technical Details**:  \n- The main method (likely asynchronous) processes a response string through multiple steps: beautification (via an external beautifier), markdown removal using regex substitutions, conditional summarization if the text exceeds a maximum length, and finally conversion into a conversational tone.  \n- Markdown removal targets code blocks, inline code, and headers using regular expressions.  \n- Asynchronous calls (`await`) indicate integration with async I/O operations, possibly involving network or CPU-bound tasks like summarization and conversational transformation.  \n- The design follows a pipeline pattern, sequentially transforming the input text.\n\n3. **Business Logic**:  \nThe code addresses the need to convert rich text responses (potentially containing markdown and lengthy content) into concise, clear, and natural-sounding speech output for voice assistant users, enhancing user experience by making responses easier to understand and more engaging.\n\n4. **Dependencies**:  \n- Uses Python\u2019s `re` module for regex operations.  \n- Relies on an external `beautifier` component with an async `beautify_response` method.  \n- Logging is done via a `logger` (likely Python\u2019s standard logging module or a wrapper).  \n- The summarization and conversational formatting methods (`_summarize_for_voice`, `_make_conversational`) are internal async",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:32.652641",
      "status": "summarized"
    },
    "response_formatter.py:chunk_4": {
      "chunk_id": "response_formatter.py:chunk_4",
      "file_path": "orchestration\\voice_assistant\\response_formatter.py",
      "chunk_hash": "9e0cd20645dd0937b8769706b6b765ae1aa039cb644e15db7d283e885214d0f5",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a response formatter module designed to clean and summarize text responses for voice assistant output. It removes markdown formatting and list markers from text and generates a concise, conversational summary suitable for voice interaction.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.sub`) to strip markdown syntax such as bold (`**text**`), italics (`*text*`), links (`[text](url)`), unordered list bullets (`-`, `*`, `+`), and ordered list numbers (`1.`).  \n- Cleans up excessive newlines and trims whitespace to produce clean text.  \n- Implements an asynchronous method `_summarize_for_voice` that constructs a prompt for a language model (LLM) to generate a voice-friendly summary.  \n- The prompt includes constraints like maximum character length (`self.max_length`), conversational tone, and intent type context.  \n- Calls an asynchronous LLM generation method (`self.llm.generate`) with parameters such as `max_tokens` and `temperature` to control output length and creativity.\n\n3. **Business Logic**:  \nThe code addresses the need to convert verbose or markdown-formatted textual responses into concise, natural-sounding speech outputs for voice assistants. This improves user experience by making responses easier to understand and more engaging when delivered via voice interfaces.\n\n4. **Dependencies**:  \n- Python `re` module for regex operations.  \n- An asynchronous language model interface",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:37.955966",
      "status": "summarized"
    },
    "response_formatter.py:chunk_6": {
      "chunk_id": "response_formatter.py:chunk_6",
      "file_path": "orchestration\\voice_assistant\\response_formatter.py",
      "chunk_hash": "8c0f307608ad219ac6fa3bcbb3c00fd339ea03f7ca8adaab5528fd9eda9e3da6",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code is part of a voice assistant's response formatting module, designed to generate concise summaries of text and transform responses into a more conversational style tailored for voice interactions.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for potentially non-blocking operations.  \n- Implements text summarization with a fallback truncation strategy if summarization fails.  \n- Applies intent-based prefixes to responses to personalize the conversational tone.  \n- Performs string replacements to convert technical jargon into friendlier terms for better voice interaction.  \n- Uses dictionaries for mapping intent types to prefixes and technical terms to their conversational equivalents.\n\n3. **Business Logic**:  \nThe code enhances user experience in a voice assistant by ensuring responses are succinct, contextually relevant, and easy to understand, thereby improving engagement and clarity when interacting with technical content via voice.\n\n4. **Dependencies**:  \n- Relies on an external summarization service or method (implied by `result.get(\"content\", ...)` and `step_name=\"voice_summarization\"`).  \n- Uses a `logger` for error logging (likely from Python\u2019s standard logging module or a custom logger).  \n- No explicit external libraries shown in the snippet, but asynchronous features imply Python 3.7+.\n\n5. **Configuration**:  \n- Uses a `self.max_length` attribute to limit summary length, suggesting configurable max response size.  \n- Intent types and their prefixes are hardcoded in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:42.918086",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_0": {
      "chunk_id": "voice_orchestrator.py:chunk_0",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "fa68028c46dfb222b72d8b9512a18b029f1810912eb082b821c81e268b92eb3a",
      "chunk_index": 0,
      "summary": "**Summary of `voice_orchestrator.py`**\n\n---\n\n### 1. Purpose\nThis module implements the main orchestration logic for a voice assistant system, managing the end-to-end voice interaction flow from receiving audio input to producing a spoken response.\n\n---\n\n### 2. Technical Details\n- **Data Models**: Uses Pydantic `BaseModel` classes (`VoiceRequest`, `VoiceResponse`) for structured, validated data exchange between frontend and backend.\n- **Workflow Coordination**: Coordinates multiple components:\n  - Speech-to-Text (STT) conversion from base64-encoded audio.\n  - Intent classification to understand user commands.\n  - Routing/orchestration of requests to appropriate services or logic.\n  - Formatting of textual responses.\n  - Text-to-Speech (TTS) synthesis to generate audio responses.\n- **Design Patterns**:\n  - **Facade/Orchestrator Pattern**: `VoiceOrchestrator` acts as a facade to unify multiple subsystems (STT, intent classifier, response formatter, TTS).\n  - **Dependency Injection**: Injects dependencies like `SessionManager`, `IntentClassifier`, `AzureVoiceAdapter` for modularity.\n- **Data Handling**: Audio data is handled as base64-encoded strings, supporting multiple audio formats (webm, mp3, wav).\n\n---\n\n### 3. Business Logic\n- Enables a seamless voice assistant experience by converting user speech into actionable intents and generating natural language responses.\n- Supports session",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:51.572112",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_2": {
      "chunk_id": "voice_orchestrator.py:chunk_2",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "055e0f4af0bbb1e2e599ce5e0dceedca5b9feb6b375a75ceb9a154ca97d86a29",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**  \nThis code defines the initialization logic for a Voice Orchestrator component that manages the end-to-end workflow of a voice assistant, including session handling, speech recognition, intent classification, response generation, and speech synthesis.\n\n2. **Technical Details**  \n- Uses an object-oriented design pattern with a central orchestrator class coordinating multiple specialized components.  \n- Components initialized include:  \n  - `SessionManager` for managing user sessions.  \n  - `ResilientLLMOrchestrator` for large language model (LLM) interactions, likely handling intent understanding and response generation.  \n  - `ResponseBeautifier` to clean and format generated responses, leveraging the LLM provider.  \n  - `IntentClassifier` that uses the LLM to classify user intents.  \n  - `VoiceResponseFormatter` to format voice responses with constraints like max length.  \n  - Conditional initialization of `AzureVoiceAdapter` for speech-to-text (STT) and translation if Azure is the configured provider.  \n- Lazy initialization is mentioned for STT/TTS clients, indicating resource optimization.\n\n3. **Business Logic**  \nEnables a voice assistant to understand user speech, interpret intent, generate appropriate responses, and synthesize speech output, thereby facilitating natural and interactive voice-based user experiences in applications.\n\n4. **Dependencies**  \n- Custom modules/classes: `SessionManager`, `ResilientLLMOrchestrator`, `ResponseBeautifier`, `IntentClassifier",
      "embedding_id": null,
      "created_at": "2025-10-22T19:31:56.543848",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_4": {
      "chunk_id": "voice_orchestrator.py:chunk_4",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "31348f5609a3931c1850515e94776b2083cccdbb107ff0632675e9a7e8ed33ee",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis Python code defines an asynchronous method within a voice orchestration component that processes voice requests end-to-end by converting audio input into a synthesized voice response.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O operations such as audio transcription and synthesis.  \n- Implements a multi-step voice processing pipeline: session management, speech-to-text (STT) transcription (including language detection and translation), intent classification, orchestration routing, response formatting, and text-to-speech (TTS) synthesis.  \n- Utilizes a session manager to maintain conversational context across requests.  \n- Logging is used extensively for tracing the flow and intermediate data (transcripts, detected languages).  \n- The transcription step appears to leverage Azure Cognitive Services for STT and translation.\n\n3. **Business Logic**  \nThe code supports a voice assistant or conversational AI system by enabling users to interact via spoken language. It handles the conversion of raw audio into actionable intents and generates spoken responses, facilitating natural and multilingual voice interactions.\n\n4. **Dependencies**  \n- Azure Cognitive Services (implied by comments and method naming for STT and translation).  \n- A session management component (`self.session_manager`).  \n- Logging framework for info-level logs.  \n- Custom data types `VoiceRequest` and `VoiceResponse` representing input and output contracts.\n\n5. **Configuration**  \n- Likely requires configuration for Azure service credentials (keys, endpoints) to enable",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:04.450651",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_6": {
      "chunk_id": "voice_orchestrator.py:chunk_6",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "d0e4b4ca8df55bcfa908f375afc1bf79668300850650d10655a742dab84c4f77",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet orchestrates a voice assistant interaction by processing a user\u2019s spoken input, classifying the intent, generating a response, formatting it for voice output, synthesizing speech, and managing the conversational session state.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially I/O-bound operations such as intent classification, orchestration routing, response formatting, and speech synthesis.  \n- Maintains conversation context via a `session_manager` that tracks turns (user and assistant) in a session identified by `session_id`.  \n- Employs an `intent_classifier` to determine user intent based on the current transcript and conversation history.  \n- Routes the classified intent and transcript to an orchestration layer (`_route_to_orchestration`) to generate a textual response and a \"thinking\" state.  \n- Formats the response text for voice output using a `response_formatter`.  \n- Synthesizes the formatted response into audio data asynchronously.  \n- Constructs and returns a `VoiceResponse` object encapsulating session details and results.\n\n3. **Business Logic**:  \nEnables a voice assistant to understand and respond to user queries in a conversational manner, maintaining context across turns to provide relevant, intent-driven responses. This supports business goals such as improving user engagement, automating customer interactions, and delivering personalized voice experiences.\n\n4. **Dependencies**:  \n- `session_manager`: Manages conversation state and history.  \n- `intent_classifier",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:09.003807",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_8": {
      "chunk_id": "voice_orchestrator.py:chunk_8",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "b26555d211cc45e71558a4245eab6d92159badcf351c734fcc4c949b431b84ee",
      "chunk_index": 8,
      "summary": "1. **Purpose**  \nThis asynchronous Python method `_transcribe_audio` transcribes spoken audio (provided as a base64 string) into text using a configured speech-to-text (STT) provider, supporting both Azure and OpenAI services. It returns a tuple containing the transcribed or translated text, the original text (if applicable), and the detected language.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O operations without blocking.  \n- Implements a conditional branching pattern to select the STT provider based on configuration (`settings.voice_stt_provider`).  \n- For Azure, it calls an async method `process_audio` on an `azure_voice` object, which returns multiple values including original audio transcription, translated text, detected language, and a note.  \n- For OpenAI, it presumably calls a different transcription method (code snippet incomplete).  \n- Returns a tuple of `(translated_text, original_text, detected_language)` to accommodate differences in provider capabilities (Azure supports translation and language detection, OpenAI returns only transcription).\n\n3. **Business Logic**  \nEnables voice-based interaction by converting user audio input into text, facilitating natural language understanding and further processing in a voice assistant or conversational AI system. This supports multilingual scenarios by providing translation and language detection, improving user experience and accessibility.\n\n4. **Dependencies**  \n- `settings` module or object for configuration (likely environment-driven).  \n- `azure_voice` service client or wrapper",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:13.029146",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_10": {
      "chunk_id": "voice_orchestrator.py:chunk_10",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "c0b18ec569c05fa35a85840be4dcd8c1337e1572d702f38a01c4ea2cd79a02f7",
      "chunk_index": 10,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles errors occurring during speech-to-text (STT) transcription using OpenAI Whisper. It manages issues such as missing API keys, unknown STT providers, and runtime exceptions during the transcription process.\n\n2. **Exception Types**:  \n   - General `Exception` is caught in the outer try-except block, covering all runtime errors during transcription.  \n   - A specific `ValueError` is raised if the OpenAI API key is not configured (checked explicitly before making API calls).\n\n3. **Recovery Strategy**:  \n   - If an unknown STT provider is configured, the code logs a warning and returns a default transcription message indicating unavailability.  \n   - On exceptions during transcription, it logs the error and returns a transcription error message instead of raising the exception further, preventing crashes.  \n   - No retries are implemented; the strategy is to fail gracefully and provide informative fallback text.\n\n4. **Logging**:  \n   - Warnings are logged when an unknown STT provider is detected (`logger.warning`).  \n   - Errors during transcription are logged with an error level (`logger.error`) including the exception message, aiding monitoring and debugging.\n\n5. **User Impact**:  \n   - Users receive a placeholder transcription string indicating either unavailability or an error, rather than raw exceptions or crashes.  \n   - This maintains user experience by providing clear feedback that transcription failed or is not configured.\n\n6. **Fallback**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:22.150774",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_12": {
      "chunk_id": "voice_orchestrator.py:chunk_12",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "8f6255183efca40d2830b182dec53f66f941e5ccf4f10066ac6eada9d29e0c62",
      "chunk_index": 12,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages failures related to speech-to-text (STT) transcription using OpenAI Whisper and placeholders for Azure Speech Services. It primarily addresses issues during the transcription API call and missing dependencies or configurations.\n\n2. **Exception Types**:  \n   - `ImportError`: Catches missing OpenAI library import failures.  \n   - `Exception`: Catches all other generic exceptions during the OpenAI Whisper transcription call.  \n   - `ValueError`: Raised explicitly if Azure Speech key configuration is missing.\n\n3. **Recovery Strategy**:  \n   - For `ImportError`, the code logs an error and returns a specific string indicating the missing library, allowing the application to continue running without crashing.  \n   - For generic exceptions, the error is logged, and the exception is re-raised, signaling a failure that likely requires higher-level handling or termination.  \n   - For Azure transcription, since it is not implemented, a warning is logged and a placeholder string is returned to avoid blocking execution.\n\n4. **Logging**:  \n   - Errors are logged with clear, emoji-prefixed messages for visibility (e.g., \"\u274c OpenAI Whisper error\").  \n   - Warnings are logged for unimplemented features (Azure STT).  \n   - Informational logs indicate routing decisions in orchestration, aiding traceability.\n\n5. **User Impact**:  \n   - If the OpenAI library is missing, users receive a",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:32.435918",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_14": {
      "chunk_id": "voice_orchestrator.py:chunk_14",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "1885182940da4c41b23740333d96e5c56ae2e17adcf934a78ada13b139c4144d",
      "chunk_index": 14,
      "summary": "1. **Purpose**  \nThis asynchronous Python code orchestrates voice assistant intents by routing user transcripts to specialized handlers based on the intent's orchestration type, managing workflows such as commit operations, GitHub queries, or general language model queries.\n\n2. **Technical Details**  \n- Uses an asynchronous pattern (`async/await`) to handle potentially long-running I/O operations without blocking.  \n- Implements a simple orchestration control flow with conditional branching on `intent.orchestration` to delegate processing to specific private handler methods (`_handle_commit_intent`, `_handle_github_query`, `_handle_general_query`).  \n- Maintains a `thinking` dictionary to track the sequence of completed orchestration steps, facilitating traceability or debugging.  \n- Employs try-except blocks for error capturing and logging.\n\n3. **Business Logic**  \nThe code supports a voice assistant's ability to interpret and respond to different types of user intents related to software development workflows: committing code changes, querying GitHub repositories via a language model, or handling general queries. This enables automation and natural language interaction with development tools and repositories.\n\n4. **Dependencies**  \n- Assumes existence of a logger instance (`logger`) for error logging.  \n- Relies on intent objects with attributes like `orchestration` and `entities`.  \n- Uses asynchronous programming constructs, likely requiring an async event loop (e.g., `asyncio`).  \n- The actual implementations of `_handle_commit_intent`, `_handle_github_query",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:40.067644",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_16": {
      "chunk_id": "voice_orchestrator.py:chunk_16",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "3158059d8a17821c8b88caa5da7fb66f022f482eb9d220f1eb08a810aa9342d0",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a voice assistant orchestration module that processes user voice queries related to GitHub/code and general topics, generating appropriate responses by leveraging language models and session context.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) to handle potentially long-running operations without blocking.  \n- Maintains session-based conversation history via a `session_manager` to provide context-aware responses.  \n- Constructs message payloads for language model (LLM) interaction, including fallback mechanisms (`chat_completion_with_fallback`) to ensure resilience.  \n- Implements modular handlers for different query types: GitHub-specific and general queries.  \n- Uses a method `_build_general_messages` to prepare input messages, possibly including language detection (though implementation details are not shown).\n\n3. **Business Logic**:  \n- Enables a voice assistant to understand and respond to user intents related to code commits and GitHub queries, improving developer productivity by integrating voice-driven codebase interactions.  \n- Provides general conversational capabilities to handle broader user queries beyond code, enhancing user engagement and assistant versatility.  \n- Currently, GitHub integration is a placeholder, indicating ongoing development to connect with a GitHub-LLM orchestrator.\n\n4. **Dependencies**:  \n- An LLM interface providing `chat_completion_with_fallback` method for generating responses.  \n- A `session_manager` component managing conversation histories per session.  \n- Likely depends on asynchronous Python frameworks or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:48.036392",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_18": {
      "chunk_id": "voice_orchestrator.py:chunk_18",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "14a0af343371abe8ad04f9a0ce47810430d5b178cf65d81094c04418aad99649",
      "chunk_index": 18,
      "summary": "1. **Purpose**  \nThis code snippet constructs a conversational message payload for a voice assistant by detecting the language of the user input, appending language-specific instructions, including recent conversation history, and preparing the input for downstream AI processing or response generation.\n\n2. **Technical Details**  \n- Uses a language detection utility function `detect_language_with_confidence` to identify the input language and its confidence score.  \n- Retrieves language-specific system instructions via `get_language_instruction` to tailor AI responses.  \n- Constructs a list of message dictionaries following a role-based schema (`system`, `user`, etc.) compatible with conversational AI models.  \n- Incorporates up to the last 5 turns of conversation history to maintain context.  \n- Uses structured logging to record detected language and confidence.  \n- The `_synthesize_speech` method stub indicates asynchronous text-to-speech synthesis, likely integrating with an external TTS provider.\n\n3. **Business Logic**  \nEnables a multilingual voice assistant to understand user input language dynamically and respond naturally and concisely, improving user experience in voice interactions by maintaining conversational context and adapting responses based on language.\n\n4. **Dependencies**  \n- Internal module: `shared.utils.language_detector` providing `detect_language_with_confidence` and `get_language_instruction`.  \n- Presumably a logging framework (`logger`) for info-level logs.  \n- An asynchronous TTS provider integration hinted by `_synthesize_speech`.\n\n5. **Configuration**  \n- Language detection and instruction",
      "embedding_id": null,
      "created_at": "2025-10-22T19:32:54.968022",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_20": {
      "chunk_id": "voice_orchestrator.py:chunk_20",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "6674083fc6eed3c6ff53241203741e023a62e1fc5c344a81fa63bce8a35d4636",
      "chunk_index": 20,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles errors occurring during text-to-speech (TTS) synthesis in a voice assistant orchestration module. It manages failures from different TTS providers (OpenAI, Azure) when converting input text into speech audio.\n\n2. **Exception Types**:  \n   - The main `try-except` block catches all exceptions (`Exception`) during the TTS provider selection and synthesis call.  \n   - The `_synthesize_openai` method explicitly raises a `ValueError` if the OpenAI API key is missing. Other exceptions from the OpenAI client library or network issues would also be caught by the outer block.\n\n3. **Recovery Strategy**:  \n   - No retries are implemented.  \n   - On error, the method logs the failure and returns `None`, effectively signaling synthesis failure to the caller.  \n   - The absence of retries or fallback TTS providers means recovery relies on upstream logic to handle `None` results.\n\n4. **Logging**:  \n   - Informational logs track the start of synthesis with text length.  \n   - Warnings are logged if an unknown TTS provider is configured.  \n   - Errors during synthesis are logged with the exception message, aiding monitoring and debugging.\n\n5. **User Impact**:  \n   - If synthesis fails, the method returns `None`, likely resulting in no audio output for the user.  \n   - This could degrade user experience by silent failures or missing",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:03.010612",
      "status": "summarized"
    },
    "voice_orchestrator.py:chunk_22": {
      "chunk_id": "voice_orchestrator.py:chunk_22",
      "file_path": "orchestration\\voice_assistant\\voice_orchestrator.py",
      "chunk_hash": "ca332e7f37546403b3d6e3d45f5d018ffea55316acffe554fd015ed6772c6200",
      "chunk_index": 22,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages exceptions that may occur during the text-to-speech (TTS) synthesis process using the OpenAI library and prepares for future Azure TTS integration. It specifically addresses missing dependencies and general runtime errors during OpenAI TTS calls.\n\n2. **Exception Types**:  \n   - `ImportError`: Triggered if the OpenAI library is not installed.  \n   - `Exception` (generic): Catches all other exceptions that may arise during the OpenAI TTS process.  \n   - Additionally, the Azure TTS method raises a `ValueError` if the Azure speech key is not configured.\n\n3. **Recovery Strategy**:  \n   - For `ImportError`, the code logs the error and returns `None`, effectively halting TTS synthesis gracefully without crashing the application.  \n   - For other exceptions, the error is logged, and the exception is re-raised, allowing higher-level handlers or the application to decide on further recovery or termination.  \n   - For Azure TTS, since it is not implemented, it logs a warning and returns `None`.\n\n4. **Logging**:  \n   - Errors related to missing OpenAI library and TTS failures are logged with clear, descriptive messages including an emoji for visibility (`\u274c`).  \n   - Azure TTS unimplemented status is logged as a warning to inform developers or operators.  \n   - Logging uses a `logger` instance,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:11.481882",
      "status": "summarized"
    },
    "secrets.py:chunk_0": {
      "chunk_id": "secrets.py:chunk_0",
      "file_path": "shared\\secrets.py",
      "chunk_hash": "77971ab92f6a1af9474173b63d57d4eec073388a71a638cdb4a7e097fe4e301e",
      "chunk_index": 0,
      "summary": "**Summary of `shared/secrets.py`:**\n\n1. **Purpose**  \nThis module provides a `SecretsManager` class responsible for securely accessing secrets stored in an Azure Key Vault. It abstracts the authentication and client initialization to facilitate secret retrieval in other parts of the application.\n\n2. **Technical Details**  \n- Uses Azure SDK clients: `SecretClient` for Key Vault interaction and `ClientSecretCredential` or `DefaultAzureCredential` for authentication.  \n- Implements a class-based design encapsulating client initialization logic within a private method `_initialize_client`.  \n- Uses Python\u2019s optional typing (`Optional[SecretClient]`) to indicate that the client may be uninitialized.  \n- Employs conditional logic to select between two Azure authentication mechanisms based on configuration presence.\n\n3. **Business Logic**  \nEnables secure, centralized management and retrieval of sensitive configuration data (e.g., API keys, passwords) from Azure Key Vault, supporting secure operations and compliance with security best practices by avoiding hardcoded secrets.\n\n4. **Dependencies**  \n- `azure.keyvault.secrets.SecretClient` for interacting with Azure Key Vault secrets.  \n- `azure.identity.DefaultAzureCredential` and `ClientSecretCredential` for Azure AD authentication.  \n- Python standard libraries: `typing` for type hints, `logging` for diagnostic messages.  \n- Internal module `.config` providing application settings.\n\n5. **Configuration**  \nRelies on the following settings (likely environment variables or config file entries) accessed via `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:17.186761",
      "status": "summarized"
    },
    "secrets.py:chunk_2": {
      "chunk_id": "secrets.py:chunk_2",
      "file_path": "shared\\secrets.py",
      "chunk_hash": "bd283278f5d9c4f7f539aec07ff9f35e1710c3213f41a7b59b9867856348f66b",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides a wrapper class (`SecretsManager`) to interact with a Key Vault service for securely retrieving and storing secrets. It abstracts secret management operations such as getting and setting secrets.\n\n2. **Technical Details**:  \n- Implements a class-based design encapsulating Key Vault client initialization and secret operations.  \n- Uses methods `get_secret` and `set_secret` to interact with the underlying Key Vault client.  \n- Employs logging for operational visibility and error tracking.  \n- Uses Python exception handling (`try-except`) to manage errors during secret operations.  \n- Returns `Optional[str]` for secret retrieval to indicate possible absence of a secret.\n\n3. **Business Logic**:  \nEnables secure storage and retrieval of sensitive information (e.g., API keys, passwords) from a centralized Key Vault, supporting secure configuration management and compliance requirements in business applications.\n\n4. **Dependencies**:  \n- A Key Vault client library (not explicitly shown but implied, e.g., Azure Key Vault SDK).  \n- Python `logging` module for logging errors and warnings.  \n- Possibly `Optional` from `typing` for type hinting.\n\n5. **Configuration**:  \n- The Key Vault client initialization likely depends on environment variables or configuration settings (not shown in the snippet) such as vault URL, credentials, or authentication tokens.  \n- Logging configuration is assumed to be set up externally.\n\n6. **Error Handling**:  \n- Handles",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:27.691235",
      "status": "summarized"
    },
    "mongodb_service.py:chunk_0": {
      "chunk_id": "mongodb_service.py:chunk_0",
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "chunk_hash": "1a25a65a2e5afae32b2311d16fdecbe40ecfa02ca0dfac84043fc7059d4b124a",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous MongoDB service class that integrates with a base service architecture to manage connections to a MongoDB database, enabling other components to interact with MongoDB through a standardized interface.\n\n2. **Technical Details**:  \n- Uses the asynchronous MongoDB driver `motor` (`AsyncIOMotorClient`) for non-blocking database operations.  \n- Inherits from a `BaseService` class, leveraging a service configuration (`ServiceConfig`) and status management (`ServiceStatus`).  \n- Implements an async `connect` method that reads connection parameters from a configuration dictionary, establishes a client connection, selects the database, and verifies connectivity by calling `server_info()`.  \n- Uses internal methods `_set_connected()` and `_set_error()` (presumably from `BaseService`) to update service state.  \n- Employs structured logging via a shared logger instance.\n\n3. **Business Logic**:  \nProvides a reusable, standardized MongoDB connection service within a larger system, likely to support data persistence or retrieval for applications such as LLM (Large Language Model) wrappers or other AI-related services, ensuring reliable and configurable database access.\n\n4. **Dependencies**:  \n- `motor.motor_asyncio.AsyncIOMotorClient`: Async MongoDB client.  \n- `shared.services.base`: Base service classes and enums for configuration and status management.  \n- `shared.logger`: Centralized logging utility.  \n- Python standard typing module for type hints.\n\n5. **",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:33.511179",
      "status": "summarized"
    },
    "mongodb_service.py:chunk_2": {
      "chunk_id": "mongodb_service.py:chunk_2",
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "chunk_hash": "be7a13e0df5e5b1dc99410b9095bab69ab4d5c5ed9f17bd5f3f7df5b98cf25af",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides asynchronous service methods to manage and interact with a MongoDB database connection, including disconnecting, testing connectivity, and executing various database actions.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle non-blocking MongoDB operations.  \n- Maintains internal state with `_client` (MongoDB client instance) and `_db` (database handle).  \n- Implements a command pattern-like dispatch in `execute` method to map action strings to corresponding private methods (`_insert`, `_find`, etc.).  \n- Uses Python dictionaries for returning structured results and error information.\n\n3. **Business Logic**:  \nEnables robust integration with MongoDB for CRUD and aggregation operations, facilitating data persistence and retrieval in an asynchronous service environment, which is critical for scalable backend systems requiring database interactions.\n\n4. **Dependencies**:  \n- Presumably depends on an asynchronous MongoDB driver such as `motor` (not explicitly shown).  \n- Uses a `ServiceStatus` enum or class to track connection status.  \n- Relies on internal private methods (`_insert`, `_find`, `_update`, `_delete`, `_aggregate`, `_list_collections`) for specific database operations.\n\n5. **Configuration**:  \n- The snippet does not show explicit configuration, but connection details (host, port, credentials) and database name are likely configured elsewhere in the service or via environment variables.  \n- Status tracking suggests integration with",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:44.920832",
      "status": "summarized"
    },
    "mongodb_service.py:chunk_4": {
      "chunk_id": "mongodb_service.py:chunk_4",
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "chunk_hash": "abc4916cd216c7a8911b92cf277c8c66257579976886c90ca961ece090fe5a9b",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous MongoDB integration services, enabling document operations such as inserting and querying documents within specified collections. It acts as a backend service layer to interact with MongoDB in an async environment.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) for non-blocking database operations.  \n- Employs a handler dispatch pattern where actions map to specific async methods (e.g., `_insert`, `_find`).  \n- Utilizes MongoDB driver methods like `insert_one` and `find` with cursor management (`to_list`) for fetching documents.  \n- Data structures include dictionaries for documents and queries, and lists for capabilities and query results.\n\n3. **Business Logic**:  \nFacilitates CRUD-like operations on MongoDB collections, supporting core business needs such as storing, retrieving, and managing data documents efficiently. This enables applications to leverage MongoDB for data persistence and retrieval with support for advanced features like aggregation and transactions.\n\n4. **Dependencies**:  \n- MongoDB async driver (likely `motor` or similar) for asynchronous database operations.  \n- Python standard typing modules (`Dict`, `Any`, `List`) for type annotations.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show configuration, but typically requires MongoDB connection settings (URI, database name) likely configured elsewhere in the service or injected during initialization.\n\n6. **Error Handling**:  \n- Catches generic exceptions during database",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:52.422509",
      "status": "summarized"
    },
    "mongodb_service.py:chunk_6": {
      "chunk_id": "mongodb_service.py:chunk_6",
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "chunk_hash": "282611817777fe26c179d3366a7b573f6aa31996b072387bfe9954c31bfc27ae",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous CRUD (Create, Read, Update, Delete) operations for interacting with MongoDB collections, specifically focusing on updating and deleting documents, and converting MongoDB ObjectId fields to strings for easier consumption.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to perform non-blocking database operations.  \n- Employs MongoDB's `update_many` and `delete_many` methods to update or delete multiple documents matching a query.  \n- Converts MongoDB's BSON `ObjectId` to string to ensure JSON serializability.  \n- Returns structured dictionaries indicating success status and operation results (e.g., counts of matched, modified, or deleted documents).  \n- Uses try-except blocks for error handling to catch and return exceptions as error messages.\n\n3. **Business Logic**:  \nEnables backend services to manage MongoDB data efficiently by updating or deleting multiple documents based on dynamic queries, supporting data integrity and maintenance tasks in applications that rely on MongoDB for storage.\n\n4. **Dependencies**:  \n- MongoDB asynchronous driver (likely `motor` or similar) for async database operations.  \n- Python standard libraries for typing (`Dict`, `Any`) and exception handling.\n\n5. **Configuration**:  \n- The code snippet references `self._db`, implying a MongoDB client or database instance is configured elsewhere in the class or service.  \n- No explicit environment variables or config files shown, but",
      "embedding_id": null,
      "created_at": "2025-10-22T19:33:58.485167",
      "status": "summarized"
    },
    "mongodb_service.py:chunk_8": {
      "chunk_id": "mongodb_service.py:chunk_8",
      "file_path": "shared\\services\\integrations\\mongodb_service.py",
      "chunk_hash": "52937ee90c83808106e5444bc3b539f9486aae3cbde77cc8724ea433351745b9",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous methods to interact with a MongoDB database, specifically to run aggregation pipelines and list collections within a database.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking database operations.  \n- Implements MongoDB aggregation via the `aggregate` method on a collection, returning results as a list with a maximum length of 100.  \n- Retrieves collection names asynchronously using `list_collection_names()`.  \n- Returns results in a consistent dictionary format indicating success status, data payload, and counts.  \n- Uses try-except blocks to catch and handle exceptions gracefully.\n\n3. **Business Logic**:  \nEnables backend services to query MongoDB with complex aggregation pipelines and retrieve metadata about the database structure (collections), supporting data analytics, reporting, or dynamic querying features in an application.\n\n4. **Dependencies**:  \n- MongoDB Python driver supporting async operations (likely `motor` or similar).  \n- Python standard typing module for type hints (`List`, `Dict`, `Any`).  \n- An internal `_db` attribute representing an asynchronous MongoDB database client instance.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show configuration, but `_db` is presumably initialized elsewhere with connection details (e.g., MongoDB URI, database name) possibly sourced from environment variables or config files.\n\n6. **Error Handling**:  \n- Catches all exceptions generically (`except Exception",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:02.638166",
      "status": "summarized"
    },
    "llm_wrapper.py:chunk_0": {
      "chunk_id": "llm_wrapper.py:chunk_0",
      "file_path": "shared\\services\\llm_wrapper.py",
      "chunk_hash": "fb81f2967e8391b5f41704ef88af5ad3ef75fa54fa9fcd08524cb457dfdb4cd8",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code provides a wrapper around a Large Language Model (LLM) client to intelligently enhance service interaction queries by analyzing service context and suggesting optimized parameters.\n\n2. **Technical Details**:  \n- Uses Pydantic's `BaseModel` to define a structured data model (`LLMServiceContext`) for passing contextual information about a service request.  \n- Implements an asynchronous method `enhance_query` in `ServiceLLMWrapper` that constructs a prompt based on the service context and sends it to an LLM client for generating enhanced query parameters.  \n- The LLM client is obtained via a factory method (`get_llm_client`), abstracting the underlying LLM provider implementation.  \n- Logging is set up using a shared logger module for traceability.\n\n3. **Business Logic**:  \nEnables intelligent augmentation of service requests by leveraging LLM capabilities to analyze and optimize input parameters, potentially improving service efficiency, accuracy, or user experience in downstream service calls.\n\n4. **Dependencies**:  \n- `pydantic` for data validation and modeling.  \n- A custom LLM client factory (`shared.llm_providers.factory.get_llm_client`) to obtain the LLM interface.  \n- A shared logging utility (`shared.logger.get_logger`).  \n- Python standard typing modules for type annotations.\n\n5. **Configuration**:  \n- The LLM client configuration is abstracted and likely managed within the `get_llm_client` factory, which",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:09.017936",
      "status": "summarized"
    },
    "llm_wrapper.py:chunk_2": {
      "chunk_id": "llm_wrapper.py:chunk_2",
      "file_path": "shared\\services\\llm_wrapper.py",
      "chunk_hash": "0b8a42f45f2d2ac368611b30e1f0d893ef6c9059e9c58c3891d52b0cc6dce101",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code provides asynchronous methods within a wrapper service around a Large Language Model (LLM) to enhance input data, interpret service responses, and suggest actions by leveraging LLM-generated completions.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running LLM calls without blocking.  \n- Constructs dynamic prompts incorporating contextual information (`context.service_name`, `context.action`, etc.) to guide the LLM in generating meaningful outputs.  \n- Returns structured dictionaries encapsulating results and success status.  \n- Employs try-except blocks for robust error handling and logging.  \n- Interacts with an LLM interface via a `chat_completion` method, passing messages and temperature parameters to control response creativity.\n\n3. **Business Logic**:  \nThe code aims to automate and enhance decision-making workflows by:  \n- Enhancing raw input data with LLM-generated suggestions.  \n- Interpreting and summarizing responses from various services to extract key insights.  \n- Suggesting next best actions based on service goals and capabilities (incomplete snippet).  \nThis supports business processes requiring natural language understanding and contextual summarization, improving efficiency and insight extraction.\n\n4. **Dependencies**:  \n- An LLM service client exposing an asynchronous `chat_completion` method (likely a wrapper around OpenAI or similar API).  \n- A `logger` instance for error logging.  \n- `LLMServiceContext` data structure providing contextual metadata",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:14.568136",
      "status": "summarized"
    },
    "llm_wrapper.py:chunk_4": {
      "chunk_id": "llm_wrapper.py:chunk_4",
      "file_path": "shared\\services\\llm_wrapper.py",
      "chunk_hash": "0c97034b88b345c82c8081a53df13fe54fc18048e3a921c896d28f72416fd248",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods that leverage a large language model (LLM) to suggest optimal actions for a given service goal and to analyze errors by providing root cause analysis, fixes, and prevention tips.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to interact with an LLM via `chat_completion` calls.  \n- Constructs prompt strings dynamically by embedding service-specific goals, capabilities, errors, and context into templated multi-line strings.  \n- The LLM interaction follows a conversational pattern with messages formatted as dictionaries containing roles and content.  \n- Error handling is implemented with try-except blocks to catch and log exceptions during LLM calls.\n\n3. **Business Logic**:  \n- Automates decision-making by suggesting the best action and parameters to achieve a specified service goal, reducing manual intervention.  \n- Provides automated error diagnosis and remediation guidance, improving incident response and operational reliability.\n\n4. **Dependencies**:  \n- An LLM interface accessible via `self.llm.chat_completion` (likely an abstraction over an API like OpenAI or similar).  \n- A logging utility (`logger`) for error reporting.  \n- Python standard libraries for typing (`Dict`, `Any`) and asynchronous programming.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are shown in the snippet.  \n- Temperature parameter for LLM responses is set to 0.3, indicating a preference for less random, more focused",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:18.210285",
      "status": "summarized"
    },
    "llm_wrapper.py:chunk_6": {
      "chunk_id": "llm_wrapper.py:chunk_6",
      "file_path": "shared\\services\\llm_wrapper.py",
      "chunk_hash": "bfb4603453f33f373acac654e41733a0a3de52199686df56c2c8e27a156c5483",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an error analysis routine within a larger function that interacts with a Large Language Model (LLM). It attempts to analyze an error and return a structured response indicating whether the error is actionable.\n\n2. **Technical Details**:  \n- Uses a try-except block to handle exceptions during the error analysis process.  \n- Returns a dictionary with keys `\"error\"`, `\"analysis\"`, and `\"actionable\"`.  \n- On success, presumably returns an analysis and marks the error as actionable (though the success path is not fully shown).  \n- On failure, logs the exception and returns a response indicating failure to analyze.\n\n3. **Business Logic**:  \nThe code supports automated error diagnosis by analyzing errors generated during LLM interactions, helping downstream systems or users decide if an error can be acted upon or requires escalation.\n\n4. **Dependencies**:  \n- A `logger` instance for error logging (likely from Python\u2019s `logging` module or a custom logger).  \n- Possibly other parts of the LLM wrapper service that generate or handle the `error` and `analysis` variables (not shown here).\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are visible in this snippet. Configuration might exist elsewhere in the module or application.\n\n6. **Error Handling**:  \n- Catches all exceptions (`Exception` base class), ensuring that any failure in error analysis does not propagate.  \n- Logs",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:24.561612",
      "status": "summarized"
    },
    "thinking_process.py:chunk_0": {
      "chunk_id": "thinking_process.py:chunk_0",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "bea84ce3ec76f52bd994ef1d58293ddf6551b2129bb14f38b94632711d29e6d9",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a shared data model to represent and track the step-by-step progress of AI thinking or processing workflows in a backend system, enabling visibility into each stage of the AI's decision-making or task execution process.\n\n2. **Technical Details**:  \n- Uses Python's `dataclasses` to define immutable and structured data containers (`ThinkingStep`).  \n- Defines an `Enum` (`StepStatus`) to represent discrete states of a step (pending, in progress, completed, failed, skipped).  \n- Each `ThinkingStep` includes fields for identification, descriptive metadata, status tracking, timestamps for start/end, and optional error messages.  \n- Includes a method `to_dict()` to serialize the step instance into a dictionary suitable for API responses, converting enums and datetime objects into JSON-friendly formats.\n\n3. **Business Logic**:  \nEnables detailed tracking and visibility of AI workflow execution steps, which is critical for debugging, auditing, monitoring, and improving AI processes. This helps business stakeholders understand AI decision flows and identify bottlenecks or failures in complex automated tasks.\n\n4. **Dependencies**:  \n- Standard Python libraries: `dataclasses`, `typing` (for type hints), `datetime` (for timestamps), and `enum` (for status enumeration).  \n- No external third-party libraries or services are referenced in this snippet.\n\n5. **Configuration**:  \n- No explicit environment variables, configuration files, or runtime settings are referenced or required",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:29.649154",
      "status": "summarized"
    },
    "thinking_process.py:chunk_2": {
      "chunk_id": "thinking_process.py:chunk_2",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "2c068e746d8e504f49e72b21ba3469de6fd3146eed44ea702c9854d5ee24aaeb",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code models and manages a structured \"thinking process\" workflow composed of ordered steps, tracking their statuses and timing information to facilitate monitoring and orchestration of complex tasks.\n\n2. **Technical Details**:  \n- Uses Python `dataclasses` to define immutable-like data structures (`ThinkingProcess` and `ThinkingStep` implied).  \n- Maintains an ordered list (`List[ThinkingStep]`) to represent sequential steps in the workflow.  \n- Tracks timestamps (`start_time`, `end_time`) using `datetime` objects to calculate durations in milliseconds.  \n- Implements methods to add steps (`add_step`) and update step statuses (`start_step`).  \n- Uses an internal helper method `_get_duration_ms` to compute elapsed time between start and end timestamps.  \n- Step statuses are managed via an enum-like construct (`StepStatus`) with states such as `PENDING` and `IN_PROGRESS`.\n\n3. **Business Logic**:  \nEnables orchestration and monitoring of multi-step workflows (e.g., LLM tests, document orchestration) by capturing each step\u2019s metadata, status, and timing. This supports business needs like process auditing, performance measurement, and error tracking in complex automated or semi-automated workflows.\n\n4. **Dependencies**:  \n- Python standard library modules: `dataclasses`, `datetime`, `typing` (for `List`, `Optional`).  \n- Custom or external enum `StepStatus` and class `ThinkingStep",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:34.827707",
      "status": "summarized"
    },
    "thinking_process.py:chunk_4": {
      "chunk_id": "thinking_process.py:chunk_4",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "2da49ceb1cd19ad3778a28cfeae0f9dc219fa262019af48ca1815b4541095592",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code manages the lifecycle of discrete \"thinking steps\" within a process, allowing steps to be started, completed, failed, or skipped, while tracking their status, timestamps, and associated metadata.\n\n2. **Technical Details**:  \n- Uses a list (`self.steps`) to store `ThinkingStep` objects, each identified by a unique `step_id`.  \n- Implements state transitions for steps via methods (`complete_step`, `fail_step`, `skip_step`) that update step status enums (`StepStatus`) and timestamps (`start_time`, `end_time`).  \n- Metadata and error information are stored as dictionaries or strings within each step.  \n- A private helper method `_find_step` performs a linear search to retrieve a step by its ID.\n\n3. **Business Logic**:  \nEnables tracking and management of discrete units of work or thought processes in a workflow or decision-making engine, supporting status updates and contextual metadata to reflect progress, failures, or skips, which is critical for auditability and process control.\n\n4. **Dependencies**:  \n- Python standard library: `datetime` for timestamping.  \n- Custom types: `ThinkingStep` (likely a data class or model), `StepStatus` enum for step states.  \n- Optional typing from `typing` module (`Optional`, `Dict`, `Any`).\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are indicated in the snippet; configuration likely happens",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:42.794489",
      "status": "summarized"
    },
    "thinking_process.py:chunk_6": {
      "chunk_id": "thinking_process.py:chunk_6",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "0733edf4d3e9915844adea9c847d4a0d943af939ac3c00233b044640207a1814",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a class that models a workflow's thinking process, providing functionality to serialize the workflow state into a dictionary format suitable for API responses. It calculates the total duration of the workflow and determines the overall status based on the statuses of individual steps.\n\n2. **Technical Details**:  \n- Uses Python data structures such as lists and dictionaries.  \n- Implements methods to convert complex objects (workflow and steps) into serializable dictionaries (`to_dict`).  \n- Calculates time durations using `datetime` arithmetic (`end_time - start_time`).  \n- Determines overall workflow status by iterating over step statuses with conditional checks (`any`, `all`).  \n- Uses enumerations or constants for step statuses (e.g., `StepStatus.FAILED`, `StepStatus.IN_PROGRESS`).  \n\n3. **Business Logic**:  \nThe code supports tracking and reporting the progress of a multi-step workflow, enabling clients or services to understand the current state, duration, and outcome of the workflow execution. This is critical for monitoring, auditing, and user feedback in business processes that involve sequential or parallel task execution.\n\n4. **Dependencies**:  \n- Likely depends on a `Step` class with a `to_dict()` method and a `status` attribute.  \n- Uses `datetime` objects for `start_time` and `end_time`.  \n- Uses a `StepStatus` enumeration or similar construct to represent step states.  \n- Imports",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:49.518120",
      "status": "summarized"
    },
    "thinking_process.py:chunk_8": {
      "chunk_id": "thinking_process.py:chunk_8",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "a787fd482f70d1c26e37f2bfba48186016c800ef1383ffb204f94455f3c890d8",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code defines factory functions to create and configure instances of a `ThinkingProcess` class representing structured workflows for different use cases, specifically for testing large language models (LLMs) and documentation orchestration.\n\n2. **Technical Details**:  \n- Uses a class `ThinkingProcess` (presumably defined elsewhere) to encapsulate a workflow identified by `workflow_id` and categorized by `workflow_type`.  \n- Workflows are composed of ordered steps added via `add_step(step_id, step_name, step_description)`.  \n- The `create_llm_thinking_process` function sets up a predefined sequence of steps typical for an LLM testing pipeline, such as input validation, provider selection, prompt preparation, and response processing.  \n- The `create_doc_orchestrator_thinking_process` function is partially shown but intended to similarly configure a workflow for document orchestration.\n\n3. **Business Logic**:  \n- Facilitates the orchestration and management of complex multi-step processes related to AI model testing and document processing, enabling modular, repeatable, and auditable workflows.  \n- Helps standardize how AI-related tasks are broken down and executed, improving maintainability and clarity in AI integration projects.\n\n4. **Dependencies**:  \n- Relies on the `ThinkingProcess` class, which is not defined in the snippet but is critical to the workflow management.  \n- No explicit external libraries or services are referenced in the provided code snippet.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:34:56.016912",
      "status": "summarized"
    },
    "thinking_process.py:chunk_10": {
      "chunk_id": "thinking_process.py:chunk_10",
      "file_path": "shared\\thinking_process.py",
      "chunk_hash": "a7b63fa6ae6785687504cd973405de186425ebaa6d12d7d37633be49a3632325",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet defines a sequence of steps in a process workflow related to automating documentation generation and publication from a GitHub repository to Confluence.\n\n2. **Technical Details**:  \n- The code uses a `process` object with an `add_step` method to register discrete workflow steps.  \n- Each step is identified by a unique key, a human-readable title, and a descriptive message.  \n- The steps suggest a pipeline pattern where tasks are executed in order, likely encapsulated in a process orchestration or state machine design.\n\n3. **Business Logic**:  \n- Automates the generation and publication of documentation by validating repository access, analyzing code via AI, generating documentation content, committing changes, pushing to GitHub, and finally publishing to Confluence.  \n- This streamlines developer workflows and ensures up-to-date documentation is maintained and published efficiently.\n\n4. **Dependencies**:  \n- Implicit dependency on a `process` object or class that supports `add_step`.  \n- Integration with GitHub (for repository access, commits, and pushes).  \n- Integration with AI services or modules for code analysis and documentation generation.  \n- Integration with Confluence for publishing documentation.\n\n5. **Configuration**:  \n- Likely requires configuration for GitHub repository credentials (tokens, URLs).  \n- AI service credentials or API keys for code analysis and documentation generation.  \n- Confluence API credentials and target space/page configuration.  \n- These",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:04.694960",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_0": {
      "chunk_id": "chromadb_provider.py:chunk_0",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "c133a692812674839a81b361b69369ac07b4bb2000a564d7ff21c828913baa7d",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module implements a vector database provider using ChromaDB, enabling persistent storage and retrieval of vector embeddings for applications such as semantic search or recommendation systems.\n\n2. **Technical Details**  \n- Defines a `ChromaDBProvider` class inheriting from a generic `VectorDBProvider` interface.  \n- Uses asynchronous initialization (`async def initialize`) to set up the ChromaDB client with persistence.  \n- Employs the ChromaDB client configured to use the \"duckdb+parquet\" backend, which supports efficient vector storage and querying with on-disk persistence.  \n- Stores the persistence directory path as an instance attribute for data durability.  \n- Uses Python\u2019s standard logging for informational messages.\n\n3. **Business Logic**  \nThe provider facilitates scalable and persistent vector storage, which is critical for business applications requiring fast similarity search over large datasets, such as document retrieval, recommendation engines, or AI-powered search tools.\n\n4. **Dependencies**  \n- `chromadb` library for vector database functionality.  \n- Python standard libraries: `logging`, `typing` (for type hints), `datetime` (imported but not used in snippet).  \n- Relative import from `..base` for base classes/interfaces: `VectorDBProvider`, `VectorSearchResult`, `DocumentMetadata`.\n\n5. **Configuration**  \n- Persistence directory configurable via the `persist_directory` constructor argument, defaulting to `./data/chromadb`.  \n- ChromaDB",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:13.318618",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_2": {
      "chunk_id": "chromadb_provider.py:chunk_2",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "b8ce1660599b02d252e5355ad4935b29474b98df16072e92023a5e55158d45dd",
      "chunk_index": 2,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages failures related to initializing the ChromaDB client, creating collections within the database, and adding documents to collections. It aims to catch issues such as missing dependencies, runtime exceptions during client setup, and operational errors during collection management.\n\n2. **Exception Types**:  \n   - `ImportError`: Specifically caught when the ChromaDB package is not installed.  \n   - `Exception`: A general catch-all for any other runtime errors during initialization and collection creation.\n\n3. **Recovery Strategy**:  \n   - Upon catching an `ImportError`, the code logs a warning with installation instructions and returns `False` to indicate failure without raising further exceptions.  \n   - For other exceptions, it logs the error details and returns `False`, signaling the calling code that the operation did not succeed.  \n   - There is no retry mechanism implemented; the code relies on the caller to handle retries or alternative flows.\n\n4. **Logging**:  \n   - Uses structured logging with different severity levels:  \n     - `info` for successful operations (client initialization, collection creation).  \n     - `warning` for missing dependencies.  \n     - `error` for failures during initialization and collection creation, including exception messages for diagnostics.  \n   - Emoji prefixes in logs improve readability and quick identification of log types.\n\n5. **User Impact**:  \n   - If initialization fails (e.g., missing ChromaDB), subsequent",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:19.655979",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_4": {
      "chunk_id": "chromadb_provider.py:chunk_4",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "1596459970b59793e97a12432d7a9495607618fd6c8611ba14eeb6f27ac5611f",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet adds a batch of documents along with their embeddings and associated metadata into a specified collection within a ChromaDB vector database.\n\n2. **Technical Details**:  \n- Retrieves a collection object from the ChromaDB client.  \n- Converts a list of `DocumentMetadata` objects into dictionaries compatible with ChromaDB's expected metadata format.  \n- Uses the `add` method of the collection to insert embeddings, documents, metadata, and document IDs atomically.  \n- Uses list comprehensions and conditional dictionary key assignments to build metadata.  \n- Logs success or failure of the operation.\n\n3. **Business Logic**:  \nEnables efficient storage and indexing of documents and their vector embeddings for downstream tasks such as semantic search, recommendation, or similarity matching within an application that relies on vector-based retrieval.\n\n4. **Dependencies**:  \n- `self.client` is a ChromaDB client instance (likely from the `chromadb` Python library).  \n- `logger` for logging informational and error messages.  \n- `DocumentMetadata` data structure (custom or imported) representing document metadata fields.\n\n5. **Configuration**:  \n- The collection name is passed as a parameter (likely configured elsewhere).  \n- ChromaDB client configuration (e.g., host, port, API keys) is assumed to be set up outside this snippet.  \n- Logging configuration is external.\n\n6. **Error Handling**:  \n- Catches all",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:23.928903",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_6": {
      "chunk_id": "chromadb_provider.py:chunk_6",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "e53123b5501a799a179cc0f961638126dabf7135b4a561980533cf20fecfdd82",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous method performs a vector similarity search on a specified ChromaDB collection using a query embedding, returning the top-k most relevant results optionally filtered by metadata.\n\n2. **Technical Details**:  \n- Uses an asynchronous function (`async def`) to enable non-blocking calls.  \n- Accepts a list of floats as the query embedding representing the vector to search against.  \n- Interacts with a ChromaDB client to retrieve a collection and execute a vector similarity query (`coll.query`).  \n- Supports optional filtering of search results based on metadata via a dictionary passed as `filter_metadata`.  \n- Processes the raw query results by iterating over returned IDs and metadata to construct a list of `VectorSearchResult` objects, which likely encapsulate document metadata and relevance information.  \n- Uses data structures such as lists and dictionaries for embeddings and metadata.\n\n3. **Business Logic**:  \nEnables semantic search functionality over a vector database, allowing applications to find the most relevant documents or items based on vector similarity rather than keyword matching. This supports use cases like document retrieval, recommendation systems, or knowledge base querying.\n\n4. **Dependencies**:  \n- ChromaDB client library for vector database operations.  \n- Custom data types such as `VectorSearchResult` and `DocumentMetadata` for encapsulating search results and metadata.  \n- Python standard typing modules (`List`, `Optional`, `Dict`, `Any`).  \n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:30.136003",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_8": {
      "chunk_id": "chromadb_provider.py:chunk_8",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "de4a998b3a5fa62a0b21e68a15728256f29873f5edcf440dbdab53685bc697a6",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a provider module interfacing with ChromaDB, a vector database. It handles searching for documents by vector similarity and deleting documents from a specified collection within ChromaDB.\n\n2. **Technical Details**:  \n- Uses vector similarity search results from ChromaDB, converting distances to similarity scores (`score = 1.0 - distance`).  \n- Constructs `VectorSearchResult` objects encapsulating document ID, content, metadata, similarity score, and optional embedding vectors.  \n- Metadata is extracted from a dictionary with default fallbacks (e.g., `content_type='text'`).  \n- Implements asynchronous deletion of documents by IDs from a collection using ChromaDB client\u2019s `delete` method.  \n- Uses try-except blocks for error handling and logging.  \n- Data structures involved include lists for search results and dictionaries for metadata.\n\n3. **Business Logic**:  \nEnables efficient retrieval and management of documents based on semantic similarity, supporting use cases like semantic search, recommendation, or knowledge retrieval in applications that require fast, vector-based querying and document lifecycle management.\n\n4. **Dependencies**:  \n- ChromaDB client library for vector database operations.  \n- A logging framework (`logger`) for info and error messages.  \n- Custom data classes or types such as `VectorSearchResult`.  \n- Python standard libraries for async programming and exception handling.\n\n5. **Configuration**:  \n- The code references",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:36.880267",
      "status": "summarized"
    },
    "chromadb_provider.py:chunk_10": {
      "chunk_id": "chromadb_provider.py:chunk_10",
      "file_path": "shared\\vector_db\\providers\\chromadb_provider.py",
      "chunk_hash": "784e92163ed2c473ba8d55ef3df9cca3b1c9e71167937e0056c12edf84295006",
      "chunk_index": 10,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of a ChromaDB provider implementation that manages interactions with a Chroma vector database, specifically focusing on deleting documents, retrieving collection statistics, and performing health checks asynchronously.\n\n2. **Technical Details**  \n- Uses asynchronous methods (`async def`) to interact with the ChromaDB client, enabling non-blocking I/O operations.  \n- Retrieves collections and document counts via the ChromaDB client API (`get_collection`, `count`).  \n- Returns structured dictionary data representing collection metadata.  \n- Uses logging to track success and failure of operations.  \n- Maintains an `initialized` state and a `client` instance to manage connection status and operations.  \n\n3. **Business Logic**  \nThe code supports managing vector data collections in ChromaDB, enabling deletion of documents and monitoring collection health and statistics. This functionality is critical for applications that rely on vector search or similarity matching, ensuring data integrity and operational health of the vector database backend.\n\n4. **Dependencies**  \n- ChromaDB Python client library (implied by usage of `self.client.get_collection`).  \n- Python `logging` module for logging info and error messages.  \n- Python `asyncio` for asynchronous method support.  \n- Typing module for type hints (`Dict`, `Any`).  \n\n5. **Configuration**  \n- Uses an `initialized` boolean flag to indicate if the provider is ready for operations.  \n- `persist_directory` attribute is included in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:43.519190",
      "status": "summarized"
    },
    "in_memory_provider.py:chunk_0": {
      "chunk_id": "in_memory_provider.py:chunk_0",
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "chunk_hash": "28c9e60b7f61727deea910279b74b58468b4a45307e979e6adf5c2bb9742c850",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module implements a simple in-memory vector database provider designed primarily for development and testing purposes. It allows creating collections to store vector embeddings and associated metadata without relying on external databases.\n\n2. **Technical Details**:  \n- Uses Python dictionaries to maintain collections, each keyed by collection name.  \n- Each collection stores:  \n  - `dimension`: integer specifying vector size  \n  - `documents`: list of raw documents (content not shown in snippet)  \n  - `embeddings`: list of numpy arrays representing vector embeddings  \n  - `metadatas`: list of metadata objects associated with documents  \n  - `doc_ids`: list of document identifiers  \n- Asynchronous methods (`async def`) for initialization and collection creation, enabling integration with async workflows.  \n- Logging is used extensively for lifecycle events and operations.  \n- Inherits from a base abstract class `VectorDBProvider`, ensuring a consistent interface.\n\n3. **Business Logic**:  \nProvides a lightweight, ephemeral vector database solution to support vector search and storage functionalities during development or testing phases, avoiding the complexity and overhead of full-fledged vector databases. This supports rapid prototyping of features like semantic search or similarity matching.\n\n4. **Dependencies**:  \n- `numpy` for vector representation and numerical operations.  \n- Python standard libraries: `logging`, `datetime`, and typing utilities (`List`, `Dict`, `Any`, `Optional`).  \n- Relative import from `..base` for base",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:52.597579",
      "status": "summarized"
    },
    "in_memory_provider.py:chunk_2": {
      "chunk_id": "in_memory_provider.py:chunk_2",
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "chunk_hash": "714afe88207f22a6f77f7b8b8ce896737409b6e212777781c41260a1bec493fe",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an in-memory vector database provider that manages collections of documents and their vector embeddings, allowing asynchronous addition of documents and similarity-based search within collections.\n\n2. **Technical Details**:  \n- Uses Python asynchronous functions (`async def`) for non-blocking operations.  \n- Stores data in-memory using dictionaries keyed by collection names, where each collection holds lists of documents, embeddings (vectors), metadata, and document IDs.  \n- Implements document addition by appending documents, embeddings, and metadata in parallel using `zip`.  \n- The search method (partially shown) intends to perform similarity search using cosine similarity on stored embeddings.  \n- Uses logging for operational visibility (`logger.info`, `logger.error`, `logger.warning`).  \n- Data structures: Lists for storing documents and embeddings, dictionaries for collections.\n\n3. **Business Logic**:  \nEnables applications to store and retrieve documents based on semantic similarity of their vector embeddings, supporting use cases like semantic search, recommendation, or content retrieval without relying on external databases.\n\n4. **Dependencies**:  \n- Python standard libraries: `logging` (implied by `logger`).  \n- Typing hints: `List`, `Optional`, `Dict`, `Any` (from `typing` module).  \n- Custom types: `DocumentMetadata`, `VectorSearchResult` (likely defined elsewhere in the codebase).  \n- No external vector search libraries or databases are referenced, indicating a",
      "embedding_id": null,
      "created_at": "2025-10-22T19:35:59.387980",
      "status": "summarized"
    },
    "in_memory_provider.py:chunk_4": {
      "chunk_id": "in_memory_provider.py:chunk_4",
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "chunk_hash": "ea73f58a31c81309d7534f4a0dcdb69b26e1ff076a36d211347291bdd58a1733",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet performs a similarity search within an in-memory vector database collection by computing cosine similarity between a query embedding and stored document embeddings, optionally filtering results based on metadata, and returning the top-k most similar documents.\n\n2. **Technical Details**:  \n- Uses numpy arrays to represent and compute vector embeddings.  \n- Calculates cosine similarity as the dot product of normalized vectors.  \n- Iterates over stored embeddings and associated metadata in a dictionary structure (`self.collections[collection]`), which holds lists of embeddings and metadata.  \n- Applies an optional metadata filter by checking attribute equality via `getattr`.  \n- Sorts similarity scores in descending order and selects the top-k results.  \n- Data structures: dictionary of collections, each with lists of embeddings and metadata objects.\n\n3. **Business Logic**:  \nEnables fast, in-memory semantic search or nearest neighbor retrieval for documents based on vector similarity, supporting use cases like recommendation, information retrieval, or content matching with optional metadata constraints to refine results.\n\n4. **Dependencies**:  \n- `numpy` for vector and linear algebra operations.  \n- A `logger` instance for warning messages (likely from Python\u2019s `logging` module).  \n- Assumes `self.collections` is a pre-populated dictionary structure managing collections of embeddings and metadata.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration shown in this snippet. The behavior depends on the state of `self.collections",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:08.274066",
      "status": "summarized"
    },
    "in_memory_provider.py:chunk_6": {
      "chunk_id": "in_memory_provider.py:chunk_6",
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "chunk_hash": "9db0828447b306890e907268aa8b895000ca3ebba652c5d10915f78dcba90aef",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of an in-memory vector database provider that manages collections of documents and their vector embeddings. It specifically implements asynchronous deletion of documents by their IDs from a named collection.\n\n2. **Technical Details**:  \n- Uses Python lists to store document-related data (`documents`, `embeddings`, `metadatas`, `doc_ids`) within a dictionary keyed by collection names.  \n- The `delete_documents` method identifies indices of documents to remove by matching document IDs, then deletes entries from all parallel lists in reverse order to maintain index consistency.  \n- The method is asynchronous (`async def`), suggesting integration with async workflows or event loops.  \n- Logging is used to track operations (seen in the snippet before this method).\n\n3. **Business Logic**:  \nEnables efficient management of document collections in an in-memory vector search system by allowing removal of specific documents. This supports use cases such as data lifecycle management, document updates, or cleanup in applications relying on vector similarity search (e.g., recommendation engines, semantic search).\n\n4. **Dependencies**:  \n- Python standard libraries (`logging` for logger usage implied).  \n- Custom data structures like `VectorSearchResult` (likely defined elsewhere in the codebase).  \n- Typing module for type hints (`List[str]`).  \n- No external databases or persistent storage indicated; purely in-memory.\n\n5. **Configuration**:  \n- No explicit environment variables or config files referenced",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:17.427577",
      "status": "summarized"
    },
    "in_memory_provider.py:chunk_8": {
      "chunk_id": "in_memory_provider.py:chunk_8",
      "file_path": "shared\\vector_db\\providers\\in_memory_provider.py",
      "chunk_hash": "1b3922015f5c1d18028505469e2362d7c75efd2d2b09209b308c18524e9d8720",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an in-memory vector database provider that manages collections of documents. It provides asynchronous methods to retrieve collection statistics and perform a health check on the provider's initialization status.\n\n2. **Technical Details**:  \n- Uses Python asynchronous functions (`async def`) to support non-blocking operations.  \n- Collections are stored in a dictionary (`self.collections`), where each collection contains metadata such as documents and their vector dimension.  \n- The `get_collection_stats` method returns metadata including the collection name, document count, vector dimension, and the provider type.  \n- The `health_check` method returns a boolean indicating if the provider has been initialized.  \n- Logging is used for operational insights (seen in the deleted documents log line).\n\n3. **Business Logic**:  \nEnables applications to manage and query vector data collections efficiently in-memory, supporting use cases like similarity search, recommendation systems, or real-time analytics where quick access to vector data and metadata is critical.\n\n4. **Dependencies**:  \n- Python standard library (`logging` for logging, `typing` for type hints like `Dict` and `Any`).  \n- No external database or storage dependencies since it is an in-memory provider.\n\n5. **Configuration**:  \n- The provider likely depends on an internal state variable `self.collections` (a dictionary) and `self.initialized` (a boolean).  \n- No explicit environment variables or config files are referenced in this",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:26.236209",
      "status": "summarized"
    },
    "logging_config.py:chunk_0": {
      "chunk_id": "logging_config.py:chunk_0",
      "file_path": "code-intelligence\\logging_config.py",
      "chunk_hash": "5ea71a5fab4bcfdeabeaa8a3848690679c13ee6f85297dad622ce2a27d382d78",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module provides a centralized logging configuration for the Code Intelligence system, enabling fine-grained control over logging verbosity across various internal components and external libraries.\n\n2. **Technical Details**  \n- Defines a `CodeIntelligenceLogger` class encapsulating logging setup.  \n- Uses Python\u2019s built-in `logging` module to manage log levels.  \n- Maintains dictionaries (`DEFAULT_LEVELS` and `PRESETS`) mapping component names (logger namespaces) to logging levels (e.g., INFO, WARNING).  \n- Supports preset configurations (e.g., 'quiet', 'normal') for quickly adjusting multiple loggers\u2019 verbosity.  \n- Logger names correspond to different subsystems or third-party libraries (e.g., `httpx`, `asyncio`), allowing selective verbosity control.\n\n3. **Business Logic**  \nBy controlling log verbosity per component, the code helps maintain readable and relevant logs, which is critical for monitoring, debugging, and auditing in a complex code intelligence platform. It reduces noise from verbose libraries and highlights important events, improving operational efficiency.\n\n4. **Dependencies**  \n- Python standard library: `logging`, `sys`  \n- Typing hints: `Optional`, `Dict` from `typing` module  \nNo external third-party dependencies are introduced in this snippet.\n\n5. **Configuration**  \n- Log levels are configured programmatically via dictionaries in the class.  \n- No environment variables or external config files are referenced here, but the design allows easy extension",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:34.861574",
      "status": "summarized"
    },
    "logging_config.py:chunk_2": {
      "chunk_id": "logging_config.py:chunk_2",
      "file_path": "code-intelligence\\logging_config.py",
      "chunk_hash": "677e041f8d9b747082f8fda4d4ea3fbfd15b18074b81dc1f3558cf49036cfafb",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines logging configurations for a code intelligence system, allowing different verbosity levels and module-specific log settings to be applied dynamically. It provides a method to configure logging behavior globally or per module, optionally directing logs to a file.\n\n2. **Technical Details**:  \n- Uses a class-based approach with a class method `configure` to set logging levels.  \n- Maintains a dictionary of preset logging configurations keyed by verbosity levels (`quiet`, `normal`, `verbose`, `debug`). Each preset maps module names to standard Python logging levels (e.g., `logging.INFO`, `logging.DEBUG`).  \n- Supports overriding these presets with a `custom_levels` dictionary, enabling fine-grained control.  \n- Optionally supports logging to a file via the `log_file` parameter.  \n- Leverages Python\u2019s built-in `logging` module for log level constants and configuration.\n\n3. **Business Logic**:  \nEnables flexible and centralized logging control for a code intelligence platform, which likely involves complex processing components such as embedding repositories, summarization, rate limiting, and HTTP requests. This helps in monitoring, debugging, and maintaining the system by adjusting log verbosity according to operational needs or troubleshooting scenarios.\n\n4. **Dependencies**:  \n- Python standard library `logging` module.  \n- Possibly other internal modules referenced by name in the logging presets (e.g., `embed_repo`, `enhanced_summarizer`), but these are not explicitly imported here",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:42.604161",
      "status": "summarized"
    },
    "logging_config.py:chunk_4": {
      "chunk_id": "logging_config.py:chunk_4",
      "file_path": "code-intelligence\\logging_config.py",
      "chunk_hash": "e555cf61f2e389c8675b30a08363f8d90208c6ab93e2a2b80aabf78b46069558",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet configures Python's logging system based on predefined logging level presets, with optional custom overrides and support for console and file output. It aims to standardize and simplify logging setup across an application.\n\n2. **Technical Details**:  \n- Uses a class-level dictionary `PRESETS` to define logging level configurations (e.g., for root logger and potentially other loggers).  \n- Validates the requested logging preset level; falls back to a default ('normal') if unknown.  \n- Merges custom logging level overrides into the preset configuration using dictionary `update()`.  \n- Creates two `logging.Formatter` instances: a detailed formatter with millisecond precision and a simpler one with only time.  \n- Sets up a console `StreamHandler` with the simple formatter and the root logging level.  \n- Clears existing handlers on the root logger before adding the new console handler to avoid duplicate logs.  \n- Contains a placeholder for adding a file handler if a log file path is provided (code incomplete).  \n\n3. **Business Logic**:  \nEnables consistent and configurable logging behavior across different environments or deployment scenarios, facilitating debugging, monitoring, and audit trails. The ability to override presets allows flexibility for different verbosity or logging requirements.\n\n4. **Dependencies**:  \n- Python standard library modules: `logging` for logging infrastructure, `sys` for standard output stream.  \n- Assumes existence of a class attribute `PRESETS` defining",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:50.280086",
      "status": "summarized"
    },
    "logging_config.py:chunk_6": {
      "chunk_id": "logging_config.py:chunk_6",
      "file_path": "code-intelligence\\logging_config.py",
      "chunk_hash": "7ada9a1f0500d07cec7f2938c8e5f32a1b35e1b678e930743818056244038aff",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code configures logging for an application, setting up file handlers and log levels for different modules to control the verbosity of log output both globally and per module.\n\n2. **Technical Details**:  \n- Uses Python\u2019s built-in `logging` module to create and configure loggers.  \n- Adds a `FileHandler` to the root logger to write logs to a specified file in append mode with a detailed formatter.  \n- Iterates over a dictionary (`levels`) mapping module names to log levels, applying these levels selectively (excluding the root logger).  \n- Provides a class method `set_level` to dynamically adjust the log level of a specific module at runtime.  \n- Uses print statements to provide console feedback about the logging configuration state.\n\n3. **Business Logic**:  \nEnables flexible and granular logging control to support debugging and monitoring of different components (e.g., summarizer, rate limiter) in various operational modes (debug, verbose, normal, quiet). This helps developers and operators diagnose issues and understand system behavior under different conditions.\n\n4. **Dependencies**:  \n- Python standard library `logging` module.  \n- No external libraries or services are referenced in the snippet.\n\n5. **Configuration**:  \n- Log file path (`log_file`) and logging levels (`levels`) are inputs to the configuration logic, likely set elsewhere in the application or passed as parameters.  \n- Logging modes such as 'debug', 'verbose',",
      "embedding_id": null,
      "created_at": "2025-10-22T19:36:58.640877",
      "status": "summarized"
    },
    "logging_config.py:chunk_8": {
      "chunk_id": "logging_config.py:chunk_8",
      "file_path": "code-intelligence\\logging_config.py",
      "chunk_hash": "aad610f685821a43d6db6c2054f4dbc2476a951bc7643318ee89f059a1226756",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code provides a configurable logging setup tailored for a \"code intelligence\" system, allowing different logging verbosity presets and custom log levels per module, optionally directing logs to a file.\n\n2. **Technical Details**:  \n- Defines a convenience function `setup_logging` that accepts preset verbosity levels (`quiet`, `normal`, `verbose`, `debug`), optional log file path, and arbitrary custom module-level log settings.  \n- Uses a class `CodeIntelligenceLogger` (implied from usage) to apply configurations, likely managing logger instances per module.  \n- Presets are stored in a dictionary mapping preset names to module-level logging levels.  \n- The script includes a CLI demo block that iterates over presets and prints configured logging levels for each module.  \n- Uses Python\u2019s built-in `logging` module for log level constants and logger management.\n\n3. **Business Logic**:  \nEnables flexible and centralized logging control for a code intelligence platform, facilitating easier debugging, monitoring, and operational visibility by adjusting log verbosity per module or globally, which is critical for maintaining and troubleshooting complex systems.\n\n4. **Dependencies**:  \n- Python standard library `logging` module.  \n- A custom `CodeIntelligenceLogger` class (not fully shown here) that encapsulates the logging configuration logic.\n\n5. **Configuration**:  \n- Accepts logging level presets as string inputs.  \n- Supports optional log file output path.  \n- Allows custom module",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:06.136567",
      "status": "summarized"
    },
    "cpp_parser.py:chunk_0": {
      "chunk_id": "cpp_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\cpp_parser.py",
      "chunk_hash": "2afdb239e7d2373b176a0cbc03b63040f5e9b6d77bbceada2affeb61cdac950e",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module defines a C/C++ source code parser class (`CppParser`) that is designed to parse C and C++ files. Currently, it delegates parsing to a fallback parser but is structured to support integration with a more advanced tree-sitter based parser in the future.\n\n2. **Technical Details**:  \n- The `CppParser` class inherits from a base parser class (`BaseParser`), indicating an object-oriented design with polymorphism for different language parsers.  \n- It overrides methods to specify the language (`cpp`) and relevant file extensions for C/C++ source and header files.  \n- Parsing is currently implemented by instantiating and delegating to a `FallbackParser` instance, passing configuration parameters (`target_chunk_tokens`, `max_chunk_tokens`) presumably defined in the base class.  \n- The parser returns a list of `CodeChunk` objects, which likely represent parsed segments of code for further processing.\n\n3. **Business Logic**:  \nThe parser facilitates the extraction and processing of C/C++ source code chunks, which can be used in business contexts such as code analysis, indexing, search, or transformation workflows. By supporting multiple C/C++ file extensions, it ensures broad applicability across typical C/C++ projects.\n\n4. **Dependencies**:  \n- Internal modules: `BaseParser` and `FallbackParser` from the same package, which provide base parsing functionality and a fallback parsing mechanism respectively.  \n- Standard Python libraries: `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:15.913777",
      "status": "summarized"
    },
    "dart_parser.py:chunk_0": {
      "chunk_id": "dart_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\dart_parser.py",
      "chunk_hash": "5edbd9305505342f55f6f7db4cf2021add327d2c5724922d39b390ce8c121590",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module defines a DartParser class designed to parse Dart source files, specifically for Flutter applications. Currently, it delegates parsing to a fallback parser, indicating a placeholder implementation until a more advanced parser (e.g., tree-sitter based) is integrated.\n\n2. **Technical Details**:  \n- The DartParser class inherits from a BaseParser abstract class, adhering to a polymorphic design pattern for language-specific parsers.  \n- It overrides methods to specify the language (\"dart\") and file extensions ([\".dart\"]).  \n- The `parse_file` method instantiates a FallbackParser with token limits (`target_chunk_tokens`, `max_chunk_tokens`) presumably defined in the base class, then calls its `parse_file` method to perform the actual parsing.  \n- The use of `CodeChunk` as the return type suggests the parser breaks source code into manageable chunks for downstream processing.\n\n3. **Business Logic**:  \nThe parser supports automated code intelligence features such as code analysis, indexing, or transformation for Dart/Flutter projects. By parsing Dart files into structured chunks, it enables tooling that improves developer productivity, code quality, or automated documentation generation.\n\n4. **Dependencies**:  \n- Python standard library: `typing` for type hints, `logging` for diagnostic messages.  \n- Internal modules:  \n  - `.base_parser` providing BaseParser and CodeChunk abstractions.  \n  - `.fallback_parser` providing a generic fallback parsing mechanism used",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:22.484730",
      "status": "summarized"
    },
    "java_parser.py:chunk_0": {
      "chunk_id": "java_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\java_parser.py",
      "chunk_hash": "d5f64ab1f240138d65370b5eac2f77472e8c02837df84ffeb7419a9350aeda71",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a Java source code parser class that is designed to parse Java files. Currently, it uses a fallback parsing mechanism but is structured to support a more advanced tree-sitter based parser in the future.\n\n2. **Technical Details**:  \n- The `JavaParser` class inherits from a base class `BaseParser`.  \n- It overrides methods to specify the language (\"java\") and file extensions ([\".java\"]).  \n- The `parse_file` method delegates parsing to a `FallbackParser` instance, passing configuration parameters (`target_chunk_tokens` and `max_chunk_tokens`) inherited from the base class.  \n- The fallback parser presumably breaks the Java source code into manageable `CodeChunk` objects, which are likely data structures representing segments of code.  \n- Logging is set up but not actively used in the snippet.\n\n3. **Business Logic**:  \nThis parser is part of a larger system that processes source code files (Java in this case) to extract meaningful code chunks for further analysis, indexing, or transformation. It enables automated understanding or manipulation of Java codebases, which is valuable for code intelligence, search, or refactoring tools.\n\n4. **Dependencies**:  \n- Python typing module (`List`) for type annotations.  \n- Python logging module for logging support.  \n- Local modules:  \n  - `.base_parser` providing `BaseParser` and `CodeChunk` abstractions.  \n  - `.fallback_parser` providing",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:29.771642",
      "status": "summarized"
    },
    "js_parser.py:chunk_0": {
      "chunk_id": "js_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "chunk_hash": "7f6d13a59ed07b638d96b98c38290bed94534c6c3b4e8a07acb3e69c171c79f4",
      "chunk_index": 0,
      "summary": "**Summary of Error Handling in `js_parser.py`:**\n\n1. **Purpose**:  \n   The error handling in this code primarily addresses issues related to the availability and initialization of the `tree-sitter-javascript` parser library. It ensures that if the required native parsing library is missing or fails to initialize, the system can detect this and respond appropriately.\n\n2. **Exception Types**:  \n   - `ImportError`: Caught when attempting to import the `tree_sitter_javascript` module and related classes.  \n   - Generic `Exception`: Catches any exception during the initialization of the `Parser` and `Language` objects from the `tree-sitter` library.\n\n3. **Recovery Strategy**:  \n   - On import failure (`ImportError`), the code sets a flag `HAS_TREE_SITTER` to `False` and logs a warning. This prevents the parser from attempting to use unavailable components.  \n   - During parser initialization, if any exception occurs, it logs the error and sets `self.parser` to `None`, effectively disabling the tree-sitter parser functionality but allowing the program to continue running.\n\n4. **Logging**:  \n   - Uses Python\u2019s standard `logging` module.  \n   - Logs a warning if the `tree-sitter-javascript` library is not available.  \n   - Logs an error with exception details if parser initialization fails.  \n   This provides visibility into missing dependencies or runtime failures for monitoring and debugging.\n\n5. **",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:35.666301",
      "status": "summarized"
    },
    "js_parser.py:chunk_2": {
      "chunk_id": "js_parser.py:chunk_2",
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "chunk_hash": "48c82a1cc912c77ebaa73eabd398b6c2473406ecd9a65b8e521f3cc02df4187b",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a parser that processes JavaScript and TypeScript source files to extract meaningful code chunks such as functions, classes, and export statements for further analysis or processing.\n\n2. **Technical Details**:  \n- Reads the source file in binary mode and decodes it to UTF-8 if necessary.  \n- Uses a parser (likely a tree-sitter or similar AST parser) to generate a syntax tree from the source code.  \n- Traverses the syntax tree to identify nodes of specific types (functions, classes, exports).  \n- Extracts code chunks from these nodes, indexing them sequentially.  \n- Applies filtering logic to skip trivial or irrelevant chunks based on content and metadata.  \n- Uses helper methods like `_traverse_tree`, `_extract_chunk`, and `should_skip_chunk` to modularize functionality.\n\n3. **Business Logic**:  \nEnables automated code intelligence features such as code summarization, indexing, or analysis by breaking down complex source files into manageable, meaningful segments. This supports use cases like code search, documentation generation, or static analysis in developer tools or CI pipelines.\n\n4. **Dependencies**:  \n- A parsing library capable of generating an AST from JavaScript/TypeScript source (e.g., tree-sitter).  \n- Internal modules or classes defining `CodeChunk` and helper methods (`_traverse_tree`, `_extract_chunk`, `should_skip_chunk`).  \n- Standard Python libraries for file I",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:39.141128",
      "status": "summarized"
    },
    "js_parser.py:chunk_4": {
      "chunk_id": "js_parser.py:chunk_4",
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "chunk_hash": "920366c555f7a5f882284e7182b0538f546a6b80d86378f3facf297b8ede9d53",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code is part of a JavaScript parser module designed to extract meaningful code chunks (such as functions or classes) from JavaScript source files for further processing or analysis.\n\n2. **Technical Details**:  \n- Uses a tree traversal algorithm (`_traverse_tree`) with a depth limit to navigate an abstract syntax tree (AST) representing the source code structure.  \n- Extracts code segments (chunks) by slicing the source code bytes using node byte offsets (`start_byte`, `end_byte`).  \n- Employs a generator pattern in `_traverse_tree` to yield nodes recursively.  \n- Implements a fallback parsing strategy (`_fallback_parse`) if no chunks are extracted initially.  \n- Uses logging for debug and error reporting.\n\n3. **Business Logic**:  \nFacilitates code intelligence features such as code indexing, symbol extraction, or automated documentation by breaking down JavaScript files into manageable, meaningful code chunks. This supports downstream tools like code search, refactoring, or static analysis in a development environment or CI pipeline.\n\n4. **Dependencies**:  \n- Likely depends on a tree-sitter or similar AST parsing library (implied by node properties like `start_byte`, `children`).  \n- Uses Python\u2019s standard `logging` module for logging debug and error messages.  \n- The `CodeChunk` data structure is referenced, presumably a custom or domain-specific class representing extracted code segments.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:45.848686",
      "status": "summarized"
    },
    "js_parser.py:chunk_6": {
      "chunk_id": "js_parser.py:chunk_6",
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "chunk_hash": "7c02fc056a2226d25169ff8a76f9dd297140c12a518a42d79bc577e9478a9511",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code processes JavaScript code snippets by extracting meaningful code chunks from an AST node, estimating their token size, truncating overly large chunks, and packaging them with metadata for further analysis or indexing.\n\n2. **Technical Details**:  \n- Uses an AST node (`node`) and source code bytes to extract a symbol name (likely function or class name) via `_get_symbol_name`.  \n- Estimates token count of the code snippet using `estimate_tokens(content)`.  \n- Applies thresholds: skips chunks with fewer than 20 tokens (likely trivial code), truncates chunks exceeding `max_chunk_tokens` by limiting to the first 20 lines and appending a truncation comment.  \n- Constructs a unique chunk ID using `create_chunk_id(file_path, chunk_index)`.  \n- Creates a `ChunkMetadata` data structure containing chunk ID, file path, language (hardcoded as \"javascript\"), line range, chunk type (normalized by removing suffixes), symbol name, token count, dependencies extracted from the content, and the content itself.  \n- Returns a `CodeChunk` object encapsulating the metadata and content.\n\n3. **Business Logic**:  \nThis code supports a code intelligence platform by breaking down JavaScript source files into manageable, meaningful chunks for indexing, search, or analysis. It ensures chunks are neither too trivial nor too large, improving the quality and efficiency of downstream processing such as code search, navigation, or AI-assisted code understanding.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:51.402231",
      "status": "summarized"
    },
    "js_parser.py:chunk_8": {
      "chunk_id": "js_parser.py:chunk_8",
      "file_path": "code-intelligence\\parsers\\js_parser.py",
      "chunk_hash": "27d2cb42eaf5336cdccb1beba9c6c545242adbb806ffdd607f01c31c2eb62966",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a JavaScript parser module designed to extract identifiers from syntax tree nodes, provide a fallback parsing mechanism for JavaScript files, and extract dependency statements such as imports and requires from JavaScript source code.\n\n2. **Technical Details**:  \n- Iterates over child nodes of a syntax tree node to find and decode an identifier token from byte offsets.  \n- Implements a fallback parsing strategy by delegating to a `FallbackParser` class when the primary parsing approach is insufficient or fails.  \n- Extracts dependencies by scanning each line of the source code for common JavaScript import patterns (`import`, `require`, `from`).  \n- Uses string operations and simple pattern matching rather than complex parsing for dependency extraction.\n\n3. **Business Logic**:  \nEnables robust code intelligence features such as code chunking and dependency analysis for JavaScript files, which are critical for applications like code search, static analysis, or automated refactoring tools.\n\n4. **Dependencies**:  \n- Internal module import: `FallbackParser` from `.fallback_parser`.  \n- Assumes the presence of a syntax tree node structure with `children`, `type`, `start_byte`, and `end_byte` attributes.  \n- Uses standard Python libraries for string manipulation and typing (`List`).\n\n5. **Configuration**:  \n- Uses instance variables `self.target_chunk_tokens` and `self.max_chunk_tokens` to configure the fallback parser, likely set elsewhere in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:37:57.906351",
      "status": "summarized"
    },
    "kotlin_parser.py:chunk_0": {
      "chunk_id": "kotlin_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\kotlin_parser.py",
      "chunk_hash": "40dc4dd8817a590e581a094a1f78be5e5f7042792f5358522c7bc488d6471ad3",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines a Kotlin source code parser class that is designed to parse Kotlin files. Although it is intended to support tree-sitter parsing eventually, it currently uses a fallback parsing mechanism.\n\n2. **Technical Details**  \n- The `KotlinParser` class inherits from a `BaseParser` abstract or base class, indicating a polymorphic design for different language parsers.  \n- It implements methods to specify the language name (`get_language`) and file extensions (`get_file_extension`) it supports.  \n- The core parsing method `parse_file` delegates parsing to a `FallbackParser` instance, passing configuration parameters such as `target_chunk_tokens` and `max_chunk_tokens` inherited from the base class.  \n- The fallback parser likely implements a generic or simpler parsing strategy, serving as a placeholder until tree-sitter integration is completed.\n\n3. **Business Logic**  \nThis parser enables the system to process Kotlin source files, extracting meaningful code chunks for downstream tasks such as code analysis, indexing, or intelligence features. It supports Kotlin development workflows by recognizing Kotlin-specific file extensions and providing a parsing interface.\n\n4. **Dependencies**  \n- Python standard library: `typing.List` for type annotations, `logging` for logging support.  \n- Internal modules:  \n  - `.base_parser` providing `BaseParser` and `CodeChunk` abstractions.  \n  - `.fallback_parser` providing `FallbackParser` as a backup parsing strategy.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:04.689191",
      "status": "summarized"
    },
    "python_parser.py:chunk_0": {
      "chunk_id": "python_parser.py:chunk_0",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "032e625afcd9505ab581739be84402f7d915667a9d8965bada2be5fb22de3f09",
      "chunk_index": 0,
      "summary": "**Summary of Error Handling in `python_parser.py`**\n\n1. **Purpose**:  \n   The error handling in this code primarily addresses issues related to the availability and initialization of the `tree-sitter-python` parsing library. It ensures that the parser can still function or degrade gracefully if the required native parsing components are missing or fail to initialize.\n\n2. **Exception Types**:  \n   - `ImportError`: Caught when attempting to import `tree_sitter_python` and `tree_sitter` modules, indicating the library is not installed or not available in the environment.  \n   - `Exception` (generic): Catches any exception during the initialization of the `Parser` and `Language` objects from the `tree_sitter` library, which could include configuration errors, runtime errors, or API misuse.\n\n3. **Recovery Strategy**:  \n   - On import failure (`ImportError`), the code sets a flag `HAS_TREE_SITTER = False` and logs a warning, allowing the rest of the system to detect the absence of tree-sitter support and potentially use alternative parsing methods.  \n   - On initialization failure (any `Exception` during parser setup), the parser instance is set to `None` and an error is logged. This prevents the application from crashing and signals that tree-sitter parsing is unavailable.\n\n4. **Logging**:  \n   - Uses Python\u2019s standard `logging` module to emit:  \n     - A **warning** when the `tree",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:08.490367",
      "status": "summarized"
    },
    "python_parser.py:chunk_2": {
      "chunk_id": "python_parser.py:chunk_2",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "3f74d929ed8494e6bbf261c7b064a581393ae410e02c4a793345706ec9dc9fea",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis method parses a Python source file to extract top-level function and class definitions as discrete code chunks for further processing or analysis.\n\n2. **Technical Details**:  \n- Reads the file in binary mode and decodes it as UTF-8 if needed.  \n- Uses a parser object (likely a tree-sitter or similar parser) to generate an abstract syntax tree (AST) from the source code.  \n- Iterates over the root node\u2019s children to identify nodes of type `function_definition` or `class_definition`.  \n- Extracts these nodes into `CodeChunk` objects via a helper method `_extract_chunk`.  \n- Applies filtering logic (`should_skip_chunk`) to exclude trivial or irrelevant chunks.  \n- Falls back to a simpler parsing method (`_fallback_parse`) if the parser is not initialized.\n\n3. **Business Logic**:  \nEnables automated code intelligence features such as code indexing, navigation, or documentation generation by isolating meaningful code segments (functions/classes) from Python source files.\n\n4. **Dependencies**:  \n- A parser object (`self.parser`), likely from an external parsing library (e.g., tree-sitter).  \n- Internal helper methods `_extract_chunk`, `_fallback_parse`, and `should_skip_chunk`.  \n- The `CodeChunk` data structure for representing extracted code segments.\n\n5. **Configuration**:  \n- The parser instance (`self.parser`) must be configured/initialized before use.  \n- No explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:17.487950",
      "status": "summarized"
    },
    "python_parser.py:chunk_4": {
      "chunk_id": "python_parser.py:chunk_4",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "aed405d07acaa3cbb9fec543a809a797eac19bb171fb82cf1b8f2e5184e05527",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code is part of a parser that extracts meaningful code chunks (such as functions or classes) from Python source files, converting them into manageable segments for further processing or analysis.\n\n2. **Technical Details**:  \n- The parser traverses an abstract syntax tree (AST) node representing Python code, extracting byte ranges corresponding to functions or classes.  \n- It decodes source code bytes into UTF-8 strings for content extraction.  \n- Symbol names are identified by locating child nodes of type 'identifier' within the AST node.  \n- Token count estimation is performed on the extracted content to determine chunk size, potentially triggering splitting logic (not fully shown).  \n- If no chunks are extracted, a fallback parsing method is invoked to process the entire file as a single chunk.  \n- Logging is used extensively for debugging and error reporting.\n\n3. **Business Logic**:  \nThe code supports a business need to analyze or index Python source code by breaking it into logical units (chunks). This enables features like code intelligence, search, summarization, or automated documentation generation by focusing on discrete, meaningful code segments rather than entire files.\n\n4. **Dependencies**:  \n- A logger instance (likely from Python\u2019s `logging` module) for debug and error messages.  \n- The code references a `CodeChunk` data structure or class (not shown) to represent extracted chunks.  \n- The AST nodes appear to be from a parsing library that provides `start",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:25.118177",
      "status": "summarized"
    },
    "python_parser.py:chunk_6": {
      "chunk_id": "python_parser.py:chunk_6",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "d0de34b78a1d08254d86e72f25503886b50655eb8c00756b7d69eb8904b722c2",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code is part of a parser that processes Python source code to create manageable chunks of code definitions (e.g., functions, classes). It splits large code definitions into smaller parts by extracting only the signature and docstring to ensure chunk size limits are respected.\n\n2. **Technical Details**:  \n- The code checks if the token count of a code definition exceeds a configured maximum (`self.max_chunk_tokens`).  \n- If the chunk is too large, it delegates to `_split_large_definition` to extract a smaller representative chunk (signature + docstring).  \n- It creates a unique chunk ID using `create_chunk_id` based on file path and chunk index.  \n- Metadata for each chunk is encapsulated in a `ChunkMetadata` data structure, which includes file path, language, line numbers, chunk type, symbol name, token count, dependencies (extracted via `extract_dependencies`), and the chunk content itself.  \n- Returns a `CodeChunk` object combining metadata and content.  \n- Uses node properties like `start_point`, `end_point`, and `type` presumably from a syntax tree (likely from a parsing library such as Tree-sitter).  \n- The `_split_large_definition` method is designed to handle large nodes by extracting only the initial part of the source code (signature and docstring), though the full implementation is not shown.\n\n3. **Business Logic**:  \nThis code supports a code intelligence platform or tool that needs",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:32.979754",
      "status": "summarized"
    },
    "python_parser.py:chunk_8": {
      "chunk_id": "python_parser.py:chunk_8",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "620faea61d78fa2fa5c63c995c4b4ca9b49291702a1c0e68f10c30a7e45445f6",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a parser that processes Python source code to extract and create metadata-rich code chunks, specifically focusing on capturing code signatures and handling fallback parsing when the primary parser fails.\n\n2. **Technical Details**:  \n- The code slices a segment of source code bytes between `start_byte` and `node.end_byte`, decodes it to UTF-8, and splits it into lines.  \n- It limits the extracted content to a maximum of 20 lines, appending a truncation notice if the content is longer.  \n- A unique `chunk_id` is generated using `create_chunk_id` based on the file path and chunk index.  \n- Constructs a `ChunkMetadata` object containing metadata such as chunk ID, file path, language, line range, chunk type (derived from the node type with `_definition` suffix removed), symbol name, estimated token count, dependencies extracted from the content, and the content itself.  \n- Returns a `CodeChunk` object encapsulating the metadata and content.  \n- Provides a `_fallback_parse` method that imports and uses a `FallbackParser` to parse files when the primary tree-sitter parser fails, passing configuration parameters like token limits.\n\n3. **Business Logic**:  \nThis code supports a code intelligence platform or tool that indexes, analyzes, and processes Python source files to generate structured representations of code segments (chunks). These chunks can be used for features like code search, navigation",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:39.736434",
      "status": "summarized"
    },
    "python_parser.py:chunk_10": {
      "chunk_id": "python_parser.py:chunk_10",
      "file_path": "code-intelligence\\parsers\\python_parser.py",
      "chunk_hash": "6359dd34014fb92a6a5364216907638d3bb265efc0ea3a19ed09b487e7e7a097",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis method extracts Python import statements from a given source code string by identifying lines that start with `import` or `from`.\n\n2. **Technical Details**:  \n- Iterates over each line of the input string after splitting by newline.  \n- Uses simple string operations (`strip()`, `startswith()`) to detect import statements.  \n- Collects matching lines into a list and returns them.  \n- Data structure used: Python list to accumulate dependencies.\n\n3. **Business Logic**:  \nEnables identification of external or internal module dependencies within Python source code, which can be used for code analysis, dependency tracking, or building a dependency graph for code intelligence purposes.\n\n4. **Dependencies**:  \nNo external libraries or modules are used; relies solely on built-in Python string and list operations.\n\n5. **Configuration**:  \nNo configuration, environment variables, or external settings influence this method.\n\n6. **Error Handling**:  \nNo explicit error handling; assumes input is a valid string. Potential issues with non-string input types are not handled.\n\n7. **API/Interface**:  \n- Public method: `extract_dependencies(content: str) -> List[str]`  \n- Input: Python source code as a single string.  \n- Output: List of strings, each representing an import statement line.\n\n8. **Performance Notes**:  \n- Simple line-by-line scan with O(n) complexity relative to number of lines.  \n- No caching",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:44.105530",
      "status": "summarized"
    },
    "summary_templates.py:chunk_1": {
      "chunk_id": "summary_templates.py:chunk_1",
      "file_path": "code-intelligence\\summary_templates.py",
      "chunk_hash": "33b4c631203cf5f0d99abffbf037dd5549f13f60e20de9e5d0340f8b2b601c8e",
      "chunk_index": 1,
      "summary": "The provided Python code defines a set of multi-line string templates intended for generating structured summaries of various configuration files and code artifacts. These templates are designed to guide an analysis tool or a user in producing detailed, categorized summaries based on the type of configuration or code being examined.\n\n---\n\n### Comprehensive Summary\n\n**1. Purpose:**  \nThe code provides predefined textual templates for analyzing and summarizing different types of configuration files and code. Each template outlines specific categories and questions to structure the summary output, facilitating consistent and comprehensive documentation or review of infrastructure, messaging, and code configurations.\n\n**2. Technical Details:**  \n- The code consists of three main string constants, each formatted as a multi-line Python f-string template with placeholders (`{file_path}`, `{file_type}`, `{content}`) for dynamic insertion of file metadata and content.\n- Templates include:\n  - `INFRASTRUCTURE_TEMPLATE`: For Docker, Kubernetes, or Helm configurations.\n  - `KAFKA_TEMPLATE`: For Kafka or messaging queue configurations.\n  - A generic code summary template (unnamed in the snippet) for analyzing code files.\n- Each template enumerates numbered points to guide the summary, covering aspects such as purpose, key settings, environment, dependencies, security, and more.\n- The templates use Markdown-style formatting (e.g., bold text, code blocks) to enhance readability in generated summaries.\n\n**3. Business Logic:**  \nThese templates support automated or semi-automated documentation, code review, or audit processes by standard",
      "embedding_id": null,
      "created_at": "2025-10-22T19:38:53.250049",
      "status": "summarized"
    },
    "summary_templates.py:chunk_3": {
      "chunk_id": "summary_templates.py:chunk_3",
      "file_path": "code-intelligence\\summary_templates.py",
      "chunk_hash": "d13a492f2f3d5279fa2727cd6f2b5b5115b6029ee2d7a5e871d15550bcd71795",
      "chunk_index": 3,
      "summary": "The provided Python code defines a set of multi-line string templates intended for generating structured summaries of various types of technical artifacts. These templates are likely used in a code intelligence or documentation generation context, where input files and their contents are analyzed and summarized according to a consistent format. Below is a detailed analysis:\n\n---\n\n### File: code-intelligence\\summary_templates.py\n\n#### Purpose\n- To provide reusable, structured prompt templates for summarizing different categories of technical content.\n- These templates guide the generation of detailed, consistent summaries for code, database schemas/migrations, and infrastructure-as-code (IaC) files.\n- Likely used in an automated system (e.g., AI assistant, documentation tool) that ingests source files and produces human-readable technical summaries.\n\n#### Defined Templates\n\n1. **Database Schema/Migration Template (`DATABASE_TEMPLATE`)**\n   - **Input Parameters:** `file_path`, `file_type`, `content`\n   - **Content:** The raw schema or migration code is included verbatim.\n   - **Summary Structure:**\n     1. Purpose of the database changes\n     2. Tables or collections modified\n     3. Schema changes (columns added, modified, removed)\n     4. Relationships (foreign keys, joins, references)\n     5. Indexes for query optimization\n     6. Constraints (unique, not null, check constraints)\n     7. Migration strategy (up/down migrations, rollback plan)\n     8. Data impact on existing",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:02.823360",
      "status": "summarized"
    },
    "summary_templates.py:chunk_5": {
      "chunk_id": "summary_templates.py:chunk_5",
      "file_path": "code-intelligence\\summary_templates.py",
      "chunk_hash": "52a1f4e51898a63cea6c218407d44fd07cdbe7dac51820fe664c70cc500fe07a",
      "chunk_index": 5,
      "summary": "The provided Python code defines a set of multi-line string templates intended for generating structured summaries of different types of infrastructure-as-code and DevOps configurations. These templates are designed to be populated with specific file paths, file types, and content, and then used to produce detailed, categorized analyses. Below is a comprehensive summary of the code:\n\n---\n\n### 1. **Purpose**\n\n- To provide reusable, structured prompt templates for analyzing and summarizing various infrastructure and DevOps-related configuration files.\n- These templates guide the generation of detailed, categorized summaries for:\n  - Infrastructure provisioning code (e.g., Terraform, CloudFormation)\n  - CI/CD pipeline configurations (e.g., GitHub Actions, Jenkinsfiles)\n  - Monitoring and observability configurations (e.g., Prometheus, Datadog)\n\n---\n\n### 2. **Resources**\n\n- No direct cloud resources are created by this code itself; rather, it is a utility to analyze code that provisions resources.\n- The templates reference common cloud resources implicitly by the categories they prompt for (e.g., EC2, S3, RDS in infrastructure).\n\n---\n\n### 3. **Networking**\n\n- Networking is referenced only in the context of what the analyzed infrastructure code might provision (VPCs, subnets, security groups).\n- The template prompts the user or system to identify networking components in the analyzed code.\n\n---\n\n### 4. **Storage**\n\n- Storage resources like volumes, buckets, and databases are mentioned as part of the infrastructure summary template.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:06.401697",
      "status": "summarized"
    },
    "summary_templates.py:chunk_7": {
      "chunk_id": "summary_templates.py:chunk_7",
      "file_path": "code-intelligence\\summary_templates.py",
      "chunk_hash": "3dcc959dabbd07fb485519b266d7d8e11fe8eded83f7e8de941e1ee97efb55fc",
      "chunk_index": 7,
      "summary": "The provided Python code defines a set of multi-line string templates intended for generating structured summaries of various software artifacts, primarily for analysis or documentation purposes. These templates appear to be used in a code intelligence or automated documentation system that ingests code or specifications and produces detailed, categorized summaries.\n\n---\n\n### 1. **Purpose**\n\n- The code provides predefined textual templates to guide the generation of structured summaries for different types of inputs:\n  - Monitoring configurations\n  - API specifications (OpenAPI, GraphQL, Proto)\n  - Exception and error handling code\n\n- Each template outlines specific categories or aspects to be analyzed and summarized, enabling consistent and comprehensive documentation or review outputs.\n\n---\n\n### 2. **Technical Details**\n\n- The code consists solely of string constants assigned to class-level variables (likely within a class, though the snippet does not show the class declaration).\n- Each template uses Python\u2019s triple-quoted string syntax for multi-line text.\n- Templates include placeholders (e.g., `{file_path}`, `{content}`, `{file_type}`, `{language}`, `{chunk_type}`) for dynamic insertion of relevant data during runtime.\n- The templates are structured as prompts or instructions, presumably for an AI or automated system to fill in the summaries based on the provided content.\n\n---\n\n### 3. **Business Logic**\n\n- The templates support automated analysis and documentation workflows, which can:\n  - Accelerate code reviews and audits\n  - Improve knowledge sharing and onboarding\n  - Ensure consistent quality and completeness in documentation",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:14.139256",
      "status": "summarized"
    },
    "summary_templates.py:chunk_9": {
      "chunk_id": "summary_templates.py:chunk_9",
      "file_path": "code-intelligence\\summary_templates.py",
      "chunk_hash": "0d4035c7f0fdaee29b6ed207a67586ba8fd520fdbe3b50ccfc011dd758d32680",
      "chunk_index": 9,
      "summary": "Summary:\n\n1. **Purpose**:  \nThe provided snippet appears to be a partial or malformed Python code fragment intended to define a summary template or checklist for analyzing error handling in code. It outlines key aspects to consider when summarizing exception management but does not contain executable logic.\n\n2. **Technical Details**:  \n- The snippet lists enumerated points related to exception handling such as exception types, recovery strategies, logging, user impact, and fallback mechanisms.  \n- There is no algorithm, data structure, or design pattern implemented in this fragment.\n\n3. **Business Logic**:  \n- The code is designed to guide developers or analysts in creating comprehensive summaries of error handling in software components, which is critical for maintaining robustness and user experience in business applications.\n\n4. **Dependencies**:  \n- No external libraries, services, or modules are imported or referenced in this snippet.\n\n5. **Configuration**:  \n- No environment variables, configuration files, or settings are indicated or used.\n\n6. **Error Handling**:  \n- The snippet itself does not implement error handling but references key elements that should be included in an error handling summary, such as exception types caught and recovery strategies.\n\n7. **API/Interface**:  \n- No functions, classes, methods, or API endpoints are defined in the provided code.\n\n8. **Performance Notes**:  \n- No performance considerations, optimizations, or scalability concerns are addressed in this fragment.\n\nOverall, this code fragment serves as a textual template or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:21.732644",
      "status": "summarized"
    },
    "servicesClient.ts:chunk_0": {
      "chunk_id": "servicesClient.ts:chunk_0",
      "file_path": "frontend\\src\\api\\servicesClient.ts",
      "chunk_hash": "974fbd44200301da161c5185418a756b47ef74351e168147165d1e6621523df4",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis TypeScript module provides a client-side API wrapper for managing external services, including connecting, disconnecting, and executing actions on those services, optionally enhanced with a Large Language Model (LLM) integration.\n\n2. **Technical Details**  \n- Uses Axios HTTP client to perform RESTful POST requests to backend endpoints under the `/api/services` base path.  \n- Defines TypeScript interfaces (`ServiceConnectionRequest`, `ServiceActionRequest`, `ServiceStatus`, `ServiceTestResult`) to strongly type request payloads and expected response structures.  \n- Implements asynchronous functions (`connectService`, `disconnectService`, `executeServiceAction`) that return the data portion of Axios responses, abstracting HTTP details from consumers.\n\n3. **Business Logic**  \nEnables frontend applications to programmatically manage service lifecycle and operations, facilitating dynamic service integration and control. The optional LLM flag in `executeServiceAction` suggests support for AI-enhanced service commands, potentially improving automation or user interaction with services.\n\n4. **Dependencies**  \n- `axios`: For making HTTP requests to backend service management endpoints.\n\n5. **Configuration**  \n- Uses a hardcoded `API_BASE` path (`/api/services`) for API endpoint URLs.  \n- Although the import mentions environment variables `serviceName` and `API_BASE`, only a local constant `API_BASE` is used in the code; environment variables are not directly referenced here.\n\n6. **Error Handling**  \n- No explicit error handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:25.660204",
      "status": "summarized"
    },
    "servicesClient.ts:chunk_2": {
      "chunk_id": "servicesClient.ts:chunk_2",
      "file_path": "frontend\\src\\api\\servicesClient.ts",
      "chunk_hash": "4c39c44ba9e0a615528025ecebbd30df27c212495b558da49272cb2cb0644abe",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis TypeScript module provides client-side functions to interact with a backend API for managing and monitoring various services. It allows fetching statuses, listing services, and testing service connectivity.\n\n2. **Technical Details**:  \n- Uses asynchronous functions with `async/await` to handle HTTP requests.  \n- Returns typed promises, e.g., `Promise<Record<string, ServiceStatus>>` and `Promise<ServiceTestResult>`.  \n- Utilizes RESTful API endpoints with HTTP GET and POST methods.  \n- Data is returned as JSON and accessed via `response.data`.  \n- Default fallback values (`{}` or `[]`) are provided when expected data fields are missing.\n\n3. **Business Logic**:  \nEnables frontend applications to monitor the health and availability of backend services by retrieving their statuses, listing all registered services, and testing connectivity. This supports operational visibility and troubleshooting in a service-oriented architecture.\n\n4. **Dependencies**:  \n- `axios`: For making HTTP requests to the backend API.  \n- TypeScript types/interfaces such as `ServiceStatus` and `ServiceTestResult` (assumed to be defined elsewhere).\n\n5. **Configuration**:  \n- `API_BASE`: Base URL for the backend API, injected via environment variables or build-time configuration.  \n- `serviceName`: Used as a dynamic path parameter in some API calls.\n\n6. **Error Handling**:  \n- No explicit error handling is implemented in the code; errors from `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:34.624884",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_0": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "7b80046d1d26f1d2781c37aabb8c688b2f60a578b99b78dd33e135dea6c76930",
      "chunk_index": 0,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This React functional component, `DocOrchestratorPanel`, provides a user interface panel to orchestrate automated documentation generation and integration workflows for a specified code repository. It manages the process of analyzing a GitHub repository, generating documentation, and committing the results back to GitHub, with optional integration to Confluence and Jira.\n\n2. **Technical Details**:  \n   - Uses React hooks (`useState`) to manage component state including user inputs (prompt, repository), feature toggles (GitHub, Confluence, Jira), and orchestration status steps.  \n   - Defines a `Step` interface to track the progress and status of each step in the orchestration pipeline (`pending`, `running`, `complete`, `error`).  \n   - Implements an asynchronous function `handleOrchestrate` to sequentially update the UI state reflecting the progress of the orchestration workflow.  \n   - The component uses icon components from `lucide-react` for UI representation of steps/status.  \n   - Interacts with an external API client (`apiClient`) to presumably trigger backend orchestration services (though the full implementation is not shown).\n\n3. **Business Logic**:  \n   The component addresses the business need to automate and streamline the creation and maintenance of project documentation by integrating with version control (GitHub) and optionally with enterprise collaboration tools (Confluence, Jira). This reduces manual documentation effort and ensures up-to-date project documentation aligned with code",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:38.830505",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_2": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "b96aa0d3fa8026b78aaa20798798095c5ad7bf97d04a5f496ce812a4902d6f01",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component code snippet manages the orchestration of documentation generation and publishing workflows, including analyzing repository files, generating documentation, publishing to Confluence, and creating Jira tickets. It updates UI steps to reflect the progress and status of each task asynchronously.\n\n2. **Technical Details**:  \n- Uses React state management (`setSteps`) to track and update the status of multiple sequential steps in the UI.  \n- Asynchronous API call (`apiClient.orchestrateDocumentation`) to trigger backend orchestration based on user-selected options.  \n- Conditional logic to update step statuses and messages based on the API response.  \n- Functional update pattern for state (`prev => prev.map(...)`) to immutably update step objects by index.\n\n3. **Business Logic**:  \nAutomates and visually tracks the process of generating documentation from a code repository, publishing it to Confluence, and optionally creating Jira tickets. This streamlines developer workflows by integrating documentation and issue tracking tools, improving productivity and traceability.\n\n4. **Dependencies**:  \n- `apiClient`: An external or internal API client module responsible for communicating with backend services that perform documentation orchestration.  \n- React (implied by use of `setSteps` and JSX-like syntax).  \n- Possibly Confluence and Jira APIs indirectly via backend orchestration.\n\n5. **Configuration**:  \n- Flags and keys such as `enableGithub`, `enableConfluence`, `confluenceSpace`, `enableJira",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:42.276072",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_4": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "8d4a4e6fbb6620ecc0b7a3cf69bb32ff52f01d65c547ae0fcaaa30a180413827",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code manages the progression and status updates of a multi-step orchestration process involving GitHub commits, Confluence page creation, and Jira ticket handling within a frontend React component.\n\n2. **Technical Details**:  \n- Uses conditional logic to check for the presence of response data (`github_commit`, `confluence_page`) and feature flags (`enableGithub`, `enableConfluence`, `enableJira`).  \n- Calls `updateStep(stepNumber, status, message?)` to update the UI or internal state about the progress of each step.  \n- Constructs commit messages dynamically based on available commit metadata (branch name or commit SHA).  \n- Implements a linear step progression pattern with branching based on enabled features.\n\n3. **Business Logic**:  \n- Automates and visually tracks the orchestration of documentation and issue tracking workflows across GitHub, Confluence, and Jira.  \n- Skips steps gracefully if corresponding integrations are disabled, providing clear status messages (\"Skipped (not enabled)\").  \n- Ensures that each step only proceeds if the previous step is complete or skipped, maintaining a clear workflow state for users.\n\n4. **Dependencies**:  \n- Relies on a `response` object presumably returned from an API call that includes GitHub commit and Confluence page data.  \n- Uses feature flags (`enableGithub`, `enableConfluence`, `enableJira`) likely sourced from component props, context, or global state.  \n- The `updateStep",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:46.219155",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_6": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "475f39ff52dd0bc8d96189d486a474b9c2bf90750f666c770e0857b8274ba172",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component manages an AI-powered documentation workflow panel that orchestrates a process involving generating or updating documentation, optionally creating a Jira ticket, and displaying the progress and results to the user.\n\n2. **Technical Details**:  \n- Uses React functional component with hooks (`useState`) to manage state such as `prompt`, `steps`, `result`, and `isRunning`.  \n- Implements asynchronous orchestration logic with `try-catch-finally` for handling API calls or processing steps.  \n- Updates UI step statuses dynamically based on the orchestration progress (e.g., 'running', 'complete', 'error').  \n- Conditional rendering and state updates based on the presence of a Jira ticket or Jira feature enablement flag.  \n- Uses JSX for UI rendering, including form elements like `<textarea>` bound to component state.\n\n3. **Business Logic**:  \nThe component facilitates a workflow where users input a documentation prompt, trigger an AI-driven process to generate or update documentation, and optionally create a Jira ticket to track the documentation task. It provides visibility into the process steps and handles cases where Jira integration is disabled or fails.\n\n4. **Dependencies**:  \n- React and React hooks (`useState`).  \n- UI icons/components such as `FileText` (likely from a UI icon library like `react-feather` or similar).  \n- External services/APIs for AI orchestration and Jira ticket creation (implied by `response.jira_ticket",
      "embedding_id": null,
      "created_at": "2025-10-22T19:39:54.627308",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_8": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "01a59680459042841d8481e0f0f5485da35ff67de502293f107649dc3c9276f8",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component code snippet renders a user interface panel that allows users to input documentation details, specify a GitHub repository, and select publishing destinations via checkboxes.\n\n2. **Technical Details**:  \n- Utilizes React functional components with state hooks (`useState`) to manage form inputs such as `repository` and `enableGithub`.  \n- Employs controlled components pattern for form inputs, binding input values to state and updating state on user interaction.  \n- Uses JSX for UI rendering with Tailwind CSS utility classes for styling and layout.  \n- Implements accessible form controls with labels and input elements.\n\n3. **Business Logic**:  \nEnables users to describe documentation needs, link to a specific GitHub repository, and choose where to publish the generated documentation, facilitating streamlined documentation orchestration and publishing workflows.\n\n4. **Dependencies**:  \n- React library for UI components and state management.  \n- Tailwind CSS for styling.  \n- Possibly other React ecosystem libraries (not visible in snippet) for state or side effects.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in the snippet; configuration likely occurs elsewhere in the application or via props.\n\n6. **Error Handling**:  \nNo explicit error handling is present in the snippet for input validation or submission errors.\n\n7. **API/Interface**:  \nNo public methods or API endpoints are defined in this snippet; it is a UI component likely integrated into a larger application",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:02.886177",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_10": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "033cfb2bb10d5991c2faf3d3cf578f1c70b1b62f324a04873adcf1195c4608ff",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component snippet renders UI elements that allow users to select options for committing documentation either to GitHub or enabling Confluence integration, providing a user-friendly interface for documentation orchestration.\n\n2. **Technical Details**:  \n- Utilizes React functional components with JSX for UI rendering.  \n- Uses controlled components pattern for checkbox inputs (`checked` and `onChange` handlers).  \n- Employs Tailwind CSS utility classes for styling and layout (flexbox, spacing, colors).  \n- Incorporates icon components (`Github`, `BookOpen`) likely imported SVG or React icon components.  \n- Uses semantic HTML elements (`label`, `input`, `div`, `span`) for accessibility and interaction.\n\n3. **Business Logic**:  \nEnables users to configure documentation workflows by choosing to commit documentation changes directly to a GitHub repository or enable Confluence integration, supporting collaborative documentation management and version control.\n\n4. **Dependencies**:  \n- React library for UI components and state management.  \n- Tailwind CSS for styling.  \n- Icon components (`Github`, `BookOpen`) which may come from a custom icon set or a library like Heroicons or React Icons.\n\n5. **Configuration**:  \n- State variable `enableConfluence` controls the checkbox state, likely managed via React `useState` or a similar state management hook.  \n- No explicit environment variables or external config files are referenced in this snippet.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:12.518453",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_12": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "5ea4e2272b5d8d2542a3a87f4eb2ecca1e2c143a1a3ad16f7be31f12408074e7",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis React component snippet provides a UI panel allowing users to enable publishing documentation to Confluence by entering a Confluence space key. It conditionally renders an input field for the space key when the \"Publish to Confluence\" option is enabled.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for rendering UI elements.  \n- State management via React hooks (`useState`) for `confluenceSpace` and `enableConfluence` (implied).  \n- Conditional rendering (`{enableConfluence && (...)}`) to show/hide input fields based on checkbox state.  \n- Controlled input component for capturing user input (`value` and `onChange` handlers).  \n- Tailwind CSS utility classes for styling and responsive UI behavior.\n\n3. **Business Logic**:  \nEnables users to integrate documentation publishing workflows directly into their Confluence spaces, streamlining the creation and management of project documentation within a familiar enterprise collaboration tool.\n\n4. **Dependencies**:  \n- React (for component and state management).  \n- Tailwind CSS (for styling).  \n- Likely other project-specific state or context providers managing `enableConfluence` and `confluenceSpace` states (not shown).  \n- Integration with Confluence API implied but not shown in this snippet.\n\n5. **Configuration**:  \n- User inputs Confluence space key manually (e.g., \"AlgoTradin\").  \n- The snippet hints at available spaces (",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:21.669378",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_14": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_14",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "099b90fe8a2a6f6d9f8b05d879e5bbaa6026acd973d4b009f63b3c13b8526240",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis React component snippet provides a UI control to enable or disable the creation of Jira tickets for documentation tracking. When enabled, it allows the user to input a Jira project key to associate with the ticket.\n\n2. **Technical Details**:  \n- Uses React functional component state hooks (`setEnableJira`, `setJiraProject`) to manage checkbox state and input value.  \n- Conditional rendering (`{enableJira && (...)}`) to show/hide the Jira project input field based on checkbox state.  \n- Utilizes JSX for UI structure and Tailwind CSS classes for styling.  \n- Incorporates an icon component (`FileCode`) for visual context.\n\n3. **Business Logic**:  \nEnables users to create Jira tickets linked to documentation tasks, facilitating issue tracking and project management integration within the documentation workflow.\n\n4. **Dependencies**:  \n- React (for component and state management)  \n- Tailwind CSS (for styling)  \n- An icon library/component providing `FileCode` (likely a React SVG icon component)  \n- Presumably Jira API integration elsewhere in the app (not shown in this snippet)\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown here.  \n- The Jira project key input expects a project identifier (e.g., \"PROJ\"), which may be validated or used in API calls elsewhere.\n\n6. **Error Handling**:  \n- No explicit error handling in this snippet (e",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:28.357277",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_16": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_16",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "81e8ad9b663e566de14bce2aa045064de31edc5d2c55bc143af97c6d043e34bf",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a user interface panel that allows users to initiate a documentation orchestration workflow by providing inputs and selecting destination platforms (GitHub, Confluence, Jira). It also displays the progress of the workflow steps once started.\n\n2. **Technical Details**:  \n- Utilizes React functional components with JSX for UI rendering.  \n- Conditional rendering is used to toggle button states and display warnings based on user input and selections.  \n- The button is disabled if the workflow is running, required inputs (`prompt`, `repository`) are empty, or no destination platform is selected.  \n- Uses state variables such as `isRunning`, `prompt`, `repository`, `enableGithub`, `enableConfluence`, `enableJira`, and `steps` to manage UI state and workflow progress.  \n- Maps over an array (`steps`) to dynamically render the workflow progress steps.  \n- Includes icon components (`Loader2`, `FileText`) likely from an icon library for visual feedback.\n\n3. **Business Logic**:  \nEnables users to start a documentation workflow that orchestrates content generation or updates across multiple platforms (GitHub, Confluence, Jira). It ensures that users provide necessary inputs and select at least one destination, preventing invalid workflow initiation. The progress display helps users track the orchestration status, improving transparency and user experience.\n\n4. **Dependencies**:  \n- React library for UI components.  \n- Icon components (`Loader2`, `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:35.235613",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_18": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_18",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "0a2170ea3270c947463cc8035a411ba215d1ce9b9a2113a8a9dbc8698245cfa0",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a visual status panel for a series of steps in a document orchestration process, displaying each step's current status with corresponding icons and messages, and shows a success message upon completion.\n\n2. **Technical Details**:  \n- Uses conditional rendering to display different icons based on the `step.status` value (`pending`, `running`, `complete`, `error`).  \n- Utilizes Tailwind CSS utility classes for styling layout and colors.  \n- Icons such as `Loader2`, `CheckCircle`, and `AlertCircle` are used to visually represent statuses.  \n- The component maps over a collection of steps (implied by the closing `))}`) to render each step\u2019s UI block.  \n- Uses React JSX syntax within a functional component structure.\n\n3. **Business Logic**:  \nThis UI component provides real-time feedback on the progress of document orchestration steps, helping users track the status of each step (e.g., pending, running, completed, error) and understand any messages or errors associated with those steps, thereby improving transparency and user experience in document processing workflows.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components (`Loader2`, `CheckCircle`, `AlertCircle`) likely imported from an icon library such as `lucide-react` or similar.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration settings",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:41.140443",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_20": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_20",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "489bc9e63c12b5ee8871ed7f0cc83cd8e31d8fc3827691a9d41100f830b812b4",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a confirmation panel indicating the successful completion of a documentation workflow, displaying status messages and quick links to related GitHub commit files.\n\n2. **Technical Details**:  \n- Utilizes JSX within a React functional component to structure UI elements.  \n- Conditional rendering (`{result.github_commit && (...)}`) is used to display GitHub commit information only if available.  \n- Uses Tailwind CSS utility classes for styling (e.g., `text-green-900`, `bg-white`, `rounded-lg`).  \n- Embeds an SVG or React icon component `<Github />` to visually represent GitHub links.  \n- Anchor tags open external URLs safely with `target=\"_blank\"` and `rel=\"noopener noreferrer\"` to prevent security risks.\n\n3. **Business Logic**:  \nThe component provides users with immediate feedback that a multi-step documentation generation and publishing process has completed successfully, enhancing user experience by linking directly to the generated documentation files in GitHub for quick access and verification.\n\n4. **Dependencies**:  \n- React (JSX syntax and component structure).  \n- Tailwind CSS for styling.  \n- A custom or third-party `<Github />` icon component.  \n- GitHub as an external service for hosting and linking documentation commits.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. However, the `result` object (likely passed as a prop or derived from state) must",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:50.210833",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_22": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_22",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "90aa1adab750c0e0f7074079da14b2d1aa301d40a596a493706558eba1d05264",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis React component snippet renders UI elements displaying metadata about a document or code commit, specifically showing a GitHub commit link and a Confluence page link if available.\n\n2. **Technical Details**:  \n- Uses JSX within a React functional component to conditionally render UI blocks based on the presence of `result.github_commit` and `result.confluence_page` objects.  \n- Utilizes Tailwind CSS utility classes for styling and layout (`flex`, `space-x-2`, `text-sm`, etc.).  \n- Icons (`FileCode`, `BookOpen`) are React components likely imported from an icon library.  \n- The commit SHA is truncated to the first 7 characters for display.  \n- Anchor tags open links in new tabs with security attributes (`rel=\"noopener noreferrer\"`).\n\n3. **Business Logic**:  \nProvides users with quick access to relevant documentation and code commits associated with a document or task, facilitating traceability and context in a developer or documentation workflow.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components (`FileCode`, `BookOpen`) from an icon library (e.g., Heroicons or similar)  \n- External URLs from `result.github_commit.commit_url` and `result.confluence_page.url`\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. The component relies on the `result` prop or state object",
      "embedding_id": null,
      "created_at": "2025-10-22T19:40:57.210659",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_24": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_24",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "f137abdba2e861da45194fd5f4fd7e26f7421c7caa3d8d59212dac47abef13a2",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis React component fragment renders UI panels displaying linked documentation and issue tracking information, specifically Confluence pages and Jira tickets, based on the `result` data object. It conditionally shows links and titles for these resources and displays an error card if the operation was unsuccessful.\n\n2. **Technical Details**:  \n- Uses conditional rendering (`{result.confluence_page && ...}`, `{result.jira_ticket && ...}`, `{result && !result.success && ...}`) to selectively display UI elements.  \n- Utilizes Tailwind CSS utility classes for styling and layout (e.g., `flex`, `space-x-2`, `text-primary-600`).  \n- Incorporates SVG icon components (`FileText`, `AlertCircle`) for visual cues.  \n- Uses anchor tags with `target=\"_blank\"` and `rel=\"noopener noreferrer\"` for safe external linking.  \n- The data structure `result` contains nested objects for `confluence_page` and `jira_ticket`, each with properties like `title`, `url`, and `key`.\n\n3. **Business Logic**:  \nSupports a business need to integrate and display relevant documentation and issue tracking references within a single UI panel, facilitating quick access to Confluence pages and Jira tickets related to a particular context or entity. It also provides user feedback on failure states.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components likely from a UI icon",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:03.487720",
      "status": "summarized"
    },
    "DocOrchestratorPanel.tsx:chunk_26": {
      "chunk_id": "DocOrchestratorPanel.tsx:chunk_26",
      "file_path": "frontend\\src\\components\\Panels\\DocOrchestratorPanel.tsx",
      "chunk_hash": "af3104eb8ea25f8fd193a5f39dbb268540c578aa94d8a035202c7bba030c26e1",
      "chunk_index": 26,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component snippet renders a user interface panel that displays an error message indicating a workflow failure, showing the specific error details from a `result` object.\n\n2. **Technical Details**:  \n- Utilizes JSX for UI rendering within a React component.  \n- Conditional rendering is used to display the error message only when a failure occurs (`result.error` is truthy).  \n- Uses Tailwind CSS utility classes for styling text and layout.\n\n3. **Business Logic**:  \nThe component provides feedback to users or operators about the failure state of a document orchestration workflow, helping them understand what went wrong during processing.\n\n4. **Dependencies**:  \n- React library for component structure and rendering.  \n- Tailwind CSS for styling.  \n- Likely depends on a parent component or context providing the `result` object containing workflow status and error details.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration likely occurs elsewhere in the application.\n\n6. **Error Handling**:  \n- Displays error messages passed via the `result.error` property.  \n- No explicit try/catch or error boundary handling in this snippet; error presentation is UI-focused.\n\n7. **API/Interface**:  \n- Exports a default React component named `DocOrchestratorPanel`.  \n- No public methods or API endpoints are defined here; it serves as a UI component.\n\n8. **Performance",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:08.335334",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_0": {
      "chunk_id": "LLMTestPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "ca92edd33647357ceaf8b6158304cf3dcd6ef5853f001893915b65c573a63e6a",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React component, `LLMTestPanel`, provides a user interface panel for interacting with a large language model (LLM). It manages a conversation-like message exchange between a user and an AI assistant, supporting rich content rendering and additional metadata related to AI responses.\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (`useState`, `useRef`, `useEffect`) for state and lifecycle management.  \n- Maintains a message list state (`messages`) where each message includes roles, content, and optional metadata such as provider info, thinking process data, approval requests, and next actions.  \n- Utilizes `ReactMarkdown` with plugins (`remark-gfm` for GitHub-flavored markdown and `rehype-highlight` for syntax highlighting) to render markdown content with code highlighting.  \n- Imports various SVG icon components from `lucide-react` for UI elements.  \n- Integrates subcomponents like `ThinkingProcess`, `ApprovalDialog`, and `ProviderSettings` to modularize complex UI features related to AI thought processes, approval workflows, and provider configuration.  \n- Uses a typed interface `Message` to enforce structure on message objects, supporting extensibility with optional fields.\n\n3. **Business Logic**:  \nEnables users to test and interact with different AI language model providers in a conversational format, facilitating tasks such as code review, content generation, or workflow automation. It supports approval workflows and next action suggestions, aligning with",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:14.560670",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_2": {
      "chunk_id": "LLMTestPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "40139a5e261497cdc267458e1e25368aca38341cb3b6376ead5380e22203034a",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React functional component snippet manages the state and UI behavior for a panel that interacts with large language models (LLMs), including conversation loading, chat clearing, and voice input features.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`, `useRef`) to manage component state and lifecycle.  \n- Maintains multiple state variables for provider selection, model choice, loading states, conversation tracking, and voice recognition.  \n- Implements event listeners for custom sidebar events to load conversations and clear chat history.  \n- Uses a ref to automatically scroll the chat view to the bottom when messages update.\n\n3. **Business Logic**:  \nEnables users to interact with different LLM providers and models, manage conversations, and optionally use voice input to enhance user experience in a chat or assistant interface. It supports loading previous conversations and resetting chat sessions, facilitating seamless conversational workflows.\n\n4. **Dependencies**:  \n- React (hooks API)  \n- Likely a voice recognition API or browser Web Speech API (indicated by `recognitionRef`)  \n- Custom event system for sidebar communication (implied by event listeners for `loadConversation` and `clearChat`)\n\n5. **Configuration**:  \n- Default provider is set to `'together'`.  \n- Default model is `'meta-llama/Llama-3.3-70B-Instruct-Turbo'`.  \n- No explicit environment variables or external config",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:23.264338",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_4": {
      "chunk_id": "LLMTestPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "eb89ef53e7ddcd5aea337e7a94bf6805c3f1403082255a57a8db101b42a915b0",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component code manages loading and clearing chat conversations within a frontend panel, fetching conversation messages and metadata from backend APIs, and updating the UI state accordingly.\n\n2. **Technical Details**:  \n- Uses React hooks (likely `useEffect`) to add and clean up event listeners (`loadConversation`, `clearChat`) on the `window` object.  \n- Defines an asynchronous function `loadConversation` that fetches conversation messages and metadata from REST API endpoints (`/api/chat/conversations/{id}/messages` and `/api/chat/conversations`).  \n- Maps fetched messages into a local state structure with properties like `role`, `content`, `duration`, and UI state `isExpanded`.  \n- Updates component state with messages, current conversation ID, and provider information.  \n- Uses an async logger wrapper (`logger.chat.track`) to track the \"Load conversation\" event.  \n- Partial implementation of `saveConversation` function that appears to save or update conversation data, starting by extracting the first user message to derive a title.\n\n3. **Business Logic**:  \nEnables users to load existing chat conversations and clear chat history in a conversational UI, supporting multi-provider chat sessions. This facilitates resuming past conversations and managing chat context, which is critical for user experience in chat-based applications or AI assistants.\n\n4. **Dependencies**:  \n- React (implied by `.tsx` and hooks usage).  \n- A logging/tracking utility (`logger.chat",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:29.408048",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_6": {
      "chunk_id": "LLMTestPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "7df316dfcfce2d3a905780e30451007ade1046a68fc0a24149756b24824d3a1b",
      "chunk_index": 6,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis React component code snippet handles saving a chat conversation to a backend API and initializes speech recognition functionality in the browser.\n\n2. **Technical Details**:  \n- Uses `fetch` API to POST conversation data (including conversation ID, title, provider, and messages) to `/api/chat/conversations`.  \n- Serializes messages by mapping them to objects containing `role`, `content`, and `duration`.  \n- Uses React hooks (`useEffect`) to initialize browser-native speech recognition (`webkitSpeechRecognition` or `SpeechRecognition`) with properties like `continuous` and `interimResults`.  \n- Uses conditional logic to truncate the first user message content to 50 characters for the conversation title.  \n- Employs `try-catch` blocks for asynchronous error handling.  \n- Uses `window.dispatchEvent` to emit a custom event (`conversationSaved`) upon successful save.\n\n3. **Business Logic**:  \nEnables users to save chat conversations with a meaningful title derived from the first user message or a default label (\"New Conversation\"). Supports voice input by initializing speech recognition, enhancing user interaction with the chat interface.\n\n4. **Dependencies**:  \n- Browser-native Web Speech API (`webkitSpeechRecognition` or `SpeechRecognition`).  \n- Backend API endpoint at `/api/chat/conversations` for conversation persistence.  \n- React (functional components, hooks).\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:36.046447",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_8": {
      "chunk_id": "LLMTestPanel.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "d9d25c581fec0c9c6065bd57360445fc304cfdb4c9b1c800875bd35f5366fd11",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component code snippet manages voice input and output functionalities, enabling speech recognition to capture user voice input and text-to-speech synthesis to play voice responses.\n\n2. **Technical Details**:  \n- Uses the Web Speech API's `SpeechRecognition` (via `recognitionRef.current`) for speech-to-text conversion, setting language to English (US).  \n- Event handlers (`onresult`, `onerror`, `onend`) update component state (`setInput`, `setIsListening`) based on recognition events.  \n- `toggleVoiceInput` function starts or stops speech recognition based on current listening state.  \n- `playVoiceResponse` uses `SpeechSynthesisUtterance` and `window.speechSynthesis` to convert text to speech, selecting an English voice if available.  \n- `extractOverview` function (partially shown) processes text content to extract a summary snippet (first paragraph or first 200 characters).\n\n3. **Business Logic**:  \nFacilitates hands-free user interaction by allowing voice commands/input and providing audible feedback, improving accessibility and user experience in applications requiring natural language interaction or LLM testing.\n\n4. **Dependencies**:  \n- Browser-native Web Speech API (`SpeechRecognition` and `SpeechSynthesis`).  \n- React hooks/state management (`useState`, `useRef`, etc.) implied but not shown explicitly.\n\n5. **Configuration**:  \n- Language for recognition is hardcoded as `'en-US",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:43.718044",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_10": {
      "chunk_id": "LLMTestPanel.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "1bd5c9127509d6a032c1e4974b212800dc00589a5895351ec5c91ef8dadc8202",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component code snippet manages the display and interaction of messages within a panel, including truncating text previews, toggling message expansion, detecting commit-related intents in messages, extracting repository identifiers from text, and handling approval actions on commit requests.\n\n2. **Technical Details**:  \n- Uses array slicing and string manipulation to generate a truncated preview of message content.  \n- Implements state updates via React's `setMessages` with functional updates to toggle message expansion flags (`isExpanded`).  \n- Utilizes keyword matching with `Array.some()` to detect commit-related intents in messages by checking for specific commit-related keywords in a case-insensitive manner.  \n- Applies regular expressions to parse repository identifiers from message strings, supporting multiple patterns to increase matching robustness.  \n- Contains an asynchronous handler (`handleApprove`) that initiates approval logic for commit-related messages, managing UI state (`setIsApprovingCommit`) during the process.\n\n3. **Business Logic**:  \nThe code supports a workflow where users review and approve commit-related messages, likely in a code collaboration or CI/CD context. It helps identify messages that indicate commit actions, extracts relevant repository information for further processing, and manages user interaction for approving these commits, streamlining code review or deployment approval processes.\n\n4. **Dependencies**:  \n- React (for state management and component rendering)  \n- No explicit external libraries are shown in the snippet, but likely depends on React hooks (`useState`) and possibly other UI",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:52.703354",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_12": {
      "chunk_id": "LLMTestPanel.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "8ff51970f9ef9f3435ee13331f97aaab8a8c5eb4b62fe8a22b6391170953df00",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet handles the approval of a commit by calling an API, processes the result, and updates the UI with a success or failure message accordingly.\n\n2. **Technical Details**:  \n- Uses asynchronous `await` to call `apiClient.approveCommit` with an approval request ID and a boolean flag.  \n- Checks the success status and presence of `operation_result` in the API response.  \n- Constructs a markdown-formatted response message dynamically based on available operation result properties (`repository`, `branch`, `commit_sha`).  \n- Creates a new assistant message object with role, content, expansion state, and optional next actions, then appends it to the existing messages state using a functional state update (`setMessages`).  \n- Implements error handling with a try-catch block, throwing an error if the operation fails and displaying an error message in the UI.\n\n3. **Business Logic**:  \nFacilitates the approval workflow for commits in a version control context, providing users with immediate feedback on the approval operation and guiding next steps if available.\n\n4. **Dependencies**:  \n- `apiClient`: an external or internal service client responsible for making API calls related to commit approval.  \n- React state management (`setMessages`) for UI updates.  \n- A `Message` type/interface defining the structure of messages displayed in the UI.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are shown in this snippet; it assumes",
      "embedding_id": null,
      "created_at": "2025-10-22T19:41:58.004563",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_14": {
      "chunk_id": "LLMTestPanel.tsx:chunk_14",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "9ecd3cf7abeddb268965cb11ab2206328cdcebbd55700d70002f6ceea41575fe",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis React component code manages user interactions related to approving or rejecting commit operations within a conversational UI panel, updating the message state accordingly and communicating with a backend API to process these approvals.\n\n2. **Technical Details**:  \n- Uses React hooks (`setMessages`, `setIsApprovingCommit`) to manage component state.  \n- Asynchronous functions (`handleReject`, `handleCommitWorkflow`) handle user actions and API calls.  \n- Messages are stored as an array of `Message` objects, each with properties like `role`, `content`, and `isExpanded`.  \n- The code follows a try-catch-finally pattern for async error handling and state cleanup.  \n- Immutable state updates are done via functional updates (`prev => [...prev, newMessage]`).\n\n3. **Business Logic**:  \nEnables users to approve or reject commit requests in a conversational interface, reflecting the outcome in the UI and ensuring backend synchronization of the commit approval status. This supports workflows where user confirmation is required before applying code changes or commits.\n\n4. **Dependencies**:  \n- `apiClient`: An external service client used to call `approveCommit` API endpoints.  \n- React (implied by hooks usage).  \n- Possibly a message or chat orchestration system (implied by message roles and content).\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in the snippet. However, the `apiClient` likely depends on",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:05.493861",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_16": {
      "chunk_id": "LLMTestPanel.tsx:chunk_16",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "cab48b8fea8cba75b99e864b4d535709fdb2e9dc81868729d5d3131fd6984f17",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis React component code snippet handles user interactions to fetch repository content or user input, then processes it through an LLM (Large Language Model) API to parse commit intents and generate assistant messages for display in a chat-like interface.\n\n2. **Technical Details**:  \n- Uses React state management (`setMessages`) to maintain a list of message objects representing the conversation.  \n- Constructs a conditional query string based on the presence of a `repository` environment variable.  \n- Asynchronously calls two API client methods: `testLLM` to fetch repository content or process user input, and `parseCommitIntent` to analyze the intent behind a commit message.  \n- Message objects include roles (`assistant`), content, approval requests, workflow data, and repository content, supporting rich message state.  \n- Uses `try-catch` blocks for error handling and throws errors when API responses are unsuccessful.\n\n3. **Business Logic**:  \nEnables users to interact with an LLM-powered assistant that understands commit intents within the context of a specific code repository, facilitating automated code review, commit message generation, or approval workflows in a developer tool or CI/CD pipeline.\n\n4. **Dependencies**:  \n- `apiClient`: An external service client providing `testLLM` and `parseCommitIntent` methods, likely wrapping HTTP calls to backend LLM services.  \n- React hooks/state (`setMessages`) for UI state management.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:14.530920",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_18": {
      "chunk_id": "LLMTestPanel.tsx:chunk_18",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "c37d9ad00091032b06324c779d503778d18017a78c13073d6b837a536e19e34f",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis React component code snippet handles sending user input to a Large Language Model (LLM) API, processes the response, and updates the chat message state accordingly. It supports both regular LLM queries and specialized commit/PR workflow intents.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`) to manage input, loading state, and messages array.  \n- Implements an asynchronous `handleSend` function that:  \n  - Validates input and loading state.  \n  - Adds the user message to the chat history.  \n  - Detects if the input is related to a commit/PR intent using `detectCommitIntent`.  \n  - If commit intent is detected, delegates to `handleCommitWorkflow`.  \n  - Otherwise, calls `apiClient.testLLM` to query the LLM with parameters like `provider`, `showBackendDetails`, and `model`.  \n  - Appends the assistant\u2019s response to the messages state.  \n- Uses a logging/tracking wrapper `logger.llm.track` around the async operation for telemetry.  \n- Messages are stored as objects with roles (`user` or `assistant`), content, and metadata like `isExpanded` and `thinking`.\n\n3. **Business Logic**:  \nEnables interactive testing of LLM responses within a UI panel, supporting both generic queries and specialized commit/PR-related commands. This facilitates developer workflows by integrating AI-powered assistance directly into the frontend, improving productivity",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:21.494032",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_20": {
      "chunk_id": "LLMTestPanel.tsx:chunk_20",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "47d3d938246e5b6e04c510a20b7136530b99c32a418100a7e2b30b7681e8b600",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis React component snippet handles asynchronous interactions with a language model API, managing conversation state, playing voice responses, and displaying messages or errors in a chat-like UI panel.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`) to manage component state such as `messages` and `isLoading`.  \n- Implements asynchronous functions with `async/await` for API calls and side effects like saving conversations and playing voice responses.  \n- Uses conditional rendering to display messages or a placeholder UI when no messages exist.  \n- Error messages are constructed as objects conforming to a `Message` type and appended to the message list state.  \n- UI layout uses Tailwind CSS classes for styling and layout.  \n- The code snippet shows a try-catch-finally pattern for robust async error handling.\n\n3. **Business Logic**:  \nEnables users to interact with a language model assistant, capturing conversation history, providing voice feedback, and gracefully handling errors to ensure a smooth user experience in a conversational AI interface.\n\n4. **Dependencies**:  \n- React (functional components and hooks)  \n- Tailwind CSS for styling  \n- Possibly a voice synthesis/playback library (implied by `playVoiceResponse`)  \n- An external language model API or service (implied by `result.response` and `result.error`)  \n- A custom `Sparkles` icon/component for UI embellishment\n\n5. **Configuration**:  \nNo explicit environment variables",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:29.725197",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_22": {
      "chunk_id": "LLMTestPanel.tsx:chunk_22",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "01ccb21fbad57cd68c5bb362f50eb2cff476d7ec03c79653d1127717ed99e67b",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a chat interface panel titled \"AI Development Assistant\" that allows users to interact with an AI by asking questions about their codebase. It displays a list of messages exchanged between the user and the AI, styling user messages differently from AI responses.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Employs conditional rendering to differentiate message roles (`user` vs AI) and applies distinct CSS classes for styling.  \n- Maps over a `messages` array to dynamically render chat bubbles aligned left or right based on the sender.  \n- Utilizes Tailwind CSS utility classes for styling gradients, spacing, typography, and layout.  \n- The message container uses flexbox for alignment and max-width constraints for responsive design.\n\n3. **Business Logic**:  \nFacilitates an interactive AI assistant feature within a developer tool or platform, enabling users to query and receive AI-generated insights or help related to their codebase, thus improving developer productivity and support.\n\n4. **Dependencies**:  \n- React (JSX syntax and component model)  \n- Tailwind CSS for styling  \n- Likely depends on a parent component or context providing the `messages` array and managing AI interaction logic (not shown here).\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration related to AI backend endpoints or API keys would be handled elsewhere in the application.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:37.690408",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_24": {
      "chunk_id": "LLMTestPanel.tsx:chunk_24",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "daf31ab24990c376ebf69370c470efdd8e8c2174f7b7f585f7a811665005bff2",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis React JSX snippet renders a UI panel section displaying an AI assistant message header with an icon, provider label, message duration, and a toggle button to expand or collapse the message content.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Conditional rendering is applied for optional elements like `message.provider` and `message.duration`.  \n- Utilizes Tailwind CSS utility classes for styling and layout (flexbox, spacing, colors, rounded corners).  \n- The `toggleMessageExpansion` function is triggered on button click to manage UI state (likely expanding/collapsing message details).  \n- The `Sparkles` component is used as an icon, presumably imported from an icon library or custom component.\n\n3. **Business Logic**:  \nThis UI component visually represents AI assistant responses, highlighting the message provider and response time, enhancing user understanding of the AI interaction and allowing users to toggle detailed message views for better context or debugging.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- `Sparkles` icon component (source not shown, likely from a UI icon library or internal component)  \n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are evident in this snippet. Styling and behavior depend on Tailwind CSS classes and React component state management.\n\n6. **Error Handling**:  \nNo explicit error handling is present in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:48.028560",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_26": {
      "chunk_id": "LLMTestPanel.tsx:chunk_26",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "7e97759a72f8fc207a0c7f8d48c2d11ed62e2a684d412d01f8f281c0cea9eec0",
      "chunk_index": 26,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a UI panel that displays messages with expandable content and conditional approval dialogs. It toggles between showing expanded or collapsed message states and handles user approval or rejection actions.\n\n2. **Technical Details**:  \n- Uses conditional rendering (`message.isExpanded ? ... : ...`) to toggle icons (ChevronUp/ChevronDown) indicating expanded/collapsed state.  \n- Renders an `ApprovalDialog` component when `message.approvalRequest` exists, passing relevant props including callbacks for approval/rejection (`handleApprove`, `handleReject`).  \n- Uses Tailwind CSS utility classes for styling prose content and icons.  \n- The component likely uses React state/hooks to manage `isApprovingCommit` and message expansion states.  \n- The `ApprovalDialog` component encapsulates workflow and intent data, supporting modular UI design.\n\n3. **Business Logic**:  \nEnables users to review and approve or reject workflow-related requests embedded in messages, facilitating decision-making processes within a larger workflow or content moderation system. This supports business processes requiring explicit user approval on generated or received content.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Custom components: `ApprovalDialog`, `ChevronUp`, `ChevronDown` icons  \n- Possibly state management hooks or context (not shown in snippet)\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in",
      "embedding_id": null,
      "created_at": "2025-10-22T19:42:54.920378",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_28": {
      "chunk_id": "LLMTestPanel.tsx:chunk_28",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "2909cea6acf8626992e702618f59bc150f55f259d84819abdb416a5adb84af39",
      "chunk_index": 28,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a message content panel that supports Markdown formatting with syntax highlighting, allows toggling between an overview and full content, and displays actionable buttons related to the message.\n\n2. **Technical Details**:  \n- Uses `ReactMarkdown` to parse and render Markdown content.  \n- Integrates `remarkGfm` plugin to support GitHub Flavored Markdown features.  \n- Uses `rehypeHighlight` for syntax highlighting of code blocks within the Markdown.  \n- Conditional rendering toggles between a summarized overview (`extractOverview`) and full message content based on `message.isExpanded`.  \n- Renders a \"Read full response\" button to expand truncated content.  \n- Displays a list of \"Next Actions\" as buttons, dynamically generated from `message.nextActions` array.  \n- Employs React state management (implied by `toggleMessageExpansion(index)`) to handle UI interaction.\n\n3. **Business Logic**:  \nFacilitates user interaction with AI-generated or system messages by providing a concise preview and the ability to expand for full details. It also guides users toward subsequent steps or actions, improving workflow efficiency and user engagement.\n\n4. **Dependencies**:  \n- `react-markdown` for Markdown rendering.  \n- `remark-gfm` for GitHub Flavored Markdown support.  \n- `rehype-highlight` for syntax highlighting of code snippets.  \n- React (JSX) for UI rendering and event handling.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:01.348632",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_30": {
      "chunk_id": "LLMTestPanel.tsx:chunk_30",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "81cd10c64ea139f8fd8718b0ffc33ebaa371816c63761dad3c2edb0da000c7b8",
      "chunk_index": 30,
      "summary": "1. **Purpose**:  \nThis React code snippet dynamically renders a list of action links with corresponding icons based on the action type. Each link opens in a new tab and is styled with Tailwind CSS for a consistent UI appearance.\n\n2. **Technical Details**:  \n- Uses conditional (ternary) operators to select an icon component (`ExternalLink`, `GitBranch`, or `GitPullRequest`) based on the `action.action` string.  \n- Maps over an array of `action` objects to generate anchor (`<a>`) elements with unique keys (`idx`).  \n- Applies Tailwind CSS utility classes for styling, hover effects, and transitions.  \n- Uses React JSX syntax to compose UI elements.\n\n3. **Business Logic**:  \nEnables users to quickly access related resources such as commits, branches, or pull requests by providing direct links with intuitive icons, improving navigation and user experience in a development or code review context.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components (`ExternalLink`, `GitBranch`, `GitPullRequest`), likely imported from an icon library or custom components\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are evident in this snippet. Styling and behavior rely on Tailwind CSS configuration and React component props.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. It assumes `action.url` and `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:11.659532",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_32": {
      "chunk_id": "LLMTestPanel.tsx:chunk_32",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "2be6e8a94ba4e6cce1cb4c79df653f0f3117348f1ce574c5a06fa00d94db807b",
      "chunk_index": 32,
      "summary": "1. **Purpose**:  \nThis React component snippet renders UI elements related to displaying backend processing details of a message and a loading indicator while awaiting a response, enhancing user feedback during asynchronous operations.\n\n2. **Technical Details**:  \n- Uses conditional rendering to display a `ThinkingProcess` component when `message.thinking` data exists and `showBackendDetails` is true.  \n- Implements a loading indicator with animated bouncing dots using CSS animations and inline styles for staggered delays.  \n- Utilizes JSX and Tailwind CSS classes for styling and layout.  \n- The `ThinkingProcess` component receives props `data` and `title` to display backend execution steps.\n\n3. **Business Logic**:  \nProvides transparency into backend AI or server-side processing steps for end-users or developers, improving trust and debugging capabilities. The loading indicator communicates ongoing processing to prevent user confusion or premature interactions.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling and animations  \n- A custom `ThinkingProcess` React component (likely internal to the project)\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. Display behavior depends on component state or props (`message.thinking`, `showBackendDetails`, `isLoading`).\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. It assumes valid data presence checks (`message.thinking`) before rendering.\n\n7. **API/Interface",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:18.735471",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_34": {
      "chunk_id": "LLMTestPanel.tsx:chunk_34",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "e4a2734b7ddbe11ab9e0ff29324bc64f74a4c27003aefd8a74b849a1db458c75",
      "chunk_index": 34,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a user interface panel for selecting and configuring a language model provider and model type within a chat or LLM testing application. It includes a dropdown to switch between providers and models dynamically.\n\n2. **Technical Details**:  \n- Uses React functional components and hooks (e.g., `useState` for `provider` and `model`, and `ref` for `messagesEndRef`).  \n- Implements controlled form elements (`<select>`) to manage user input and state updates.  \n- Conditional logic in the `onChange` handler to toggle between providers (`'azure'` and `'together'`) and set the model accordingly.  \n- Utilizes Tailwind CSS classes for styling and layout.  \n- Includes inline SVG icon components (e.g., `<Sparkles />`) for UI embellishment.\n\n3. **Business Logic**:  \nEnables users to select different AI language model providers and specific models, facilitating testing or interaction with various LLM backends. This supports business needs around flexibility in AI model experimentation and deployment.\n\n4. **Dependencies**:  \n- React (likely React 16.8+ for hooks).  \n- Tailwind CSS for styling.  \n- Custom or third-party icon components (e.g., `Sparkles`).  \n- State management hooks (`useState`, `useRef`).\n\n5. **Configuration**:  \n- Model and provider options are hardcoded in the dropdown options (e.g",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:26.980704",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_36": {
      "chunk_id": "LLMTestPanel.tsx:chunk_36",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "0ce60b9f27e4f33ad516442c61948acf2aea1f7ad78bfb07e19490c6c7173bdf",
      "chunk_index": 36,
      "summary": "1. **Purpose**:  \nThis React component snippet renders part of a user interface panel for selecting different large language model (LLM) backends, toggling display options such as \"Show Thinking\" and \"Voice,\" and providing a text input area for user queries or commands.\n\n2. **Technical Details**:  \n- Uses JSX to define UI elements including `<select>`, `<option>`, `<input type=\"checkbox\">`, and `<textarea>`.  \n- State management is implied via React hooks (`checked={showBackendDetails}`, `onChange` handlers calling `setShowBackendDetails` and `setVoiceEnabled`).  \n- The component includes a child component `<ProviderSettings />` likely responsible for additional configuration related to the selected LLM provider.  \n- Layout uses Tailwind CSS utility classes for styling and responsive design (`flex`, `gap-3`, `text-xs`, `rounded`, etc.).\n\n3. **Business Logic**:  \nEnables users to choose between multiple LLM providers (e.g., DeepSeek-R1, Qwen3 Coder, GPT-4 via Azure) and customize interaction preferences such as enabling voice output or showing backend processing details. This supports a flexible, user-configurable AI assistant or testing interface.\n\n4. **Dependencies**:  \n- React (functional components and hooks)  \n- Tailwind CSS for styling  \n- Possibly external LLM services or APIs referenced by the option values (e.g., \"azure\" for GPT-4)",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:34.057013",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_38": {
      "chunk_id": "LLMTestPanel.tsx:chunk_38",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "55d5591dea94408f1703565efbf700c7f08296c391673fa219a098e889931715",
      "chunk_index": 38,
      "summary": "1. **Purpose**:  \nThis React component snippet implements a user input textarea with voice input toggle functionality, allowing users to type or speak queries which are then processed on pressing Enter or clicking the microphone button.\n\n2. **Technical Details**:  \n- Uses React state hooks (`setInput`, `isListening`, `isLoading`) to manage input value, voice input status, and loading state.  \n- Event handlers:  \n  - `onChange` updates the input state with the textarea value.  \n  - `onKeyDown` listens for Enter key (without Shift) to trigger `handleSend()` while preventing default newline behavior.  \n- Conditional rendering and styling based on `isListening` and `isLoading` states, using Tailwind CSS utility classes.  \n- Button toggles voice input mode with `toggleVoiceInput` callback and displays microphone icons (`Mic`, `MicOff` components) accordingly.\n\n3. **Business Logic**:  \nEnables users to interact with a language model or chatbot interface via text or voice input, improving accessibility and user experience by supporting multiple input modalities and providing visual feedback during voice capture.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Icon components `Mic` and `MicOff` (likely from a UI icon library such as Heroicons or Material UI)  \n- External voice recognition service or API implied but not shown in this snippet\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:41.399707",
      "status": "summarized"
    },
    "LLMTestPanel.tsx:chunk_40": {
      "chunk_id": "LLMTestPanel.tsx:chunk_40",
      "file_path": "frontend\\src\\components\\Panels\\LLMTestPanel.tsx",
      "chunk_hash": "2958675c75a0f488a5be78c2143b03bf2455d57e4b7a5292fff536c4a7463342",
      "chunk_index": 40,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a styled button within a panel that triggers a send action when clicked, typically used to submit user input to a backend or service. The button visually indicates loading state and disables interaction when input is empty or a request is in progress.\n\n2. **Technical Details**:  \n- Uses React functional component with JSX for UI rendering.  \n- The button\u2019s `onClick` handler is `handleSend`, presumably a function that processes or sends the input data.  \n- The button is disabled if `isLoading` is true or if the trimmed `input` string is empty, preventing invalid or duplicate submissions.  \n- Conditional rendering displays a spinning loader icon (`Loader2`) when loading, otherwise a send icon (`Send`).  \n- Tailwind CSS utility classes are used extensively for styling, including gradients, hover effects, disabled states, shadows, and transitions.  \n- The button layout uses flexbox with gap spacing for icon and text alignment.\n\n3. **Business Logic**:  \nEnables users to submit input (likely text) to a language model or backend service, ensuring that submissions are valid (non-empty) and preventing multiple concurrent submissions. The loading indicator improves user experience by signaling ongoing processing.\n\n4. **Dependencies**:  \n- React (functional components and hooks implied).  \n- Tailwind CSS for styling.  \n- Icon components `Loader2` and `Send` (likely from an icon library or custom SVG components",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:48.028835",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_0": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "daa77dbfb0355b6ca3f60d5a975b538676075ac951859c00faefab1785b98574",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component implements a voice assistant panel that manages voice interactions by recording user speech, processing it, and playing back assistant responses within a conversational session.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`, `useRef`) to manage component state and lifecycle.  \n- Defines TypeScript interfaces for structured message data (`Message`), voice session metadata (`VoiceSession`), and voice interaction states (`VoiceState`).  \n- Utilizes `MediaRecorder` API (referenced via `mediaRecorderRef`) to capture audio input in chunks (`audioChunksRef`).  \n- Manages audio playback through an `HTMLAudioElement` reference (`currentAudioRef`).  \n- Uses canvas and animation frame references (`canvasRef`, `animationRef`) likely for visualizing audio or voice activity.  \n- Implements session management with a unique `sessionId` and tracks conversation turns and status.  \n- Controls voice assistant states such as 'idle', 'recording', 'processing', and 'speaking' to orchestrate the user interaction flow.\n\n3. **Business Logic**:  \nEnables a voice-driven conversational interface that allows users to interact with an assistant via speech, supporting continuous sessions with contextual awareness. This facilitates hands-free user engagement and enhances accessibility and user experience in applications requiring voice commands or queries.\n\n4. **Dependencies**:  \n- `react` for UI and state management.  \n- `lucide-react` for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:43:55.284144",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_2": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "054c3ca1e8c6b7f2c79f61c8a7a18c2a166b2d7b946a6e9294899c53ea4c683f",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component code snippet implements an animated voice visualization on a canvas element, displaying dynamic circles and dots that respond visually to the voice assistant's state (e.g., recording or speaking).\n\n2. **Technical Details**:  \n- Uses React's `useEffect` hook to perform canvas drawing and animation side effects.  \n- Accesses the canvas DOM element via a `canvasRef` React ref.  \n- Utilizes the Canvas 2D API (`getContext('2d')`) for rendering.  \n- Animates multiple concentric circles with sinusoidal radius variations to create a pulsating effect.  \n- Draws dots arranged in a circular pattern around the center, rotating based on an angle that increments over time.  \n- The animation depends on the `voiceState` variable to determine active states and adjust visual opacity and animation presence.\n\n3. **Business Logic**:  \nEnhances user experience by providing a real-time, visually appealing indicator of the voice assistant's activity status, improving user engagement and feedback during voice interactions.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Browser Canvas API (native)  \n- No explicit external libraries shown in the snippet, but likely part of a larger React frontend project.\n\n5. **Configuration**:  \n- Environment variable: `alpha` (mentioned but not directly used in the snippet)  \n- Canvas size and styling likely configured elsewhere or via CSS.\n\n6. **Error Handling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:02.059528",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_4": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "25637b9bf22fe20ddac203ff5d0a8f96e4696386ee75fe02f0db3997d0d85c80",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis React component code snippet is part of a voice assistant panel that animates a visual waveform, manages an AI assistant greeting message, and initializes a voice session for user interaction.\n\n2. **Technical Details**  \n- Uses the HTML5 Canvas API (`ctx.arc`, `ctx.fillStyle`, `ctx.fill`) to draw animated circles representing voice activity, with dynamic opacity controlled by a sine wave function for smooth pulsation effects.  \n- Employs `requestAnimationFrame` for efficient, smooth animation loops, with proper cleanup via `cancelAnimationFrame` to avoid memory leaks.  \n- React hooks (`useEffect`) manage side effects such as animation lifecycle and auto-greeting logic triggered by state changes (`voiceState`, `hasGreeted`, `sessionId`).  \n- Asynchronous session initialization via `axios.post` to create a voice session on the backend.  \n- State management includes message arrays and flags like `hasGreeted` and `autoListen` to control UI and interaction flow.  \n- Delayed execution using `setTimeout` to sequence greeting display, speech synthesis (`speakText`), and starting voice recording (`startRecording`).\n\n3. **Business Logic**  \nEnables an interactive AI voice assistant that greets users automatically upon session start, visually represents voice input activity, and manages voice session lifecycle to facilitate natural language interactions, improving user engagement and support efficiency.\n\n4. **Dependencies**  \n- `axios` for HTTP requests to",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:08.425681",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_6": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "4d1bea0fffa5a55aec57a3cd00c2212cc0a62ff2a79573299c0b20401b9f290b",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component code snippet manages the initialization of a voice session and handles audio recording from the user's microphone, capturing audio data for further processing.\n\n2. **Technical Details**:  \n- Uses asynchronous functions (`async/await`) to handle API calls and media device access.  \n- Utilizes the Web Media API (`navigator.mediaDevices.getUserMedia`) to capture audio streams.  \n- Employs the `MediaRecorder` API to record audio in `audio/webm;codecs=opus` format for compatibility.  \n- Uses React state hooks (`setSessionId`, `setVoiceState`, `setError`) and refs (`audioChunksRef`, `mediaRecorderRef`) to manage session state and audio data chunks.  \n- Event-driven design with `ondataavailable` and `onstop` handlers to accumulate audio data and trigger processing after recording stops.\n\n3. **Business Logic**:  \nEnables voice interaction capabilities by initializing a voice session and recording user audio input, likely for voice commands, transcription, or voice assistant features within the application.\n\n4. **Dependencies**:  \n- Browser Web APIs: `navigator.mediaDevices`, `MediaRecorder`.  \n- React hooks and state management (implied by `setSessionId`, `setVoiceState`, `setError`).  \n- An external API/service providing the `session_id` (from the omitted part of the code).\n\n5. **Configuration**:  \n- Audio recording is configured to use `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:16.206671",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_8": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "b83ac1709486de544efdfb3e4aa8fc8da9ed6ae345aecc0fd289f36eac3bfa86",
      "chunk_index": 8,
      "summary": "1. **Purpose**  \nThis React component code manages voice recording functionality within a frontend panel, including starting/stopping audio capture, detecting pauses to auto-stop recording, and processing recorded audio data.\n\n2. **Technical Details**  \n- Uses `MediaRecorder` API referenced via `mediaRecorderRef` to handle audio recording.  \n- Implements pause detection with a timer (`pauseDetectionTimerRef`) that triggers auto-stop after 1.5 seconds of silence.  \n- Audio data is buffered in `audioChunksRef` for later processing.  \n- State management via React hooks (`setVoiceState`, `setError`) controls UI states like 'recording', 'processing', and 'idle'.  \n- Functions are modularized for starting/stopping recording, resetting/clearing pause detection timers, and processing audio asynchronously.\n\n3. **Business Logic**  \nEnables users to record voice input efficiently with automatic silence detection to improve UX by stopping recording when the user pauses, reducing unnecessary audio capture and streamlining voice assistant interactions.\n\n4. **Dependencies**  \n- Browser Web APIs: `MediaRecorder`, `window.setTimeout`, `window.clearTimeout`.  \n- React state management hooks (implied by `setVoiceState`, `setError`).  \n- No explicit external libraries shown in this snippet.\n\n5. **Configuration**  \n- Pause detection timeout is hardcoded to 1500 milliseconds (1.5 seconds).  \n- No environment variables or external config files are referenced in this excerpt.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:23.826704",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_10": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "4a65278c2a26725d6482610ac44d43a2686c105e2060a36211cda3939e76f2ee",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code captures audio input from the user, converts it to a base64-encoded string, sends it to a backend API for voice processing, and then updates the UI with the transcribed text, detected intent, and AI-generated response.\n\n2. **Technical Details**:  \n- Uses the `Blob` API to aggregate audio chunks into a single audio file in `webm` format.  \n- Converts the audio blob to a base64 string using `FileReader.readAsDataURL`.  \n- Sends an asynchronous POST request via `axios` to the `/api/voice/process` endpoint with the audio data and session ID.  \n- Parses the JSON response containing transcript, intent, confidence, and AI-generated response text/audio.  \n- Updates React state by appending user and assistant messages to the message list, leveraging React hooks (`setMessages`).  \n- Uses TypeScript typing for message objects (`Message` interface).\n\n3. **Business Logic**:  \nEnables a voice assistant feature that transcribes user speech, detects user intent, and generates contextual AI responses, facilitating hands-free interaction and improving user experience in applications like customer support or smart assistants.\n\n4. **Dependencies**:  \n- `axios` for HTTP requests.  \n- React (implied by use of hooks and components).  \n- Browser APIs: `Blob`, `FileReader`.  \n- Backend service at `/api/voice/process` for speech-to-text, intent recognition, and response",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:30.873697",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_12": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "ee4ae040503a1fa3d83a6c36769dff8e7a5533ea5d2c0538c717cdaec988c1d0",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis React component code snippet handles processing voice assistant interactions by managing AI-generated messages, playing audio responses (either via base64 audio playback or browser TTS), and controlling the voice recording lifecycle with support for auto-listening.\n\n2. **Technical Details**:  \n- Uses React state management (`setMessages`, `setVoiceState`, `setError`) to update UI and internal state.  \n- Implements asynchronous audio playback by decoding base64-encoded audio data into an `ArrayBuffer` and playing it via Web Audio API or similar.  \n- Uses `setTimeout` to schedule delayed actions such as restarting voice recording for continuous listening.  \n- Employs try-catch blocks for error handling during asynchronous operations.  \n- Conditional logic to fallback from audio playback to text-to-speech (TTS) if no audio response is available.\n\n3. **Business Logic**:  \nEnables a seamless voice assistant experience by processing user voice input, delivering AI-generated responses audibly, and optionally maintaining continuous voice interaction through auto-listening. This supports hands-free user engagement and improves accessibility.\n\n4. **Dependencies**:  \n- Browser Web APIs: `atob` for base64 decoding, possibly Web Audio API for audio playback.  \n- React framework for component and state management.  \n- External AI or voice processing backend (implied by `response_audio`, `response_text`, and error response structure).  \n- Text-to-Speech (TTS) functionality, likely",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:37.934473",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_14": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_14",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "2ba30d38ef78b92f9c2647c18271ac69c1b871bebf6c9561dfca15ccaaf4159e",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet from `VoiceAssistantPanel.tsx` handles audio playback of AI-generated speech by decoding audio data into a playable format and provides a fallback text-to-speech (TTS) method using the browser's native speech synthesis.\n\n2. **Technical Details**:  \n- Converts a string of audio data into an `ArrayBuffer` and then into a `Blob` of MIME type `audio/mpeg`.  \n- Creates an `Audio` object from the blob URL to play the audio asynchronously.  \n- Uses React state (`setVoiceState`) to track the voice assistant's status (`speaking`, `idle`).  \n- Implements event handlers on the audio object for `onplay`, `onended`, and `onerror` to manage playback lifecycle and resource cleanup (`URL.revokeObjectURL`).  \n- Provides a fallback `speakText` function that uses the Web Speech API's `SpeechSynthesisUtterance` for TTS with configurable rate, pitch, and volume.\n\n3. **Business Logic**:  \nEnables the voice assistant feature in the frontend to audibly communicate AI responses to users, enhancing accessibility and user engagement by providing spoken feedback either via pre-generated audio or fallback browser TTS.\n\n4. **Dependencies**:  \n- Browser Web APIs: `Blob`, `URL.createObjectURL`, `Audio`, `window.speechSynthesis`, `SpeechSynthesisUtterance`.  \n- React hooks/state management (im",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:43.706250",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_16": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_16",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "862f1c4a115942b9bb69a96031ba97d66a2921965777f0c932219883eb90d218",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis React component code manages voice assistant functionalities, including selecting a preferred speech synthesis voice, controlling speech playback, toggling automatic listening (speech recognition), and updating UI state icons based on voice interaction states.\n\n2. **Technical Details**:  \n- Uses the Web Speech API's `speechSynthesis` for text-to-speech capabilities.  \n- Selects a preferred voice by filtering available voices for English language and female gender, with fallbacks.  \n- Manages speech utterance lifecycle events (`onstart`, `onend`) to update UI state.  \n- Controls audio playback via a `currentAudioRef` React ref.  \n- Implements toggle logic for automatic speech recognition listening, invoking `startRecording` and `stopRecording` functions.  \n- Uses React state (`voiceState`, `autoListen`) to track and render UI components conditionally.  \n- UI icons are conditionally rendered based on `voiceState` using components like `<Mic />` and `<Loader2 />`.\n\n3. **Business Logic**:  \nEnables interactive voice assistant features in a frontend application, improving user experience by providing speech output and voice command input with visual feedback on the assistant\u2019s current state (speaking, recording, processing).\n\n4. **Dependencies**:  \n- Browser Web Speech API (`window.speechSynthesis`) for TTS and possibly speech recognition (implied by `startRecording`/`stopRecording`).  \n- React for component state and rendering.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:49.553826",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_18": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_18",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "abee99b1580a943c376ed44485c98f543dea6dd165772fe54cc942bf03eceabf",
      "chunk_index": 18,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a voice assistant panel UI that visually reflects the current voice interaction state (e.g., recording, processing, speaking) with corresponding icons, colors, and descriptive text.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with conditional rendering via `switch` statements.  \n- UI state is driven by a `voiceState` variable, which controls icon selection (`Volume2`, `Sparkles` components), background colors, shadows, and display text.  \n- Tailwind CSS utility classes are applied dynamically for styling and animations (e.g., `animate-pulse`, color classes).  \n- The component returns JSX elements structured with flexbox and responsive width constraints.\n\n3. **Business Logic**:  \nProvides real-time visual feedback to users interacting with an AI voice assistant, enhancing user experience by clearly indicating the assistant\u2019s current status (listening, processing, speaking, idle). This helps manage user expectations and engagement during voice interactions.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components (`Volume2`, `Sparkles`) likely from a UI icon library (e.g., Lucide React or similar)  \n- Possibly state management hooks or props (not shown in snippet) to provide `voiceState` and `autoListen` values\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are visible in this snippet. The component behavior",
      "embedding_id": null,
      "created_at": "2025-10-22T19:44:55.380840",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_20": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_20",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "ded8b1cebb8939a468fbf32aee7420155e844669569a5fa1fff1b724a5e04909",
      "chunk_index": 20,
      "summary": "1. **Purpose**:  \nThis React component renders a voice assistant panel featuring an animated voice visualization, status text reflecting the current voice assistant state, and user controls to interact with the voice assistant functionality.\n\n2. **Technical Details**:  \n- Uses a `<canvas>` element referenced by `canvasRef` to render animated voice visualizations, likely driven by audio input data.  \n- Overlay div uses absolute positioning to center a circular UI element that changes color and icon dynamically based on the voice assistant\u2019s state (`getStateColor()`, `getStateIcon()`).  \n- Displays dynamic status text (`stateText.title` and `stateText.subtitle`) and conditionally shows error messages in red.  \n- Includes interactive buttons with event handlers (e.g., `toggleAutoListen`) and state-dependent disabling (e.g., disabled when `voiceState === 'processing'`).  \n- Uses Tailwind CSS classes for styling and layout.\n\n3. **Business Logic**:  \nEnables users to interact with a voice assistant feature by visualizing voice input activity, providing real-time status updates, and allowing control over listening modes. This enhances user engagement and accessibility for voice-driven applications.\n\n4. **Dependencies**:  \n- React (functional components, hooks such as `useRef` implied)  \n- Tailwind CSS for styling  \n- Possibly other voice/audio processing libraries or custom hooks (not shown in snippet) managing `canvasRef`, `voiceState`, `stateText`, `error`, and event",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:03.146053",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_22": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_22",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "823faa1da39cf4295e65c5e6c12b22d6cae9fbe10c55f618dae366912580d96e",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis React component code snippet renders interactive buttons for controlling a voice assistant panel, allowing users to toggle voice listening and stop voice speaking with visual feedback based on the current voice state.\n\n2. **Technical Details**:  \n- Uses conditional rendering and dynamic class names to reflect UI states (`autoListen` and `voiceState`).  \n- Employs Tailwind CSS utility classes for styling and transitions.  \n- Uses React JSX fragments (`<>...</>`) to group icon and text elements.  \n- Icons (`Mic`, `MicOff`, `VolumeX`) are used to visually represent voice states.  \n- Button `disabled` attributes and cursor styles are dynamically set based on voice state to prevent invalid interactions.\n\n3. **Business Logic**:  \nEnables users to control voice assistant functionality by toggling automatic listening and stopping speech output, improving user interaction with voice-enabled features in the application.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Icon components (`Mic`, `MicOff`, `VolumeX`) likely from a UI icon library (e.g., Heroicons or similar)  \n- `stopSpeaking` function presumably defined elsewhere in the component or passed as a prop\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \nNo explicit error handling or exception management is present in this UI rendering code; interaction disabling",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:11.180735",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_24": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_24",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "4dfea61c08133064134c14dc080d8aa99efb6a5b7c9c4b9168a723db68b6b8f5",
      "chunk_index": 24,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a voice assistant panel UI that displays the current speaking status and a conversation history between the user and an AI assistant.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX syntax.  \n- Conditional rendering to toggle UI elements based on state (e.g., whether the user is speaking or not, presence of messages).  \n- Maps over a `messages` array to dynamically render conversation bubbles, styling them differently based on the message role (`user` vs. assistant).  \n- Utilizes Tailwind CSS utility classes for styling and layout.  \n- Uses icons (e.g., `Volume2`) likely imported from an icon library.\n\n3. **Business Logic**:  \nEnables users to interact with an AI voice assistant by showing real-time speaking status and maintaining a visible conversation history, improving user engagement and clarity during voice interactions.\n\n4. **Dependencies**:  \n- React (JSX, component rendering).  \n- Tailwind CSS for styling.  \n- An icon library providing the `Volume2` icon (possibly Lucide or similar).  \n- State management for `messages` and `sessionId` (not shown but implied).\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. The component likely depends on higher-level app state or context for `messages` and `sessionId`.\n\n6. **Error Handling**:  \nNo explicit error handling is present",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:16.004361",
      "status": "summarized"
    },
    "VoiceAssistantPanel.tsx:chunk_26": {
      "chunk_id": "VoiceAssistantPanel.tsx:chunk_26",
      "file_path": "frontend\\src\\components\\Panels\\VoiceAssistantPanel.tsx",
      "chunk_hash": "f3e650cc0e0b4a7c77f2f1ec568a7ba958c4d02a49a3347c6e858a800363ff76",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis React component renders a voice assistant chat panel that displays a conversation between a user and an AI assistant, showing messages with roles, intents, and confidence scores, along with helper text describing the system capabilities and modes.\n\n2. **Technical Details**:  \n- Uses React functional component structure with JSX for UI rendering.  \n- Iterates over a list of message objects, conditionally rendering UI elements based on message properties (`role`, `intent`, `confidence`).  \n- Displays user messages labeled as \"You\" and AI messages labeled with an emoji and \"AI Assistant\".  \n- Shows intent and confidence as supplementary information next to messages.  \n- Uses Tailwind CSS classes for styling (e.g., `ml-2`, `text-xs`, `opacity-70`).  \n- Conditional rendering for continuous conversation mode status (`autoListen` boolean).  \n- The component likely receives props or uses state to manage messages and `autoListen` mode (not shown in snippet).\n\n3. **Business Logic**:  \nEnables interactive voice-based conversations with an AI assistant that intelligently routes queries based on detected intent (e.g., code questions routed to GitHub, commits to Workflow, others to the assistant). This supports enhanced user productivity by integrating AI-driven assistance and context-aware routing in a conversational UI.\n\n4. **Dependencies**:  \n- OpenAI Whisper (Speech-to-Text) and GPT (Large Language Model) services are referenced in the helper text, indicating backend",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:25.201683",
      "status": "summarized"
    },
    "ApprovalDialog.tsx:chunk_0": {
      "chunk_id": "ApprovalDialog.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Shared\\ApprovalDialog.tsx",
      "chunk_hash": "c8237711cfd15667b4268766ba7afee7898eef2c3e3a3977fa5d797f0425a61e",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component renders an approval dialog UI that displays details of an approval request and allows users to approve or reject it, optionally showing a loading state during processing.\n\n2. **Technical Details**:  \n- Uses TypeScript interfaces for strong typing of props (`ApprovalDialogProps`).  \n- Functional component with destructured props including approval request data, workflow info, intent metadata, and callback handlers for approval actions.  \n- JSX structure includes semantic HTML with Tailwind CSS utility classes for styling and layout.  \n- Uses icon components (`GitBranch`, `CheckCircle`, `XCircle`, `FileCode`) from the `lucide-react` icon library for visual cues.  \n- Conditional disabling of buttons based on `isLoading` state to prevent multiple submissions.\n\n3. **Business Logic**:  \nFacilitates user interaction for approving or rejecting workflow-related requests, likely part of a larger system managing automated or manual approval processes. It displays contextual information about the request and the intent behind it, helping users make informed decisions.\n\n4. **Dependencies**:  \n- React (functional components, JSX)  \n- TypeScript (type safety)  \n- `lucide-react` for SVG icon components  \n- Tailwind CSS for styling (implied by class names)\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are referenced in this snippet. Styling and behavior are controlled via props passed from parent components.\n\n6. **Error Handling**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:32.450298",
      "status": "summarized"
    },
    "ApprovalDialog.tsx:chunk_2": {
      "chunk_id": "ApprovalDialog.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Shared\\ApprovalDialog.tsx",
      "chunk_hash": "055e585a858eb6bfbea0f4764d469d691f8dc3b7ead8a3994885f18c747161e6",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component snippet renders an approval dialog UI with \"Reject\" and \"Approve & Execute\" buttons, displaying the current intent's platform and action details. It facilitates user interaction for approving or rejecting an operation within a frontend application.\n\n2. **Technical Details**:  \n- Utilizes React functional components with JSX for UI rendering.  \n- Uses Tailwind CSS utility classes for styling buttons and layout.  \n- Conditional rendering is applied to the approve button label, showing a loading state (\"Executing...\") when an asynchronous operation is in progress (`isLoading` flag).  \n- Icons (`XCircle`, `CheckCircle`) are embedded as React components, likely from an icon library.  \n- Layout uses CSS grid and flexbox for responsive and accessible design.\n\n3. **Business Logic**:  \nEnables users to approve or reject a specific \"intent\" action on a platform, likely part of a workflow or transaction approval process. This UI component supports decision-making in business processes requiring explicit user consent before executing critical actions.\n\n4. **Dependencies**:  \n- React (for component structure and state management).  \n- Tailwind CSS (for styling).  \n- Icon components (`XCircle`, `CheckCircle`), possibly from a library like Heroicons or similar.  \n- Props such as `onApprove`, `isLoading`, and `intent` are passed from parent components, indicating integration with higher-level business logic and state management.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:37.377538",
      "status": "summarized"
    },
    "ApprovalDialog.tsx:chunk_4": {
      "chunk_id": "ApprovalDialog.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Shared\\ApprovalDialog.tsx",
      "chunk_hash": "abd207abcdf4e3339d9bece253b8e78f0b839031dbdf88f7f2d2493e62576781",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a UI dialog section displaying confidence scores and detailed operation metadata related to an intent, such as repository, branch, and commit message information.\n\n2. **Technical Details**:  \n- Uses JSX to conditionally render UI elements based on the presence of `template_data`.  \n- Employs Tailwind CSS utility classes for styling (e.g., text colors, spacing, grid layout).  \n- Displays numeric confidence values formatted as percentages with zero decimal places using JavaScript\u2019s `toFixed(0)`.  \n- Uses React component `<FileCode />` (likely an icon) to visually represent operation details.  \n- Conditional rendering is used to selectively show repository, branch, and commit message fields if they exist in `template_data`.\n\n3. **Business Logic**:  \nThe component supports a business workflow where users review and approve detected intents or operations, providing transparency by showing confidence levels and contextual metadata about code repository operations (e.g., which repo, branch, and commit message are involved). This helps users make informed decisions during approval processes.\n\n4. **Dependencies**:  \n- React for component structure and rendering.  \n- Tailwind CSS for styling.  \n- An icon component `FileCode` (likely from a UI icon library or custom component).  \n- The data props `intent` and `template_data` are passed in from parent components or state management.\n\n5. **Configuration**:  \nNo explicit environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:44.703046",
      "status": "summarized"
    },
    "ApprovalDialog.tsx:chunk_6": {
      "chunk_id": "ApprovalDialog.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Shared\\ApprovalDialog.tsx",
      "chunk_hash": "cdfb516bbba58b7420c46bcdd79dd52971893e8becd4845018b9f501f4cdc3ae",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React functional component, `ApprovalDialog`, renders a user interface dialog displaying details of an approval request, including commit messages, associated files, and expiration time.\n\n2. **Technical Details**:  \n- Uses JSX to conditionally render UI elements based on the presence and content of `template_data` properties.  \n- Displays commit messages and a truncated list of file names (up to 3), appending a count of additional files if more than three exist.  \n- Formats the expiration timestamp using JavaScript's `Date` object and `toLocaleTimeString()` for user-friendly display.  \n- Utilizes Tailwind CSS utility classes for styling and layout (e.g., `text-gray-500`, `col-span-2`, `bg-amber-50`).\n\n3. **Business Logic**:  \nThe component supports the business need to present approval requests clearly to users, showing relevant commit information and files involved, along with a visual indicator of when the approval expires, facilitating timely decision-making.\n\n4. **Dependencies**:  \n- React (functional components and JSX)  \n- Tailwind CSS for styling  \n- No explicit external services or APIs are shown in this snippet.\n\n5. **Configuration**:  \n- No environment variables or external configuration are evident in this snippet.  \n- Assumes `approvalRequest` and `template_data` are passed as props or obtained from context/state.\n\n6. **Error Handling**:  \n- No explicit error",
      "embedding_id": null,
      "created_at": "2025-10-22T19:45:49.504716",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_0": {
      "chunk_id": "LogViewer.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "ca65332a990aeeaa022485face385fc5de8baa667618566b069ec50d9d6cd081",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component, `LogViewer`, provides a user interface for displaying, filtering, and managing application logs in the frontend. It allows users to view logs by level and category, expand individual log entries, and clear the log history.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`, `useRef`) for state management and DOM interaction.  \n- Maintains internal state for UI toggles (`isOpen`), filtering criteria (`selectedLevel`, `selectedCategory`), and expanded log entries (`expandedLogs` as a `Set` for efficient membership checks).  \n- Filters logs based on selected log level and category using array filtering and set operations.  \n- Automatically scrolls the log container to the bottom when new logs arrive via a `useEffect` hook referencing a DOM element (`logContainerRef`).  \n- Dynamically derives unique categories from the logs array using `Set` to populate filter options.\n\n3. **Business Logic**:  \nEnables developers or users to monitor application behavior and diagnose issues by viewing logs in real-time with filtering capabilities. This supports debugging, auditing, and operational monitoring within the application.\n\n4. **Dependencies**:  \n- React (core library for UI components and hooks).  \n- `useLogStore` and `LogLevel` from a local utility module (`../../utils/logger`) for centralized log state management.  \n- Icon components (`Terminal`, `X`, `Filter",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:00.066404",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_2": {
      "chunk_id": "LogViewer.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "57e6b9030c381581555e0c1a005761fe4a694c6a41567fd457875489e0dcce66",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component code snippet is part of a log viewer UI that visually categorizes log entries by severity level, provides icons for each log level, allows toggling the expansion of individual log entries, and formats timestamps for display.\n\n2. **Technical Details**:  \n- Uses a `switch` statement to map log levels (`debug`, `info`, `warn`, `error`, `success`) to corresponding CSS classes for styling and emoji icons for visual identification.  \n- Maintains expanded/collapsed state of logs using a React state hook with a `Set` data structure to efficiently track which log entries are expanded.  \n- Provides a utility function to format JavaScript `Date` objects into a consistent 24-hour time string using `toLocaleTimeString`.  \n- Conditional rendering is used to show a button when the log viewer is closed, with event handlers to toggle the viewer\u2019s open state.\n\n3. **Business Logic**:  \nEnables users (likely developers or system operators) to easily view, distinguish, and interact with application logs by severity, improving debugging and monitoring workflows within the frontend application.\n\n4. **Dependencies**:  \n- React (hooks like `useState` implied) for component state and rendering.  \n- Tailwind CSS classes for styling (e.g., `text-gray-500`, `bg-gray-50`).  \nNo explicit external services or APIs are referenced in this snippet.\n\n5. **Configuration**:  \nNo environment",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:04.836080",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_4": {
      "chunk_id": "LogViewer.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "c83f6f4c4c31b841f85f6fc9b4d6deca9ed99643a229eef95993cefee7fb8246",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component implements a user interface for viewing and managing application logs. It provides a button to open the log viewer and displays a modal window showing the activity logs with options to clear logs or close the viewer.\n\n2. **Technical Details**:  \n- Utilizes React functional components with hooks (e.g., `useState`) for state management (`isOpen`, `logs`, `filteredLogs`).  \n- Conditional rendering is used to display a notification badge on the log viewer button when logs exist, capped at \"99+\".  \n- The log viewer modal is styled using Tailwind CSS classes for layout, positioning (`fixed` bottom-right), and appearance (shadows, borders, rounded corners).  \n- UI elements include SVG icon components (`Terminal`, `Trash2`) likely imported from an icon library.  \n- Event handlers like `onClick` manage user interactions such as clearing logs and closing the viewer.\n\n3. **Business Logic**:  \nEnables users (likely developers or support staff) to monitor application activity logs in real-time or near-real-time, facilitating debugging, auditing, or operational monitoring. The ability to clear logs supports log management and cleanup.\n\n4. **Dependencies**:  \n- React (functional components and hooks)  \n- Tailwind CSS for styling  \n- Icon components (`Terminal`, `Trash2`) from an external icon library (e.g., react-feather or similar)  \n- Possibly a logging or state management context/provider (not",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:11.072547",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_6": {
      "chunk_id": "LogViewer.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "faef392728073428139714edfb8e45db9f107fd275efdf9ce4dee54537a7f183",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component snippet provides a user interface for filtering and viewing logs based on log levels and categories. It includes UI elements such as dropdown selectors for filtering logs and a close button for dismissing the log viewer.\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (e.g., `useState` for managing selected filters, `useRef` for referencing the log container).  \n- Implements controlled `<select>` elements to filter logs by `selectedLevel` and `selectedCategory`.  \n- Maps over arrays (`levels` and `categories`) to dynamically generate `<option>` elements for filtering.  \n- Uses Tailwind CSS utility classes for styling and hover effects.  \n- JSX structure includes semantic grouping of UI elements (filters, buttons, logs container).\n\n3. **Business Logic**:  \nEnables users (likely developers or support engineers) to filter and inspect application logs by severity level and category, facilitating quicker debugging and monitoring of application behavior.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Icon components such as `<X />` and `<Filter />` (likely from a UI icon library or custom components)  \n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are shown in this snippet. The component likely relies on props or context for `levels`, `categories`, and log data.\n\n6. **Error Handling**:  \nNo explicit error",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:17.746100",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_8": {
      "chunk_id": "LogViewer.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "9444536564f84648cf4e4cd2c3e0a884fb4082a088a7a655e9780ab1f78f8d4c",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a scrollable, styled log viewer that displays a list of filtered log entries. It supports expanding and collapsing individual log details for better readability.\n\n2. **Technical Details**:  \n- Uses React functional component patterns with JSX for UI rendering.  \n- Conditional rendering to show either a \"No logs to display\" message or a list of logs.  \n- Uses a map function to iterate over `filteredLogs` array, rendering each log entry with a unique `key` based on `log.id`.  \n- Implements interactive UI elements with click handlers (`onClick`) to toggle expansion of log details, tracked via a `Set` or similar collection (`expandedLogs`).  \n- Uses utility functions like `formatTime` (likely formats timestamps), `getLevelIcon` (returns an icon component based on log severity), and `getLevelColor` (returns CSS classes for log level styling).  \n- Tailwind CSS classes are heavily used for styling and layout (flexbox, spacing, colors, fonts).\n\n3. **Business Logic**:  \nEnables users (likely developers or operators) to view and analyze application logs in a user-friendly interface, facilitating troubleshooting, monitoring, and debugging of the system by categorizing and timestamping log entries.\n\n4. **Dependencies**:  \n- React (JSX, state management implied).  \n- Tailwind CSS for styling.  \n- Custom or third-party icon components (`ChevronDown`, `Chevron",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:21.512074",
      "status": "summarized"
    },
    "LogViewer.tsx:chunk_10": {
      "chunk_id": "LogViewer.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Shared\\LogViewer.tsx",
      "chunk_hash": "a1207a53578eb83eacbf5a86e6b2e8cf98daf42ab95d097a6da5c2b2f82dc690",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component, `LogViewer`, renders a list of log entries with expandable details. It displays each log's message and conditionally shows formatted JSON data when a log entry is expanded.\n\n2. **Technical Details**:  \n- Uses React functional component and JSX for rendering.  \n- Employs conditional rendering to show detailed log data only if the log has associated data and is expanded (tracked via a `Set` or similar collection named `expandedLogs`).  \n- Utilizes CSS utility classes (likely Tailwind CSS) for styling elements such as flex layout, colors, padding, and overflow handling.  \n- Renders JSON data with `JSON.stringify(log.data, null, 2)` for pretty-printing inside a `<pre>` tag to preserve formatting.\n\n3. **Business Logic**:  \nProvides a user interface component for viewing application or system logs, allowing users (e.g., developers, support engineers) to inspect log messages and delve into additional structured data for troubleshooting or auditing purposes.\n\n4. **Dependencies**:  \n- React library for component creation and rendering.  \n- Possibly Tailwind CSS for styling (inferred from class names like `text-gray-200`, `bg-gray-800`).  \n- No explicit external services or APIs are referenced in the snippet.\n\n5. **Configuration**:  \nNo environment variables or external configuration settings are evident in this snippet. Configuration related to styling or log data source likely exists elsewhere in the",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:26.310270",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_0": {
      "chunk_id": "ProviderSettings.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "6fe53100774b660dbb7c8126c2997698c44ea41e2005ec79da9b2e15708b5812",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component, `ProviderSettings`, manages and displays the configuration settings for AI service providers related to speech-to-text (STT), chat, and text-to-speech (TTS) functionalities. It fetches available providers and current user/provider configurations, allowing users to view and potentially update these settings.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`) for state management and lifecycle handling.  \n- Defines TypeScript interfaces (`ProviderStatus`, `ProviderConfig`) for strong typing of provider data and configuration.  \n- Asynchronous data fetching with `fetch` API to retrieve provider lists and configurations from backend endpoints.  \n- Maintains multiple UI states such as loading, saving, and save status to manage user interactions and feedback.  \n- Uses icon components from the `lucide-react` library for UI representation.  \n- Logging is done via a custom `logger` utility scoped to settings.\n\n3. **Business Logic**:  \nEnables users or administrators to select and configure AI providers for different AI capabilities (STT, chat, TTS), ensuring that the application uses the correct external AI services based on availability and preference. This supports flexible integration with multiple AI vendors and improves user experience by adapting to available services.\n\n4. **Dependencies**:  \n- React (hooks) for UI and state management.  \n- `lucide-react` for SVG icon components.  \n- A custom `logger` utility",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:32.717456",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_2": {
      "chunk_id": "ProviderSettings.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "628f98ec0a4358a08583bac50b08812e4a2433a9e4147a55eea8c6407f935af4",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component code manages fetching, displaying, and saving AI provider configuration settings in a frontend application. It handles asynchronous API calls to retrieve and update provider configurations while providing user feedback on the operation status.\n\n2. **Technical Details**:  \n- Uses asynchronous functions (`fetchConfig`, `handleSave`) with `async/await` to perform HTTP requests to backend endpoints.  \n- State management is implied via React hooks (`setConfig`, `setIsSaving`, `setSaveStatus`, `setErrorMessage`) to track configuration data, loading/saving states, and error messages.  \n- Logging is performed using a structured logger (`logger.settings`) with different severity levels (`info`, `warn`, `error`).  \n- Error responses from the backend are parsed to extract detailed error messages, supporting nested error structures (`errorData.detail.details`).\n\n3. **Business Logic**:  \nEnables users or administrators to configure AI provider settings through a UI, ensuring that the latest configuration is fetched from the server and that updates are saved reliably. It supports fallback to default settings if fetching fails and provides clear feedback on save success or failure, which is critical for maintaining correct AI provider behavior.\n\n4. **Dependencies**:  \n- Browser `fetch` API for HTTP requests.  \n- A logging utility (`logger.settings`) for structured logging.  \n- React state management hooks (implied by `setConfig`, etc.).  \n- Backend API endpoints at `/api/ai/config",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:39.497823",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_4": {
      "chunk_id": "ProviderSettings.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "e379842cc5b2241c83cf86b00dde199802813fdb71bfbc714482c73f71df0038",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component code manages provider settings for different capabilities (speech-to-text, chat, text-to-speech) in a frontend application, allowing users to select and save configuration options for various service providers.\n\n2. **Technical Details**:  \n- Uses React functional components and hooks (`setSaveStatus`, `setErrorMessage`, `setIsSaving`) for state management.  \n- Defines a helper function `getProviderOptions` that filters available providers based on a capability mapping object.  \n- Implements a reusable `ProviderSelect` component that renders a labeled dropdown with an icon, dynamically populated with provider options filtered by capability.  \n- Employs try-catch-finally blocks for asynchronous save operations with logging.\n\n3. **Business Logic**:  \nEnables users to configure and save their preferred providers for speech-to-text, chat, and text-to-speech functionalities, supporting customizable integration with multiple backend AI or communication services.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- A logging utility (`logger.settings.error`) for error tracking  \n- Presumably a `providers` data source (likely from props or context) containing provider metadata including capabilities\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in the snippet; provider capabilities and selections appear to be configured dynamically at runtime via the `providers` array and component props.\n\n6. **Error Handling**:  \n- Catches network or server errors during save",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:46.060346",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_6": {
      "chunk_id": "ProviderSettings.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "89c41afbf898810dc333b5876c6a1d8e37eec06e11dae09ab1b200900f7f2497",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component renders a user interface for selecting and configuring a \"provider\" from a list of options. It toggles between a button to open the settings panel and a detailed settings view with a dropdown selector for providers.\n\n2. **Technical Details**:  \n- Uses React functional components and hooks (e.g., `useState` for `isOpen` state management).  \n- Renders a `<select>` dropdown populated dynamically from an `options` array.  \n- Conditional rendering is employed to show a placeholder option when no providers are available.  \n- Uses JSX with Tailwind CSS utility classes for styling.  \n- Event handling via `onChange` on the `<select>` element to propagate selected provider values upstream.\n\n3. **Business Logic**:  \nEnables users to configure or switch between different service providers (likely cloud or API providers) within the application, facilitating customization or integration with external services.\n\n4. **Dependencies**:  \n- React library for UI components and state management.  \n- Tailwind CSS for styling.  \n- Custom icon components such as `<Settings />` and `<Cloud />` (likely SVG or React components).  \n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in the snippet. The component relies on props such as `options` and `onChange` passed from parent components.\n\n6. **Error Handling**:  \n- Handles the edge case where the `options` array is empty",
      "embedding_id": null,
      "created_at": "2025-10-22T19:46:51.248644",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_8": {
      "chunk_id": "ProviderSettings.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "66d519e9f73e7c979e506ba39c10c5255806c3529a783699d223b49d096a50c1",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a user interface for configuring backend service providers related to speech and chat functionalities, allowing users to select providers for Speech-to-Text (STT), Chat Completion, and Text-to-Speech (TTS).\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (implied by `setConfig` and `setIsOpen` callbacks) for state management.  \n- Renders multiple `ProviderSelect` components, each bound to a specific capability (`stt`, `chat`, `tts`).  \n- Employs controlled components pattern where the selected provider value is stored in a `config` state object and updated via `onChange` handlers.  \n- Utilizes Tailwind CSS utility classes for styling and layout.  \n- Displays the count of available providers dynamically.\n\n3. **Business Logic**:  \nEnables end-users or administrators to configure which backend providers power key AI-driven features such as speech recognition, chat completions, and speech synthesis. This flexibility supports integration with multiple third-party AI services and allows switching providers without code changes, facilitating customization and potentially cost or performance optimization.\n\n4. **Dependencies**:  \n- React (functional components and hooks)  \n- Tailwind CSS for styling  \n- Custom `ProviderSelect` component (likely a dropdown or selector UI element)  \n- Icon components (`Mic`, `MessageSquare`) for visual cues\n\n5. **Configuration**:  \n- The component relies",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:01.314431",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_10": {
      "chunk_id": "ProviderSettings.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "8d3dc0b104fbd9892036557944a46cb5400a96e4856bf0aa2b76e9c8622d9313",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a user interface section for saving provider settings, displaying real-time feedback on the save operation's status (success, error, or in-progress).\n\n2. **Technical Details**:  \n- Uses conditional rendering to show different UI elements based on the `saveStatus` state (`'success'`, `'error'`, or default).  \n- Displays icons (`CheckCircle`, `XCircle`, `Save`) alongside status messages to improve UX.  \n- The save button triggers a `handleSave` function and is disabled during the saving process (`isSaving` flag).  \n- Shows a spinning loader animation when saving is in progress using CSS classes (`animate-spin`).  \n- Utilizes Tailwind CSS utility classes for styling and layout (`flex`, `space-x-2`, `text-green-600`, etc.).\n\n3. **Business Logic**:  \nEnables users to save configuration or settings related to a \"provider\" entity, providing immediate visual confirmation of success or failure to enhance user trust and interaction efficiency.\n\n4. **Dependencies**:  \n- React (JSX syntax and component structure).  \n- Icon components (`CheckCircle`, `XCircle`, `Save`) likely imported from an icon library such as Heroicons or similar.  \n- Tailwind CSS for styling and animations.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration are referenced in this snippet. Styling and behavior depend on Tailwind CSS configuration.\n\n6.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:09.828343",
      "status": "summarized"
    },
    "ProviderSettings.tsx:chunk_12": {
      "chunk_id": "ProviderSettings.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Shared\\ProviderSettings.tsx",
      "chunk_hash": "5d5c96ad5f7295aa83d1c1e76123ff3d80ed6dd9e8b8ba6cdda7776b8b98eef6",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component snippet renders UI elements to display error messages and informational notes related to AI provider settings in a frontend application.\n\n2. **Technical Details**:  \n- Uses JSX to conditionally render a styled error message block when `errorMessage` is present.  \n- Renders a static informational note about backend usage of AI providers.  \n- Utilizes Tailwind CSS utility classes for styling (e.g., margins, padding, colors, borders, text size).  \n- The component is exported as a default export for use elsewhere in the application.\n\n3. **Business Logic**:  \nThe component informs users about errors in configuring AI providers and communicates that changes to provider settings immediately affect backend AI request routing, ensuring transparency and immediate feedback during configuration.\n\n4. **Dependencies**:  \n- React (for JSX and component structure)  \n- Tailwind CSS (for styling)  \n- Possibly other parts of the frontend app that manage state and provide `errorMessage` (not shown in snippet)\n\n5. **Configuration**:  \nNo explicit environment variables or config files are referenced in this snippet. The component likely relies on props or context to receive `errorMessage` and provider settings.\n\n6. **Error Handling**:  \n- Displays error messages passed via `errorMessage` prop or state.  \n- No explicit try/catch or error boundary logic shown; error handling is limited to UI feedback.\n\n7. **API/Interface**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:18.197885",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_0": {
      "chunk_id": "serviceRegistry.ts:chunk_0",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "c7279b19a68cf876bd5da18978d91813ffe787eb422f1c4f7164ee7990d04a10",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a centralized service registry in the frontend application that lists and configures third-party integrations (e.g., GitHub, Jira). It provides metadata, authentication details, configuration fields, and test endpoints for each service.\n\n2. **Technical Details**:  \n- Uses a typed array (`ServiceDefinition[]`) to store service configurations.  \n- Each service object includes fields such as `id`, `name`, `type`, `category`, `authType`, and configuration schema (`configFields`).  \n- Defines a `testAction` object specifying how to validate the connection to the service via an API endpoint, HTTP method, and success/error messages.  \n- The structure supports extensibility by allowing multiple services with different capabilities and config requirements.\n\n3. **Business Logic**:  \nEnables the frontend to dynamically render integration setup UIs and manage connections to external tools like GitHub and Jira. This supports business workflows such as code repository access, issue tracking, and automation by standardizing how integrations are configured and tested.\n\n4. **Dependencies**:  \n- Imports `ServiceDefinition` type from a local module (`../types/integrations`).  \n- Relies on backend API endpoints (e.g., `/api/integrations/github/test`) to validate service connections.  \n- No external third-party libraries are directly referenced in this snippet.\n\n5. **Configuration**:  \n- Configuration fields are defined per service, including sensitive fields like tokens marked as `secret",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:24.389506",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_2": {
      "chunk_id": "serviceRegistry.ts:chunk_2",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "787410caa4420f11edadc9a483f0f30a8e4c51fc1e4f83314127acfebc234b75",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code snippet defines the configuration schema and connection details for integrating a Jira service within a frontend application. It specifies how to connect to Jira for issue tracking and project management, including authentication and test connection parameters.\n\n2. **Technical Details**:  \n- The configuration is structured as an object with descriptive metadata (description, icon, authType, status flags).  \n- Uses an array of `configFields` objects to define required and optional input fields for Jira integration, including field types (url, text, password), validation requirements, placeholders, and descriptions.  \n- Defines a `testAction` object specifying an API endpoint, HTTP method, and user-facing messages for connection testing.  \n- No complex algorithms or design patterns are present; this is primarily a declarative configuration object.\n\n3. **Business Logic**:  \nEnables users or administrators to configure and validate a Jira integration within the application, facilitating automated issue tracking and project management workflows by connecting to a Jira cloud instance. This supports business needs for seamless task management and bug tracking.\n\n4. **Dependencies**:  \n- Relies on Jira cloud services (via REST API) for issue tracking.  \n- The test endpoint `/api/integrations/jira/test` suggests a backend service that handles connection validation, but no direct external libraries are referenced in this snippet.\n\n5. **Configuration**:  \n- Requires user-provided configuration values: Jira instance URL, user email, API token",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:35.152320",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_4": {
      "chunk_id": "serviceRegistry.ts:chunk_4",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "c3cf79dcbf669e0c332af91698be8eeee046ad2d95b97f537a4414d48765e395",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code snippet defines part of a service registry configuration for integrating with external services, specifically detailing the configuration schema for a Confluence integration within a frontend application.\n\n2. **Technical Details**:  \n- The code uses a structured object array to represent service configurations.  \n- Each service entry includes metadata such as `id`, `name`, `type`, `category`, and UI-related properties like `icon`.  \n- The `configFields` array defines the configuration form schema with fields specifying name, label, type, validation requirements, placeholders, and descriptions.  \n- The `authType` property indicates the authentication mechanism (here, 'basic' auth).  \n- Flags like `isConfigured`, `isActive`, and `status` track the integration state.\n\n3. **Business Logic**:  \n- Enables the frontend to dynamically render configuration forms for connecting to Confluence, facilitating documentation publishing workflows.  \n- Supports managing multiple service integrations by standardizing their configuration and status representation.  \n- Helps ensure that required credentials and settings are collected to authenticate and interact with Confluence APIs.\n\n4. **Dependencies**:  \n- No explicit external libraries are shown in this snippet.  \n- Implicit dependency on Atlassian Confluence API for integration.  \n- Likely used within a React or similar frontend framework that consumes this config to render UI forms.\n\n5. **Configuration**:  \n- Configuration fields include environment-specific values such as `confluence",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:43.532396",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_6": {
      "chunk_id": "serviceRegistry.ts:chunk_6",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "fb83ad86f6f04ae249642ca8077e02057e9427b59d0cb54db95c07d540692171",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code snippet defines part of a service registry configuration for integrating external services (specifically Confluence and Grafana) into a frontend application. It specifies connection details, authentication, configuration fields, and test actions for these services.\n\n2. **Technical Details**:  \n- The code uses a structured array of service objects, each representing an integration with properties such as `id`, `name`, `type`, `category`, and `description`.  \n- Each service object includes metadata for UI rendering (e.g., `icon`), authentication type (`authType`), and status flags (`isConfigured`, `isActive`, `status`).  \n- Configuration fields are defined as arrays of objects specifying form input details (name, label, type, required, placeholder, description, secret).  \n- A `testAction` object defines an API endpoint and HTTP method to verify connectivity, along with success and error messages for user feedback.\n\n3. **Business Logic**:  \nThis configuration enables the frontend to dynamically render integration setup forms, manage connection states, and validate connectivity to external services like Confluence (for content collaboration) and Grafana (for monitoring dashboards). It supports business needs for extensible integrations and user-friendly configuration management.\n\n4. **Dependencies**:  \n- The snippet references REST API endpoints (`/api/integrations/confluence/test`, `/api/integrations/grafana/test`) presumably provided by a backend service.  \n- No",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:51.732608",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_8": {
      "chunk_id": "serviceRegistry.ts:chunk_8",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "26c9b45a661f29426a8bd71c1474e93037599636f1afcd4436b7027e02c34cff",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code snippet defines a service configuration object for a PostgreSQL database connector within a frontend application\u2019s service registry. It specifies metadata, authentication type, connection status, and the required configuration fields to establish a database connection.\n\n2. **Technical Details**:  \n- The code uses a structured object literal to represent a service descriptor.  \n- The `configFields` array defines the schema for user input required to configure the PostgreSQL connection, including field types, validation requirements, default values, and UI hints (e.g., placeholders, secret fields).  \n- The service object includes state flags (`isConfigured`, `isActive`, `status`) to track connection lifecycle and readiness.  \n- No algorithms or complex data structures are present; it is primarily a declarative configuration.\n\n3. **Business Logic**:  \nThis configuration enables the frontend to dynamically render forms for connecting to PostgreSQL databases, facilitating data operations such as querying metrics, fetching dashboards, or alerts. It abstracts database connection details, allowing users or administrators to configure and activate database services without hardcoding credentials or connection parameters.\n\n4. **Dependencies**:  \n- The snippet itself does not explicitly import or use external libraries.  \n- It likely integrates with UI components that interpret `configFields` to render input forms and with backend services that use these configurations to establish database connections.  \n- The `icon: 'Database'` suggests usage of an icon library or design system for UI representation",
      "embedding_id": null,
      "created_at": "2025-10-22T19:47:59.469058",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_10": {
      "chunk_id": "serviceRegistry.ts:chunk_10",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "3104e29010a60ba841a4363d177eda3b3a0722bb2718f4157612c5c942938ab0",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration objects for service integrations within a frontend application, specifically detailing metadata, authentication, configuration fields, and test endpoints for external services like databases and AI providers (e.g., OpenAI).\n\n2. **Technical Details**:  \n- Uses structured JSON-like objects to represent service registry entries.  \n- Each service object contains properties such as `id`, `name`, `type`, `category`, `description`, `icon`, `authType`, and status flags (`isConfigured`, `isActive`, `status`).  \n- Configuration fields are defined as arrays of objects specifying input types (`password`, `select`), validation (`required`), and UI hints (`placeholder`, `description`).  \n- Includes `testAction` objects specifying REST API endpoints and HTTP methods to verify service connectivity, along with success and error messages.\n\n3. **Business Logic**:  \nEnables dynamic integration and management of external services (databases, AI providers) by defining how they should be configured, authenticated, and tested. This supports business needs for extensibility and operational validation of third-party services critical to application functionality.\n\n4. **Dependencies**:  \n- Relies on backend API endpoints (e.g., `/api/integrations/database/test`, `/api/integrations/openai/test`) for connectivity testing.  \n- Likely integrated with a frontend framework (React, Vue, etc.) that consumes these configurations to render UI forms and trigger test actions",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:06.438579",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_12": {
      "chunk_id": "serviceRegistry.ts:chunk_12",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "113f02c2a8dcc60fe62507d69559bccb2da6dd42cac0fecaf23e5f985e7af5fa",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis TypeScript code snippet is part of a service registry configuration that defines metadata and connection details for AI service providers, specifically here for the Azure Speech service. It outlines how the frontend should handle configuration, authentication, and connectivity testing for this service.\n\n2. **Technical Details**:  \n- Uses an array of service descriptor objects, each representing a distinct AI provider.  \n- Each service object includes fields such as `id`, `name`, `type`, `category`, `description`, `icon`, and authentication details (`authType`).  \n- Configuration fields (`configFields`) are defined as arrays of objects specifying input types, labels, placeholders, and validation requirements.  \n- A `testAction` object defines how to verify the service connection via an HTTP request (endpoint and method), along with success and error messages.  \n- The design follows a declarative configuration pattern, enabling dynamic UI generation and service management.\n\n3. **Business Logic**:  \nEnables the application to integrate multiple AI service providers (like Azure Speech) by standardizing how they are configured and tested. This supports business needs such as speech-to-text and text-to-speech capabilities, allowing users or administrators to connect and manage AI services seamlessly within the app.\n\n4. **Dependencies**:  \n- Relies on backend API endpoints (e.g., `/api/azure/speech/test`) to validate service connectivity.  \n- Likely integrates with Azure Cognitive Services for speech capabilities.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:17.057384",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_14": {
      "chunk_id": "serviceRegistry.ts:chunk_14",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "3ce047ebba832250fada9f7f4093828dac77336a2f611f14137bacce854afafe",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis TypeScript code defines a service registry configuration object for integrating multiple AI service providers, specifically detailing the Azure Translator service. It outlines the metadata, authentication, configuration fields, capabilities, and test connectivity actions for the service.\n\n2. **Technical Details**:  \n- Uses an array of service descriptor objects, each representing an AI service provider.  \n- Each service object includes properties such as `id`, `name`, `type`, `category`, `description`, `icon`, `authType`, `isConfigured`, `isActive`, and `status`.  \n- Configuration fields are defined as an array of objects specifying form input metadata (name, label, type, required, secret, placeholder, description).  \n- A `testAction` object defines an API endpoint, HTTP method, and success/error messages for validating service connectivity.  \n- The design follows a declarative configuration pattern, enabling dynamic UI generation and service management without hardcoding logic.\n\n3. **Business Logic**:  \nEnables the application to support multiple AI service providers by registering their configuration and capabilities centrally. This allows business users or administrators to configure, activate, and test AI services (like translation or speech recognition) dynamically, facilitating multilingual support and AI integration in the product.\n\n4. **Dependencies**:  \n- Relies on backend API endpoints (e.g., `/api/azure/translator/test`) for connectivity tests.  \n- Likely integrated with UI components that consume this config to render",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:23.765304",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_16": {
      "chunk_id": "serviceRegistry.ts:chunk_16",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "942cb4021eaecac3e72114cf7c7414b4ef5af7ddd391820fce24ab76d8241286",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration metadata for integrating external services into a frontend application, specifically detailing the Azure OpenAI service and MongoDB database. It serves as a service registry to standardize how these services are configured, authenticated, and tested within the app.\n\n2. **Technical Details**:  \n- Uses a structured object array to represent service configurations.  \n- Each service entry includes typed fields such as `id`, `name`, `type`, `category`, `description`, `icon`, `authType`, and status flags (`isConfigured`, `isActive`, `status`).  \n- `configFields` is an array of configuration descriptors specifying input types, validation requirements, and UI hints (e.g., placeholders, labels).  \n- `testAction` defines an API endpoint and HTTP method to verify service connectivity, along with success and error messages.  \n- The design follows a declarative pattern for service registration, enabling dynamic UI generation and runtime validation.\n\n3. **Business Logic**:  \nFacilitates easy onboarding and management of AI and database services by providing a unified configuration interface. This abstraction helps non-technical users or administrators configure critical backend services (like Azure OpenAI for AI capabilities and MongoDB for data storage) without deep technical knowledge, accelerating deployment and integration.\n\n4. **Dependencies**:  \n- Relies on Azure OpenAI service endpoints and API keys for AI functionalities.  \n- Uses MongoDB connection strings for database access.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:28.865389",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_18": {
      "chunk_id": "serviceRegistry.ts:chunk_18",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "7b5ace8fc2e8d44493f9522a22eba5bcf85fe65b8120762b5d085e5d500e1587",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration metadata for service integrations within a frontend application, specifically detailing connection parameters, status flags, and testing endpoints for services like MongoDB and Stripe.\n\n2. **Technical Details**:  \n- Uses structured objects to represent each service integration with fields such as `id`, `name`, `type`, `category`, and configuration details.  \n- Defines `configFields` as an array of configuration descriptors, each specifying input properties (name, label, type, required, placeholder, description, defaultValue).  \n- Includes a `testAction` object specifying an API endpoint, HTTP method, and success/error messages to validate the service connection.  \n- Status flags (`isConfigured`, `isActive`, `status`) track the current state of the integration.  \n- The design follows a declarative configuration pattern, enabling dynamic UI rendering and validation based on these metadata objects.\n\n3. **Business Logic**:  \nEnables the frontend to manage and configure external service integrations (e.g., databases, payment gateways) by providing necessary connection details and validating connectivity. This supports business needs such as data storage (MongoDB) and payment processing (Stripe) within the application ecosystem.\n\n4. **Dependencies**:  \n- Relies on backend API endpoints (e.g., `/api/integrations/mongodb/test`) to test service connectivity.  \n- Likely integrated with UI components that consume this configuration to render forms and status indicators.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:35.078731",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_20": {
      "chunk_id": "serviceRegistry.ts:chunk_20",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "6bdd08ba251192bf2d45adc3081d23b5c80ab837e4fdbe5686725585636f6a53",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration metadata for third-party service integrations (e.g., Stripe, Twilio) used in a frontend application, specifying connection details, authentication fields, and test endpoints.\n\n2. **Technical Details**:  \n- Uses structured objects to represent each service with properties such as `id`, `name`, `type`, `category`, and `status`.  \n- Defines `configFields` arrays for each service containing field descriptors (name, label, type, required, placeholder, description) to dynamically generate UI forms for configuration.  \n- Includes a `testAction` object specifying an API endpoint, HTTP method, and success/error messages to validate service connectivity.  \n- Uses simple key-value pairs and arrays to represent capabilities and configuration states.  \n\n3. **Business Logic**:  \nEnables the application to integrate with external APIs (payment processing via Stripe, messaging via Twilio) by providing a standardized way to configure, test, and manage these services, thereby supporting business functions like payments, subscriptions, invoicing, and communications.\n\n4. **Dependencies**:  \n- Relies on backend API endpoints (e.g., `/api/integrations/stripe/test`) to perform connectivity tests.  \n- No explicit external libraries shown in this snippet; likely consumed by frontend UI components and HTTP clients elsewhere in the app.\n\n5. **Configuration**:  \n- Configuration fields correspond to sensitive credentials (e.g., Stripe secret key, Twilio",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:42.160860",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_22": {
      "chunk_id": "serviceRegistry.ts:chunk_22",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "d1f91ccb4bb5ec7b3f8b05a96ae09de6f0fb359b718020a1c7e24b2f71344462",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration objects for third-party service integrations (specifically Twilio and SendGrid) within a frontend application, detailing their authentication fields, connection test actions, and capabilities.\n\n2. **Technical Details**:  \n- Uses structured JSON-like objects to represent each service integration.  \n- Each service includes metadata (id, name, type, category, description, icon), authentication configuration fields (with types, labels, placeholders, and security flags), and test action definitions (endpoint, HTTP method, success/error messages).  \n- The design follows a declarative configuration pattern, enabling dynamic rendering of integration setup UIs and standardized connection testing.\n\n3. **Business Logic**:  \n- Facilitates integration of communication services (Twilio for SMS/voice/WhatsApp/video, SendGrid for email) into the application.  \n- Enables users or administrators to configure and validate these services through the UI, supporting business workflows that rely on messaging and email delivery.\n\n4. **Dependencies**:  \n- Implicitly depends on backend API endpoints (e.g., `/api/integrations/twilio/test`) for connection testing.  \n- Likely integrated with UI components that consume these configurations to render forms and handle user input.\n\n5. **Configuration**:  \n- Defines required configuration fields such as `twilio_auth_token`, `twilio_phone_number`, `sendgrid_api_key`, and `sendgrid_from_email`.  \n- Fields include metadata",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:51.136816",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_24": {
      "chunk_id": "serviceRegistry.ts:chunk_24",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "86bd5d681112670851a7ab80ffff5081ebc66fb937a8d50068d62e38bd91f833",
      "chunk_index": 24,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration objects for service integrations within a frontend application, specifically detailing metadata, authentication, and connection testing for external services like SendGrid and custom REST APIs.\n\n2. **Technical Details**:  \n- Uses structured objects to represent service registry entries, each containing fields such as `id`, `name`, `type`, `category`, `description`, `icon`, `authType`, and status flags (`isConfigured`, `isActive`, `status`).  \n- Each service includes `configFields` arrays specifying configuration parameters (name, label, type, required, placeholder, description).  \n- Defines `testAction` objects encapsulating API endpoints, HTTP methods, and user-facing success/error messages for connection validation.  \n- Uses simple key-value mappings without complex algorithms or design patterns, focusing on declarative configuration.\n\n3. **Business Logic**:  \nEnables the frontend to dynamically render integration setup forms and manage connection states for various third-party services (e.g., email providers, APIs). This supports business needs for extensible integrations, allowing users to configure, test, and activate external services that enhance application capabilities like email sending, analytics, and marketing.\n\n4. **Dependencies**:  \nNo explicit external libraries or modules are shown in the snippet; however, it references REST API endpoints (e.g., `/api/integrations/sendgrid/test`) that imply backend services handling integration tests. The code likely depends on frontend frameworks (React",
      "embedding_id": null,
      "created_at": "2025-10-22T19:48:55.985578",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_26": {
      "chunk_id": "serviceRegistry.ts:chunk_26",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "2ed5e731e2f8f6a6f159af6eab9c23955a05a11c0454e2bac16854007e571b89",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis TypeScript code defines configuration metadata for service integrations within a frontend application, specifying authentication methods, configuration fields, test endpoints, and capabilities for different service types such as custom APIs and vector databases.\n\n2. **Technical Details**:  \n- Uses structured objects and arrays to represent service configurations.  \n- Defines authentication options as selectable values with labels (e.g., none, bearer token, API key, basic auth).  \n- Specifies form field properties like `name`, `label`, `type`, `required`, `secret`, and `placeholder` to drive UI rendering and validation.  \n- Includes a `testAction` object describing how to verify connectivity via an HTTP POST endpoint with success and error messages.  \n- Uses flags such as `isConfigured`, `isActive`, and `status` to track service state.  \n- Categorizes services by type and category, supporting extensibility for different integration types.\n\n3. **Business Logic**:  \nEnables the frontend to dynamically render and manage integration configurations for various external services, facilitating secure authentication setup and connectivity testing. This supports business needs around extensible integrations, secure credential management, and operational status monitoring.\n\n4. **Dependencies**:  \nNo explicit external libraries or modules are shown in the snippet; however, it likely depends on frontend frameworks (e.g., React) for UI rendering and HTTP clients for test actions. The `icon` property suggests integration with an icon library.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:01.683807",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_28": {
      "chunk_id": "serviceRegistry.ts:chunk_28",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "845e65483d77a2c799d39dc51bdd822272dbd93a2cbec256e785964f93a46ee0",
      "chunk_index": 28,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code defines configuration metadata for vector database services used in a frontend application, including service options, parameters, and test actions. It also provides utility functions to retrieve service definitions by category or ID.\n\n2. **Technical Details**:  \n- Uses a structured array (`SERVICE_REGISTRY`) of service definitions, each containing fields such as `options`, `description`, `testAction`, and `capabilities`.  \n- Each service parameter is described with properties like `name`, `label`, `type`, `required`, `defaultValue`, and `placeholder`.  \n- Implements two filter functions:  \n  - `getServicesByCategory(category: string): ServiceDefinition[]` filters services by their category string.  \n  - `getServiceById(id: string): ServiceDefinition | undefined` retrieves a single service by its unique identifier.  \n- The `testAction` object defines an API endpoint and HTTP method to verify service connectivity, along with success and error messages.\n\n3. **Business Logic**:  \nEnables dynamic selection and configuration of vector database providers (e.g., In-Memory for dev/test, ChromaDB for production) to support features like semantic search, repository indexing, code similarity, and knowledge retrieval. This abstraction facilitates flexible backend integration and environment-specific setups.\n\n4. **Dependencies**:  \nNo explicit external libraries or modules are imported or referenced in the snippet. The code likely depends on a broader application context where `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:07.215939",
      "status": "summarized"
    },
    "serviceRegistry.ts:chunk_30": {
      "chunk_id": "serviceRegistry.ts:chunk_30",
      "file_path": "frontend\\src\\config\\serviceRegistry.ts",
      "chunk_hash": "2f02b3157b0d2423505e890a29dd591020aa1cb061c157b43f3a14423bb0e1d0",
      "chunk_index": 30,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis TypeScript code provides utility functions to query a service registry by filtering or finding services based on specific criteria such as service ID, active status, or configuration status.\n\n2. **Technical Details**:  \n- Uses array methods `.find()` and `.filter()` on a constant array `SERVICE_REGISTRY`.  \n- `SERVICE_REGISTRY` is presumably an array of `ServiceDefinition` objects, each representing a service with properties like `id`, `isActive`, and `isConfigured`.  \n- The functions return either a single service object (`getServiceById`) or arrays of services (`getActiveServices`, `getConfiguredServices`).  \n- The code follows a functional programming style with pure functions that do not mutate state.\n\n3. **Business Logic**:  \n- Supports dynamic retrieval of service metadata for frontend components or modules that need to interact with backend or microservices.  \n- Enables filtering services that are currently active or properly configured, which is critical for feature toggling, service health checks, or conditional rendering in the UI.\n\n4. **Dependencies**:  \n- Relies on a local module or constant `SERVICE_REGISTRY` which is not shown but expected to be an array of service definitions.  \n- Uses TypeScript standard library features; no external libraries are evident in this snippet.\n\n5. **Configuration**:  \n- No direct environment variables or external configuration files are referenced here.  \n- The `SERVICE_REGISTRY` data source",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:13.327142",
      "status": "summarized"
    },
    "analysis_endpoints.py:chunk_0": {
      "chunk_id": "analysis_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\analysis_endpoints.py",
      "chunk_hash": "de49c0e6c4a940b0059d1f770053b82451f5c8fae5163636cf30abaf3e58a1ff",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a FastAPI router with an endpoint to analyze software issues. It supports automated workflows such as generating code fixes, creating pull requests, and publishing documentation based on issue analysis.\n\n2. **Technical Details**:  \n- Uses FastAPI's `APIRouter` to modularize API endpoints under the `/api` prefix with the tag \"analysis\".  \n- Defines Pydantic models (`IssueAnalysisRequest`, `WebhookPayload`) for request validation and serialization.  \n- The `/analyze` endpoint is asynchronous and accepts an `IssueAnalysisRequest` payload.  \n- Background tasks are used to offload long-running operations (e.g., code generation, test orchestration).  \n- Imports domain-specific modules dynamically within the endpoint function to resolve context, analyze issues, generate fixes, and orchestrate tests, indicating a layered architecture separating API and business logic.\n\n3. **Business Logic**:  \nEnables automated issue triage and remediation workflows for software projects. It helps teams by analyzing reported issues, optionally generating code fixes, creating pull requests, and publishing related documentation, thereby accelerating development cycles and improving code quality.\n\n4. **Dependencies**:  \n- FastAPI for API framework and background task management.  \n- Pydantic for data validation and serialization.  \n- Custom shared modules: `shared.models` (for domain enums and data structures), `shared.logger` (for logging).  \n- Feature modules under `features` namespace for core business logic",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:21.676917",
      "status": "summarized"
    },
    "analysis_endpoints.py:chunk_2": {
      "chunk_id": "analysis_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\analysis_endpoints.py",
      "chunk_hash": "aa19d5cb832bd5b60aa8856193a698b00265d36ac5a2fb37f83ae90eaebf5672",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet processes an issue analysis request by resolving contextual data, performing issue analysis, generating code fixes, and optionally orchestrating tests to create a pull request.\n\n2. **Technical Details**:  \n- Uses asynchronous calls (`await`) for non-blocking operations such as context resolution, analysis, fix generation, and test orchestration.  \n- Constructs a `ContextResolverInput` data structure to encapsulate input parameters for context resolution.  \n- Utilizes a domain-specific data model `EnrichedContext` to represent enriched issue context.  \n- Conditional logic to handle creation of pull requests based on the presence of fixes and a request flag.  \n- Uses structured logging (`logger.info`) for traceability.\n\n3. **Business Logic**:  \nThe code automates the workflow of analyzing software issues by gathering relevant context (logs, metrics, related issues), analyzing the issue, generating potential code fixes, and optionally initiating automated testing and pull request creation. This streamlines issue resolution and accelerates development cycles.\n\n4. **Dependencies**:  \n- `features.doc_publisher.publish_documentation` (imported but not shown used in snippet)  \n- `ContextResolverInput`, `resolve_context` (likely internal modules/services for context gathering)  \n- `EnrichedContext` (data model for enriched issue data)  \n- `analyze_issue`, `generate_code_fix`, `orchestrate_tests` (asynchronous functions for analysis, fix generation,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:29.433228",
      "status": "summarized"
    },
    "analysis_endpoints.py:chunk_4": {
      "chunk_id": "analysis_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\analysis_endpoints.py",
      "chunk_hash": "989cdb76ca057222e1e13e8045b5abdf07c42eacd42c6477aa47871b9b3ff812",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis code defines an asynchronous API endpoint `/webhook/{source}` that handles incoming webhook events from multiple external sources (e.g., GitHub, Grafana, Jira), processing them according to their event types and optionally triggering background tasks.\n\n2. **Technical Details**  \n- Uses FastAPI's `@router.post` decorator to define an async POST endpoint with path parameter `source`.  \n- Accepts a strongly-typed `WebhookPayload` object representing the webhook data.  \n- Employs conditional branching based on `source` and `payload.event_type` to determine processing logic.  \n- Uses `BackgroundTasks` from FastAPI to schedule asynchronous background processing (though the actual task logic is not implemented in the snippet).  \n- Logging is used extensively for tracing incoming events and processing steps.  \n- Exception handling wraps the broader analysis logic (partially shown above the webhook handler) to log errors and return HTTP 500 responses.\n\n3. **Business Logic**  \nThe endpoint facilitates integration with external systems by receiving webhook notifications and triggering corresponding internal workflows, such as issue processing for GitHub issues, alert handling for Grafana alerts, and issue creation events from Jira. This enables automated, event-driven updates and synchronization between the business\u2019s internal systems and external tools.\n\n4. **Dependencies**  \n- FastAPI framework for API routing, request handling, and background tasks.  \n- A custom `WebhookPayload` data model (likely a Pydantic model) for request",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:34.694238",
      "status": "summarized"
    },
    "analysis_endpoints.py:chunk_6": {
      "chunk_id": "analysis_endpoints.py:chunk_6",
      "file_path": "interfaces\\api\\analysis_endpoints.py",
      "chunk_hash": "2104fd60c7ecfb6650897f5fea73803b4fd4597f9bdef0bb8783e7df53dd59d8",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous function processes a GitHub issue by creating an analysis request and invoking an issue analysis endpoint as a background task.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running operations without blocking.  \n- Constructs an `IssueAnalysisRequest` data object with parameters such as issue ID, source type, repository, and flags for creating a PR and publishing docs.  \n- Calls `analyze_issue_endpoint` asynchronously, passing the request and a new `BackgroundTasks` instance to handle the processing in the background.  \n- Logging is used for informational and error tracking.\n\n3. **Business Logic**:  \nAutomates the processing and analysis of GitHub issues, likely to facilitate issue triage, automated PR creation, or documentation generation workflows within a software development lifecycle.\n\n4. **Dependencies**:  \n- `IssueAnalysisRequest` and `SourceType` (likely custom data models/enums).  \n- `analyze_issue_endpoint` function (presumably an async function handling issue analysis).  \n- `BackgroundTasks` (possibly from FastAPI or a similar async framework).  \n- `logger` for logging.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are shown in this snippet; however, the behavior (e.g., `create_pr=True`, `publish_docs=False`) is hardcoded in the request object.\n\n6. **Error Handling**:  \n- Catches all",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:41.931642",
      "status": "summarized"
    },
    "basic_endpoints.py:chunk_0": {
      "chunk_id": "basic_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\basic_endpoints.py",
      "chunk_hash": "5e642390ea565aaed7a5e8df30a08efe4958ee49cb83e88a83df55a3afc93f05",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines basic API endpoints and serves the frontend for an AI development agent service, including root API info, health checks, and serving a React single-page application (SPA).\n\n2. **Technical Details**  \n- Uses FastAPI's `APIRouter` to modularize endpoint definitions under the \"basic\" tag.  \n- Serves static frontend files using `FileResponse` from FastAPI if the React build exists.  \n- Uses Python's `pathlib.Path` to handle filesystem paths in a cross-platform manner.  \n- Logger instance is created via a shared logging utility for consistent logging (though logging calls are not shown in the snippet).  \n- Endpoints are asynchronous (`async def`), enabling non-blocking I/O operations.\n\n3. **Business Logic**  \nProvides essential service metadata and health status to clients and operators, enabling monitoring and integration. Also delivers the frontend UI for user interaction, supporting a seamless full-stack deployment of the AI Dev Agent platform.\n\n4. **Dependencies**  \n- `fastapi` for web framework and routing.  \n- `fastapi.responses.FileResponse` for serving static files.  \n- `pathlib` for filesystem path manipulation.  \n- `shared.logger` custom module for logging.  \n- React frontend build expected at a relative path (`frontend/dist`).\n\n5. **Configuration**  \n- Assumes a specific directory structure where the frontend build output is located three levels up from this file under `frontend/dist`.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:50.396532",
      "status": "summarized"
    },
    "basic_endpoints.py:chunk_2": {
      "chunk_id": "basic_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\basic_endpoints.py",
      "chunk_hash": "88467645f11eea0194b1f30c0ae636e8cfe07254aa8d78fbd60d448f6515820c",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines a catch-all HTTP GET endpoint that serves the React Single Page Application (SPA) by returning the `index.html` file from the frontend build directory, enabling client-side routing for any unmatched paths.\n\n2. **Technical Details**:  \n- Uses FastAPI's routing with a path parameter `{full_path:path}` to capture all unmatched routes.  \n- Serves static files using `FileResponse` from FastAPI to deliver the SPA's `index.html`.  \n- Uses Python's `pathlib.Path` to construct filesystem paths relative to the current file location.  \n- Raises an HTTP 404 exception if the `index.html` file is missing.\n\n3. **Business Logic**:  \nSupports seamless client-side routing in a React SPA by ensuring that all frontend routes (which do not correspond to backend API endpoints) return the SPA's entry point, allowing the React router to handle navigation and rendering.\n\n4. **Dependencies**:  \n- FastAPI framework (`router`, `HTTPException`, `FileResponse`)  \n- Python standard library's `pathlib.Path` for filesystem path manipulation\n\n5. **Configuration**:  \n- Assumes a specific directory structure where the frontend build artifacts are located at `frontend/dist` relative to the backend codebase.  \n- No explicit environment variables or external configuration files are referenced in this snippet.\n\n6. **Error Handling**:  \n- Checks for the existence of the `index.html` file before serving.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:49:56.533885",
      "status": "summarized"
    },
    "chat_endpoints.py:chunk_0": {
      "chunk_id": "chat_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\chat_endpoints.py",
      "chunk_hash": "d3dcb26ef97df4d1ee73550a89bf92624112424109ae11c4a5427e51a9d54458",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module provides REST API endpoints for managing chat conversations, including saving, updating, and retrieving chat history and messages within a conversation.\n\n2. **Technical Details**  \n- Uses FastAPI\u2019s `APIRouter` to define a modular set of endpoints under the `/api/chat` prefix.  \n- Defines Pydantic models (`ChatMessageModel`, `SaveConversationRequest`, `ConversationResponse`, `MessageResponse`) for request validation and response serialization.  \n- Relies on SQLAlchemy ORM for database interactions via a `Session` dependency injection (`Depends(get_db)`).  \n- Implements asynchronous endpoint handlers (`async def`) for non-blocking I/O operations.  \n- Uses a repository pattern (`ChatRepository`) to abstract database operations related to chat conversations and messages.  \n- Logging is integrated via a shared logger instance.\n\n3. **Business Logic**  \nEnables persistence and management of chat conversations and their messages, supporting features like conversation updates, message tracking, and metadata management (e.g., provider, timestamps). This supports applications requiring chat history retention, multi-provider chat integration, and conversation analytics.\n\n4. **Dependencies**  \n- FastAPI for API framework and dependency injection.  \n- Pydantic for data validation and serialization.  \n- SQLAlchemy ORM for database session and model management.  \n- Custom modules:  \n  - `db` for repository and ORM models (`ChatRepository`, `ChatConversation`, `ChatMessage`).  \n  - `interfaces.api.core",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:01.885158",
      "status": "summarized"
    },
    "chat_endpoints.py:chunk_2": {
      "chunk_id": "chat_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\chat_endpoints.py",
      "chunk_hash": "26393bb5cab8bed526116fe953fb34afdea2c7701e1a14a077f98b09258f4261",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet implements backend API endpoints for managing chat conversations, including creating or updating conversations and listing all conversations.\n\n2. **Technical Details**:  \n- Uses a repository pattern (`ChatRepository`) to abstract database operations related to conversations and messages.  \n- Conditional logic to either update an existing conversation (by ID) or create a new one based on the presence of `request.conversation_id`.  \n- Iterates over a list of message objects to persist each message linked to a conversation.  \n- Uses exception handling to catch and log errors, then raises HTTP exceptions with appropriate status codes.  \n- The code snippet shows a FastAPI route decorator (`@router.get`) indicating asynchronous endpoint definitions.\n\n3. **Business Logic**:  \n- Enables users or systems to maintain chat conversations by adding messages and managing conversation metadata (title, provider).  \n- Supports both creation of new conversations and updating existing ones, facilitating ongoing chat sessions.  \n- Provides an endpoint to retrieve all conversations, likely for display or management purposes.\n\n4. **Dependencies**:  \n- `ChatRepository`: a custom data access layer for chat-related database operations.  \n- `FastAPI` framework components such as `HTTPException`, `Depends`, and routing decorators.  \n- `SQLAlchemy` session (`db: Session`) for database interaction.  \n- A logger instance for error logging.  \n- Pydantic models for request and response validation (implied by `response_model",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:05.808145",
      "status": "summarized"
    },
    "chat_endpoints.py:chunk_4": {
      "chunk_id": "chat_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\chat_endpoints.py",
      "chunk_hash": "8725e4b149dceac00370208706dad0f12d4a88b95f6bed47c940ab97c4cca4bc",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines API endpoints for retrieving chat conversations and their associated messages from a database, formatting them into response models for client consumption.\n\n2. **Technical Details**:  \n- Uses a repository pattern (`ChatRepository`) to abstract database operations.  \n- Retrieves a list of conversations with a fixed limit (50) and maps each conversation entity to a `ConversationResponse` data model.  \n- Retrieves messages for a specific conversation and maps each message entity to a `MessageResponse` data model.  \n- Utilizes asynchronous FastAPI route handlers with dependency injection (`Depends(get_db)`) for database session management.  \n- Uses list comprehensions and iteration for data transformation.\n\n3. **Business Logic**:  \nEnables clients to fetch a paginated list of chat conversations and the detailed messages within a selected conversation, supporting features like chat history browsing and message review in a chat application.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and dependency injection.  \n- SQLAlchemy or similar ORM for database session and repository pattern (implied by `Session` and `ChatRepository`).  \n- Pydantic models (`ConversationResponse`, `MessageResponse`) for response validation and serialization.  \n- Logging module for error tracking.  \n- HTTPException from FastAPI for error response handling.\n\n5. **Configuration**:  \n- Database session dependency (`get_db`) likely configured elsewhere to manage DB connections.  \n- No explicit environment variables or config files shown",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:10.673724",
      "status": "summarized"
    },
    "chat_endpoints.py:chunk_6": {
      "chunk_id": "chat_endpoints.py:chunk_6",
      "file_path": "interfaces\\api\\chat_endpoints.py",
      "chunk_hash": "5c555e2751507b14429e35602551f2ecafef767f731e39237c6caa730c80eb8e",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous HTTP DELETE endpoint to delete a chat conversation by its ID from the database.\n\n2. **Technical Details**:  \n- Uses FastAPI's routing and dependency injection (`Depends`) to manage database sessions.  \n- Interacts with a repository pattern (`ChatRepository`) to abstract database operations.  \n- Implements exception handling to catch and log errors, then raise HTTP exceptions with appropriate status codes.  \n- Returns JSON responses indicating success or failure.\n\n3. **Business Logic**:  \nEnables users or systems to remove an entire chat conversation identified by `conversation_id`. This supports data management and cleanup in chat applications, ensuring users can delete conversations that are no longer needed.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and HTTP exception handling.  \n- SQLAlchemy or similar ORM for database session management (`Session`, `get_db`).  \n- A custom `ChatRepository` class that encapsulates database operations related to chat conversations.  \n- A logging utility (`logger`) for error tracking.\n\n5. **Configuration**:  \n- Database connection and session management are likely configured elsewhere and injected via `get_db`.  \n- Logging configuration is assumed to be set up globally.  \n- No explicit environment variables or config files are referenced in this snippet.\n\n6. **Error Handling**:  \n- Catches generic exceptions during the delete operation.  \n- Logs errors with descriptive messages.  \n- Returns HTTP 404 if the conversation does",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:17.703011",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_0": {
      "chunk_id": "commit_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "6e10712c1a5893fa60d25368c9faab937d5f2135d7512612757cb2ed07da1653",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines API endpoints for managing commit and publish workflows, particularly parsing user intents related to GitHub commits and handling approval processes within a commit pipeline.\n\n2. **Technical Details**  \n- Uses FastAPI\u2019s `APIRouter` to modularize API endpoints under the `/api/commit` prefix.  \n- Defines Pydantic models (`CommitWorkflowRequest`, `ApprovalResponse`) for request validation and response serialization.  \n- The `/parse-intent` endpoint asynchronously processes commit intent messages, leveraging an external orchestrator (imported dynamically) to interpret user input and generate approval templates.  \n- Optional fields in request models allow flexible input, supporting partial data such as repository, branch, files, and contextual information.  \n- Logging is integrated via a shared logger instance for traceability.\n\n3. **Business Logic**  \nEnables users to initiate commit or publish workflows by parsing natural language messages to detect intent, ensuring that commits are validated and approved before being applied to GitHub repositories. This supports controlled, auditable deployment or content publishing processes.\n\n4. **Dependencies**  \n- FastAPI for API routing and HTTP exception handling.  \n- Pydantic for data validation and serialization.  \n- A shared logging utility (`shared.logger`).  \n- A resilient orchestrator module (`shared.llm_providers.resilient_orchestrator`) for intent parsing and workflow orchestration.  \n- Python standard libraries: `uuid`, `typing`.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:25.028792",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_2": {
      "chunk_id": "commit_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "27542747666035b1aafd1c4b8adbabdd3bfc000ee227b4ace921a5bd64899434",
      "chunk_index": 2,
      "summary": "**Summary of `interfaces/api/commit_endpoints.py`**\n\n1. **Purpose**  \nThis code snippet handles parsing a user's commit intent message within a commit workflow API endpoint. It validates the presence of GitHub repository content before routing the parsed intent to the appropriate commit workflow for execution.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`await`) to handle potentially long-running operations such as intent parsing and workflow routing.  \n- Employs a router pattern (`CommitWorkflowRouter`) to delegate intent processing and workflow execution.  \n- Validates input data (`request.files`) to ensure required repository content is present.  \n- Uses structured logging to trace processing steps and errors.  \n- The `get_resilient_orchestrator()` function (not shown) likely returns a fault-tolerant orchestrator instance for managing LLM (Large Language Model) interactions.  \n- The intent parsing and routing are separated concerns, promoting modularity and extensibility.\n\n3. **Business Logic**  \nThe code supports an automated commit creation process by interpreting user messages as commit intents and ensuring the necessary repository context is loaded. This enables a streamlined developer experience where commit actions can be driven by natural language or structured intent, reducing manual steps and errors.\n\n4. **Dependencies**  \n- `orchestration.commit_workflow.CommitWorkflowRouter`: Core router for commit workflows.  \n- `orchestration.commit_workflow.approval_system.get_approval_manager`: Possibly used elsewhere for approval workflows.  \n- `",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:32.121112",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_4": {
      "chunk_id": "commit_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "6f5db2f660fd6ab465a5bdf7c52e5a75c06746500a8583cfba7a801804a2ffd4",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an API endpoint implementation that processes commit intents and handles approval workflows for operations, culminating in an `/approve` endpoint where users can approve or reject commit operations.\n\n2. **Technical Details**  \n- Uses asynchronous FastAPI route handlers (`@router.post(\"/approve\")`) for non-blocking I/O.  \n- Utilizes a workflow engine or manager (`approval_manager`) to create approval requests based on parsed workflow results.  \n- Data structures include dictionaries for request files, context, and workflow/template metadata.  \n- The approval request object supports serialization via `.to_dict()`.  \n- Exception handling wraps the commit intent parsing logic to catch and log errors, then raises HTTP 500 errors.  \n- The code snippet implies use of dependency injection or factory pattern via `get_approval_manager()` to obtain the approval manager instance.\n\n3. **Business Logic**  \n- Facilitates a controlled commit operation workflow requiring user approval, ensuring that critical operations undergo validation before execution.  \n- Supports dynamic workflows and templates, allowing flexible approval processes tailored to different operation types.  \n- Captures intent metadata (platform, action, confidence) to inform approval decisions.\n\n4. **Dependencies**  \n- FastAPI framework for API routing and HTTP exception handling.  \n- A custom `approval_manager` module or service responsible for managing approval requests.  \n- A logger instance for error logging.  \n- Pydantic models (implied by `ApprovalResponse` type",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:39.418820",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_7": {
      "chunk_id": "commit_endpoints.py:chunk_7",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "bb8814a3864f29368646f9d1e4ccd9dca9c78741fca6f31dd3321b62b0b30966",
      "chunk_index": 7,
      "summary": "**Summary of `interfaces\\api\\commit_endpoints.py`**\n\n---\n\n1. **Purpose**  \nThis code defines API endpoints and internal functions to manage and execute commit approval workflows, specifically listing pending approval requests and performing approved commit or publish operations through GitHub integration.\n\n2. **Technical Details**  \n- Uses asynchronous FastAPI route handlers (`@router.get`) for non-blocking I/O operations.  \n- Employs a centralized approval manager (`get_approval_manager()`) to retrieve and manage approval requests.  \n- Utilizes a wrapper pattern (`GitHubWrapper`) to encapsulate GitHub client instantiation and environment-specific configurations.  \n- Converts domain objects (`pending` approval requests) to dictionaries for JSON serialization in API responses.  \n- The `execute_commit_operation` function dynamically imports required modules and extracts the underlying PyGithub client from the wrapper for executing GitHub operations.\n\n3. **Business Logic**  \n- Provides a mechanism for stakeholders to view all pending commit approval requests, facilitating controlled and auditable code changes.  \n- Enables execution of commit or publish operations only after approvals, enforcing governance and compliance in the software delivery pipeline.  \n- Supports integration with GitHub for version control operations, aligning with modern DevOps workflows.\n\n4. **Dependencies**  \n- `orchestration.commit_workflow.approval_system` for approval management logic.  \n- `orchestration.commit_workflow.GitHubOperations` for encapsulated GitHub-related commit operations.  \n- `shared.clients",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:47.416415",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_9": {
      "chunk_id": "commit_endpoints.py:chunk_9",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "13c8daba18dde1e7084a673177daebc050d8ff63b0f7eb3b7c12591c5fcd476b",
      "chunk_index": 9,
      "summary": "1. **Purpose**:  \nThis code snippet handles committing files to a GitHub repository asynchronously via a centralized GitHub client, then constructs URLs and response data for subsequent user actions like viewing the commit or branch.\n\n2. **Technical Details**:  \n- Uses an asynchronous method (`await github_ops.commit_files`) to perform GitHub commit operations.  \n- Employs a wrapper pattern (`github_wrapper`) to obtain a GitHub client instance, preferring an environment-based client over a Replit client.  \n- Constructs URLs dynamically based on commit and branch information returned from the commit operation.  \n- Returns a dictionary combining the commit operation result with UI-related metadata for next user actions.\n\n3. **Business Logic**:  \nEnables automated, programmatic commits to GitHub repositories as part of a larger workflow, likely supporting CI/CD, content updates, or template-based repository modifications. It facilitates user interaction by providing direct links to view the commit and branch on GitHub.\n\n4. **Dependencies**:  \n- `github_wrapper`: a custom or third-party wrapper managing GitHub client instances.  \n- `GitHubOperations`: a class encapsulating GitHub API operations, presumably using PyGithub or similar.  \n- `logger`: for logging informational and warning messages.  \n- GitHub API (via PyGithub or similar) for commit operations.\n\n5. **Configuration**:  \n- Relies on environment variables or environment-based authentication to initialize the GitHub client (`_env_client`).  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:50:56.239428",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_11": {
      "chunk_id": "commit_endpoints.py:chunk_11",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "0654b35941df3d91a8e793e054303a2cbc37544f975b1f5ff3a708fc96731320",
      "chunk_index": 11,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous API endpoint handler that manages GitHub operations related to commits and pull requests. Specifically, it handles creating pull requests on GitHub and returns structured results including URLs and metadata for UI consumption.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to perform non-blocking GitHub API calls.  \n- Constructs and returns dictionaries containing action metadata such as URLs, labels, and repository/branch information.  \n- Utilizes dictionary `.get()` methods with default values to safely access optional keys in `template_data` and `result`.  \n- The code snippet shows conditional branching based on `operation_type` to differentiate between commit-related and pull request-related operations.\n\n3. **Business Logic**:  \nEnables automation of GitHub workflows by programmatically creating pull requests with customizable parameters such as source/target branches, reviewers, assignees, labels, and draft status. This supports streamlined code review and integration processes within a CI/CD or developer tooling context.\n\n4. **Dependencies**:  \n- `github_ops` module or service that abstracts GitHub API interactions, particularly the `create_pull_request` async function.  \n- Likely depends on an async HTTP client or GitHub SDK under the hood (not shown in snippet).  \n- Uses standard Python data structures (dicts, lists).\n\n5. **Configuration**:  \n- Pull request parameters (repository, branches, title,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:02.326344",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_13": {
      "chunk_id": "commit_endpoints.py:chunk_13",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "851b3694a6dd5ffba3b739505158a2271446fb653b3c0ff45b47176bf3884c33",
      "chunk_index": 13,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet handles operations related to committing code changes and creating pull requests on GitHub repositories. It processes input data to perform commits and PR creation, then returns structured results including URLs for further user actions.\n\n2. **Technical Details**:  \n- Uses asynchronous function calls (`await`) to interact with GitHub operations, likely via an API wrapper.  \n- Accepts a dictionary `template_data` containing repository details, commit messages, files, and PR metadata.  \n- Constructs a response dictionary that merges operation results with a `next_actions` list, which provides actionable links (e.g., view commit, view PR).  \n- Employs dictionary unpacking (`**result`) to merge response data.  \n- Uses conditional branching on `operation_type` to determine the operation flow.\n\n3. **Business Logic**:  \nAutomates the process of committing code changes and creating pull requests in a GitHub repository, streamlining developer workflows and enabling integration with other systems or UI components that can trigger these operations and present next steps to users.\n\n4. **Dependencies**:  \n- `github_ops` module or service that provides `commit_and_create_pr` asynchronous method for GitHub interactions.  \n- Assumes an asynchronous runtime environment (e.g., `asyncio`).  \n- Likely part of a larger API framework handling HTTP requests (not shown in snippet).\n\n5. **Configuration**:  \n- Repository name, branch names, commit messages",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:09.498420",
      "status": "summarized"
    },
    "commit_endpoints.py:chunk_15": {
      "chunk_id": "commit_endpoints.py:chunk_15",
      "file_path": "interfaces\\api\\commit_endpoints.py",
      "chunk_hash": "40faa81181eeee075ec505eb29a6749c7fb0ab8fbca9251930c6d3db7d2f9737",
      "chunk_index": 15,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet appears to be part of a function that processes different operation types related to commits or pull requests, returning structured results including URLs for viewing pull requests. It handles recognized operation types by returning relevant data and logs a warning with an error response for unknown types.\n\n2. **Technical Details**:  \n- Uses conditional branching (`if-else`) to handle different `operation_type` values.  \n- Constructs and returns a dictionary (`result`) containing keys such as `\"label\"` and `\"url\"`.  \n- Uses logging (`logger.warning`) to record unexpected operation types.  \n- The data structure returned is a nested dictionary with lists, suitable for JSON serialization.\n\n3. **Business Logic**:  \nSupports workflows involving commit or pull request operations by providing clients with actionable links (e.g., \"View Pull Request\") based on the operation type. This enables UI components or API consumers to present relevant navigation options to users.\n\n4. **Dependencies**:  \n- Relies on a `logger` instance for logging warnings.  \n- Assumes `result` dictionary is populated elsewhere in the function or module.  \n- No explicit external libraries shown in the snippet, but likely part of a larger API framework.\n\n5. **Configuration**:  \n- No direct configuration or environment variables are referenced in this snippet.  \n- Logging behavior may depend on external logging configuration.\n\n6. **Error Handling**:  \n- Handles unknown `operation_type` values by logging a",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:17.909744",
      "status": "summarized"
    },
    "doc_endpoints.py:chunk_0": {
      "chunk_id": "doc_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\doc_endpoints.py",
      "chunk_hash": "02fc4e320ab3c71a2e1e46fdb8c5018361db93e1187bd40d71523d3b7d7cf7f7",
      "chunk_index": 0,
      "summary": "**Summary of `interfaces/api/doc_endpoints.py`:**\n\n1. **Purpose**  \n   This module defines API endpoints for generating and orchestrating documentation workflows based on natural language prompts. It supports generating docs, optionally committing them to GitHub, publishing to Confluence, and creating Jira tickets.\n\n2. **Technical Details**  \n   - Uses FastAPI to define RESTful API endpoints with `APIRouter`.  \n   - Defines Pydantic models (`DocGenerationRequest`, `DocOrchestrationRequest`) for request validation and serialization.  \n   - Employs asynchronous endpoint handler (`async def`) for potentially non-blocking I/O operations.  \n   - Uses a logger instance for structured logging.  \n   - The design follows a modular, layered approach separating API layer from business logic (implied but not shown here).\n\n3. **Business Logic**  \n   Enables automated generation of project documentation from prompts, streamlining developer workflows by integrating with version control (GitHub), documentation platforms (Confluence), and issue tracking (Jira). This reduces manual documentation effort and improves knowledge sharing.\n\n4. **Dependencies**  \n   - **FastAPI**: Web framework for API creation.  \n   - **Pydantic**: Data validation and settings management via models.  \n   - **shared.logger**: Custom logging utility (likely wraps Python\u2019s logging).  \n   - Optional integrations implied: GitHub API, Confluence API, Jira API (not shown but referenced in request models).\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:22.264448",
      "status": "summarized"
    },
    "doc_endpoints.py:chunk_2": {
      "chunk_id": "doc_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\doc_endpoints.py",
      "chunk_hash": "38569a472d66bb0167a350957e327c6fa3690d02898f47f2e49f9ceee2ffef96",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/docs/orchestrate` that accepts a documentation orchestration request and generates project-specific documentation by invoking a documentation generation service.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running documentation generation without blocking.  \n- Calls an imported coroutine `generate_documentation` with parameters extracted from the request object.  \n- Returns a structured JSON response containing success status, generated documentation, analyzed files count, repository info, commit hash, metadata, and any error messages.  \n- Uses structured logging to record the prompt used for generation and errors encountered.  \n- Exception handling wraps the call to `generate_documentation` to catch all exceptions and respond with HTTP 500 errors.\n\n3. **Business Logic**:  \nEnables automated generation of technical documentation (e.g., API docs, architecture docs) for code repositories based on user prompts, helping development teams quickly produce up-to-date documentation tailored to specific areas like authentication or user services.\n\n4. **Dependencies**:  \n- `features.doc_generator.generate_documentation`: Core service performing the documentation generation logic.  \n- `logger`: Presumably a configured logging instance for info and error logs.  \n- `HTTPException`: From FastAPI or Starlette, used to return HTTP error responses.  \n- `DocOrchestrationRequest`: A Pydantic model or similar schema validating the incoming request payload.\n\n5. **Configuration**:  \nNo",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:29.820595",
      "status": "summarized"
    },
    "doc_endpoints.py:chunk_4": {
      "chunk_id": "doc_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\doc_endpoints.py",
      "chunk_hash": "1aef19686f29066b941742b8e66b9d73119d47a592cc5377612c79264542b877",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet defines an asynchronous API endpoint that orchestrates a complete documentation workflow by analyzing a code repository, generating documentation, committing it to GitHub, publishing it to Confluence, and optionally creating a Jira ticket.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially long-running I/O operations without blocking.  \n- Delegates the core workflow to a single orchestrator function `orchestrate_documentation` imported from `features.doc_orchestrator`.  \n- Accepts multiple parameters related to repository details, commit options, Confluence publishing, and Jira ticket creation.  \n- Uses structured JSON input to configure the workflow steps.  \n- Logging is used to track the start of the orchestration process.\n\n3. **Business Logic**:  \nAutomates the end-to-end process of generating and publishing technical documentation for a software repository, integrating with GitHub for version control, Confluence for documentation hosting, and Jira for issue tracking. This streamlines documentation efforts, reduces manual work, and ensures documentation is up-to-date and properly tracked.\n\n4. **Dependencies**:  \n- Internal module: `features.doc_orchestrator` for the main orchestration logic.  \n- External services/APIs: GitHub (for commits), Confluence (for publishing), Jira (for ticket creation).  \n- Logging framework (implied by `logger.info`).\n\n5. **Configuration**:  \n- Parameters such as repository name, commit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:36.324795",
      "status": "summarized"
    },
    "doc_endpoints.py:chunk_6": {
      "chunk_id": "doc_endpoints.py:chunk_6",
      "file_path": "interfaces\\api\\doc_endpoints.py",
      "chunk_hash": "aae18a754349a1e73214dc201500c63e9f5d8160459f6fc5150480e68f971db2",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet constructs a dictionary containing various documentation-related attributes from a `result` object and handles any exceptions by logging an error and returning an HTTP 500 error response.\n\n2. **Technical Details**:  \n- The snippet extracts multiple fields (e.g., `documentation`, `files_analyzed`, `repository`, etc.) from a `result` object and organizes them into a dictionary.  \n- It uses a try-except block to catch any exceptions during this process.  \n- On exception, it logs the error using a `logger` and raises an `HTTPException` with a 500 status code, indicating an internal server error.\n\n3. **Business Logic**:  \nThe code is part of a documentation orchestration process, likely aggregating and returning metadata about code documentation, repository state, and related workflow artifacts (e.g., Jira tickets, Confluence pages). This supports business needs for tracking and managing documentation quality and workflow status in software projects.\n\n4. **Dependencies**:  \n- `logger`: a logging utility for error reporting.  \n- `HTTPException`: presumably imported from a web framework like FastAPI or Starlette to handle HTTP error responses.  \n- `result`: an object containing documentation and workflow-related data, likely returned from a service or orchestration layer.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet. Configuration might be external to this code, such as logging setup or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:39.971592",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_0": {
      "chunk_id": "llm_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "44b78fa81ca685e04342555690ee71c43ec56f14098b72bd605f1ba784b901e5",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines a FastAPI router with endpoints for testing Large Language Model (LLM) providers, supporting both synchronous and streaming interactions. It facilitates sending prompts and conversation context to LLMs and orchestrates task execution based on the responses.\n\n2. **Technical Details**  \n- Uses FastAPI's `APIRouter` to modularize API endpoints under the `/api` prefix with the `llm` tag.  \n- Defines Pydantic models (`LLMTestRequest`, `StreamOrchestrationRequest`) for request validation and serialization.  \n- Supports dual input methods for the `/test/llm` POST endpoint: via request body (new frontend) or query parameters (legacy frontend).  \n- Imports `StreamingResponse` indicating potential support for streaming LLM outputs (though not shown in the snippet).  \n- Uses Python typing hints for clarity and validation (`Optional`, `List`, `Dict`).  \n- Logger integration via a shared logger module for structured logging.\n\n3. **Business Logic**  \nEnables clients (likely frontend applications) to test and interact with different LLM providers and models by sending prompts and conversation histories. This supports evaluating LLM responses, debugging, and orchestrating multi-step tasks, which is critical for applications relying on AI-driven conversational agents or content generation.\n\n4. **Dependencies**  \n- FastAPI: Web framework for API creation.  \n- Pydantic: Data validation and settings management.  \n- Python standard libraries:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:47.238900",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_2": {
      "chunk_id": "llm_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "49735a20c794a2206fb94fe0bede98f3ee37b8ca6a48fb6fbde0b49107c34cf6",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an API endpoint designed to test a Large Language Model (LLM) provider. It processes input prompts, applies conversation context if available, and routes GitHub-related queries through a specialized GitHub-LLM orchestration pipeline.\n\n2. **Technical Details**:  \n- Extracts parameters from the request object, supporting both body and query parameters for backward compatibility.  \n- Uses conditional logic to determine the LLM provider and model, defaulting to \"together\" and \"meta-llama/Llama-3.3-70B-Instruct-Turbo\" respectively.  \n- Detects GitHub-related queries using `is_github_query` and retrieves relevant context with `get_github_context`.  \n- Applies conversation history context via `ConversationContextManager`.  \n- Integrates with `github_llm_orchestrator` to handle GitHub-specific queries, likely involving vector database lookups or orchestration workflows.  \n- Uses structured models (`QueryRequest`, `QueryType`) to formalize query handling.\n\n3. **Business Logic**:  \nEnables testing and evaluation of different LLM providers and models, with enhanced handling for GitHub-related queries by leveraging domain-specific context and orchestration. This supports improved response relevance and accuracy in developer-centric applications or tools that interact with GitHub data.\n\n4. **Dependencies**:  \n- `shared.llm.llm_client`: Core LLM client interface.  \n- `shared",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:52.451937",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_4": {
      "chunk_id": "llm_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "61a4c4da95eaf9f74805f730d2604dd2b6ade87b6550a3292c97ec277be6c839",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis code snippet processes an incoming prompt by optionally augmenting it with conversational context, detects if the query relates to GitHub, and conditionally routes the request to a specialized GitHub LLM orchestrator for handling.\n\n2. **Technical Details**  \n- Uses a `ConversationContextManager` class to enrich the prompt based on prior conversation history, implementing a context augmentation pattern.  \n- Detects GitHub-related queries via the `is_github_query` function and extracts relevant GitHub context using `get_github_context`.  \n- Implements conditional asynchronous routing: if the query is GitHub-related and the GitHub orchestrator is initialized, it delegates processing to `_handle_github_orchestration`.  \n- Logging is used extensively for observability of context augmentation and query analysis steps.\n\n3. **Business Logic**  \nThe code supports a conversational AI interface that adapts responses based on prior dialogue and intelligently routes GitHub-specific queries to a dedicated orchestrator. This enables enhanced, context-aware interactions and specialized handling of GitHub-related requests, improving user experience and response relevance.\n\n4. **Dependencies**  \n- `ConversationContextManager` (likely a custom class/module for managing conversational context)  \n- `is_github_query` and `get_github_context` functions for query classification and context extraction  \n- `github_llm_orchestrator` object, presumably an instance of a service or orchestrator managing GitHub-specific LLM interactions  \n- `logger` for",
      "embedding_id": null,
      "created_at": "2025-10-22T19:51:56.608253",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_6": {
      "chunk_id": "llm_endpoints.py:chunk_6",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "605d23b026b5e2702118831c8023e83addb6d83ce40a77a1fc64e74a7bb98277",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of an asynchronous orchestration layer that routes natural language prompts to a specialized GitHub LLM (Large Language Model) orchestrator for intelligent processing of GitHub-related queries, falling back to a standard pipeline if the orchestrator is not initialized.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running orchestration tasks without blocking.  \n- Implements a routing mechanism based on the `query_type` extracted from the `github_context` dictionary, mapping string identifiers to a `QueryType` enum for type-safe query handling.  \n- Employs a dictionary (`query_type_map`) as a lookup table to convert string query types into enum values.  \n- Logging is used extensively for tracing execution flow and debugging.  \n- The orchestration pipeline is modularized, with a dedicated private async function `_handle_github_orchestration` encapsulating GitHub-specific logic.\n\n3. **Business Logic**  \nThe code addresses the business need to intelligently process different types of GitHub-related queries (such as code search, file explanation, semantic search, documentation retrieval, and repository summary) by routing them to a specialized LLM orchestrator. This enables enhanced developer productivity and more accurate, context-aware responses in developer tools or platforms integrating GitHub data.\n\n4. **Dependencies**  \n- `github_llm_orchestrator` from `interfaces.vector_db_api`: the core orchestrator handling GitHub LLM queries",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:02.142061",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_8": {
      "chunk_id": "llm_endpoints.py:chunk_8",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "292e8e9298eb58b5db4e89bd35b0de66fef3b1d22fa514c9948e72ea7fe0e0e9",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code snippet constructs a query request based on a prompt and query type, sends it asynchronously to a GitHub-LLM orchestrator for processing, logs the request and response details including processing time and confidence score, and prepares structured data representing the thinking process for UI display.\n\n2. **Technical Details**:  \n- Uses a `QueryRequest` data structure to encapsulate query parameters such as prompt, query type, repository context, and search options.  \n- Employs asynchronous programming (`await`) to handle the query processing without blocking.  \n- Measures processing time using `datetime.now()` before and after the asynchronous call.  \n- Logs key events and metrics using a logger.  \n- Constructs a dictionary (`thinking_data`) to represent stepwise progress/status for UI consumption.\n\n3. **Business Logic**:  \nEnables querying a GitHub repository context with a large language model (LLM) orchestrator to retrieve relevant information or insights, supporting developer workflows such as code search, analysis, or automated assistance within a repository.\n\n4. **Dependencies**:  \n- `QueryRequest` class or data structure (likely custom or from an internal SDK).  \n- `github_llm_orchestrator` service/module providing `process_query` async method.  \n- `logger` for logging events.  \n- `datetime` module for timing.  \n- `github_context` dictionary providing repository and query type metadata.\n\n5. **Configuration**:  \n- The repository",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:10.050657",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_10": {
      "chunk_id": "llm_endpoints.py:chunk_10",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "f378ab77364655abf00abd0b86b76305a2833fa48e0acfa66cba941998b5abb1",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet constructs and returns a structured response object summarizing the results of a GitHub-related large language model (LLM) orchestration process, including metadata about query sources, confidence scores, timing, and workflow details.\n\n2. **Technical Details**:  \n- Uses Python dictionaries and lists to build nested JSON-like response data.  \n- Tracks timing with `start_time.isoformat()` and `datetime.now().isoformat()` for timestamps.  \n- Generates unique workflow IDs using `uuid.uuid4()`.  \n- Includes metadata fields such as source count, confidence score (formatted as a percentage), and query type (likely an enum with `.value`).  \n- The response aggregates multiple stages or steps, each with its own status and duration metrics.\n\n3. **Business Logic**:  \nThe code supports a business process that queries multiple GitHub data sources via an LLM orchestration layer, evaluates confidence in the aggregated results, and reports detailed execution metadata. This enables transparency and traceability in automated GitHub data querying workflows, likely for insights, code analysis, or developer assistance.\n\n4. **Dependencies**:  \n- Python standard libraries: `datetime`, `uuid`  \n- Custom or external types: `response` object with attributes like `sources`, `confidence_score`, and `query_type` (likely from a domain-specific module)  \n- Possibly an LLM orchestration framework or service providing the `response` data\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:15.696417",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_12": {
      "chunk_id": "llm_endpoints.py:chunk_12",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "0d1313228b7f3fb60fbce23bdeba086cbef0dba4000461788e01ebd432254452",
      "chunk_index": 12,
      "summary": "**Summary of `interfaces\\api\\llm_endpoints.py`**\n\n---\n\n1. **Purpose**  \nThis code snippet is part of an asynchronous orchestration pipeline that processes prompts using a large language model (LLM) integrated with GitHub context and other services. It attempts to generate enriched responses with metadata and optionally includes intermediate \"thinking\" data for transparency.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle potentially long-running orchestration tasks without blocking.  \n- Employs a facade design pattern (`OrchestrationFacade`) to abstract complex orchestration logic behind a simplified interface.  \n- Utilizes a connection factory (`get_service_manager`) to dynamically obtain service managers that handle integrations with external systems.  \n- Constructs a structured response dictionary containing:  \n  - A beautified or summarized response text  \n  - Flags indicating orchestration usage  \n  - Contextual GitHub data  \n  - Metadata including query type, source count, confidence score, and processing time  \n  - Optional \"thinking\" data for debugging or transparency, controlled by a flag (`show_thinking`).\n\n3. **Business Logic**  \nThe code supports a business need to provide enhanced LLM-driven responses enriched with contextual data from GitHub repositories and other integrated services. This enables more accurate, traceable, and confidence-scored answers for end users, improving trust and utility in AI-powered query systems.\n\n4. **Dependencies**  \n- Internal modules:  \n  - `orchestration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:23.366675",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_14": {
      "chunk_id": "llm_endpoints.py:chunk_14",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "a5528d9f4c7ed5782d3e20b556317ccdc5cfed804d20d5958b1acfb7f56ad4c1",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code initializes an orchestration facade to process a natural language prompt through a multi-stage pipeline (parsing, enriching, prompt building, and agent execution), then extracts and returns the final response from the pipeline results.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially long-running I/O or compute-bound operations without blocking.  \n- Implements a facade design pattern (`OrchestrationFacade`) to encapsulate complex orchestration logic behind a simple interface.  \n- Processes the input message through a sequence of stages: parser \u2192 enricher \u2192 prompt builder \u2192 agent, likely involving multiple components or microservices.  \n- Uses a dictionary (`result`) to hold pipeline outputs, including a list of task results (`task_results`), where each task result is an instance of a dataclass (`AgentTask`).  \n- Extracts the final response by accessing the last task\u2019s result dictionary.\n\n3. **Business Logic**:  \nEnables a modular, extensible pipeline for processing user prompts or messages in an AI-driven application, such as a chatbot or virtual assistant. This supports complex workflows where input is parsed, contextually enriched, transformed into prompts, and executed by an agent to generate meaningful responses.\n\n4. **Dependencies**:  \n- `get_service_manager()`: an async function to retrieve service management context, likely from an internal service registry or dependency injection framework.  \n- `OrchestrationFacade`: a custom class encaps",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:30.220831",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_16": {
      "chunk_id": "llm_endpoints.py:chunk_16",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "0ecee3031b5b794f0049141eade6554ed73544f285251fed1bf73865deb2fc3e",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an orchestration pipeline for handling responses from a large language model (LLM) endpoint. It processes the orchestration result, extracts GitHub-related context if available, and constructs a detailed \"thinking\" data structure that tracks the workflow execution metadata.\n\n2. **Technical Details**:  \n- Uses a dictionary (`result`) to hold orchestration outputs and metadata.  \n- Extracts GitHub context via a helper function `_extract_github_context`.  \n- Constructs a \"thinking\" dictionary containing workflow steps, unique workflow ID (UUID), timestamps, status, and duration metrics.  \n- Uses asynchronous function `_build_orchestration_thinking` to optionally build this thinking data based on a flag (`show_thinking`).  \n- Exception handling with logging and structured error response.  \n- Uses Python standard libraries such as `datetime` for timestamps and `uuid` for unique identifiers.\n\n3. **Business Logic**:  \nThe code supports a business need to orchestrate multiple LLM calls or processing steps, track their execution state, and enrich responses with contextual information (e.g., GitHub data). This enables transparency, debugging, and enhanced response quality in AI-driven workflows, likely for developer tools or code intelligence platforms.\n\n4. **Dependencies**:  \n- Python standard libraries: `datetime`, `uuid`  \n- Presumably a logging framework (`logger`) for error reporting  \n- Internal helper functions/modules such as `_extract_github_context",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:46.665813",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_18": {
      "chunk_id": "llm_endpoints.py:chunk_18",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "c8a103e998b18b045d35119085c0da1a4358ab569cc09bfd006089ffc64bd4ed",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an orchestration workflow that processes and enriches a message, tracks the progress through discrete steps, and records timing and status metadata before returning a structured summary of the workflow execution.\n\n2. **Technical Details**:  \n- Uses Python dictionaries and lists to accumulate step-wise metadata in `thinking_data[\"steps\"]`.  \n- Conditional checks on keys (`parsed_message`, `enriched_context`) in a result dictionary to append corresponding step details.  \n- Tracks workflow timing using `datetime.now()` and calculates total duration in milliseconds.  \n- The `_extract_github_context` function stub suggests modular extraction of GitHub-specific data from enriched context, returning an optional dictionary.\n\n3. **Business Logic**:  \nThe code supports a business process that involves parsing incoming messages to identify references, enriching the context with additional data, and providing a detailed audit trail of these steps with timing and status. This is likely used in a system that automates or assists in understanding and processing complex inputs, such as customer support, code review, or knowledge management.\n\n4. **Dependencies**:  \n- Python standard library: `datetime` for time tracking.  \n- The code references `result` and `thinking_data` objects which are presumably passed in or constructed elsewhere in the application.  \n- The presence of `parsed_message.references` and `enriched_context.context_items` implies domain-specific classes or data structures defined elsewhere.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:54.085693",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_20": {
      "chunk_id": "llm_endpoints.py:chunk_20",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "9e1d035ebd1898fec4997e7fa286e4387da5c37f7312bdd80984084e6698a28b",
      "chunk_index": 20,
      "summary": "1. **Purpose**  \nThis code snippet defines a FastAPI endpoint `/orchestration/stream` that streams real-time orchestration pipeline activity as Server-Sent Events (SSE). It also includes logic to extract GitHub-related context items from an enriched context object.\n\n2. **Technical Details**  \n- Uses asynchronous FastAPI endpoint with `@router.post` decorator to handle POST requests.  \n- Implements streaming response via `StreamingResponse` to deliver real-time backend processing updates.  \n- Extracts GitHub-related items by filtering `enriched_context.context_items` based on the presence of a `source_type` attribute containing \"github\".  \n- Uses list comprehensions and set operations to aggregate unique GitHub repositories from metadata.  \n- Employs dependency injection pattern by instantiating `ServiceManager` and passing it to `StreamingOrchestrationWrapper`, which likely encapsulates orchestration logic and streaming behavior.\n\n3. **Business Logic**  \nEnables clients to receive live updates on orchestration pipeline progress, improving transparency and responsiveness in workflows that involve multiple backend services. The GitHub context extraction supports business use cases where orchestration depends on or integrates with GitHub repositories, allowing filtering or enhanced context awareness.\n\n4. **Dependencies**  \n- `orchestration.streaming_wrapper.StreamingOrchestrationWrapper`: Handles orchestration logic and streaming.  \n- `shared.services.manager.ServiceManager`: Manages service dependencies or configurations for orchestration.  \n- FastAPI framework components (`@router",
      "embedding_id": null,
      "created_at": "2025-10-22T19:52:59.705134",
      "status": "summarized"
    },
    "llm_endpoints.py:chunk_22": {
      "chunk_id": "llm_endpoints.py:chunk_22",
      "file_path": "interfaces\\api\\llm_endpoints.py",
      "chunk_hash": "575ecc22edebbe35e2b589e8950e127a390898bece456003751cfdfa4395e313",
      "chunk_index": 22,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet initiates a server-sent events (SSE) HTTP response that streams processed messages from a language model wrapper based on the incoming request parameters.\n\n2. **Technical Details**:  \n- Utilizes a streaming response pattern to send incremental data to the client in real-time.  \n- Calls `wrapper.stream_process_message()` with parameters extracted from the request object (`message`, `template_name`, `execute_tasks`).  \n- Sets HTTP headers to disable caching, maintain a persistent connection, and disable proxy buffering (`X-Accel-Buffering: no`), which is important for real-time streaming.  \n- Uses the media type `\"text/event-stream\"` to comply with SSE protocol.\n\n3. **Business Logic**:  \nEnables real-time, incremental delivery of processed language model outputs (likely for chatbots, AI assistants, or dynamic content generation), improving user experience by providing immediate feedback rather than waiting for the entire response.\n\n4. **Dependencies**:  \n- `wrapper` module or object that exposes the `stream_process_message` method (likely a custom abstraction over an LLM or AI service).  \n- HTTP framework capable of streaming responses (e.g., FastAPI, Starlette, or similar).  \n- SSE protocol support on client and server sides.\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown in this snippet.  \n- Headers suggest configuration considerations for reverse proxies (e.g., Ngin",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:06.542408",
      "status": "summarized"
    },
    "voice_endpoints.py:chunk_0": {
      "chunk_id": "voice_endpoints.py:chunk_0",
      "file_path": "interfaces\\api\\voice_endpoints.py",
      "chunk_hash": "13c4020c41bc716d3f11cee9b52ace3d2aa079cb12ee260a68feec7c4c4e54c7",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis code defines API endpoints for managing voice assistant sessions, including creating/getting voice conversation sessions and processing voice input, as part of a voice assistant backend service.\n\n2. **Technical Details**  \n- Uses FastAPI\u2019s `APIRouter` to define RESTful endpoints under the `/api/voice` prefix.  \n- Implements lazy initialization of a singleton `VoiceOrchestrator` instance to manage voice session orchestration.  \n- Defines Pydantic models (`VoiceSessionRequest`, `VoiceSessionResponse`, `VoiceProcessRequest`) for request validation and response serialization.  \n- Handles audio data as Base64 encoded strings with specified audio formats (default \"webm\").  \n- Uses Python typing hints for clarity and validation.\n\n3. **Business Logic**  \nEnables clients to initiate or retrieve voice assistant sessions and submit voice data for processing, facilitating interactive voice conversations and session management in a voice assistant application.\n\n4. **Dependencies**  \n- FastAPI for API routing and HTTP exception handling.  \n- Pydantic for data validation and serialization.  \n- Python standard libraries: `uuid` (likely for session IDs), `datetime` for timestamps.  \n- Custom modules: `shared.logger` for logging, `orchestration.voice_assistant.VoiceOrchestrator` for core voice session orchestration logic.\n\n5. **Configuration**  \nNo explicit environment variables or config files are referenced in this snippet. Configuration likely occurs in the `VoiceOrchestrator",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:12.271600",
      "status": "summarized"
    },
    "voice_endpoints.py:chunk_2": {
      "chunk_id": "voice_endpoints.py:chunk_2",
      "file_path": "interfaces\\api\\voice_endpoints.py",
      "chunk_hash": "5d92f6bd1cb5f6a16c98eb798e0d370e5163258e149a46e3bfdb9608ba6c2f7e",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines a data model for voice processing responses and implements an API endpoint to create or retrieve a voice conversation session, maintaining conversational context across multiple voice interactions.\n\n2. **Technical Details**:  \n- Uses Pydantic's `BaseModel` for data validation and serialization (`VoiceProcessResponse`).  \n- Implements an asynchronous FastAPI POST endpoint (`/session`) to handle voice session creation or retrieval.  \n- Utilizes a session manager pattern (`orchestrator.session_manager.get_or_create_session`) to encapsulate session lifecycle management.  \n- Generates a UUID for session ID if not provided, ensuring unique session identification.  \n- Logs request and error information for traceability.\n\n3. **Business Logic**:  \nEnables persistent voice conversation sessions to maintain context and state across multiple user interactions, supporting continuous and coherent voice-based user experiences in applications such as virtual assistants or customer support bots.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and async support.  \n- Pydantic for data modeling and validation.  \n- A custom `get_voice_orchestrator()` function/module that provides orchestration and session management capabilities.  \n- Python standard libraries: `uuid` for unique ID generation, `logging` for logging.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are shown in the snippet; however, the orchestrator and session manager likely rely on external configuration for persistence, timeouts, or resource management, which",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:16.826755",
      "status": "summarized"
    },
    "voice_endpoints.py:chunk_4": {
      "chunk_id": "voice_endpoints.py:chunk_4",
      "file_path": "interfaces\\api\\voice_endpoints.py",
      "chunk_hash": "7f8372358ad7181adc5458493f6b17dc450b916595dc3164dc963a4eb795d5dd",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint to process voice input end-to-end, converting audio into text, identifying user intent, routing the request to appropriate business logic, and returning both textual and synthesized speech responses.\n\n2. **Technical Details**:  \n- Utilizes an asynchronous FastAPI POST endpoint (`/process`) to handle voice processing requests.  \n- Implements a multi-step voice processing pipeline: speech-to-text (STT), intent classification, orchestration routing, response formatting, and text-to-speech (TTS).  \n- Uses a `VoiceRequest` data structure to encapsulate session and audio data.  \n- Invokes an orchestrator component (`get_voice_orchestrator()`) that likely implements the orchestration design pattern to delegate tasks based on intent.  \n- Returns a structured response model (`VoiceProcessResponse`) containing session metadata, transcript, intent, confidence scores, and audio output.\n\n3. **Business Logic**:  \nEnables voice-driven interactions by converting raw audio into actionable commands or queries, supporting scenarios such as committing code, querying GitHub, or general voice assistant tasks. This facilitates hands-free, natural language interfaces to backend services, enhancing user experience and accessibility.\n\n4. **Dependencies**:  \n- `orchestration.voice_assistant.voice_orchestrator.VoiceRequest` for request encapsulation.  \n- FastAPI framework for API routing and HTTP exception handling.  \n- Presumably logging utilities (`logger`) for operational insights.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:22.649858",
      "status": "summarized"
    },
    "voice_endpoints.py:chunk_6": {
      "chunk_id": "voice_endpoints.py:chunk_6",
      "file_path": "interfaces\\api\\voice_endpoints.py",
      "chunk_hash": "841fd6582eb7e19036ab7491029c12a7c03ab9d226375733f6b451f7c2fcbcf2",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint to retrieve the conversation history of a voice interaction session identified by `session_id`. It returns the stored dialogue exchanges for that session.\n\n2. **Technical Details**:  \n- Utilizes FastAPI's router to define a GET HTTP endpoint at `/session/{session_id}/history`.  \n- Calls a voice orchestrator component (`get_voice_orchestrator()`) to access the session manager and fetch conversation history.  \n- Returns a JSON response containing the session ID, the list of conversation history entries, and the count of those entries.  \n- Uses Python async/await syntax for asynchronous request handling.  \n- Employs structured logging for error tracking.\n\n3. **Business Logic**:  \nEnables clients (such as voice assistants or customer service platforms) to retrieve past conversation data for a given session, facilitating features like session continuity, auditing, analytics, or user experience improvements by reviewing prior interactions.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and HTTP exception handling.  \n- A custom voice orchestration module providing `get_voice_orchestrator()` and session management capabilities.  \n- Python standard logging for error reporting.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are shown in this snippet.  \n- Presumably relies on external configuration for the voice orchestrator and session manager setup, which is abstracted away.\n\n6. **Error Handling**:  \n- Catches all",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:27.101017",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_0": {
      "chunk_id": "code_intelligence_api.py:chunk_0",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "fce45bb673792e2acb1bec335b1d509f51d6fbf0f8799a5a0aa2c9af40baf75c",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines a FastAPI-based REST API router to integrate a code intelligence pipeline with a vector database, enabling embedding and querying of rich technical summaries of source code repositories.\n\n2. **Technical Details**  \n- Uses FastAPI's `APIRouter` to define API endpoints under the `/api/code-intelligence` prefix.  \n- Defines Pydantic models (`EmbedRepoRequest`, `EmbedRepoResponse`) for request validation and response serialization.  \n- Dynamically adjusts Python path to import internal modules related to code parsing, summarization, rate limiting, and vector storage.  \n- Imports components like `RateLimitController` for quota management, `RepoState` for repository metadata, `parser_registry` for language parsing, `ChangePlanner` for incremental updates, `EnhancedCodeSummarizer` for generating embeddings, and `VectorStore` for storing embeddings.  \n- Uses asynchronous programming (`asyncio`) to potentially handle concurrent embedding or querying operations.  \n- Logging is configured via a shared logger utility for traceability.\n\n3. **Business Logic**  \nEnables automated embedding of code repositories into a vector database to support advanced code search, summarization, and analysis features within a larger application. This facilitates developer productivity by allowing semantic queries over codebases and maintaining up-to-date embeddings through reindexing.\n\n4. **Dependencies**  \n- FastAPI for API routing and HTTP exception handling.  \n- Pydantic for data validation and serialization.  \n- Python standard",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:31.790456",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_2": {
      "chunk_id": "code_intelligence_api.py:chunk_2",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "a9040c8ac4f195037445bd73f42c612ca47d2af7ae77dce5a745e8ed4e5687eb",
      "chunk_index": 2,
      "summary": "1. **Purpose**  \nThis code defines data models and an orchestrator class to handle code intelligence queries by integrating with Azure AI services and a vector database, enabling semantic search and summarization of code snippets.\n\n2. **Technical Details**  \n- Uses Pydantic `BaseModel` for request (`QueryCodeRequest`) and response (`QueryCodeResponse`) data validation and serialization.  \n- `QueryCodeRequest` supports query text, result limiting, collection targeting, optional filters, and embedding type selection (\"code\", \"summary\", or \"both\").  \n- `CodeIntelligenceOrchestrator` follows an asynchronous initialization pattern to set up components like a rate limiter (`RateLimitController`), repository state management (`RepoState`), and an enhanced summarizer leveraging Azure AI.  \n- The orchestrator maintains internal state flags (`_initialized`) to prevent redundant initialization.  \n- Uses async/await for non-blocking initialization, suggesting integration with async frameworks or event loops.\n\n3. **Business Logic**  \nEnables efficient and scalable semantic code search and summarization within an application, improving developer productivity by providing relevant code intelligence results filtered and ranked by AI-powered embeddings.\n\n4. **Dependencies**  \n- Pydantic for data modeling (`BaseModel`).  \n- Azure AI services (implied by comments and summarizer initialization).  \n- Custom or external modules/classes: `RateLimitController`, `RepoState`, and the summarizer component (not fully shown).  \n- Logging module for operational",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:37.742907",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_4": {
      "chunk_id": "code_intelligence_api.py:chunk_4",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "f7de922faf8470a11269213d31e4ad8b8039c12e7e35ccc0d5b5802532f87d14",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a code intelligence orchestrator that initializes components for summarizing code repositories and embedding their contents into a vector store for enhanced code search and analysis.\n\n2. **Technical Details**:  \n- Uses an `EnhancedCodeSummarizer` class to generate enriched summaries of code, potentially leveraging AI models if available.  \n- Initializes a `VectorStore` instance backed by Qdrant, a vector similarity search engine, specifying a collection name and local storage path.  \n- The `embed_repository` method is asynchronous and designed to embed the contents of a code repository, supporting options for limiting the number of files processed and forcing reindexing.  \n- Initialization is guarded with exception handling to log and propagate errors.\n\n3. **Business Logic**:  \nEnables automated, AI-enhanced indexing and summarization of code repositories to improve developer productivity by facilitating advanced code search, navigation, and understanding within large codebases.\n\n4. **Dependencies**:  \n- `EnhancedCodeSummarizer` (likely a custom or third-party AI summarization tool)  \n- `VectorStore` (wrapper around Qdrant vector database)  \n- `azure_ai_manager.models` (conditional AI model provider from Azure)  \n- `logger` for logging  \n- Python async features for asynchronous embedding operations\n\n5. **Configuration**:  \n- Vector store configured with a fixed collection name `\"code_intelligence\"` and local data path `\"./q",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:44.836962",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_6": {
      "chunk_id": "code_intelligence_api.py:chunk_6",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "be10c2b8da87779130fab2c4108df9f083489f441efb710c3a84d702b3f0167e",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis code snippet orchestrates the process of generating code intelligence embeddings by discovering, prioritizing, parsing, and chunking source code files within a given repository path.\n\n2. **Technical Details**  \n- Uses a `ChangePlanner` class instance to prioritize files based on change detection and other criteria.  \n- Discovers files via a method `_discover_files(repo_path)`.  \n- Detects changed files either by forcing a full reindex or by querying `self.repo_state.get_changed_files(all_files)`.  \n- Prioritizes files with `change_planner.get_top_priority_files()`, limiting the number of files processed.  \n- Parses files using a `parser_registry.parse_file(file_path)` call, which returns chunks of code.  \n- Aggregates all parsed chunks into a single list.  \n- Employs structured logging for progress and error reporting.\n\n3. **Business Logic**  \nThe code supports incremental code intelligence embedding generation, enabling efficient updates by focusing on changed or high-priority files rather than reprocessing the entire codebase. This optimizes resource usage and speeds up embedding refreshes, which are critical for features like code search, navigation, or automated code review.\n\n4. **Dependencies**  \n- `ChangePlanner` class for prioritization logic.  \n- `parser_registry` module or object for file parsing and chunk generation.  \n- `self.repo_state` for tracking repository file changes.  \n- `logger` for logging informational and error messages.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:50.018631",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_8": {
      "chunk_id": "code_intelligence_api.py:chunk_8",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "f6f406dc562ef402185ba81f0f5d8e0fa748be948814695a397201a3b8ccc4ee",
      "chunk_index": 8,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis code snippet processes chunks of source code by generating enhanced natural language summaries, creating dual embeddings (for both raw code and summaries), and storing these embeddings in a vector database for later retrieval or analysis.\n\n2. **Technical Details**  \n- Uses asynchronous calls (`await`) to handle batch summarization and embedding generation, improving concurrency.  \n- Processes a list of code chunks (`all_chunks`), each with associated metadata.  \n- Generates two embeddings per chunk: one from the raw code and one from the enhanced summary.  \n- Constructs metadata dictionaries for each chunk embedding to maintain contextual information.  \n- Prepares embedding points for insertion into a vector database, likely using a list to accumulate these points before batch storage.\n\n3. **Business Logic**  \nEnables enhanced code intelligence features such as semantic search, code navigation, or automated documentation by enriching raw code data with natural language summaries and storing both representations in a vector database for efficient similarity queries.\n\n4. **Dependencies**  \n- An asynchronous summarizer component (`self.summarizer.summarize_batch`) for generating summaries.  \n- An embedding service or method (`self._embed_batch`) that produces vector embeddings from text.  \n- A vector database client or interface for storing embeddings (implied but not shown).  \n- A logger for informational messages.\n\n5. **Configuration**  \nNo explicit configuration or environment variables are shown in this snippet. Configuration might be external and related to the summarizer,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:53:58.170502",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_10": {
      "chunk_id": "code_intelligence_api.py:chunk_10",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "53feeb50bbf330467c749c2bcaf76b4840fd5fe6c5dc6b5cc728c7082ca1b6ed",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet creates and appends two types of embedding points\u2014raw code embeddings and enhanced summary embeddings\u2014for a given code chunk, preparing structured data for downstream processing such as search or analysis.\n\n2. **Technical Details**:  \n- Uses a data structure `EmbeddingPoint` (likely a class or namedtuple) to encapsulate embedding data along with metadata.  \n- Embeddings are indexed by `chunk_id` with suffixes `_code` and `_summary` to distinguish embedding types.  \n- Metadata dictionaries are merged using `**base_metadata` to include common attributes, extended with embedding-specific keys.  \n- The code handles two embedding arrays: `code_embeddings` and `summary_embeddings`, indexed by `i`.  \n- Summaries are retrieved from a dictionary `summaries` keyed by `chunk.chunk_id`.\n\n3. **Business Logic**:  \nSupports a code intelligence or search system by generating vector embeddings for both raw code and enhanced summaries, enabling richer semantic search, code understanding, or recommendation features.\n\n4. **Dependencies**:  \n- `EmbeddingPoint` class or data structure (likely defined elsewhere in the codebase).  \n- Embedding vectors (`code_embeddings`, `summary_embeddings`) presumably generated by an external ML model or embedding service.  \n- `summaries` dictionary containing textual summaries per chunk.  \n- `base_metadata` dictionary with common metadata fields.\n\n5. **Configuration**:  \nNo explicit environment variables or config files",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:05.059528",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_12": {
      "chunk_id": "code_intelligence_api.py:chunk_12",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "15a79465dd93926e6505d3302f7839e2e5f26b02f9612e848a9a7a4014768b46",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet processes and stores embedding points generated from code and summaries into a vector store, updates the repository state for processed files, saves the updated manifest, and returns statistics about the embedding operation.\n\n2. **Technical Details**:  \n- Uses asynchronous batch upsert (`await self.vector_store.upsert_batch`) to efficiently insert embedding points into a vector database.  \n- Embedding points are split evenly between code and summary embeddings, as indicated by the log message.  \n- Iterates over prioritized files to update their processing state in `self.repo_state` using metadata from file chunks.  \n- Maintains repository state and persists it via `self.repo_state.save_manifest()`.  \n- Collects and returns detailed statistics about files and chunks processed, including success and failure counts from the upsert operation.\n\n3. **Business Logic**:  \nSupports a code intelligence platform by embedding code and summary data into a vector store for fast semantic search or analysis. It tracks the processing status of files in a repository to ensure up-to-date indexing and provides operational metrics to monitor ingestion quality and progress.\n\n4. **Dependencies**:  \n- `self.vector_store`: An asynchronous vector database client or abstraction supporting batch upsert operations.  \n- `self.repo_state`: A repository state manager responsible for tracking file processing status and persisting manifests.  \n- `logger`: For structured logging of processing metrics.  \n- Data structures like `embedding_points`, `prioritized_files`, `all",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:11.491252",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_14": {
      "chunk_id": "code_intelligence_api.py:chunk_14",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "91e12d47226377435ec165013547ab7b6eaa8107fb5d3906ef57451596c46bf8",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method `_embed_batch` generates two types of vector embeddings for a batch of code chunks: one embedding representing the raw code for exact matching, and another embedding derived from enhanced summaries combined with code context for conceptual or semantic search.\n\n2. **Technical Details**:  \n- The method processes input `chunks` in batches, where batch size is dynamically determined by a rate limiter (`self.rate_limiter.get_adaptive_batch_size`).  \n- For each batch, it extracts two sets of text inputs: raw code snippets truncated to 2000 characters, and enhanced summary texts combining a summary string (from a dictionary keyed by chunk ID) with the first 500 characters of the code context.  \n- It returns a tuple of two lists of embeddings (`code_embeddings`, `summary_embeddings`), presumably generated later in the method (not shown in the snippet).  \n- Uses asynchronous programming (`async def`) to support concurrency and potentially I/O-bound embedding generation calls.\n\n3. **Business Logic**:  \nThe code supports a code intelligence platform that indexes source code for two distinct search modalities: exact code retrieval (via raw code embeddings) and conceptual/semantic search (via enhanced summary embeddings). This dual embedding strategy improves search relevance and developer productivity by enabling both precise and contextual code discovery.\n\n4. **Dependencies**:  \n- A `rate_limiter` component that manages adaptive batch sizing based on quota constraints (`QuotaType.EMBEDDING`).",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:15.287041",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_16": {
      "chunk_id": "code_intelligence_api.py:chunk_16",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "363008d4dd9a7987b125c05b75b04e93bdb2cc741e35c3b8c3a81761fbdf70fc",
      "chunk_index": 16,
      "summary": "**Summary:**\n\n1. **Purpose**:  \nThis code asynchronously generates vector embeddings for raw source code snippets and their enhanced summaries using Azure OpenAI's embedding models, enabling semantic understanding and downstream processing.\n\n2. **Technical Details**:  \n- Defines two asynchronous functions, `embed_code` and `embed_summaries`, each calling Azure OpenAI's embedding API with the `\"text-embedding-3-large\"` model.  \n- Uses `asyncio.gather` to run both embedding tasks concurrently, improving throughput.  \n- Employs a rate limiter (`self.rate_limiter.submit`) to control API usage quotas and prioritize embedding requests.  \n- Extracts embeddings from the API response by iterating over returned items.\n\n3. **Business Logic**:  \nTransforms raw code and its summaries into vector embeddings to support features like code search, similarity detection, or AI-assisted code intelligence, enhancing developer productivity and codebase insights.\n\n4. **Dependencies**:  \n- `azure_ai_manager`: A module managing Azure OpenAI API interactions.  \n- `asyncio`: Python's asynchronous concurrency library.  \n- `self.rate_limiter`: Custom or third-party rate limiting utility managing API quota and prioritization.  \n- Constants/enums like `QuotaType.EMBEDDING` for quota categorization.\n\n5. **Configuration**:  \n- Requires Azure OpenAI credentials and endpoint configuration within `azure_ai_manager`.  \n- Model name `\"text-embedding-3-large\"` is hardcoded but could",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:20.740488",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_18": {
      "chunk_id": "code_intelligence_api.py:chunk_18",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "0ee84b254ed3545967ac819ca2478aaa73753cd865b0e62bdb6430c32fd93a30",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a module that processes batches of code and summary texts to generate embeddings, and discovers code files within a repository directory. It handles embedding requests with rate limiting and manages file discovery while excluding irrelevant directories.\n\n2. **Technical Details**:  \n- Uses a rate limiter (`self.rate_limiter.submit`) to manage quota consumption when generating embeddings for code and summaries.  \n- Embeddings are generated in batches and appended to cumulative lists (`code_embeddings`, `summary_embeddings`).  \n- On failure during embedding, placeholder zero vectors of fixed size (3072 floats) are appended to maintain alignment.  \n- File discovery uses `os.walk` to recursively traverse directories, filtering out unwanted folders (e.g., `.git`, `node_modules`).  \n- Supported file extensions are dynamically retrieved from a `parser_registry` component, indicating a plugin or registry pattern for extensibility.\n\n3. **Business Logic**:  \nThe code supports a code intelligence platform or service that indexes and analyzes source code repositories by generating vector embeddings for code snippets and their summaries. This enables features like semantic search, code recommendations, or automated documentation.\n\n4. **Dependencies**:  \n- Standard Python libraries: `os`, `pathlib.Path` for filesystem operations.  \n- A `parser_registry` module or object that provides supported file extensions.  \n- A `rate_limiter` component managing quota and prioritization of embedding requests.  \n- A logging utility (`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:26.557806",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_20": {
      "chunk_id": "code_intelligence_api.py:chunk_20",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "ad5fa3ae9de2fa1bd015dde8138d21e122ae9c21bd7b5c25e9a0fa265357344f",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a code intelligence API that performs semantic search queries over source code files within a repository. It filters files by extension and executes natural language queries to retrieve relevant code chunks with summaries.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running operations such as embedding generation and querying.  \n- Filters directory traversal by excluding certain patterns and selecting files based on supported extensions.  \n- Employs semantic search by generating vector embeddings of the query and code snippets, supporting different embedding types (\"code\", \"summary\", or \"both\").  \n- Uses Python `Path` objects for filesystem path manipulations and relative path calculations.  \n- Maintains filters as dictionaries to refine search results based on metadata like language or file path.\n\n3. **Business Logic**:  \nEnables developers or automated systems to perform intelligent, semantic searches over large codebases, improving code discoverability, understanding, and reuse. This supports tasks such as code review, debugging, and knowledge management by returning relevant code snippets matching natural language queries.\n\n4. **Dependencies**:  \n- Likely depends on asynchronous libraries such as `asyncio`.  \n- Uses Python standard libraries like `pathlib` for file path operations.  \n- Presumably integrates with an embedding service or machine learning model for generating vector representations (`_embed_query` method).  \n- May rely on an external vector database or search backend to perform semantic similarity",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:32.836481",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_22": {
      "chunk_id": "code_intelligence_api.py:chunk_22",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "9509adf5151406c520716c20089e50281ee6c320fce5fbdfa5193d6e661f6f5e",
      "chunk_index": 22,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a search functionality that queries a vector database using different types of code embeddings (\"raw_code\", \"enhanced_summary\", or both) and merges results when searching across multiple embedding types to provide deduplicated, combined search results.\n\n2. **Technical Details**:  \n- Uses a dictionary `search_filters` to specify the embedding type filter for the vector search.  \n- Calls a `vector_store.search()` method with a query embedding and a limit, adjusting the limit when searching both embedding types to allow for deduplication.  \n- Implements a private method `_merge_dual_results` that merges search results by grouping them based on a `parent_chunk_id` metadata field, combining scores from different embedding types for the same chunk.  \n- Uses a dictionary (`chunk_map`) to aggregate and deduplicate results keyed by `parent_chunk_id`.\n\n3. **Business Logic**:  \nEnables flexible and accurate code search by allowing users to search using different embedding types (raw code embeddings, summary embeddings, or both). When searching both, it merges results to avoid duplicates and improve relevance, enhancing developer productivity by providing more comprehensive and relevant code intelligence.\n\n4. **Dependencies**:  \n- A vector search store or database abstraction (`self.vector_store`) that supports embedding-based search with filtering and scoring.  \n- Python standard data structures (`dict`, `list`).  \n- Likely depends on external vector database or embedding generation services (not shown",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:39.641492",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_24": {
      "chunk_id": "code_intelligence_api.py:chunk_24",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "50d3e7d14d686c6d62b4a2ebe67444534b53186a75f86970e9410849a22abbb3",
      "chunk_index": 24,
      "summary": "1. **Purpose**:  \nThis code snippet processes a collection of code intelligence results by aggregating scores from different embedding types (raw code and enhanced summary), computing a weighted combined score for each code chunk, and preparing the results for ranking and retrieval.\n\n2. **Technical Details**:  \n- Uses a dictionary (`chunk_map`) keyed by `parent_id` to aggregate data for each code chunk.  \n- Filters metadata to exclude the `\"embedding_type\"` key when copying.  \n- Assigns scores conditionally based on the embedding type (`raw_code` or `enhanced_summary`).  \n- Computes a weighted combined score with fixed weights (40% code score, 60% summary score).  \n- Prepares a sorted list of merged results based on the combined score for downstream consumption.\n\n3. **Business Logic**:  \nThe code supports a code intelligence system that ranks code snippets or chunks by relevance and quality, combining raw code similarity and enhanced summary information to improve search or recommendation accuracy. This helps developers quickly find the most relevant code segments with contextual summaries.\n\n4. **Dependencies**:  \n- Implicitly depends on the structure of `result` objects, which likely come from an embedding or vector search service.  \n- No explicit external libraries shown in the snippet, but likely integrated with a vector database or ML model producing embeddings and scores.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in this snippet.  \n- The weighting factors (0",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:50.814031",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_26": {
      "chunk_id": "code_intelligence_api.py:chunk_26",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "327aeb3409f0e24c6043a21ee600f1f25b82cf8a6137088fbe63b04e1ca99bb7",
      "chunk_index": 26,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a backend service that processes code intelligence data by embedding queries into vector representations and ranking results based on combined scoring metrics. It provides asynchronous embedding generation and resource cleanup functionalities.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle embedding requests efficiently.  \n- Implements a rate limiter (`self.rate_limiter.submit`) to control usage quotas and prioritize embedding requests.  \n- Processes a collection of code intelligence data (`chunk_map.values()`), extracting relevant fields and sorting results by a combined score in descending order.  \n- Encapsulates embedding logic inside an inner async function (`embed`) to be submitted to the rate limiter.  \n- Uses a global orchestrator instance (`CodeIntelligenceOrchestrator`) to coordinate operations.  \n- The snippet ends with a FastAPI route decorator (`@router.post(\"/embed\")`), indicating an HTTP POST endpoint for embedding requests.\n\n3. **Business Logic**:  \nThe code supports a code intelligence platform that helps developers by embedding code or query text into vector space for similarity search or ranking. This enables features like code search, summarization, or recommendation by scoring and returning the most relevant code snippets or summaries.\n\n4. **Dependencies**:  \n- `azure_ai_manager.models.create_embeddings`: Azure AI service for generating text embeddings.  \n- `self.rate_limiter`: Custom or third-party rate limiting utility managing quota and prioritization.  \n- FastAPI (",
      "embedding_id": null,
      "created_at": "2025-10-22T19:54:58.252140",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_28": {
      "chunk_id": "code_intelligence_api.py:chunk_28",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "dc78d865c647fcf030effde85bfacb90e84e66b3795296ddfe18e4bdea099812",
      "chunk_index": 28,
      "summary": "1. **Purpose**  \nThis code provides asynchronous API endpoints to embed a code repository into a vector database with enhanced technical summaries and to query the embedded code using semantic search with multiple embedding types.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) for non-blocking I/O operations.  \n- The `embed_repository` function orchestrates repository embedding by discovering code files, generating summaries, embedding code and summaries, and storing them in a vector database.  \n- The `query_code` endpoint supports semantic search over embeddings with three modes: \"code\" (raw code embeddings), \"summary\" (conceptual summaries), and \"both\" (merged results).  \n- Employs structured request and response models (`EmbedRepoRequest`, `EmbedRepoResponse`, `QueryCodeRequest`, `QueryCodeResponse`) for data validation and serialization.  \n- Uses a centralized orchestrator component (`orchestrator.embed_repository`) to encapsulate embedding logic, promoting separation of concerns.\n\n3. **Business Logic**  \nEnables enhanced code intelligence by embedding repositories with rich technical summaries to improve searchability and understanding of codebases. This supports developer productivity tools, code review automation, or knowledge management systems by allowing semantic search over code and its summaries.\n\n4. **Dependencies**  \n- An `orchestrator` module or service responsible for embedding repositories.  \n- A vector database for storing embeddings (implied, not explicitly shown).  \n- Logging (`logger`) for error tracking.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:10.777327",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_30": {
      "chunk_id": "code_intelligence_api.py:chunk_30",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "15ef9c8717c7e175a21d33258298e1042e892aeae7f99719981171b082d3aa95",
      "chunk_index": 30,
      "summary": "1. **Purpose**  \nThis Python code defines an asynchronous API endpoint `/status` within a code intelligence service, providing real-time status information about the system\u2019s readiness, vector database state, repository statistics, and supported programming languages.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async def`) to handle I/O-bound operations efficiently.  \n- Interacts with an `orchestrator` component that manages code querying, vector store operations, and repository state.  \n- Retrieves metadata from a vector database collection and repository statistics via method calls (`get_collection_info()`, `get_stats()`).  \n- Utilizes a `parser_registry` to obtain supported programming languages, likely a registry pattern managing language parsers.  \n- Implements structured JSON response returning system status and diagnostic data.\n\n3. **Business Logic**  \nThe endpoint supports operational monitoring and health checks of the code intelligence platform, enabling clients or administrators to verify system readiness and inspect underlying data stores and repository indexing status, which is critical for maintaining reliable code search and analysis services.\n\n4. **Dependencies**  \n- `orchestrator`: Core service component managing code queries, vector store, and repository state.  \n- `parser_registry`: Registry managing supported language parsers.  \n- `logger`: For error logging.  \n- `HTTPException`: From a web framework (likely FastAPI or similar) for HTTP error responses.  \n- Asynchronous web framework router (`@router.get`) for endpoint declaration.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:18.193415",
      "status": "summarized"
    },
    "code_intelligence_api.py:chunk_32": {
      "chunk_id": "code_intelligence_api.py:chunk_32",
      "file_path": "interfaces\\code_intelligence_api.py",
      "chunk_hash": "e2d1c93da44303ef96348651edf8ef825674bf500f8c51004a4e545b68170c32",
      "chunk_index": 32,
      "summary": "1. **Purpose**:  \nThis code defines a health check API endpoint (`/health`) that verifies the operational status of various system components including an orchestrator, a vector store, and an Azure OpenAI service.\n\n2. **Technical Details**:  \n- Uses an asynchronous FastAPI route handler (`@router.get(\"/health\")`) for non-blocking I/O operations.  \n- Calls `orchestrator.initialize()` asynchronously to prepare or verify system readiness.  \n- Checks health status of the vector store via `orchestrator.vector_store.health_check()`.  \n- Queries availability of Azure OpenAI models through `azure_ai_manager.models.is_available()`.  \n- Returns a JSON response indicating health status and any error messages.  \n- Exception handling wraps the entire logic to catch and report errors gracefully.\n\n3. **Business Logic**:  \nEnsures system reliability by providing a centralized health endpoint that can be polled by monitoring tools or load balancers to detect service availability and readiness, thus supporting operational stability and uptime guarantees.\n\n4. **Dependencies**:  \n- `orchestrator`: Likely a core service managing workflows or data orchestration.  \n- `azure_ai_manager`: Manages Azure OpenAI service interactions.  \n- `parser_registry` (mentioned in the snippet before the endpoint): Possibly manages supported file extensions or parsers.  \n- FastAPI framework for routing and async support.\n\n5. **Configuration**:  \n- Implicit reliance on configuration for orchestrator initialization and Azure",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:23.425191",
      "status": "summarized"
    },
    "services_api.py:chunk_0": {
      "chunk_id": "services_api.py:chunk_0",
      "file_path": "interfaces\\services_api.py",
      "chunk_hash": "a31c2363af8fa2f9b7da9e9b377dfb379d7a74b24987c12e90b7a234b9748c26",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines API endpoints for managing and connecting to various external services through a FastAPI router. It allows clients to request connections to services and execute actions on them dynamically.\n\n2. **Technical Details**:  \n- Uses FastAPI to create RESTful API endpoints with asynchronous support.  \n- Defines Pydantic models (`ServiceConnectionRequest`, `ServiceActionRequest`) for request validation and serialization.  \n- Utilizes a service manager pattern (`service_manager`) to handle lifecycle and interaction with different service instances.  \n- Employs a mapping from service type strings to concrete service classes (e.g., `GitHubService`, `ConfluenceService`) to instantiate appropriate service handlers dynamically.  \n- Logging is integrated via a shared logger for traceability and debugging.\n\n3. **Business Logic**:  \nEnables the dynamic integration and management of multiple third-party or internal services (e.g., GitHub, Confluence, Azure services) through a unified API. This supports business workflows that require connecting to and interacting with diverse service platforms without hardcoding service-specific logic in the client applications.\n\n4. **Dependencies**:  \n- **FastAPI**: For API routing and request handling.  \n- **Pydantic**: For data validation and serialization of request bodies.  \n- **Typing**: For type annotations.  \n- **Shared modules**:  \n  - `service_manager` for managing service instances.  \n  - `ServiceConfig` for encapsulating service",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:31.173485",
      "status": "summarized"
    },
    "services_api.py:chunk_2": {
      "chunk_id": "services_api.py:chunk_2",
      "file_path": "interfaces\\services_api.py",
      "chunk_hash": "1cb7095b62e4ae7a59905acf920c1505161221ad12c02616e8bdae46bd02e334",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code dynamically selects and instantiates a service class based on a requested service type, registers the service with a service manager, attempts to connect to the service, and returns a structured response indicating success or failure along with the service status.\n\n2. **Technical Details**:  \n- Uses a dictionary (`service_classes`) to map string identifiers to service class constructors, enabling dynamic service instantiation (a form of the Factory pattern).  \n- Retrieves the appropriate service class by normalizing the input service type to lowercase and performing a dictionary lookup.  \n- Asynchronously registers and connects the service using `await` calls on `service_manager` methods, indicating an async I/O model.  \n- Returns JSON-like dictionaries as responses with keys such as `\"success\"`, `\"error\"`, `\"message\"`, and `\"status\"`.  \n- Uses the service instance\u2019s `get_status()` method to fetch current service state for response payloads.\n\n3. **Business Logic**:  \nEnables integration with multiple external or internal services (e.g., GitHub, Confluence, MongoDB, Azure services) by abstracting service initialization and connection logic. This supports a modular, pluggable architecture where new services can be added with minimal changes, facilitating extensibility in a multi-service environment.\n\n4. **Dependencies**:  \n- Custom service classes: `GitHubService`, `ConfluenceService`, `MongoDBService`, `AzureSpeechService`, `AzureTranslatorService`,",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:37.132872",
      "status": "summarized"
    },
    "services_api.py:chunk_4": {
      "chunk_id": "services_api.py:chunk_4",
      "file_path": "interfaces\\services_api.py",
      "chunk_hash": "507624260c4f06527314530d431d672d33b503411e570fd913d75eb5b4e94e88",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous API endpoints for managing external service connections, executing actions on those services (optionally enhanced by a language model), and retrieving the status of all connected services.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O operations without blocking.  \n- Implements RESTful API endpoints using a router (likely FastAPI or similar framework).  \n- Utilizes a service manager abstraction (`service_manager`) to encapsulate service operations such as disconnecting, executing actions with optional LLM enhancement, and fetching statuses.  \n- Employs structured logging (`logger.error`) for error tracking.  \n- Raises HTTP exceptions (`HTTPException`) to communicate errors with appropriate HTTP status codes and messages.\n\n3. **Business Logic**:  \nEnables dynamic management of external services by allowing clients to disconnect services, execute complex actions (potentially enhanced by a large language model for improved results), and monitor the health/status of all services. This supports business workflows that depend on orchestrating multiple service integrations reliably.\n\n4. **Dependencies**:  \n- `service_manager`: a module or class responsible for service lifecycle and action execution.  \n- `logger`: a logging utility for error reporting.  \n- `HTTPException`: likely from FastAPI or Starlette for HTTP error handling.  \n- `ServiceActionRequest`: a data model (probably a Pydantic model) representing the payload for the execute endpoint.\n\n5. **",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:43.190083",
      "status": "summarized"
    },
    "services_api.py:chunk_6": {
      "chunk_id": "services_api.py:chunk_6",
      "file_path": "interfaces\\services_api.py",
      "chunk_hash": "6ee9980bb45223dac4ec525865b03afbe3ac107401320a2483a61a302d637019",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis Python code defines a set of asynchronous REST API endpoints to manage and monitor various services, including retrieving service statuses, listing all services, and testing service connections.\n\n2. **Technical Details**  \n- Uses FastAPI framework with asynchronous route handlers (`async def`) for non-blocking I/O operations.  \n- Employs a service manager abstraction (`service_manager`) to interact with service objects.  \n- Each service exposes methods like `get_status()` (sync) and `get_capabilities()` (async).  \n- Standard JSON response structure with `\"success\"` flags and relevant data or error messages.  \n- Logging is used for error tracking (`logger.error`).  \n- HTTP exceptions (`HTTPException`) are raised with appropriate status codes on failures.\n\n3. **Business Logic**  \nEnables clients (e.g., frontend dashboards or monitoring tools) to:  \n- Check the operational status and capabilities of individual services.  \n- Retrieve a list of all registered services for inventory or management purposes.  \n- Test connectivity or functionality of a specific service to ensure reliability and troubleshoot issues.\n\n4. **Dependencies**  \n- FastAPI for API routing and HTTP exception handling.  \n- An external or internal `service_manager` module that manages service lifecycle and data.  \n- A logging framework (likely Python\u2019s standard `logging` module).  \n- Possibly asyncio for asynchronous operations.\n\n5. **Configuration**  \n- Not explicitly shown in the snippet, but likely relies on:  \n  -",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:50.178217",
      "status": "summarized"
    },
    "services_api.py:chunk_8": {
      "chunk_id": "services_api.py:chunk_8",
      "file_path": "interfaces\\services_api.py",
      "chunk_hash": "b2420a842efa9dc74495f0d4286e7a5322c8a8efd958a69b999ebf8734804beb",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet attempts to retrieve a service by name and test its connectivity, returning the test result or an error message if the service is not found.\n\n2. **Technical Details**:  \n- Uses an asynchronous call (`await service.test_connection()`) to test the service connection, indicating the service supports async operations.  \n- Retrieves the service instance via `service_manager.get_service(service_name)`.  \n- Returns a dictionary with success or error information.  \n- Exception handling wraps the entire operation to log errors and raise an HTTP 500 error.\n\n3. **Business Logic**:  \nEnables validation of external or internal services by testing their connectivity/status, which is critical for health checks, diagnostics, or onboarding new services dynamically.\n\n4. **Dependencies**:  \n- `service_manager`: a module or object responsible for managing service instances.  \n- `logger`: for error logging.  \n- `HTTPException`: likely from FastAPI or Starlette, used to return HTTP error responses.\n\n5. **Configuration**:  \nNo explicit configuration shown, but the `service_manager` likely depends on configuration files or environment variables to know available services and their connection parameters.\n\n6. **Error Handling**:  \n- Handles the case where the requested service does not exist, returning a structured error response.  \n- Catches all exceptions during the connection test, logs the error, and raises an HTTP 500 error with the exception details.\n\n7. **",
      "embedding_id": null,
      "created_at": "2025-10-22T19:55:56.906464",
      "status": "summarized"
    },
    "teams_bot.py:chunk_0": {
      "chunk_id": "teams_bot.py:chunk_0",
      "file_path": "interfaces\\teams_bot.py",
      "chunk_hash": "5f62030579ab508c000a8baf2249834b4d63607d7bb182af8c6bd3b2a6f8864a",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python code defines a Microsoft Teams bot (`AIDevBot`) that listens for user messages and triggers an issue analysis workflow when a message starts with the keyword \"analyze\". It processes commands to analyze issues from specified sources and provides feedback to the user within the Teams chat.\n\n2. **Technical Details**:  \n- Implements the `ActivityHandler` class from the Bot Framework SDK to handle incoming message activities asynchronously.  \n- Parses user input text to extract command parameters (`source` and `issue_id`).  \n- Uses a command pattern where the first word triggers an action (\"analyze\").  \n- Constructs a `ContextResolverInput` data transfer object to encapsulate issue context parameters.  \n- Integrates with a context resolver and issue analyzer modules (`resolve_context`, `analyze_issue`) to process the issue data.  \n- Uses Python\u2019s `logging` module for informational logging.  \n- Employs async/await for asynchronous message handling and processing.\n\n3. **Business Logic**:  \nThe bot automates the process of analyzing software development issues (e.g., bugs, tickets) from various sources (like GitHub, Jira). It enables developers or support teams to quickly request and receive analysis results directly within Microsoft Teams, improving issue triage and resolution efficiency.\n\n4. **Dependencies**:  \n- `botbuilder.core` and `botbuilder.schema` from Microsoft Bot Framework SDK for Teams integration.  \n- Custom modules: `features.context_resolver",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:02.064210",
      "status": "summarized"
    },
    "teams_bot.py:chunk_2": {
      "chunk_id": "teams_bot.py:chunk_2",
      "file_path": "interfaces\\teams_bot.py",
      "chunk_hash": "86f4543c7d599b7610055380e643caaadf7fdd455bfc8540663ed25e7643d069",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet processes a user command to analyze an issue by resolving context, performing an analysis, and returning a formatted response with the analysis results or error messages via a Teams bot interface.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running I/O operations without blocking.  \n- Invokes `resolve_context(context_input)` to obtain enriched context data, likely returning a result object with success status and enriched data or error message.  \n- Constructs an `EnrichedContext` data structure via unpacking (`**context_result.enriched_data`), indicating use of a data class or similar structure for typed context representation.  \n- Calls `analyze_issue(enriched_context)` asynchronously to perform the core issue analysis, returning an object with properties like `issue_id`, `root_cause`, `confidence_score`, and `suggested_fixes`.  \n- Formats a multi-line Markdown response string summarizing the analysis results, including confidence as a percentage and count of suggested fixes.  \n- Uses `turn_context.send_activity(MessageFactory.text(response))` to send messages back to the user, indicating integration with Microsoft Bot Framework or similar messaging SDK.  \n- Contains a usage hint fallback if the command format is incorrect.\n\n3. **Business Logic**:  \nEnables users (likely support or engineering teams) to submit issue identifiers and source information to receive automated root cause analysis and suggested fixes, streamlining troubleshooting and reducing",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:06.718396",
      "status": "summarized"
    },
    "teams_bot.py:chunk_4": {
      "chunk_id": "teams_bot.py:chunk_4",
      "file_path": "interfaces\\teams_bot.py",
      "chunk_hash": "5a663fbecff0930161fadfa22a62aea58a4a641392055c51df646dba9c55a93c",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet implements part of a Teams bot named \"AI Dev Agent\" that interacts with users by processing text commands such as \"help\", \"status\", and unknown commands, and sends appropriate responses. It also welcomes new members added to the conversation.\n\n2. **Technical Details**:  \n- The bot listens for incoming messages and uses conditional branching (`if-elif-else`) to parse command text.  \n- Commands handled include:  \n  - `\"help\"`: Sends a multi-line help message describing available commands.  \n  - `\"status\"`: Sends a status confirmation message.  \n  - Default: Sends a message indicating an unknown command.  \n- The `on_members_added_activity` asynchronous method detects when new members join the conversation and sends a greeting message to each new member except the bot itself.  \n- Uses asynchronous programming (`async/await`) to handle I/O-bound operations with the Teams API.  \n- Utilizes `MessageFactory.text()` to create message activities for sending responses.\n\n3. **Business Logic**:  \nThe bot serves as an AI development assistant within Microsoft Teams, providing users with quick access to commands related to issue analysis and bot status, improving developer productivity and collaboration by integrating issue tracking and bot status updates directly into the chat interface.\n\n4. **Dependencies**:  \n- Microsoft Bot Framework SDK for Python (implied by use of `TurnContext`, `ChannelAccount`, and `MessageFactory`).  \n- The bot likely depends",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:11.900808",
      "status": "summarized"
    },
    "translation_api.py:chunk_0": {
      "chunk_id": "translation_api.py:chunk_0",
      "file_path": "interfaces\\translation_api.py",
      "chunk_hash": "eac8e802f07f3a342f1e895405f2e237fb37bc1c04b561b7875b033e86b5cab3",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines REST API endpoints for text translation and language detection using Azure's Translation Service, enabling multilingual chat capabilities within an LLM testing environment.\n\n2. **Technical Details**:  \n- Utilizes FastAPI's `APIRouter` to modularize API endpoints under the `/api/translation` prefix.  \n- Defines Pydantic models (`TranslationRequest`, `TranslationResponse`, `LanguageDetectionRequest`, `LanguageDetectionResponse`) for request validation and response serialization.  \n- Integrates with an external `AzureTranslationService` class to perform translation and language detection operations.  \n- Uses Python's standard logging for traceability and debugging.\n\n3. **Business Logic**:  \nProvides a backend translation and language detection service to support multilingual interactions in a large language model (LLM) testing platform, facilitating communication across different languages and improving user experience.\n\n4. **Dependencies**:  \n- `fastapi` for API framework and routing.  \n- `pydantic` for data validation and serialization.  \n- `logging` for application logging.  \n- Custom module `shared.azure_services` which encapsulates Azure Translation Service integration.\n\n5. **Configuration**:  \n- The code snippet does not explicitly show environment variables or config files, but the `AzureTranslationService` likely requires Azure credentials and endpoint configurations, typically set via environment variables or configuration files external to this module.\n\n6. **Error Handling**:  \n- Uses FastAPI's `HTTPException`",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:17.310782",
      "status": "summarized"
    },
    "translation_api.py:chunk_2": {
      "chunk_id": "translation_api.py:chunk_2",
      "file_path": "interfaces\\translation_api.py",
      "chunk_hash": "9a760da315f6766d67c6ec3965d86dfe8a56583a16fbf737dbe103533167b61a",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis asynchronous function translates a given text into a specified target language, auto-detecting the source language if not provided, with a default target language of English.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running translation calls without blocking.  \n- Checks service availability before proceeding.  \n- Logs key information about the translation request for traceability.  \n- Invokes an external translation service asynchronously to perform the actual translation and language detection.  \n- Returns a structured response object encapsulating original text, translated text, detected source language, target language, success status, and a descriptive message.\n\n3. **Business Logic**:  \nEnables multilingual support by translating user input or content into a target language, facilitating communication, localization, or content adaptation in applications that require language translation capabilities.\n\n4. **Dependencies**:  \n- `translation_service`: An external or internal module/service responsible for performing the translation and language detection.  \n- `TranslationRequest` and `TranslationResponse`: Data models representing the input request and output response structures.  \n- `HTTPException`: Likely from a web framework (e.g., FastAPI) to handle HTTP error responses.  \n- `logger`: For logging informational messages.\n\n5. **Configuration**:  \n- The availability of the translation service depends on its configuration, presumably set via environment variables or config files (e.g., Azure Translation Service credentials).  \n- Default target language is English",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:26.431679",
      "status": "summarized"
    },
    "translation_api.py:chunk_4": {
      "chunk_id": "translation_api.py:chunk_4",
      "file_path": "interfaces\\translation_api.py",
      "chunk_hash": "e1feb293fe8197ddfe50489ad768a6c7cfc7c2550e06f93923da37569f4ddf94",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint that translates input text from any detected language into English using an external translation service.\n\n2. **Technical Details**:  \n- Uses FastAPI's `@router.post` decorator to define an HTTP POST endpoint.  \n- Asynchronous function `translate_to_english` accepts a string parameter `text`.  \n- Calls an asynchronous method `translation_service.translate_to_english(text)` which returns a tuple of translated text and detected source language.  \n- Returns a `TranslationResponse` model containing original text, translated text, source and target languages, success status, and a message.  \n- Logging is used for informational and error messages.  \n- Raises `HTTPException` with appropriate HTTP status codes for error signaling.\n\n3. **Business Logic**:  \nProvides a convenient, reliable translation endpoint primarily for chat or voice applications that require automatic detection of the input language and translation into English, facilitating multilingual communication and content understanding.\n\n4. **Dependencies**:  \n- FastAPI framework (`HTTPException`, routing).  \n- A `translation_service` module or object that interfaces with an external translation API (likely Azure Translation Service).  \n- A `TranslationResponse` Pydantic model for response serialization.  \n- A `logger` for logging events and errors.\n\n5. **Configuration**:  \n- The availability of the translation service is checked via `translation_service.is_available()`, which likely depends on environment variables or configuration files specifying API keys",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:32.415192",
      "status": "summarized"
    },
    "translation_api.py:chunk_6": {
      "chunk_id": "translation_api.py:chunk_6",
      "file_path": "interfaces\\translation_api.py",
      "chunk_hash": "93c93e6ec09fba8740f93900d17f7a93bb924d511b0f32371c6619211fd297bf",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis code provides API endpoints for language detection and health checking of an Azure-based translation service. It enables clients to detect the language of a given text and verify the availability of the translation service.\n\n2. **Technical Details**  \n- Implements asynchronous FastAPI route handlers (`@router.post` and `@router.get`).  \n- Uses a service abstraction (`translation_service`) to interact with Azure Translation APIs.  \n- Returns structured response models (`LanguageDetectionResponse`) for consistent API output.  \n- Logging is used for operational insight and debugging.  \n- Exception handling converts internal errors into HTTP responses with appropriate status codes.\n\n3. **Business Logic**  \nSolves the business need to automatically identify the language of user-provided text, which is critical for multilingual applications requiring language-specific processing or translation. The health endpoint supports operational monitoring to ensure service reliability.\n\n4. **Dependencies**  \n- FastAPI framework for API routing and HTTP exception handling.  \n- An external `translation_service` module or class that wraps Azure Translation API calls.  \n- Logging module for event tracking.  \n- Pydantic models (`LanguageDetectionRequest`, `LanguageDetectionResponse`) for request validation and response serialization.\n\n5. **Configuration**  \n- The availability and endpoint URL of the Azure Translation Service are likely configured externally, possibly via environment variables or config files accessed by `translation_service.is_available()` and `translation_service.translation_endpoint`.  \n- No explicit configuration code shown, but the service abstraction implies external",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:40.684770",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_0": {
      "chunk_id": "unified_ai_api.py:chunk_0",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "cd50308fe016b8ded6f85329d984c28b1ec1fbe2666490814c5e9a4cc8f741c4",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a unified, cloud-agnostic API layer for AI services such as chat completion, speech-to-text transcription, and translation. It abstracts away provider-specific implementations by routing requests through a common orchestration layer.\n\n2. **Technical Details**:  \n- Uses FastAPI\u2019s `APIRouter` to define REST API endpoints under the `/api/ai` prefix.  \n- Defines Pydantic models (`ChatRequest`, `TranscriptionRequest`, `TranslationRequest`) for request validation and serialization.  \n- Maintains an in-memory dictionary `_provider_config` to select default AI service providers for speech-to-text, chat, and text-to-speech.  \n- Imports an orchestration layer (`orchestrator`) and a provider registry (`register_all_providers`) to dynamically route requests to appropriate cloud providers.  \n- Uses base64 encoding for audio data transmission in transcription requests.\n\n3. **Business Logic**:  \nEnables clients to interact with multiple AI service providers through a single, consistent API interface, simplifying integration and reducing the need to manage provider-specific APIs. This supports flexibility in choosing or switching AI providers without changing client code.\n\n4. **Dependencies**:  \n- FastAPI for API routing and request handling.  \n- Pydantic for data validation and serialization.  \n- Base64 for encoding/decoding audio data.  \n- Custom orchestration modules (`orchestration.cloud_providers.registry`, `orchestration.cloud_providers.or",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:47.202838",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_2": {
      "chunk_id": "unified_ai_api.py:chunk_2",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "a412eb0bc3a590b29f5b535232c4054711d926db45614e93d34b9d7208ad9617",
      "chunk_index": 2,
      "summary": "1. **Purpose**  \nThis Python code defines an API endpoint `/chat` that provides chat completion services by orchestrating multiple large language model (LLM) providers. It routes requests to the best available provider based on user preference or a fallback chain.\n\n2. **Technical Details**  \n- Uses FastAPI-style asynchronous endpoint (`async def`) for non-blocking I/O.  \n- Defines Pydantic models (`TTSRequest`, `ChatRequest` implied) for request validation and serialization.  \n- Implements a provider orchestration pattern where a preferred provider is used if specified; otherwise, a fallback chain (Azure \u2192 Together AI \u2192 OpenAI) is employed.  \n- Logging is used for request tracing and debugging.  \n- The orchestrator component handles the actual interaction with LLM providers and returns a unified response object containing content, model info, provider metadata, and usage statistics.\n\n3. **Business Logic**  \nEnables a unified chat interface that abstracts multiple LLM providers, allowing seamless failover and provider preference. This ensures high availability and flexibility in delivering AI-powered chat completions to end-users or client applications.\n\n4. **Dependencies**  \n- `FastAPI` or similar ASGI framework for routing and async endpoint handling.  \n- `Pydantic` for data validation (`BaseModel`).  \n- An `orchestrator` module/component responsible for managing LLM provider interactions.  \n- Logging framework (likely Python\u2019s standard `logging`).\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:56:54.110315",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_4": {
      "chunk_id": "unified_ai_api.py:chunk_4",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "6c720ba7b95ffdc99c1a5d02912ad9715c03c025546d92de4a772434a1212b55",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis Python code defines an asynchronous API endpoint `/transcribe` that accepts audio data and transcribes it into text by orchestrating multiple speech-to-text (STT) providers, automatically selecting the best available provider based on user preference or fallback logic.\n\n2. **Technical Details**  \n- Uses FastAPI's `@router.post` decorator to define an asynchronous POST endpoint.  \n- Accepts a `TranscriptionRequest` object containing base64-encoded audio, audio format, language, and optional provider preference.  \n- Decodes base64 audio data into raw bytes.  \n- Calls an asynchronous orchestrator method `speech_to_text` which implements provider selection logic (primary user-configured, fallback to Azure, then OpenAI).  \n- Returns a JSON response with transcription text, detected language, confidence score, method used, and provider metadata.  \n- Uses structured logging for request tracing and debugging.  \n- Exception handling wraps the transcription call, logs errors, and raises HTTP 500 errors on failure.\n\n3. **Business Logic**  \nSolves the business problem of providing reliable, flexible, and accurate audio transcription services by abstracting multiple STT providers behind a unified API. This enables clients to transcribe audio without managing provider-specific integrations or failover logic.\n\n4. **Dependencies**  \n- FastAPI for API routing and HTTP exception handling.  \n- An `orchestrator` module/component responsible for managing multiple STT providers and selecting the best one.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:00.524517",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_6": {
      "chunk_id": "unified_ai_api.py:chunk_6",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "7d50bb16ef4548ac1baf4b2ae1e805da1121edd3ce537098e558153b89d0417e",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/translate` that accepts text translation requests and returns translated text by orchestrating calls to translation service providers, primarily Azure Translator.\n\n2. **Technical Details**:  \n- Uses FastAPI-style async route handler (`@router.post(\"/translate\")`) for handling HTTP POST requests.  \n- Accepts a `TranslationRequest` data model containing text, target language, optional source language, and preferred translation provider.  \n- Calls an `orchestrator.translate_text` async method that abstracts the logic of selecting and invoking translation providers.  \n- Returns a JSON response with translated text, detected source language, target language, confidence score, provider metadata, and operation duration in milliseconds.  \n- Logging is used for tracing request receipt and parameters.\n\n3. **Business Logic**:  \nEnables multi-provider text translation functionality in a unified API, allowing clients to translate text into different languages with provider preference or automatic selection. This supports multilingual user experiences and internationalization in applications.\n\n4. **Dependencies**:  \n- FastAPI (or similar) for API routing and HTTP exception handling.  \n- An `orchestrator` module/component responsible for managing translation providers and executing translation requests.  \n- Logging framework for info and error logs.  \n- Azure Translator service as the primary translation provider (implied by comments).\n\n5. **Configuration**:  \n- Provider preference can be specified per request or defaults to automatic selection.  \n- Likely environment",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:07.233980",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_8": {
      "chunk_id": "unified_ai_api.py:chunk_8",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "bb923506afdecc8b0043191e7f4a39492b645e2fb3ea3b2db88bd1a84c1833c0",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis code defines an asynchronous API endpoint `/speak` that converts input text into speech audio by orchestrating multiple text-to-speech (TTS) providers, automatically selecting the best available service.\n\n2. **Technical Details**:  \n- Implements an asynchronous POST endpoint using an API router (likely FastAPI or similar).  \n- Uses an orchestrator pattern to abstract and route TTS requests between multiple providers (OpenAI TTS as primary, Azure Speech Service as fallback).  \n- Encodes raw audio binary data into a base64 string for safe JSON transport.  \n- Logs key request metadata such as text length and provider preference.  \n- Returns a structured JSON response containing the base64-encoded audio, audio format, provider metadata, and audio duration in milliseconds.\n\n3. **Business Logic**:  \nEnables clients to convert arbitrary text into speech audio seamlessly, improving user experience in applications requiring voice output (e.g., accessibility, virtual assistants). The automatic provider fallback ensures high availability and reliability of the TTS service.\n\n4. **Dependencies**:  \n- `orchestrator.text_to_speech`: a custom module or service handling multi-provider TTS orchestration.  \n- `base64` standard library for encoding audio data.  \n- `logger` for structured logging.  \n- `HTTPException` for API error signaling (likely from FastAPI).  \n- `TTSRequest` data model for request validation and parsing.\n\n5. **Configuration",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:14.027520",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_10": {
      "chunk_id": "unified_ai_api.py:chunk_10",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "2e03101f2dca67c1083c7b96ca984d779aa48ef135f149201fe5339e6915df9c",
      "chunk_index": 10,
      "summary": "1. **Purpose**  \nThis Python code defines API endpoints to expose the status of a cloud orchestration system and to list all registered cloud providers along with their capabilities.\n\n2. **Technical Details**  \n- Uses asynchronous FastAPI route handlers (`@router.get`) for non-blocking I/O operations.  \n- Retrieves orchestrator status via an asynchronous call to `orchestrator.get_orchestrator_status()`.  \n- Dynamically inspects cloud providers and their capabilities by iterating over a predefined list of provider names and enumerated `ProviderCapability` values.  \n- Uses a factory pattern (`ProviderFactory`) to query available providers per capability.  \n- Structured logging is used for operational visibility.\n\n3. **Business Logic**  \nEnables clients (e.g., frontend dashboards or monitoring tools) to query the health and configuration of the cloud orchestration platform and to discover which cloud providers and AI capabilities are currently registered and available for use. This supports dynamic provider selection and fallback strategies in multi-cloud AI orchestration.\n\n4. **Dependencies**  \n- `orchestration.cloud_providers.templates.base.ProviderCapability`: Enum defining provider capabilities.  \n- `orchestration.cloud_providers.factory.ProviderFactory`: Factory class to retrieve available providers by capability.  \n- FastAPI framework for HTTP routing and exception handling (`HTTPException`).  \n- A logger instance (not fully shown) for logging info and errors.\n\n5. **Configuration**  \n- The list of providers (`[\"azure\", \"together\",",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:21.709030",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_12": {
      "chunk_id": "unified_ai_api.py:chunk_12",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "b46affdb56e273699f99fc9dfcee2dbf6138c92e55a45e93bb989adba86e1064",
      "chunk_index": 12,
      "summary": "1. **Purpose**  \nThis Python code defines API endpoints to list available cloud AI providers with their capabilities and to get or update the current provider configuration for speech-to-text (STT), chat, and text-to-speech (TTS) services.\n\n2. **Technical Details**  \n- Uses FastAPI-style asynchronous route handlers (`@router.get`, `@router.post`).  \n- Maintains a global dictionary `_provider_config` representing the current provider settings.  \n- Iterates over providers and their capabilities, appending capability values to a list and tracking availability status.  \n- Returns structured JSON responses with provider names, availability flags, and capability lists.  \n- Uses try-except blocks to catch and log exceptions, raising HTTP 500 errors on failure.  \n- Imports `ProviderCapability` enum or class to check provider capabilities.\n\n3. **Business Logic**  \nSupports dynamic orchestration of multiple cloud AI providers by exposing APIs to:  \n- Retrieve a list of providers and their supported AI capabilities (STT, chat, TTS).  \n- Retrieve the current configuration of which providers are assigned to which AI tasks.  \n- Update the backend configuration to change provider preferences, enabling flexible switching or fallback strategies in AI service orchestration.\n\n4. **Dependencies**  \n- `orchestration.cloud_providers.templates.base.ProviderCapability` for capability enumeration.  \n- FastAPI (implied by `@router.get` and `@router.post` decorators and `HTTPException`).  \n- A",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:29.065971",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_14": {
      "chunk_id": "unified_ai_api.py:chunk_14",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "460aa7477231fcd82667773d1607e33dacb99e0cacfcd08ab12a9b29f65a2c1c",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet validates a configuration dictionary specifying cloud AI providers for speech-to-text (STT), chat (LLM), and text-to-speech (TTS) services, ensuring that each configured provider supports the required capability before saving the configuration.\n\n2. **Technical Details**:  \n- Uses a set (`valid_keys`) to validate allowed configuration keys.  \n- Maps configuration keys to specific provider capabilities via a dictionary (`capability_map`).  \n- Iterates over the configuration items to verify each provider supports the required capability by querying `ProviderFactory.get_available_providers()`.  \n- Collects validation errors if providers do not meet capability requirements.  \n- Raises HTTP exceptions for invalid keys or potentially for unsupported providers (incomplete snippet).\n\n3. **Business Logic**:  \nEnsures that the AI service providers configured for different functionalities (STT, chat, TTS) are valid and capable, preventing misconfiguration that could lead to runtime failures or degraded user experience in AI-driven features.\n\n4. **Dependencies**:  \n- `orchestration.cloud_providers.factory.ProviderFactory`: Used to retrieve available providers by capability.  \n- `ProviderCapability`: Enum or constant definitions representing capabilities like SPEECH_TO_TEXT, LLM_CHAT, TEXT_TO_SPEECH.  \n- `logger`: For logging configuration save attempts.  \n- `HTTPException`: Likely from FastAPI or Starlette, used to return HTTP error responses.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:35.221663",
      "status": "summarized"
    },
    "unified_ai_api.py:chunk_16": {
      "chunk_id": "unified_ai_api.py:chunk_16",
      "file_path": "interfaces\\unified_ai_api.py",
      "chunk_hash": "855e2d9812e9815669ca6e0c4e45e34b30ef00d3a3c87cd059a59f8aa823a455",
      "chunk_index": 16,
      "summary": "**Summary of Error Handling in `interfaces\\unified_ai_api.py`**\n\n1. **Purpose**  \n   This code segment handles errors related to validating and saving provider configurations within a unified AI API interface. It ensures that the provider supports required capabilities and that the configuration data is valid before persisting changes.\n\n2. **Exception Types**  \n   - **Generic `Exception`**: Catches all exceptions during provider validation to accumulate validation error messages without stopping the entire validation process.  \n   - **`HTTPException`**: Explicitly caught and re-raised to allow HTTP error responses to propagate correctly.  \n   - **Other unexpected exceptions**: Caught in the outer `except Exception` block, logged, and converted into a 500 Internal Server Error HTTP response.\n\n3. **Recovery Strategy**  \n   - Validation errors are collected in a list (`validation_errors`) rather than failing immediately on the first error, allowing comprehensive feedback on all validation issues.  \n   - If any validation errors exist, the function raises an HTTP 400 error with detailed messages, preventing invalid configurations from being saved.  \n   - No automatic retries are implemented; the function fails fast after validation or unexpected errors.\n\n4. **Logging**  \n   - Validation failures are logged at the warning level with detailed error messages for monitoring provider validation issues.  \n   - Successful configuration saves are logged at the info level, confirming the updated provider configuration.  \n   - Unexpected failures during saving are logged as errors, capturing exception",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:40.492111",
      "status": "summarized"
    },
    "tracing.py:chunk_0": {
      "chunk_id": "tracing.py:chunk_0",
      "file_path": "observability\\tracing.py",
      "chunk_hash": "95d838660670ab4247cbd4ecff15d50a7bf6b6572c806702582d3d9abea201a7",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code sets up OpenTelemetry-based distributed tracing for a FastAPI application, enabling observability by capturing and exporting trace data to the console. It provides initialization and retrieval of tracer instances for instrumentation.\n\n2. **Technical Details**:  \n- Uses OpenTelemetry SDK to create a `TracerProvider` configured with a `Resource` that identifies the service by name.  \n- Adds a `BatchSpanProcessor` with a `ConsoleSpanExporter` to asynchronously export trace spans to the console output.  \n- Instruments the FastAPI app automatically via `FastAPIInstrumentor` to capture incoming HTTP request traces.  \n- Provides a function to retrieve a tracer instance scoped to the current module.  \n- Logging is used to confirm tracing initialization.\n\n3. **Business Logic**:  \nEnables detailed tracing of requests and operations within the AI development agent service (\"ai-dev-agent\"), facilitating monitoring, debugging, and performance analysis in distributed systems or microservices architectures.\n\n4. **Dependencies**:  \n- `opentelemetry` core and SDK packages (`trace`, `TracerProvider`, `BatchSpanProcessor`, `ConsoleSpanExporter`, `Resource`)  \n- `opentelemetry.instrumentation.fastapi` for automatic FastAPI instrumentation  \n- Python standard `logging` module\n\n5. **Configuration**:  \n- Service name is configurable via the `service_name` parameter in `setup_tracing` (default: \"ai-dev-agent\")  \n- No environment variables or external",
      "embedding_id": null,
      "created_at": "2025-10-22T19:57:54.848629",
      "status": "summarized"
    },
    "openai_provider.py:chunk_0": {
      "chunk_id": "openai_provider.py:chunk_0",
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "chunk_hash": "d9392700c1bd188bd2f1e5ceff4de3c53d0e770c1c40efa665107f0b1f8c2194",
      "chunk_index": 0,
      "summary": "**Summary of `openai_provider.py`**\n\n1. **Purpose**  \n   This module implements a cloud-agnostic provider class for OpenAI services, encapsulating Speech-to-Text (Whisper), Text-to-Speech (TTS), and Large Language Model (LLM) chat capabilities within a unified interface.\n\n2. **Technical Details**  \n   - Implements multiple inheritance from abstract base classes/interfaces: `CloudProvider`, `STTProvider`, `TTSProvider`, and `LLMProvider`.  \n   - Uses a provider capability enumeration (`ProviderCapability`) to define supported features.  \n   - Maintains internal state for configuration (`ProviderConfig`) and selected capability.  \n   - Logging is integrated via a shared logger utility for traceability.  \n   - The design follows the provider pattern, enabling polymorphic usage of different cloud providers through a common interface.\n\n3. **Business Logic**  \n   Enables seamless integration of OpenAI\u2019s AI services into a broader orchestration framework, abstracting away provider-specific details. This supports business use cases such as automated transcription, voice synthesis, and conversational AI, facilitating multi-cloud or multi-provider strategies.\n\n4. **Dependencies**  \n   - Python standard library: `typing` (for type hints), `base64` (likely for encoding/decoding media data).  \n   - Internal modules: `..templates.base` (providing base classes and data structures), `shared.logger` (for logging).  \n   - External OpenAI API",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:02.628426",
      "status": "summarized"
    },
    "openai_provider.py:chunk_2": {
      "chunk_id": "openai_provider.py:chunk_2",
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "chunk_hash": "8d3d82be3179a9c9033affbf84de8ff466e14fd3f2561ecd16156c63611bf292",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods within an OpenAI provider class to perform health checks and transcribe audio data into text using OpenAI's Whisper model.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle I/O-bound operations efficiently.  \n- Utilizes the `AsyncOpenAI` client from the OpenAI Python SDK to interact with OpenAI's API.  \n- Converts raw audio bytes into an in-memory file-like object (`io.BytesIO`) to simulate file upload for transcription.  \n- Returns a structured transcription result encapsulated in an `STTResult` data structure, including transcribed text, detected language, and method metadata.\n\n3. **Business Logic**:  \nEnables automated speech-to-text transcription services leveraging OpenAI's Whisper model, facilitating features like audio content indexing, accessibility improvements, or voice command processing within a larger orchestration or cloud provider framework.\n\n4. **Dependencies**:  \n- `openai` Python SDK (specifically `AsyncOpenAI` for asynchronous API calls).  \n- Python standard library module `io` for in-memory file handling.  \n- Presumably, a custom `STTResult` class or data structure for returning transcription results.\n\n5. **Configuration**:  \n- Requires an API key (`self.config.api_key`) for authenticating with OpenAI's services.  \n- Model selection is configurable via `self.config.model`, defaulting to `\"whisper-1",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:08.647689",
      "status": "summarized"
    },
    "openai_provider.py:chunk_4": {
      "chunk_id": "openai_provider.py:chunk_4",
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "chunk_hash": "f5d20311e95f35d43738fa6ab9540a321c1f2d2c4f0cf0cb1ed5201650d114c2",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code provides an asynchronous implementation for text-to-speech (TTS) synthesis using OpenAI's API within a cloud provider orchestration framework. It converts input text into speech audio data, returning it in a specified audio format.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking API calls to OpenAI's TTS service.  \n- Dynamically imports `AsyncOpenAI` client from the `openai` package within the method scope to possibly reduce startup overhead or manage optional dependencies.  \n- Retrieves TTS configuration parameters (`tts_model`, `tts_voice`) from a configuration object, with defaults provided.  \n- Calls `client.audio.speech.create()` to generate speech audio from text input.  \n- Wraps the resulting audio bytes and metadata into a `TTSResult` data structure for standardized output.\n\n3. **Business Logic**:  \nEnables applications to convert textual content into spoken audio, facilitating features such as voice assistants, accessibility tools, or multimedia content generation, leveraging OpenAI's advanced speech synthesis capabilities.\n\n4. **Dependencies**:  \n- `openai` Python SDK, specifically the asynchronous client `AsyncOpenAI`.  \n- A `TTSResult` class or data structure (likely defined elsewhere) to encapsulate audio data and metadata.  \n- A `logger` instance for error logging.  \n- Configuration object `self.config` that holds API keys and additional T",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:18.084069",
      "status": "summarized"
    },
    "openai_provider.py:chunk_6": {
      "chunk_id": "openai_provider.py:chunk_6",
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "chunk_hash": "ffcc452faf303b40ed64ab65ea5cbbe4b7250198599c63ee5ec554817d4a6d58",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis asynchronous Python method `chat_completion` generates chat-based text completions by interacting with the OpenAI API, returning either a streamed or full response wrapped in a custom `LLMResult` object.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to call OpenAI's chat completion endpoint without blocking.  \n- Dynamically imports `AsyncOpenAI` client from the `openai` library within the method scope.  \n- Constructs the client with an API key from the instance configuration (`self.config.api_key`).  \n- Sends a request to `client.chat.completions.create` with parameters: model name, message history, temperature, max tokens, and streaming option.  \n- Handles both streaming and non-streaming responses: returns the raw streaming response if `stream=True`, otherwise extracts the first choice's message content.  \n- Wraps the result in an `LLMResult` data structure, including content, model used, and token usage statistics.\n\n3. **Business Logic**  \nEnables integration with OpenAI\u2019s language models to provide conversational AI capabilities such as chatbots, virtual assistants, or automated content generation, supporting configurable parameters to tailor output style and length.\n\n4. **Dependencies**  \n- `openai` Python SDK (specifically `AsyncOpenAI` for asynchronous API calls).  \n- Custom `LLMResult` class (likely defined elsewhere in the codebase) for standardized result encapsulation.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:24.309342",
      "status": "summarized"
    },
    "openai_provider.py:chunk_8": {
      "chunk_id": "openai_provider.py:chunk_8",
      "file_path": "orchestration\\cloud_providers\\implementations\\openai_provider.py",
      "chunk_hash": "4c28659d36661b64bdc3f8ad9328dd344ac92fae9bd59a43104b6710ba07cbd3",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code provides an asynchronous interface to interact with OpenAI's API for generating text embeddings and managing chat completions, encapsulating OpenAI API calls within a cloud provider implementation.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to call OpenAI's API without blocking.  \n- Employs the `AsyncOpenAI` client from the `openai` Python package to interact with OpenAI services.  \n- Implements methods to generate embeddings (`generate_embedding`) and retrieve the current model name (`model_name` property).  \n- Uses exception handling to log and propagate errors during API calls.  \n- Returns embeddings as a list of floats extracted from the API response.\n\n3. **Business Logic**:  \nEnables the application to generate semantic embeddings of text inputs and manage chat completions using OpenAI models, which can be used for tasks such as natural language understanding, search, recommendation, or conversational AI features.\n\n4. **Dependencies**:  \n- `openai` Python package, specifically the `AsyncOpenAI` client for asynchronous API calls.  \n- A logger instance (`logger`) for error logging.  \n- Configuration object (`self.config`) providing API keys and model names.\n\n5. **Configuration**:  \n- Requires an API key (`self.config.api_key`) to authenticate with OpenAI.  \n- Supports specifying the model name via configuration (`self.config.model`), defaulting to `\"gpt-4.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:32.591524",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_0": {
      "chunk_id": "langgraph_router.py:chunk_0",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "26f1132072461e7306ac1521ce985c55e8751c4ff8bf43b6dbca0573a5039888",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration/commit_workflow/langgraph_router.py`**\n\n---\n\n1. **Purpose**  \nThis module implements an intelligent routing mechanism for commit-related workflows by leveraging a Large Language Model (LLM) to parse user intent and direct the request to the appropriate commit or publishing workflow template.\n\n2. **Technical Details**  \n- Uses Python `Enum` (`WorkflowAction`) to define possible workflow actions such as commit, create PR, publish, etc.  \n- Defines a `CommitIntent` dataclass encapsulating parsed user intent including platform, action, confidence score, and parameters extracted from the user message.  \n- The `CommitWorkflowRouter` class (partially shown) is designed as a router that interprets user input via LLM and maps it to workflow templates, likely using a factory pattern (`CommitTemplateFactory`) to instantiate appropriate templates based on intent.  \n- Serialization support via `CommitIntent.to_dict()` for easy conversion to JSON or other dict-based formats.\n\n3. **Business Logic**  \nEnables automation and intelligent decision-making in software development workflows by interpreting natural language user commands related to commits, pull requests, publishing, and ticket creation. This reduces manual steps and errors in the commit lifecycle, improving developer productivity and workflow consistency.\n\n4. **Dependencies**  \n- Standard Python libraries: `logging`, `json`, `dataclasses`, `enum`, `typing`  \n- Internal modules: `orchestration.commit_workflow.templates` providing `CommitTemplate",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:39.525694",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_2": {
      "chunk_id": "langgraph_router.py:chunk_2",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "69a84df9234251df7cfb36875649287b47b76276bd3370a41d7854dd35daab33",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python class serves as a router within a commit workflow system, leveraging a large language model (LLM) orchestrator to parse user natural language messages and detect commit or publish intents, extracting structured parameters for further processing.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running LLM calls without blocking.  \n- Constructs prompts dynamically based on user input and optional context to query the LLM.  \n- Parses LLM-generated completions, extracting JSON-formatted intent data.  \n- Likely uses a custom `CommitIntent` data structure to encapsulate parsed intent details such as platform, action, and parameters.  \n- Employs logging for traceability and debugging.  \n\n3. **Business Logic**:  \nEnables users to interact with version control or publishing workflows through natural language commands, simplifying and automating commit or publish operations by interpreting user intent accurately and programmatically.\n\n4. **Dependencies**:  \n- A `ResilientLLMOrchestrator` instance, presumably a wrapper around an LLM API (e.g., OpenAI GPT or similar).  \n- Python standard libraries such as `logging`.  \n- Possibly uses typing hints (`Optional`, `Dict`, `Any`) from `typing`.  \n- Custom classes or modules for `CommitIntent` and internal helper methods (`_build_intent_parsing_prompt`, `_extract_json_from_response`).  \n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:46.487121",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_4": {
      "chunk_id": "langgraph_router.py:chunk_4",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "7a1c4a12e77e10b7ed72eb285c71a4cd91ba6754dd038489899d68f8495d1971",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a workflow orchestration module that parses user messages to detect commit-related intents using a Large Language Model (LLM). It extracts structured intent information such as platform, action, confidence, and parameters to facilitate automated commit or publish operations.\n\n2. **Technical Details**:  \n- Defines a `CommitIntent` data structure populated from parsed intent data.  \n- Uses enums or similar constructs (`TemplatePlatform`, `WorkflowAction`) to strongly type platform and action fields.  \n- Implements a try-except block to parse intent and fallback to a secondary method if parsing fails.  \n- Constructs a prompt string for the LLM that includes the user message and optional context serialized as JSON.  \n- Logging is used to record successful intent detection and fallback warnings.\n\n3. **Business Logic**:  \nEnables automation of commit workflows by interpreting natural language user inputs into actionable intents, supporting multiple platforms (GitHub, Confluence, Jira). This reduces manual effort and errors in generating commit messages and branch names, streamlining developer or content publishing workflows.\n\n4. **Dependencies**:  \n- Likely depends on a logging framework (`logger`).  \n- Uses JSON serialization (`json.dumps`).  \n- Relies on custom enums or classes: `CommitIntent`, `TemplatePlatform`, `WorkflowAction`.  \n- Integrates with an LLM service for natural language understanding (implied but not shown).\n\n5. **Configuration**:  \n- No explicit environment",
      "embedding_id": null,
      "created_at": "2025-10-22T19:58:53.011537",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_6": {
      "chunk_id": "langgraph_router.py:chunk_6",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "ef71feafd1fe576440c22acd03af0c5cebc30304b09737db5aaeda7a5be8ee90",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet defines a structured JSON output format for orchestrating GitHub repository actions such as committing code, creating pull requests, publishing, or creating tickets. It ensures that commit messages and branch names are generated meaningfully and follow a consistent naming convention.\n\n2. **Technical Details**:  \n- The code uses a JSON schema-like structure to specify required fields: `platform`, `action`, `confidence`, and `parameters`.  \n- Parameters include repository details, commit messages, branch names, and branch prefixes.  \n- Branch names must follow a pattern (`feature/description`, `fix/description`, or `docs/description`) and avoid using the default branch name \"main\".  \n- Commit messages are generated to be clear, concise, and descriptive based on user intent.  \n- Confidence scores (0.0 to 1.0) indicate the certainty of the action inferred.\n\n3. **Business Logic**:  \n- Enforces best practices in Git workflows by automating the generation of meaningful commit messages and feature branches, improving code quality and traceability.  \n- Supports multiple GitHub-related actions to streamline developer workflows and reduce manual errors in branch naming and commit messaging.  \n- Helps maintain consistency across repositories, which is critical for collaboration and CI/CD pipelines.\n\n4. **Dependencies**:  \n- Implicitly depends on GitHub as the platform for repository actions.  \n- No explicit external libraries or modules are shown in the snippet, but it likely",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:02.098206",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_8": {
      "chunk_id": "langgraph_router.py:chunk_8",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "b0906355f20776fbf44545ef98d4a728b9d35777b1fd211e12fbca3aa2ab2ede",
      "chunk_index": 8,
      "summary": "1. **Purpose**  \nThis Python code snippet is part of a workflow orchestration module that processes natural language inputs to detect user intents related to commit and publishing actions, extracting structured JSON commands from responses generated by a large language model (LLM).\n\n2. **Technical Details**  \n- The code includes a method `_extract_json_from_response` which parses JSON embedded within markdown-style code blocks (```json ... ```) from a raw LLM response string.  \n- It uses string manipulation to isolate JSON content and then deserializes it using `json.loads`.  \n- A fallback intent detection method `_fallback_intent_detection` is partially shown, indicating a rule-based approach to intent detection when LLM parsing fails.  \n- Data structures involved include Python dictionaries for JSON representation and possibly a custom `CommitIntent` class for intent encapsulation.\n\n3. **Business Logic**  \nThe code supports automating developer workflows by interpreting natural language commands such as \"commit and create PR for bug fix\" or \"publish to Confluence\" into actionable, structured instructions. This enables integration with platforms like GitHub and Confluence to streamline code commits, pull requests, and documentation publishing.\n\n4. **Dependencies**  \n- Python standard library modules: `json` for JSON parsing, `logging` (implied by `logger.warning`) for logging warnings.  \n- Possibly external or internal modules defining `CommitIntent` and logging configuration.  \n- The code interacts with a large language model (LLM) service",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:08.543838",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_10": {
      "chunk_id": "langgraph_router.py:chunk_10",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "0ab95554d44e91d9f12fe1da8f54946d807d785b8ca14b5eb42dc1d8328e096a",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a message intent classification function that analyzes a lowercased input string (`message_lower`) to determine the appropriate commit workflow intent, returning a `CommitIntent` object with specified platform, action, confidence, and parameters.\n\n2. **Technical Details**:  \n- Uses simple keyword-based conditional checks (`if-elif-else`) on the input string to classify intent.  \n- Returns instances of the `CommitIntent` data structure, which encapsulates the target platform (e.g., Confluence, Jira, GitHub), the workflow action (e.g., publish, create ticket, create PR, commit), a confidence score, and an empty parameters dictionary.  \n- Differentiates between creating a pull request and committing with a pull request based on the presence of the keyword \"commit\".  \n- The snippet is part of an asynchronous class method (indicated by `async def route_to_workflow` starting after the snippet), suggesting integration into an async workflow.\n\n3. **Business Logic**:  \nThe code automates routing of user or system messages to the appropriate commit-related workflow based on detected keywords, enabling integration with multiple platforms (Confluence, Jira, GitHub). This supports business processes such as publishing documentation, creating tickets, or managing code commits and pull requests, streamlining developer or content workflows.\n\n4. **Dependencies**:  \n- Custom classes/enums: `CommitIntent`, `TemplatePlatform`, and `WorkflowAction",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:14.422130",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_12": {
      "chunk_id": "langgraph_router.py:chunk_12",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "44131c1be8792874f410fe638d5b8fe3dc30660ae361009148551e943bb3cd73",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis method routes a given commit intent to the appropriate workflow based on the platform and action, then generates and returns a corresponding commit template for that workflow.\n\n2. **Technical Details**:  \n- Merges parameters from the `CommitIntent` object and any additional parameters into a single dictionary.  \n- Uses conditional logic to determine the platform (e.g., GitHub) and action (e.g., commit) to select the correct workflow.  \n- Dynamically imports the `generate_branch_name` function to create branch names when not explicitly provided.  \n- Utilizes a factory pattern (`CommitTemplateFactory`) to create platform-specific commit templates.  \n- Uses structured logging to trace workflow routing.\n\n3. **Business Logic**:  \nEnables automated orchestration of commit workflows by interpreting user or system intents into actionable templates, facilitating consistent and standardized commit operations across different platforms (currently GitHub). This supports streamlined CI/CD and version control processes.\n\n4. **Dependencies**:  \n- Internal module: `orchestration.commit_workflow.github_operations` for branch name generation.  \n- `CommitIntent` data structure encapsulating intent details.  \n- `TemplatePlatform` and `WorkflowAction` enums or constants to identify platform and action types.  \n- `CommitTemplateFactory` for generating commit templates.  \n- Python standard libraries: `logging` for info logs, `typing` for type hints.\n\n5. **Configuration**:  \n- Parameters such as `commit",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:19.722168",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_14": {
      "chunk_id": "langgraph_router.py:chunk_14",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "3599f48fb7619d60f60738f48973bd41728363a3cb22e01181ffd24341f86490",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet selects and creates different GitHub-related commit or pull request templates based on the specified workflow action (commit, create PR, or commit and create PR). It prepares the appropriate template and identifies the workflow type accordingly.\n\n2. **Technical Details**:  \n- Uses conditional branching (`if-elif-else`) to determine the workflow action.  \n- Utilizes a factory design pattern (`CommitTemplateFactory`) to instantiate different commit or PR templates.  \n- Extracts parameters from a dictionary (`params`) with default values to configure templates.  \n- Assigns a workflow identifier string (`workflow`) corresponding to the selected action.\n\n3. **Business Logic**:  \nAutomates and standardizes the creation of GitHub commits and pull requests as part of a larger orchestration or CI/CD pipeline, enabling streamlined code integration workflows based on user intent.\n\n4. **Dependencies**:  \n- `CommitTemplateFactory`: a module/class responsible for generating commit and PR templates.  \n- `WorkflowAction`: an enumeration or class defining possible workflow actions like `CREATE_PR`, `COMMIT_AND_PR`.  \n- Likely depends on GitHub API or SDK indirectly through these templates (not shown here).\n\n5. **Configuration**:  \n- Parameters such as `repository`, `branch_name`, `target_branch`, `pr_title`, and `commit_message` are passed dynamically via the `params` dictionary.  \n- Default values are provided for some parameters (e",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:28.837257",
      "status": "summarized"
    },
    "langgraph_router.py:chunk_16": {
      "chunk_id": "langgraph_router.py:chunk_16",
      "file_path": "orchestration\\commit_workflow\\langgraph_router.py",
      "chunk_hash": "ac86d7968b69acccde755d9c3084a7a1d336a670805a7161d3acb82a159e20cb",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet dynamically generates a commit or publish template based on the specified platform in the `intent` object, and determines the corresponding workflow to execute (e.g., GitHub commit, Confluence publish, Jira ticket creation).\n\n2. **Technical Details**:  \n- Uses conditional branching (`if-elif-else`) to select the appropriate template creation method from `CommitTemplateFactory` based on the platform type (`TemplatePlatform` enum).  \n- Extracts parameters from a `params` dictionary to pass relevant data to the template factory methods.  \n- Returns a dictionary containing the chosen workflow name, generated template, serialized intent, and a flag indicating that approval is required.  \n- Logging is used to record successful template generation.\n\n3. **Business Logic**:  \nThe code supports multi-platform content or issue creation workflows by abstracting template generation for different platforms (GitHub, Confluence, Jira). This enables a unified orchestration layer to handle commit or publishing actions across various tools, streamlining content management and issue tracking processes.\n\n4. **Dependencies**:  \n- `CommitTemplateFactory`: A factory class responsible for creating platform-specific templates.  \n- `TemplatePlatform`: An enumeration defining supported platforms (GitHub, Confluence, Jira).  \n- `intent`: An object representing the user's intent, which includes platform information and can be serialized via `to_dict()`.  \n- `logger`: For logging informational messages.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:35.426656",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_0": {
      "chunk_id": "github_repo_loader.py:chunk_0",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "cb957e5ceacc0f6c08e9d1522ffc607374410950606cef4c47e4a759e607b266",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module defines a `GitHubRepoLoader` class that loads a user's GitHub repositories by querying the GitHub API using an authentication token and populates a centralized repository registry.\n\n2. **Technical Details**:  \n- Uses the GitHub REST API v3 with authenticated requests via a personal access token.  \n- Employs standard HTTP requests through the `requests` library.  \n- Loads environment variables from a `.env` file if present, using `python-dotenv`.  \n- Uses a class-based design encapsulating API interaction and token management.  \n- Imports a global repository registry accessor (`get_global_registry`) to store fetched repositories (though usage not shown in snippet).  \n- Logging is configured to provide debug-level insights into environment loading.\n\n3. **Business Logic**:  \nAutomates the synchronization of a user's GitHub repositories into an internal registry system, enabling downstream processes or services to access up-to-date repository metadata without manual input. This supports business needs such as project tracking, code analysis, or deployment orchestration.\n\n4. **Dependencies**:  \n- `os` and `pathlib.Path` for environment and file path management.  \n- `logging` for diagnostic output.  \n- `requests` for HTTP API calls.  \n- `dotenv` (optional) for loading environment variables from a `.env` file.  \n- Internal module: `orchestration.message_parser.extractors.repository_registry` for the global repository registry.\n\n5.",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:42.525095",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_2": {
      "chunk_id": "github_repo_loader.py:chunk_2",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "8ef7d08fcb5423c593ae93b3786fd5da897ec17bb46fc9c78064e193e4983ee2",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a GitHub repository loader that fetches and registers repositories for a specified GitHub user or the authenticated user if no username is provided. It handles authentication via a token and logs the process.\n\n2. **Technical Details**:  \n- Uses conditional logic to set the GitHub API endpoint based on whether a username is provided.  \n- Authentication is handled by adding an `Authorization` header with a token if available.  \n- Fetches repositories using a method `_fetch_all_pages(url)` which likely handles pagination.  \n- Registers the fetched repositories via `_register_repos(repos)` and returns the count of loaded repositories.  \n- Logging is used extensively for tracing execution and outcomes.\n\n3. **Business Logic**:  \nEnables the orchestration system to programmatically retrieve and register GitHub repositories for users, supporting workflows that depend on repository metadata, such as code analysis, CI/CD orchestration, or inventory management.\n\n4. **Dependencies**:  \n- GitHub REST API (external service) for repository data.  \n- A logger instance (likely Python\u2019s `logging` module or a wrapper).  \n- Internal methods `_fetch_all_pages` and `_register_repos` which are not shown but are critical for API pagination handling and repository registration.\n\n5. **Configuration**:  \n- `self.token`: GitHub API token used for authenticated requests, likely sourced from environment variables or secure config.  \n- `self.headers`:",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:46.968594",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_4": {
      "chunk_id": "github_repo_loader.py:chunk_4",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "a153cdd8482d4d20836623963c9bcc48f1f782497609f420643c179acaf85fd2",
      "chunk_index": 4,
      "summary": "1. **Purpose**  \nThis Python code provides functionality to load GitHub repositories either for an entire organization or a specific repository, fetching repository data from the GitHub API and registering it into an internal system.\n\n2. **Technical Details**  \n- Uses REST API calls to GitHub endpoints (`/orgs/{org_name}/repos` and `/repos/{owner}/{repo}`) to retrieve repository data.  \n- Implements pagination handling via a helper method `_fetch_all_pages(url)` to fetch all pages of organization repositories.  \n- Registers fetched repositories through `_register_repos(repos)`, presumably storing or processing them internally.  \n- Uses structured logging with different log levels (info, error) and emoji for clarity.  \n- The `load_org_repos` method returns an integer count of repositories loaded, while `load_specific_repo` returns a boolean indicating success.\n\n3. **Business Logic**  \nEnables synchronization or ingestion of GitHub repository metadata into an internal registry or system, supporting organizational-level bulk loading and individual repository loading. This supports business needs such as inventory management, analytics, or integration workflows that depend on up-to-date repository information.\n\n4. **Dependencies**  \n- `requests` library for HTTP calls to GitHub API.  \n- A logger instance (`logger`) for logging operations and errors.  \n- Internal helper methods `_fetch_all_pages` and `_register_repos` which are not shown but critical for pagination and data registration.\n\n5. **Configuration**  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:52.757059",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_6": {
      "chunk_id": "github_repo_loader.py:chunk_6",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "81a6339c4feb3be43a365a859b28532e694ddd6c3e2609818311c6f89a4b1f09",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a GitHub repository loader that fetches repository data from the GitHub API, registers repositories in a global registry, and supports pagination to retrieve all repository pages.\n\n2. **Technical Details**:  \n- Uses the `requests` library to perform HTTP GET requests to GitHub API endpoints.  \n- Implements pagination by iteratively fetching pages of results using query parameters (`per_page` and `page`).  \n- Parses JSON responses to extract repository data.  \n- Registers repositories via a global registry pattern (`get_global_registry()`), which likely maintains a centralized state of loaded repositories.  \n- Uses structured logging (`logger.info`, `logger.error`) for success and failure events.  \n- Exception handling wraps API calls to catch and log any errors, returning boolean success flags.\n\n3. **Business Logic**:  \nEnables the orchestration system to load and track GitHub repositories dynamically by fetching repository metadata and registering them centrally. This supports business processes that depend on up-to-date repository information, such as CI/CD pipelines, analytics, or dependency management.\n\n4. **Dependencies**:  \n- `requests` for HTTP communication with GitHub API.  \n- A global registry module or singleton accessed via `get_global_registry()`.  \n- A logging framework (`logger`).  \n- GitHub API as an external service.\n\n5. **Configuration**:  \n- API request headers are passed via `self.headers`, which likely include authentication",
      "embedding_id": null,
      "created_at": "2025-10-22T19:59:58.102890",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_8": {
      "chunk_id": "github_repo_loader.py:chunk_8",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "9226e80a1b3a4e7527a7b58e615c691a1b4de9eca98797316e1fa40679829c8f",
      "chunk_index": 8,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The error handling code manages exceptions that occur during the fetching and registration of GitHub repositories. Specifically, it handles network-related errors during API calls and data integrity issues when processing repository information.\n\n2. **Exception Types**:  \n   - `requests.exceptions.RequestException`: Catches all HTTP/network related errors during the GitHub API requests.  \n   - `KeyError`: Catches missing keys in the repository data dictionary during registration (e.g., missing 'owner' or 'name' fields).\n\n3. **Recovery Strategy**:  \n   - For API request errors (`RequestException`), the code logs the error and breaks out of the pagination loop, effectively stopping further attempts to fetch more pages. No retries are attempted within this snippet.  \n   - For data processing errors (`KeyError`), the snippet is incomplete, but presumably, it would handle missing data gracefully, potentially skipping the problematic repository without halting the entire registration process.\n\n4. **Logging**:  \n   - Errors during fetching are logged at the error level with a clear message including the page number and exception details, aiding in monitoring and troubleshooting.  \n   - Successful fetches and registrations are logged at the debug level, providing detailed traceability of operations.\n\n5. **User Impact**:  \n   - If a network error occurs, the fetching process stops early, potentially resulting in incomplete repository data being processed or displayed to the user.  \n   - Missing data in",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:04.783283",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_10": {
      "chunk_id": "github_repo_loader.py:chunk_10",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "feb11b47c78ac3d49f3921d69f4aa3937edcd97f5bcc8aa38415e15035c847b7",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a GitHub repository loader that automatically loads repositories based on environment configurations, supporting organization repos, user repos, and authenticated user repos.\n\n2. **Technical Details**:  \n- The method `auto_load_from_env` reads environment variables to determine which repositories to load.  \n- It uses conditional logic to decide whether to load organization repositories (`load_org_repos`), user repositories (`load_user_repos`), or authenticated user repositories if a token is present but no specific user/org is given.  \n- It accumulates and returns the total count of repositories loaded.  \n- Logging is used to provide runtime information about the loading process.\n\n3. **Business Logic**:  \nEnables automated, environment-driven loading of GitHub repositories to facilitate integration or synchronization workflows, such as syncing repo metadata or triggering downstream processes based on repo data without manual input.\n\n4. **Dependencies**:  \n- Uses `os.environ` to access environment variables.  \n- Relies on a `logger` for logging informational and warning messages.  \n- Presumably depends on internal methods `load_org_repos` and `load_user_repos` for actual data fetching, which likely interact with the GitHub API.  \n- Uses an authentication token (`self.token`) to access private or authenticated user repositories.\n\n5. **Configuration**:  \n- Environment variables:  \n  - `GITHUB_ORG`: Specifies the GitHub organization name to load repositories from",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:14.021672",
      "status": "summarized"
    },
    "github_repo_loader.py:chunk_12": {
      "chunk_id": "github_repo_loader.py:chunk_12",
      "file_path": "orchestration\\message_parser\\extractors\\github_repo_loader.py",
      "chunk_hash": "2979fc9498132dc10a1842af9946f0f081bd3c2ccd40802c045765a7c86a9004",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code automatically loads GitHub repositories into a global registry when the module is imported, enabling immediate access to a user's or organization's repositories for downstream processing.\n\n2. **Technical Details**:  \n- Defines a function `auto_load_github_repos()` that instantiates a `GitHubRepoLoader` object and calls its `auto_load_from_env()` method to fetch repositories based on environment configuration.  \n- Uses logging to report success or failure and the count of repositories loaded.  \n- Retrieves a global registry object via `get_global_registry()` and logs a summary of the first 10 repositories loaded.  \n- The function is invoked immediately upon module import, ensuring the registry is populated without explicit calls elsewhere.  \n- Uses try-except to catch and log any exceptions during loading.\n\n3. **Business Logic**:  \nAutomatically populates a repository registry with GitHub repositories associated with a configured user or organization, facilitating seamless integration and access to repository metadata for orchestration, analysis, or automation workflows.\n\n4. **Dependencies**:  \n- `GitHubRepoLoader` class (presumably defined elsewhere) responsible for fetching repositories from GitHub.  \n- `get_global_registry()` function to access the shared repository registry.  \n- `logger` for structured logging.  \n- GitHub API (implicitly via `GitHubRepoLoader`).  \n\n5. **Configuration**:  \n- Environment variables `GITHUB_ORG` or `GITHUB_USER` are expected to",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:20.685022",
      "status": "summarized"
    },
    "connection_factory.py:chunk_0": {
      "chunk_id": "connection_factory.py:chunk_0",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "e9b40867df64123eb5233530cc024ffb50c686f949e5bf72b9fdabd19d518adf",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module provides a factory class to create and manage service connections using credentials configured in IntegrationsHub, supporting initialization from multiple sources.\n\n2. **Technical Details**  \n- Implements a `ConnectionFactory` class following the Factory design pattern to encapsulate connection creation logic.  \n- Uses asynchronous initialization (`async def initialize_from_integrations`) to support non-blocking I/O operations, likely involving network or database calls.  \n- Maintains an internal `_initialized` flag to ensure idempotent initialization.  \n- Attempts a two-step initialization: first from a database, then falls back to environment variables if the database initialization fails.  \n- Uses Python\u2019s standard logging module for structured logging and diagnostics.\n\n3. **Business Logic**  \nEnables dynamic and flexible service connection setup for integrations by abstracting credential management. This supports business needs for connecting to multiple external services securely and reliably, adapting to different deployment environments (database-driven or environment variable-driven configurations).\n\n4. **Dependencies**  \n- `logging` for logging events and errors.  \n- `typing` for type hints (`Optional`, `Dict`, `Any`).  \n- `shared.services.manager.ServiceManager` which presumably manages service lifecycle or connection details.\n\n5. **Configuration**  \n- IntegrationsHub credentials are sourced primarily from a database (likely a centralized credential store).  \n- Environment variables serve as a fallback configuration source, allowing for flexible deployment setups without database dependency.\n\n6. **Error Handling**  \n- Catches",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:25.157020",
      "status": "summarized"
    },
    "connection_factory.py:chunk_2": {
      "chunk_id": "connection_factory.py:chunk_2",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "61c966f0e6c0d914e80d2438f85101b69605d853ffe95adbb904670028a13815",
      "chunk_index": 2,
      "summary": "**Summary of `orchestration/shared/connection_factory.py` - `_initialize_from_database` method**\n\n---\n\n1. **Purpose**  \n   This asynchronous method initializes integration configurations by loading them from a database, preparing the system to interact with enabled and connected integrations.\n\n2. **Technical Details**  \n   - Dynamically adjusts the Python module search path (`sys.path`) to include the project root, enabling relative imports.  \n   - Uses SQLAlchemy ORM session (`SessionLocal`) for synchronous database access within an async method.  \n   - Retrieves all integration records via a repository pattern (`IntegrationRepository`).  \n   - Filters integrations based on `enabled` flag and `status` field.  \n   - Uses logging to provide runtime information about the loading process.\n\n3. **Business Logic**  \n   The method supports the business need to dynamically load and manage external system integrations that are configured and active in the database. It ensures only enabled and currently connected integrations are considered for further orchestration or processing.\n\n4. **Dependencies**  \n   - Python standard libraries: `sys`, `pathlib.Path`  \n   - Internal modules:  \n     - `data.repositories.integration_repository.IntegrationRepository` (repository pattern for integration data access)  \n     - `data.database.SessionLocal` (SQLAlchemy session factory)  \n   - Logging (implied by `logger.info` calls, though logger import not shown)\n\n5. **Configuration**  \n   - Relies on database connection settings configured in `data.database`",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:33.213432",
      "status": "summarized"
    },
    "connection_factory.py:chunk_4": {
      "chunk_id": "connection_factory.py:chunk_4",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "867179ffbf9d3a9e0d856af7e7ddae2ba6972e9144802ef6a8afd32b4f4a8289",
      "chunk_index": 4,
      "summary": "**Summary of `orchestration/shared/connection_factory.py`**\n\n---\n\n1. **Purpose**  \nThis code is part of a connection factory responsible for initializing and registering integration services asynchronously, either from a database or as a fallback from environment variables. It manages service connectivity lifecycle within an orchestration context.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle service registration concurrently without blocking.  \n- Implements a try-except-finally structure to ensure database connections are properly closed after initialization attempts.  \n- Conditional logic to skip services that are not enabled or connected, improving efficiency.  \n- Logging at multiple levels (debug, info, error) to trace execution flow and failures.  \n- Lazy import of settings within methods to avoid circular dependencies or reduce startup overhead.\n\n3. **Business Logic**  \nThe code supports dynamic integration with external services (e.g., GitHub) by registering them based on configuration stored in a database or environment variables. This enables the business to flexibly connect to multiple third-party services, ensuring that only enabled and properly configured integrations are activated, which is critical for maintaining operational integrity and reducing unnecessary connections.\n\n4. **Dependencies**  \n- `shared.config.settings`: Configuration management module providing access to environment variables or app settings.  \n- Implicit database connection object (`db`) for service configuration retrieval and lifecycle management.  \n- Logging framework (likely Python\u2019s standard `logging` module) for structured log output.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:38.211454",
      "status": "summarized"
    },
    "connection_factory.py:chunk_6": {
      "chunk_id": "connection_factory.py:chunk_6",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "14e116ad82ec88c07c246cfae1984b2b52ead480eefa2688afa024b4fbf901e0",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet initializes connections to external services\u2014GitHub, Jira, and Confluence\u2014using credentials and URLs provided via environment variables or configuration settings. It attempts to register these services asynchronously and logs the success or failure of each initialization.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to register services, indicating non-blocking I/O operations.  \n- Conditional checks ensure required credentials (URLs, emails, tokens) are present before attempting initialization.  \n- Logging is used extensively for tracing success (`info`), warnings, and errors.  \n- The code likely resides within a class method, given the use of `self._register_*` private methods for service registration.\n\n3. **Business Logic**:  \nEnables the orchestration system to interact with key external platforms (GitHub for source control, Jira for issue tracking, Confluence for documentation) by establishing authenticated connections. This facilitates automation, data integration, or workflow management across these tools.\n\n4. **Dependencies**:  \n- External services: GitHub, Jira, Confluence APIs.  \n- Presumably uses an async HTTP client or SDKs within `_register_*_from_env` methods (not shown).  \n- Logging framework for structured logs.  \n- A `settings` object or module providing configuration values.\n\n5. **Configuration**:  \n- Environment variables or config settings supplying:  \n  - GitHub token (`GITHUB_TOKEN` or equivalent)",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:42.887749",
      "status": "summarized"
    },
    "connection_factory.py:chunk_8": {
      "chunk_id": "connection_factory.py:chunk_8",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "89f1b416b68a4b6455b165d4ed9556d0d7e54896df8718d6c9688ecb1d8c6aed",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a connection factory responsible for initializing and registering various external services (e.g., GitHub, Jira, Grafana, Confluence) asynchronously from environment variables or configuration settings.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to initialize services without blocking.  \n- Employs a service manager pattern to track and manage service instances, ensuring services are only registered once.  \n- Uses structured logging to report success or failure of service initialization.  \n- Configuration data for each service is passed as dictionaries to internal registration methods (e.g., `_register_github`, `_register_jira`).  \n- Conditional checks prevent re-initialization if the service is already registered.\n\n3. **Business Logic**:  \nThe code automates the setup of integrations with key business tools (GitHub for source control, Jira for issue tracking, Grafana for monitoring, Confluence for documentation) by reading credentials and endpoints from environment variables. This enables seamless orchestration and centralized management of these services within an enterprise application.\n\n4. **Dependencies**:  \n- `logger`: Presumably a configured logging instance for error and info messages.  \n- `settings`: A configuration object or module providing environment variables such as URLs, API keys, tokens, and credentials.  \n- `self.service_manager`: A service registry or manager component responsible for storing and retrieving service instances.  \n- External services: GitHub, Jira, Grafana",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:49.296092",
      "status": "summarized"
    },
    "connection_factory.py:chunk_10": {
      "chunk_id": "connection_factory.py:chunk_10",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "8ab90cb2430fb394443cf00fd6b9f74d31172c5f8e65605ecd0b627dc44fb62f",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous methods to register various external services (Confluence, Grafana, GitHub, Jira, etc.) with a service manager, primarily using configuration details sourced from environment variables or integration configurations.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to perform non-blocking service registration operations.  \n- Employs conditional checks to avoid duplicate service registrations (`if not self.service_manager.get_service(service_name)`).  \n- Uses a service manager pattern to centralize and manage external service instances.  \n- Configuration data is passed as dictionaries containing credentials and URLs.  \n- The `_register_service` method acts as a dispatcher, routing registration calls based on the service name.\n\n3. **Business Logic**:  \nEnables dynamic and flexible integration of third-party services (e.g., Confluence, Grafana, GitHub, Jira) into an orchestration platform by registering them at runtime. This supports automation workflows that depend on these services for documentation, monitoring, code management, and issue tracking.\n\n4. **Dependencies**:  \n- Relies on an external `service_manager` component to manage service instances.  \n- Assumes existence of private methods like `_register_confluence`, `_register_grafana`, `_register_github`, etc., which handle the specifics of each service registration.  \n- Uses asynchronous features from Python\u2019s `asyncio` or compatible frameworks.\n\n5. **Configuration**:  \n- Service credentials and endpoints",
      "embedding_id": null,
      "created_at": "2025-10-22T20:00:56.183509",
      "status": "summarized"
    },
    "connection_factory.py:chunk_12": {
      "chunk_id": "connection_factory.py:chunk_12",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "0fb79cf6634d50b14c8e466d17052dff7950c12b643595bb8703d5c0b6ddda09",
      "chunk_index": 12,
      "summary": "**Summary: Error Handling in `connection_factory.py` Service Registration**\n\n1. **Purpose**:  \n   The code handles errors related to service registration within an orchestration layer, specifically when registering external services like GitHub, Grafana, PostgreSQL, MongoDB, and others. It ensures that required configuration parameters (e.g., tokens) are present and valid before attempting to register and connect services.\n\n2. **Exception Types**:  \n   - Explicitly raises `ValueError` if mandatory configuration data (e.g., GitHub token) is missing.  \n   - No other explicit exception types are caught or handled within the shown snippet; exceptions from service registration or connection attempts are presumably propagated.\n\n3. **Recovery Strategy**:  \n   - There is no retry or recovery logic shown in the snippet.  \n   - The code relies on raising exceptions early (e.g., missing token) to prevent invalid registrations.  \n   - Unknown service types are not registered but logged as warnings, avoiding crashes.\n\n4. **Logging**:  \n   - Unknown service types trigger a warning log entry with the service name, aiding monitoring and debugging of misconfigurations or unsupported services.  \n   - No explicit error logging is shown for exceptions raised (e.g., missing token), implying that higher-level handlers or the runtime environment must handle such logs.\n\n5. **User Impact**:  \n   - Missing or invalid configurations cause immediate failure to register the service, potentially disabling integrations dependent on those services.",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:03.026899",
      "status": "summarized"
    },
    "connection_factory.py:chunk_14": {
      "chunk_id": "connection_factory.py:chunk_14",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "51beefb34a30dc2f890db6b6f737a63e396bcd90e76052d715779578acc3b16c",
      "chunk_index": 14,
      "summary": "**Summary: Error Handling in `connection_factory.py` for Service Registration**\n\n1. **Purpose**  \n   The code snippet primarily handles validation errors related to incomplete configuration data when registering external services (specifically Confluence). It ensures that critical configuration parameters (`url`, `username`, `api_token`) are present before proceeding with service instantiation and registration.\n\n2. **Exception Types**  \n   - Explicitly raises a `ValueError` if any of the required configuration parameters for Confluence are missing.  \n   - No other exceptions are caught or handled within this snippet.\n\n3. **Recovery Strategy**  \n   - There is no retry or recovery mechanism implemented in this code.  \n   - The error is raised immediately to prevent further execution with invalid configuration, effectively failing fast.\n\n4. **Logging**  \n   - The snippet does not include any logging statements for errors or operational events.  \n   - Comments indicate that Jira service registration is not yet implemented, but no error or info logs are present.\n\n5. **User Impact**  \n   - If configuration is incomplete, the system raises an exception, likely causing the service registration process to fail.  \n   - This failure may prevent the Confluence integration from being available, potentially impacting users who rely on this integration.\n\n6. **Fallback**  \n   - No default values or fallback configurations are provided.  \n   - The system does not degrade gracefully; it requires complete configuration to proceed.  \n   - For Jira, the code currently does nothing beyond",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:09.489634",
      "status": "summarized"
    },
    "connection_factory.py:chunk_16": {
      "chunk_id": "connection_factory.py:chunk_16",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "0808b2b23d30820fd04ea74966eef195acd4b60df56db58b8d2ab98e98bf7ed5",
      "chunk_index": 16,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   The code handles configuration validation errors for service registration functions related to Jira, Grafana, PostgreSQL, and MongoDB. It ensures that required configuration parameters (e.g., URLs, API tokens, connection strings) are present before proceeding with service registration.\n\n2. **Exception Types**:  \n   - Raises `ValueError` exceptions when mandatory configuration parameters are missing or incomplete.  \n   - No other exception types are explicitly caught or handled within the shown code.\n\n3. **Recovery Strategy**:  \n   - There is no explicit recovery or retry mechanism implemented.  \n   - The functions immediately raise exceptions upon detecting incomplete configurations, effectively halting the registration process for that service.\n\n4. **Logging**:  \n   - Informational logs (`logger.info`) are used to indicate that service registration is not yet implemented, including the relevant URL or service name.  \n   - No error-level logging or monitoring is present for the raised exceptions within this snippet.\n\n5. **User Impact**:  \n   - Since the registration functions raise exceptions on missing configurations and do not implement actual service registration, end users may experience failures or lack of integration with these services if configurations are incomplete.  \n   - The impact depends on how these exceptions are handled upstream; unhandled exceptions could cause application errors or degraded functionality.\n\n6. **Fallback**:  \n   - No default values or fallback mechanisms are provided for missing configuration parameters.  \n   - The code does not",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:15.086438",
      "status": "summarized"
    },
    "connection_factory.py:chunk_18": {
      "chunk_id": "connection_factory.py:chunk_18",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "2bee387dfee3e18019a0deab5369a74191d7a2e15a5e486af69305cddc1eb917",
      "chunk_index": 18,
      "summary": "**Summary of Error Handling in `connection_factory.py`**\n\n1. **Purpose**  \n   The code primarily handles errors related to missing or invalid MongoDB connection configuration during service initialization. It ensures that a valid MongoDB connection string is provided before attempting to instantiate and register the MongoDB service.\n\n2. **Exception Types**  \n   - Explicitly raises a `ValueError` if the MongoDB connection string is not found in the configuration (`config.get('connection_string')` returns `None` or empty).  \n   - No other exceptions are explicitly caught or handled within this snippet.\n\n3. **Recovery Strategy**  \n   - There is no retry or recovery mechanism implemented in this code.  \n   - The approach is fail-fast: if the connection string is missing, the code raises an exception immediately to prevent proceeding with an invalid configuration.\n\n4. **Logging**  \n   - The provided snippet does not include any logging statements for errors or exceptions.  \n   - Error monitoring or logging would need to be implemented elsewhere or added to improve observability.\n\n5. **User Impact**  \n   - If the connection string is missing, the service initialization fails immediately, likely causing the application or the MongoDB-dependent features to be unavailable.  \n   - Since the error is raised early, it prevents downstream failures but results in service unavailability until the configuration issue is resolved.\n\n6. **Fallback**  \n   - No default connection string or fallback configuration is provided.  \n   - The system does not degrade",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:21.556864",
      "status": "summarized"
    },
    "connection_factory.py:chunk_20": {
      "chunk_id": "connection_factory.py:chunk_20",
      "file_path": "orchestration\\shared\\connection_factory.py",
      "chunk_hash": "8a261363f40fe966f0a52858070db82744574843251df17245c3e06dfb981383",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides asynchronous factory methods to obtain a singleton instance of a `ConnectionFactory` and to retrieve a `ServiceManager` from that factory, facilitating centralized management of service connections.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to initialize and retrieve connection-related objects.  \n- Implements a factory pattern (`ConnectionFactory`) to encapsulate the creation and initialization of service connections.  \n- Likely uses lazy initialization to create the factory instance only once and reuse it.  \n- The `get_service_manager` function acts as a facade to access the `ServiceManager` from the factory.\n\n3. **Business Logic**:  \nEnables the orchestration layer to manage and reuse connections to various integrated services efficiently, ensuring consistent access to service managers that handle business operations or external integrations.\n\n4. **Dependencies**:  \n- Depends on the `ConnectionFactory` and `ServiceManager` classes/modules, presumably defined elsewhere in the codebase.  \n- Uses Python\u2019s asynchronous features (`async/await`).  \n- No explicit external libraries are shown in this snippet.\n\n5. **Configuration**:  \n- The initialization method `initialize_from_integrations()` suggests configuration-driven setup, likely reading integration details from environment variables, config files, or service registries.  \n- Specific configuration sources are not shown in this snippet.\n\n6. **Error Handling**:  \n- No explicit error handling is present in the provided code snippet.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:30.136034",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_0": {
      "chunk_id": "streaming_wrapper.py:chunk_0",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "c40e29543997b119b92f4e17a62a72c408909d2caee9be5a35605c6f0443e5b8",
      "chunk_index": 0,
      "summary": "**Summary of `orchestration/streaming_wrapper.py`**\n\n---\n\n1. **Purpose**  \nThis module provides a streaming wrapper around the orchestration backend pipeline, enabling real-time capture and streaming of processing activity logs to the frontend, typically via Server-Sent Events (SSE).\n\n2. **Technical Details**  \n- Implements a wrapper class `StreamingOrchestrationWrapper` around the core `OrchestrationFacade`.  \n- Uses an internal activity log (a list of dictionaries) to accumulate timestamped events representing processing steps and their statuses.  \n- The `_emit_activity` method constructs structured activity events with ISO 8601 UTC timestamps, step names, statuses, and optional details.  \n- Designed to support asynchronous streaming of these events, likely through an async generator method (`stream_process_message`), facilitating real-time frontend updates.  \n- Uses standard Python libraries for logging, async programming (`asyncio`), typing hints, datetime handling, and JSON serialization.\n\n3. **Business Logic**  \nEnables transparent, real-time monitoring and user feedback of backend orchestration processes, improving user experience by streaming live status updates of complex workflows or AI/LLM-driven tasks. This is critical in business scenarios where users need immediate visibility into long-running or multi-step backend operations.\n\n4. **Dependencies**  \n- Internal modules:  \n  - `orchestration.facade.OrchestrationFacade` (core orchestration logic)  \n  - `shared.services.manager.ServiceManager` (service management",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:36.247369",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_2": {
      "chunk_id": "streaming_wrapper.py:chunk_2",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "6a72aad1c43d4f8f0570742d887be5a8ada60fa9b9c48e8a0c628e441fc03e30",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python generator method processes an input message through a multi-step backend pipeline, streaming real-time Server-Sent Events (SSE) to clients that describe the current state and progress of the processing.\n\n2. **Technical Details**:  \n- Uses an `AsyncGenerator` to yield SSE-formatted JSON events asynchronously, enabling real-time streaming of backend activity.  \n- Implements a stepwise pipeline pattern, where each stage emits an activity event indicating its status (e.g., \"pipeline_start\", \"parsing\").  \n- Utilizes asynchronous calls (`await`) for non-blocking operations, such as parsing the message and sleeping briefly to simulate or allow processing time.  \n- Maintains an internal `activity_log` list to track emitted events, possibly for auditing or debugging.  \n- Uses a helper method `_emit_activity` to standardize the event structure before JSON serialization.\n\n3. **Business Logic**:  \nThe code supports a business workflow that involves extracting and processing key information (e.g., GitHub URLs, Jira tickets, Confluence pages) from user messages. This enables real-time feedback and transparency for users or systems monitoring the backend processing pipeline, improving user experience and operational visibility.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous programming and non-blocking sleeps.  \n- `json` for serializing activity events into JSON format suitable for SSE.  \n- A `facade` object with a `parser` component",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:43.641692",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_4": {
      "chunk_id": "streaming_wrapper.py:chunk_4",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "65dc077b4ebba65a8bfd5025c5b2e78a9c28aae6e379f162948b4465e9ffa128",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an asynchronous streaming wrapper that processes parsed messages containing references, emits activity status updates as JSON-formatted server-sent events (SSE), and enriches the context by fetching additional data related to those references.\n\n2. **Technical Details**:  \n- Uses asynchronous programming with `asyncio` to yield streaming data and introduce non-blocking delays (`await asyncio.sleep(0.1)`).  \n- Processes a collection of `parsed_message.references` to count and categorize references by type (e.g., GitHub, Jira, Confluence) using list comprehensions and string matching (`'github' in r.type.value.lower()`).  \n- Emits structured activity updates via a helper method `_emit_activity` that likely formats the event data with status and metadata.  \n- Yields data in SSE format (`data: <json>\\n\\n`) for real-time client consumption.  \n- Invokes an asynchronous enrichment method (`self.facade.enricher.enrich`) to augment the context with external data related to the references.\n\n3. **Business Logic**:  \nThe code supports a business workflow where messages containing references to external systems (GitHub, Jira, Confluence) are processed in real-time, providing progress updates and enriching the message context with relevant external information. This enables enhanced visibility and integration across development and project management tools.\n\n4. **Dependencies**:  \n- Python standard library: `asyncio` for asynchronous",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:49.070507",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_6": {
      "chunk_id": "streaming_wrapper.py:chunk_6",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "680c3fce29c6325ace831a839377ed0a58f3f4b932e78f63c6dfb547ea9852c7",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of an asynchronous streaming wrapper that processes incoming messages by enriching their context if references are found, emits activity logs about the enrichment process, and subsequently proceeds to build a prompt for further processing.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle streaming data efficiently.  \n- Employs generator pattern (`yield`) to stream JSON-encoded activity events incrementally to the client.  \n- Enrichment involves checking for references in the parsed message and conditionally invoking an enrichment service (`self.facade.enricher.enrich`).  \n- Activity events are emitted via a helper method `_emit_activity` with structured metadata such as counts of context items, cache hits, and source types.  \n- Introduces small delays (`asyncio.sleep(0.1)`) likely to throttle the streaming or allow event loop processing.\n\n3. **Business Logic**:  \nThe code supports a business workflow where incoming messages are enriched with additional context (e.g., metadata, references) to improve downstream processing such as prompt building for AI or search tasks. It also provides transparency into the enrichment process by streaming real-time activity updates, which can be used for monitoring or user feedback.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous control flow and sleeping.  \n- `json` for serializing activity data to JSON format.  \n- An internal `facade.enricher` service/module responsible for",
      "embedding_id": null,
      "created_at": "2025-10-22T20:01:53.270790",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_8": {
      "chunk_id": "streaming_wrapper.py:chunk_8",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "d8450a65e5c005f0d89ab5ec8f0c6a02cd33c4880a529f3375d87927334b201e",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python code snippet is part of a streaming orchestration wrapper that formats prompts using a specified template, emits activity status updates as JSON data streams, and conditionally initiates task planning based on user intent.\n\n2. **Technical Details**:  \n- Uses Python `asyncio` for asynchronous execution and non-blocking delays (`await asyncio.sleep(0.1)`).  \n- Employs generator pattern with `yield` to stream JSON-encoded activity updates incrementally.  \n- Interacts with a `facade.prompt_builder` component to asynchronously build formatted prompts from enriched context and template parameters.  \n- Uses structured dictionaries to represent activity states and metadata, which are serialized with `json.dumps` for streaming.  \n- Conditional logic controls whether task planning is triggered (`if execute_tasks:`).  \n- The `_emit_activity` method appears to standardize activity event creation with status and metadata.\n\n3. **Business Logic**:  \nThe code supports a business workflow that dynamically constructs user prompts based on templates and context, streams real-time progress updates to clients (likely for UI feedback or logging), and plans tasks aligned with user intent. This facilitates interactive, context-aware automation or conversational AI orchestration.\n\n4. **Dependencies**:  \n- Python standard library modules: `asyncio`, `json`.  \n- A custom `facade` object with a `prompt_builder` that exposes an asynchronous `build` method.  \n- Presumably other internal modules",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:00.602024",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_10": {
      "chunk_id": "streaming_wrapper.py:chunk_10",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "89a2314e5d1c3210695ee6ad793f2f3020a5cd1db89a92da253bcec625b3e982",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet is part of a streaming wrapper that incrementally yields JSON-encoded activity updates related to task planning and execution within an agent orchestration workflow.\n\n2. **Technical Details**:  \n- Uses Python `asyncio` for asynchronous execution and non-blocking sleeps (`await asyncio.sleep(0.1)`) to pace streaming data.  \n- Employs Python generators (`yield`) to stream data incrementally, likely for server-sent events (SSE) or similar real-time client updates.  \n- Interacts with an agent facade (`self.facade.agent.plan_tasks`) to generate a list of tasks based on enriched context and user intent.  \n- Uses a helper method `_emit_activity` to create structured activity dictionaries containing status, task metadata, and progress information.  \n- Iterates over tasks with enumeration to track and emit execution progress per task.\n\n3. **Business Logic**:  \nThe code supports a business process where an AI or automation agent plans and executes a series of tasks derived from user input and contextual data. It provides real-time feedback on task planning completion and ongoing task execution, enabling transparent monitoring of the orchestration pipeline.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous programming.  \n- `json` for serialization of activity data.  \n- A facade pattern object (`self.facade.agent`) that abstracts the agent\u2019s task planning logic.  \n- Presumably part of a larger orchestration framework or",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:05.933122",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_12": {
      "chunk_id": "streaming_wrapper.py:chunk_12",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "937ac236fc320b713d9f72e2a6dc74c7d5208dac76f6d7d589409c8b210ed5dc",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an asynchronous streaming wrapper that executes tasks via an agent, emits real-time activity updates as server-sent events (SSE), and collects the results of these tasks.\n\n2. **Technical Details**:  \n- Uses Python `asyncio` for asynchronous task execution and non-blocking delays (`await asyncio.sleep(0.1)`).  \n- Implements server-sent events by yielding JSON-encoded activity data prefixed with `\"data: \"` and followed by double newlines, adhering to SSE format.  \n- Collects task execution results in a list (`results`).  \n- Uses a facade pattern (`self.facade.agent.execute(task)`) to abstract task execution logic.  \n- Emits activity updates before and after task execution using a helper method `_emit_activity`, which packages metadata about task status and errors.\n\n3. **Business Logic**:  \nEnables real-time monitoring and reporting of task execution status in a streaming fashion, supporting use cases like progress tracking, live dashboards, or client notifications during long-running or batch operations. It also supports conditional execution, skipping tasks when disabled.\n\n4. **Dependencies**:  \n- `asyncio` for asynchronous programming.  \n- `json` for serialization of activity data.  \n- A facade object (`self.facade.agent`) that exposes an `execute` coroutine method for task execution.  \n- The `_emit_activity` method, presumably defined elsewhere in the class, formats activity messages.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:12.826300",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_14": {
      "chunk_id": "streaming_wrapper.py:chunk_14",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "36a24e5afb56543b58e892b7b73596f0824c8866a0cde222152fd51e60e51a8f",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an asynchronous streaming pipeline that yields JSON-encoded activity updates and a final result summary related to the execution of a series of tasks or operations.\n\n2. **Technical Details**:  \n- Uses Python's `asyncio` for asynchronous execution and non-blocking delays (`await asyncio.sleep(0.1)`).  \n- Employs a generator pattern (`yield`) to stream data incrementally, likely for server-sent events (SSE) or similar streaming protocols.  \n- Aggregates metrics such as total duration of tasks, counts of references, context items, tasks executed, and successful tasks.  \n- Uses list comprehensions and conditional checks to compute aggregated statistics from `results` and other objects.  \n- Serializes data to JSON format using `json.dumps()` before yielding.\n\n3. **Business Logic**:  \nThe code tracks and reports the progress and completion status of a processing pipeline, providing real-time feedback on task execution metrics and enriched contextual information. This supports business needs for monitoring, auditing, or user feedback during complex workflows involving message parsing and context enrichment.\n\n4. **Dependencies**:  \n- Python standard library: `json`, `asyncio`.  \n- Custom or external classes/objects such as `parsed_message`, `enriched_context`, and `results` which are not defined here but represent domain-specific data structures.  \n- Presumably part of a larger orchestration framework (`self._emit_activity` suggests a",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:19.070320",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_16": {
      "chunk_id": "streaming_wrapper.py:chunk_16",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "ba7f61e592543ff5759ba616b66291bd5556e8832886f8e3ffb4df3a077e873c",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a streaming orchestration wrapper that manages and reports the progress and results of a task pipeline asynchronously. It yields JSON-formatted streaming data updates about task execution status and handles errors by emitting structured error activities.\n\n2. **Technical Details**:  \n- Uses Python async generator (`yield`) to stream JSON data incrementally to a consumer, likely over HTTP (e.g., Server-Sent Events).  \n- Tracks and summarizes task execution metrics such as planned tasks, executed tasks, and successful completions by counting items in lists and filtering by status.  \n- Maintains an `activity_log` list to record detailed step-by-step activity data.  \n- Implements exception handling with logging and error activity emission.  \n- The method `get_activity_summary` asynchronously returns a summary dictionary of the total logged activities.\n\n3. **Business Logic**:  \nThe code supports real-time monitoring and reporting of complex task orchestration pipelines, enabling clients or downstream systems to receive live updates on the progress and final results of automated workflows. This is critical for transparency, debugging, and operational insights in business processes that rely on multi-step asynchronous tasks.\n\n4. **Dependencies**:  \n- `json` module for serialization of Python objects to JSON strings.  \n- `logger` for error logging (likely from Python\u2019s `logging` module or a configured logger).  \n- Presumably uses an internal method `_emit_activity` to generate structured activity records.",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:25.920619",
      "status": "summarized"
    },
    "streaming_wrapper.py:chunk_18": {
      "chunk_id": "streaming_wrapper.py:chunk_18",
      "file_path": "orchestration\\streaming_wrapper.py",
      "chunk_hash": "4160c6247b92da898655ff78470f5df1aada7a98f7a7bf02a546b4197c281b7f",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet calculates summary statistics from an activity log by counting how many activities have completed successfully and how many have failed, then returns these counts along with the full activity log.\n\n2. **Technical Details**:  \n- Uses list comprehensions to filter and count dictionary entries in `self.activity_log` based on the `'status'` key.  \n- Data structure involved is a list of dictionaries, where each dictionary represents an activity with a `'status'` field.  \n- The snippet is likely part of a method that returns a dictionary summarizing the activity log.\n\n3. **Business Logic**:  \n- Provides a quick overview of the progress and outcome of a series of activities or steps in an orchestration or workflow process.  \n- Helps in monitoring and reporting the number of completed and failed steps, which is critical for operational visibility and troubleshooting.\n\n4. **Dependencies**:  \n- No explicit external libraries or services are referenced in this snippet.  \n- Depends on the internal state `self.activity_log` being a list of dictionaries with a `'status'` key.\n\n5. **Configuration**:  \n- No configuration parameters or environment variables are involved in this snippet.\n\n6. **Error Handling**:  \n- No explicit error handling is present.  \n- Assumes `self.activity_log` is well-formed and each entry contains a `'status'` key.\n\n7. **API/Interface**:  \n- This snippet appears to be",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:30.375682",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_0": {
      "chunk_id": "response_cleaner.py:chunk_0",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "92b7930d650bb8157d59b29224a35a2f7f62f3991f83cd34fcc8af00f8b9ac93",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module provides functionality to clean and format large language model (LLM) generated text responses, improving their readability by normalizing line breaks, adjusting spacing around headers and lists, and removing excessive whitespace.\n\n2. **Technical Details**:  \n- Implements a `ResponseCleaner` class encapsulating the cleaning logic.  \n- Uses regular expressions (via `re` module) for pattern matching and text transformations.  \n- The `clean` method orchestrates multiple private helper methods (e.g., `_normalize_line_breaks`, `_fix_header_spacing`, `_fix_list_formatting`) to apply sequential text normalization steps.  \n- Logging is integrated for traceability and debugging, using Python\u2019s standard `logging` module.\n\n3. **Business Logic**:  \nThe code addresses the problem of inconsistent or poorly formatted textual output from LLMs, which can hinder user comprehension or downstream processing. By standardizing formatting, it enhances the presentation quality of AI-generated content in applications such as chatbots, report generators, or content management systems.\n\n4. **Dependencies**:  \n- Standard Python libraries: `re` for regex operations, `logging` for event logging, and `typing` for type annotations (`List`, `Tuple`).  \n- No external third-party libraries or services are used.\n\n5. **Configuration**:  \n- No explicit environment variables or configuration files are referenced in the provided code snippet.  \n- Logging behavior depends on the broader application\u2019s logging configuration.\n\n6",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:34.994773",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_2": {
      "chunk_id": "response_cleaner.py:chunk_2",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "9ca462077bdc3e716db08693c1bd060a8cbacd88767bc40e0ee7a3b35568203f",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code is part of a text response cleaning utility designed to normalize and format markdown text. It processes raw text to fix spacing issues around code blocks, headers, paragraphs, and line breaks, ultimately producing clean, well-structured markdown output.\n\n2. **Technical Details**:  \n- The code uses string manipulation and regular expressions to identify markdown elements such as headers and code blocks.  \n- It normalizes line breaks to Unix-style (`\\n`), ensures proper spacing before and after headers, fixes code block indentation, removes excessive whitespace, and adjusts paragraph spacing.  \n- The processing is done in sequential steps, each encapsulated in private methods (e.g., `_fix_code_blocks`, `_remove_excessive_whitespace`, `_fix_paragraph_spacing`, `_normalize_line_breaks`, `_fix_header_spacing`).  \n- The text is split into lines for line-by-line processing, and lists are used to accumulate processed lines before joining them back into a string.\n\n3. **Business Logic**:  \nThe code addresses the business need for generating clean, readable markdown responses, likely for display in user interfaces or reports. By ensuring consistent formatting, it improves the user experience and readability of dynamically generated markdown content, which may come from various sources or automated systems.\n\n4. **Dependencies**:  \n- Uses Python standard libraries: `re` for regular expressions and `logging` for debug output.  \n- No external third-party libraries are evident in the provided snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:40.728866",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_4": {
      "chunk_id": "response_cleaner.py:chunk_4",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "90b3cfd4e7f26563d4d6cbd2022848556acecec9153b0dc1b143873980b476e4",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a text processing utility designed to clean and format textual responses, specifically focusing on fixing spacing and alignment issues in list items within multi-line text blocks.\n\n2. **Technical Details**:  \n- The code operates by splitting input text into lines and iterating through them.  \n- It uses regular expressions (`re.match`) to detect list items, including unordered lists (marked by `-`, `*`, or `+`) and ordered lists (numbers followed by a period).  \n- It maintains state with a boolean flag (`in_list`) to track whether the current line is part of a list, enabling it to insert empty lines before and after lists to improve readability.  \n- The output is reconstructed by joining the processed lines with newline characters.\n\n3. **Business Logic**:  \nThe code addresses the business need for clean, human-readable textual summaries or reports by ensuring consistent formatting of lists. This is likely important in contexts such as generating user-facing documentation, summaries, or automated reports where presentation quality impacts user experience and comprehension.\n\n4. **Dependencies**:  \n- Uses Python's built-in `re` module for regular expression matching.  \n- No external libraries or services are indicated in the snippet.\n\n5. **Configuration**:  \n- No explicit environment variables, configuration files, or settings are referenced or required by this code.\n\n6. **Error Handling**:  \n- The snippet does not include explicit error handling or",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:47.656268",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_6": {
      "chunk_id": "response_cleaner.py:chunk_6",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "40201c067eccf0f6c4836b45395e6cc5ebe9768f224adabcd1a1110f3e3d938c",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a text processing utility designed to clean and format textual responses, specifically ensuring proper formatting around code blocks and controlling whitespace in multi-line strings.\n\n2. **Technical Details**:  \n- The `_fix_code_blocks` method processes input text line-by-line to enforce formatting rules around Markdown-style code blocks (denoted by triple backticks ```).  \n- It uses a boolean flag `in_code_block` to track whether the current line is inside a code block.  \n- It inserts empty lines before opening and after closing code blocks if they are not already present, ensuring readability and consistent formatting.  \n- The method operates by splitting the text into lines, iterating with enumeration, and conditionally appending lines and empty lines to a result list, which is then joined back into a string.  \n- The snippet also shows partial code for `_remove_excessive_whitespace`, which presumably removes more than two consecutive empty lines to reduce unnecessary vertical space.\n\n3. **Business Logic**:  \nThis code supports a business need to produce clean, well-formatted textual summaries or responses, likely for display in user interfaces, reports, or logs where Markdown formatting is used. Proper spacing around code blocks improves readability and user experience, especially in documentation, chatbots, or automated report generation systems.\n\n4. **Dependencies**:  \nNo external libraries or modules are explicitly used in the provided snippet; it relies solely on Python standard string and",
      "embedding_id": null,
      "created_at": "2025-10-22T20:02:52.928205",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_8": {
      "chunk_id": "response_cleaner.py:chunk_8",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "9aca39e5323c5befb5540609f2821648cae70029f532fcba9c5ea3c3b9b8a8a5",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a text cleaning and formatting utility designed to normalize and improve the readability of multi-line text inputs by fixing paragraph spacing and removing excessive newlines and trailing whitespace.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.sub` and `re.split`) to identify and replace patterns of multiple newlines.  \n- Splits text into lines and paragraphs to process them individually.  \n- Applies line-level trimming (`rstrip`) to remove trailing whitespace.  \n- Differentiates between special blocks (code blocks, headers, lists) and regular paragraphs to preserve formatting for structured content.  \n- Joins cleaned lines or paragraphs back into a single string with normalized spacing.\n\n3. **Business Logic**:  \nThe code addresses the problem of inconsistent or messy text formatting, which is common in user-generated content, logs, or aggregated textual data. By enforcing consistent paragraph spacing and removing unnecessary blank lines, it improves the clarity and presentation of textual summaries or reports, enhancing user experience and downstream text processing.\n\n4. **Dependencies**:  \n- Python standard library: `re` module for regular expressions.  \n- No external libraries or services are referenced in this snippet.\n\n5. **Configuration**:  \n- No explicit environment variables, configuration files, or settings are used or required in this code snippet.\n\n6. **Error Handling**:  \n- The provided code does not include explicit error handling or exception management. It assumes well",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:00.193205",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_10": {
      "chunk_id": "response_cleaner.py:chunk_10",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "39384e5f5ddd6bc65f53fae5b05d9cebb330742f6701c88c2bd5298d810598c5",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a text cleaning utility that processes paragraphs by conditionally joining lines and provides a method to clean text while returning metadata about the cleaning process, such as line and length reductions.\n\n2. **Technical Details**:  \n- The code checks if lines in a paragraph start with common bullet or numbered list markers (`'-', '*', '+', '1.', '2.', '3.'`). If none of the lines start with these markers, it joins the lines into a single paragraph string.  \n- Paragraphs are then joined with double newlines to preserve paragraph separation.  \n- The `clean_with_metadata` method wraps the cleaning operation, capturing metrics before and after cleaning: number of lines, text length, and percentage reduction in length.  \n- Uses list comprehensions and string operations (`strip()`, `join()`) for efficient text manipulation.  \n- Returns a tuple containing the cleaned text and a metadata dictionary.\n\n3. **Business Logic**:  \nThis code supports the business need for producing clean, well-formatted textual summaries or responses by removing unnecessary line breaks except when formatting (like bullet points) should be preserved. The metadata helps track the effectiveness of the cleaning process, which can be useful for logging, auditing, or improving text processing pipelines.\n\n4. **Dependencies**:  \n- No explicit external libraries are shown in the snippet.  \n- Uses Python built-in types and functions (`str`, `list`, `tuple`,",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:06.176070",
      "status": "summarized"
    },
    "response_cleaner.py:chunk_12": {
      "chunk_id": "response_cleaner.py:chunk_12",
      "file_path": "orchestration\\summary_layer\\response_cleaner.py",
      "chunk_hash": "367d4cc5aa8f40238e64fbcacd11f1528e8325332570b376381ff187cec753c2",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet logs the details of a response cleaning operation, showing the reduction in lines and characters after cleaning, and returns the cleaned response along with metadata. It also defines a global instance of the `ResponseCleaner` class for reuse.\n\n2. **Technical Details**:  \n- Uses Python's formatted string literals (f-strings) for structured logging.  \n- Tracks and logs metrics such as original vs cleaned line counts and character lengths, as well as percentage reduction.  \n- Returns a tuple containing the cleaned data and associated metadata.  \n- Implements a singleton-like pattern by creating a global instance `response_cleaner` for centralized access.\n\n3. **Business Logic**:  \nThe code supports the business need to process and optimize textual responses by cleaning them\u2014likely to reduce payload size, improve readability, or remove unnecessary content\u2014while tracking the effectiveness of this cleaning for monitoring or auditing purposes.\n\n4. **Dependencies**:  \n- Assumes a `logger` instance is available for logging (likely from Python\u2019s `logging` module or a custom wrapper).  \n- Depends on the `ResponseCleaner` class definition, which is not shown here but is essential for the cleaning logic.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are referenced in this snippet. Configuration might be handled elsewhere in the `ResponseCleaner` class or logging setup.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. It assumes",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:11.388935",
      "status": "summarized"
    },
    "azure_voice_adapter.py:chunk_0": {
      "chunk_id": "azure_voice_adapter.py:chunk_0",
      "file_path": "orchestration\\voice_assistant\\azure_voice_adapter.py",
      "chunk_hash": "3d0353b0abaddcab96d19aea95e449c17b97ea3df69243e6fef3ffa69bf04b86",
      "chunk_index": 0,
      "summary": "**Summary:**\n\n1. **Purpose**  \nThis code defines an adapter class that integrates Azure AI services to convert spoken language into text (Speech-to-Text) with automatic language detection and subsequently translate the recognized text into English. It serves as a bridge for voice assistant orchestration to handle multilingual voice inputs seamlessly.\n\n2. **Technical Details**  \n- Implements a class `AzureVoiceAdapter` encapsulating Azure Speech and Translation services.  \n- Uses composition to instantiate `AzureSpeechService` and `AzureTranslationService` objects.  \n- Employs a configuration flag (`enable_translation`) to conditionally enable translation features.  \n- Uses Python\u2019s standard logging for operational insights.  \n- The design follows an adapter pattern, providing a unified interface abstracting underlying Azure service complexities.\n\n3. **Business Logic**  \nSolves the problem of enabling a voice assistant to understand and process user speech in multiple languages by:  \n- Automatically detecting the spoken language via Azure STT.  \n- Translating the detected text to English to standardize downstream processing.  \n- Providing fallback mechanisms if services are unavailable, ensuring robustness in voice interaction workflows.\n\n4. **Dependencies**  \n- `shared.azure_services` module providing `AzureSpeechService` and `AzureTranslationService` abstractions.  \n- `shared.config` module for application settings (`settings.enable_auto_translation`).  \n- Python standard libraries: `logging`, `typing` (for type hints).\n\n5. **Configuration**  \n- Controlled by a configuration setting `",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:16.795997",
      "status": "summarized"
    },
    "azure_voice_adapter.py:chunk_2": {
      "chunk_id": "azure_voice_adapter.py:chunk_2",
      "file_path": "orchestration\\voice_assistant\\azure_voice_adapter.py",
      "chunk_hash": "be2c1f14310f3e1987602cb7be5b7939cb81b59c7496c98430fa1f1c2c537e66",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method processes audio input by converting speech to text using Azure's speech-to-text (STT) service, optionally detecting the spoken language and translating the transcript if enabled.\n\n2. **Technical Details**:  \n- Uses async/await for non-blocking I/O operations.  \n- Accepts base64-encoded audio and supports multiple audio formats (webm, mp3, wav).  \n- Implements a pipeline pattern: first transcribes audio with language auto-detection, then optionally translates the text.  \n- Returns a tuple containing the original transcript, translated text, detected language, and an optional confidence note.  \n- Uses logging for traceability and debugging.\n\n3. **Business Logic**:  \nEnables voice assistant functionality by converting user speech into text and translating it if needed, supporting multilingual interactions and enhancing accessibility for users speaking different languages.\n\n4. **Dependencies**:  \n- Azure Speech Services SDK or a custom wrapper (`self.speech_service`) for speech transcription and language detection.  \n- Python standard libraries for async operations and logging.  \n- Possibly other internal modules for translation (not shown in snippet).\n\n5. **Configuration**:  \n- `self.enable_translation`: a boolean flag controlling whether translation is performed.  \n- Audio format parameter defaults to \"webm\" but can be configured per call.  \n- Likely configured via environment variables or config files outside this snippet to set Azure credentials and service endpoints.\n\n6. **",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:25.300035",
      "status": "summarized"
    },
    "azure_voice_adapter.py:chunk_4": {
      "chunk_id": "azure_voice_adapter.py:chunk_4",
      "file_path": "orchestration\\voice_assistant\\azure_voice_adapter.py",
      "chunk_hash": "69a8f3332e428a798edf9bea088eb42b1110d1ecf01e0269112b0270582ffdb5",
      "chunk_index": 4,
      "summary": "**Summary:**\n\n1. **Purpose**:  \n   This code segment handles errors related to the availability and configuration of Azure Speech-to-Text (STT) and translation services within a voice assistant orchestration module. Specifically, it ensures that transcription only proceeds if Azure STT is configured and available, and that translation to English is performed only when enabled and necessary.\n\n2. **Exception Types**:  \n   - Raises a `ValueError` explicitly when the Azure Speech Service is not configured or unavailable.  \n   - No other explicit exception types are caught or raised in this snippet.\n\n3. **Recovery Strategy**:  \n   - The code does not implement retries or alternative recovery mechanisms upon failure of the Azure STT service. Instead, it raises an exception to halt further processing.  \n   - For translation, it conditionally skips translation if the detected language is English or if the translation service is unavailable, avoiding unnecessary errors.\n\n4. **Logging**:  \n   - Uses `logger.info` to log successful transcription and translation steps, including detected languages and translated text.  \n   - Uses `logger.warning` to log when Azure STT is not available, providing visibility into configuration or service availability issues.\n\n5. **User Impact**:  \n   - If Azure STT is not configured, transcription fails immediately, likely causing the voice assistant to not process user speech input, resulting in a failure or degraded user experience.  \n   - If translation is disabled or not needed, the user input",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:31.608155",
      "status": "summarized"
    },
    "azure_voice_adapter.py:chunk_6": {
      "chunk_id": "azure_voice_adapter.py:chunk_6",
      "file_path": "orchestration\\voice_assistant\\azure_voice_adapter.py",
      "chunk_hash": "b3bf383f4f5e4fb871c501116d0a3b76d80a9e66bd94ba820e5b9d56a25cdfb4",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet is part of an Azure voice adapter module that processes voice input by detecting the language, optionally translating the text to English, and logging the results. It also provides a method to check the availability of Azure voice services.\n\n2. **Technical Details**:  \n- Uses conditional logic to determine if translation is needed based on detected language and configuration flags.  \n- Logs detailed information about the original and translated text along with language detection confidence notes.  \n- Employs exception handling to catch and log errors during voice processing.  \n- The `is_available` method acts as a simple proxy to check the underlying speech service availability.  \n- The code snippet suggests a class-based design with encapsulated service calls (e.g., `self.speech_service.is_available()`).\n\n3. **Business Logic**:  \n- Enables multilingual voice input handling by detecting language and translating non-English input to English, facilitating consistent downstream processing.  \n- Supports scenarios where translation may be disabled or unavailable, ensuring graceful fallback to original text.  \n- Provides operational transparency through detailed logging, aiding debugging and monitoring.\n\n4. **Dependencies**:  \n- Azure Speech Services SDK or a custom wrapper (`self.speech_service`) for speech recognition and translation.  \n- A logging framework (`logger`) for info and error messages.\n\n5. **Configuration**:  \n- Likely relies on configuration flags or environment variables to enable/disable translation features (implied by comments and conditional checks).  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:37.179902",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_0": {
      "chunk_id": "azure_config_validator.py:chunk_0",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "0db1d3371bdc6281a8e27f6b8432fe0f94671bfeb916a5865de77a9b5d4ad011",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module defines a service class `AzureConfigValidator` that validates Azure AI-related configuration parameters loaded from `.env` files. It ensures all required Azure service environment variables are present and correctly set, separating validation logic from the main Azure AI management components.\n\n2. **Technical Details**:  \n- Uses a dictionary (`required_vars`) to define required Azure configuration keys and their default/example values.  \n- Likely reads environment variables or `.env` files (though full code not shown) to check presence and validity of these keys.  \n- Employs standard Python logging for reporting validation status or issues.  \n- Uses class encapsulation to organize validation logic and potentially provide methods for checking, reporting, and managing `.env` files.\n\n3. **Business Logic**:  \nEnsures that all necessary Azure AI service credentials and endpoints are correctly configured before the application attempts to use Azure Speech and Translation services. This prevents runtime failures due to missing or incorrect configuration, improving reliability and maintainability of AI-powered features.\n\n4. **Dependencies**:  \n- Python standard libraries: `logging`, `os`, `pathlib.Path`, `typing` (Dict, Any, List)  \n- Internal module: `shared.config.settings` (likely for accessing application-wide configuration or environment settings)\n\n5. **Configuration**:  \n- Environment variables related to Azure services, specifically:  \n  - Azure Speech Service: `AZURE_SPEECH_KEY`, `AZURE_SPE",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:43.335385",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_2": {
      "chunk_id": "azure_config_validator.py:chunk_2",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "724eac1acbec9b68f7d8f2c17cd7c0a2d25fdb3bd95620d39a8e1787a4a60cc5",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a configuration validator for Azure-related services, specifically validating that required Azure AI and OpenAI deployment settings are correctly set in the environment configuration.\n\n2. **Technical Details**:  \n- Uses a dictionary to store key-value pairs representing Azure service configuration parameters.  \n- Implements a method `validate_configuration` that checks for missing or incomplete configuration values, accumulating missing keys and warnings.  \n- Likely relies on a `settings` object (not fully shown) to access environment variables or configuration values.  \n- The validation method returns structured feedback (missing keys, warnings) to ensure configuration completeness before runtime.\n\n3. **Business Logic**:  \nEnsures that all necessary Azure AI and OpenAI service credentials and deployment names are properly configured to enable seamless integration with Azure cognitive services, preventing runtime failures due to misconfiguration. This is critical for applications relying on Azure OpenAI models, speech-to-text, transcription, and multi-service AI endpoints.\n\n4. **Dependencies**:  \n- Azure Cognitive Services endpoints and keys (external cloud services).  \n- Presumably depends on a `settings` module or object that loads environment variables (e.g., via `pydantic`, `dotenv`, or similar).  \n- Python standard libraries (`typing.Dict`, `Any`) for type hinting.\n\n5. **Configuration**:  \n- Environment variables or settings keys such as:  \n  - `AZURE_OPENAI_ENDPOINT`  \n  -",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:48.252583",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_4": {
      "chunk_id": "azure_config_validator.py:chunk_4",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "18c674226184dc660333448540ae5a398f761dd5cff71cff43948d857440e4e4",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet validates the presence of essential Azure service configuration settings, appending missing required configurations to an error list and noting optional configurations with default fallbacks as warnings.\n\n2. **Technical Details**:  \n- Uses conditional checks on configuration attributes (likely from a settings object) to verify presence or absence.  \n- Appends missing required configuration keys to a `missing_config` list.  \n- Appends informational warnings for optional configurations that have defaults but should ideally be explicitly set.  \n- No complex algorithms or data structures beyond list appends and boolean logic.\n\n3. **Business Logic**:  \nEnsures that the application has the necessary Azure service credentials and deployment names configured before runtime, preventing misconfiguration issues that could cause failures in speech recognition, translation, or OpenAI model usage. This validation helps maintain reliability and proper integration with Azure cognitive services.\n\n4. **Dependencies**:  \n- Relies on a `settings` object or module that holds Azure-related configuration values.  \n- Implicit dependency on Azure Cognitive Services (Speech, Translation) and Azure OpenAI services for which these configurations are relevant.\n\n5. **Configuration**:  \n- Environment variables or config file entries expected:  \n  - `AZURE_SPEECH_REGION`  \n  - `AZURE_TRANSLATION_KEY` or `AZURE_TRANSLATOR_KEY`  \n  - `AZURE_TRANSLATION_REGION` or `AZURE_TRANSLATOR_REGION`  \n  - `AZURE_OPENAI",
      "embedding_id": null,
      "created_at": "2025-10-22T20:03:55.094449",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_6": {
      "chunk_id": "azure_config_validator.py:chunk_6",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "52b4cc8fd7600da18053a788d5435f195a8154007f5d316d0d34725f5b34f969",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a configuration validation utility for Azure-related services, specifically validating and reporting the status of Azure Speech and Translation service configurations from environment settings.\n\n2. **Technical Details**:  \n- Uses dictionary data structures to aggregate configuration status and warnings.  \n- Implements boolean checks to verify presence and completeness of required configuration keys.  \n- Returns structured dictionaries indicating missing configurations, warnings, and overall validity.  \n- The method `get_configuration_status` provides a detailed snapshot of current Azure service configuration states.\n\n3. **Business Logic**:  \nEnsures that the application has the necessary Azure service credentials and endpoints configured correctly to enable features like speech-to-text (STT), text-to-speech (TTS), and translation. This validation helps prevent runtime failures due to missing or incomplete Azure service configurations, improving reliability and user experience.\n\n4. **Dependencies**:  \n- Relies on a `settings` object or module that encapsulates environment variables or configuration parameters (likely loaded from `.env` or similar config files).  \n- Uses standard Python data types and typing hints (`Dict`, `Any`).  \n- No explicit external libraries are shown in the snippet, but it depends on Azure service keys and endpoints being set externally.\n\n5. **Configuration**:  \n- Environment variables or settings keys expected include:  \n  - `azure_gpt_audio_mini_deployment` (with a default fallback)  \n  - `azure_speech_key",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:02.246100",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_8": {
      "chunk_id": "azure_config_validator.py:chunk_8",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "48bd8361d2d42f25d692635679a15bdf436c37a112ffeca349862ad768d31aa2",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet validates and consolidates configuration settings related to Azure services, specifically Azure Translator and Azure OpenAI, by checking the presence and values of various keys and endpoints to determine if these services are properly configured.\n\n2. **Technical Details**:  \n- Uses Python dictionaries to organize configuration status and parameters for different Azure services.  \n- Employs boolean expressions to check the presence of required keys and endpoints.  \n- Uses logical OR (`or`) operators to provide fallback values for settings (e.g., default endpoints or deployment names).  \n- No complex algorithms or design patterns are evident; the code is primarily configuration validation and aggregation.\n\n3. **Business Logic**:  \nEnsures that the application has the necessary Azure service credentials and endpoints configured before attempting to use those services. This prevents runtime errors and enables conditional logic elsewhere in the application to activate or deactivate features depending on service availability.\n\n4. **Dependencies**:  \n- Relies on a `settings` object or module that holds configuration values, likely loaded from environment variables or configuration files.  \n- Implicit dependency on Azure Cognitive Services and Azure OpenAI services for which these configurations apply.\n\n5. **Configuration**:  \n- Reads multiple configuration keys such as `azure_translation_key`, `azure_translator_key`, `azure_translation_region`, `azure_openai_endpoint`, `azure_openai_api_key`, `azure_openai_api_version`, and deployment names.  \n- Provides default values where appropriate,",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:09.217883",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_10": {
      "chunk_id": "azure_config_validator.py:chunk_10",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "a8bc7ed76f3481be047c8505e83fbfc03fddfc91bbf92af444d5b58adabeb2f4",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a configuration validation utility that checks for the presence and correctness of required Azure-related environment variables. It optionally updates a `.env` file with missing variables to ensure proper configuration for Azure AI services.\n\n2. **Technical Details**:  \n- Uses a dictionary (`self.required_vars`) to define required environment variables and their default values.  \n- Iterates over these variables, checking their presence and validity in the current environment using `os.getenv()`.  \n- Identifies missing or placeholder values (e.g., values starting with `\"your-\"`) as invalid.  \n- Returns a dictionary summarizing missing variables and potentially updates the `.env` file if requested.  \n- Uses boolean logic to determine if Azure AI services are configured based on key and endpoint presence.\n\n3. **Business Logic**:  \nEnsures that critical Azure AI service configuration parameters (like API keys and endpoints) are correctly set before the application runs. This validation prevents runtime failures due to misconfiguration and supports automated environment setup by optionally updating `.env` files.\n\n4. **Dependencies**:  \n- Python standard library: `os` for environment variable access.  \n- Presumably a `settings` module or object that holds configuration values (not fully shown).  \n- Possibly uses `.env` file handling libraries or custom file I/O for updating environment variables (not shown in snippet).\n\n5. **Configuration**:  \n- Environment variables such as `azure_ai_services_key",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:15.086477",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_12": {
      "chunk_id": "azure_config_validator.py:chunk_12",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "0e8afba05f9a237d051ea60b16effa1cf8062c40f217e92b0ef5cb563435d0ad",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a utility that validates Azure-related environment variables and optionally updates a local `.env` file by appending any missing configuration variables required for Azure AI services.\n\n2. **Technical Details**:  \n- Uses file I/O operations to read and write to a `.env` file located in the current working directory.  \n- Employs a dictionary (`result`) to track the status of the update operation, including whether the file was modified and which variables were added.  \n- Checks for the existence of the `.env` file using `Path.exists()` from the `pathlib` module.  \n- Ensures proper formatting by adding a newline if the existing `.env` file does not end with one before appending new variables.  \n- Uses a list (`new_content_lines`) to accumulate lines to append to the `.env` file, including a comment header for clarity.\n\n3. **Business Logic**:  \nThe code supports automated environment configuration management for Azure AI services by ensuring all required environment variables are present. This reduces manual setup errors and streamlines deployment or development workflows that depend on Azure configurations.\n\n4. **Dependencies**:  \n- Python standard library modules: `pathlib.Path` for file path handling, built-in `open()` for file operations.  \n- Typing hints (`List`, `Dict`, `Any`) indicating use of Python's `typing` module for type annotations.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:20.466250",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_14": {
      "chunk_id": "azure_config_validator.py:chunk_14",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "e034f98e3d0728944343a66959416bb94c5c0357f7bc1bb78dcfcd6e3617565f",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a Python class responsible for validating and updating environment configuration files (specifically `.env` files) by ensuring required environment variables are present, adding missing ones with default values, and logging the validation results.\n\n2. **Technical Details**:  \n- The code checks if each required environment variable (`var_name`) is present in the existing `.env` file content.  \n- Missing variables are appended to a list (`new_content_lines`) with their default values sourced from `self.required_vars`.  \n- The `.env` file is updated by appending new variables at the end if any are missing.  \n- Results of the operation (added variables, file update status, errors) are collected in a dictionary `result`.  \n- Logging is used extensively to report success, warnings, and errors.  \n- The `log_validation_results` method calls `validate_configuration()` (not fully shown) to retrieve validation info and logs warnings for missing configuration.\n\n3. **Business Logic**:  \nEnsures that critical environment variables required for Azure services or application configuration are present and correctly set in the `.env` file, preventing runtime failures due to missing configuration and facilitating smoother deployment and environment consistency.\n\n4. **Dependencies**:  \n- Uses Python's built-in file I/O for reading and writing `.env` files.  \n- Uses a `logger` object for logging info, warnings, and errors (likely from the `logging` module or a",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:27.690783",
      "status": "summarized"
    },
    "azure_config_validator.py:chunk_16": {
      "chunk_id": "azure_config_validator.py:chunk_16",
      "file_path": "shared\\azure_services\\azure_config_validator.py",
      "chunk_hash": "92ea329ec2953296e0bb933697ef0e1acfb7f06d67e7bd21de48e41adc5e6079",
      "chunk_index": 16,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet logs the status of Azure AI configuration validation, indicating which configuration values are using defaults and confirming when all required Azure AI settings are properly set.\n\n2. **Technical Details**:  \n- Uses Python's logging module to output informational messages.  \n- Checks a `validation` dictionary containing keys `\"warnings\"` (a list of config keys using default values) and `\"is_valid\"` (a boolean indicating overall config validity).  \n- String formatting with f-strings to dynamically generate log messages.  \n- Instantiates a singleton/global instance of `AzureConfigValidator` for reuse.\n\n3. **Business Logic**:  \nEnsures that the Azure AI service configuration is correctly set up before the application proceeds, helping prevent runtime errors due to misconfiguration and providing visibility into which settings are defaulted.\n\n4. **Dependencies**:  \n- Python standard `logging` module (implied by `logger.info`).  \n- A custom `AzureConfigValidator` class defined elsewhere in the codebase.\n\n5. **Configuration**:  \n- Relies on environment variables or `.env` file values for Azure AI configuration parameters, validated by `AzureConfigValidator`.  \n- The `.env` file is referenced in the log message, indicating it as the source of configuration.\n\n6. **Error Handling**:  \n- No explicit exception handling in this snippet; assumes validation results are precomputed and passed in.  \n- Warnings about default values are logged but do not",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:34.762294",
      "status": "summarized"
    },
    "confluence_wrapper.py:chunk_0": {
      "chunk_id": "confluence_wrapper.py:chunk_0",
      "file_path": "shared\\clients\\wrappers\\confluence_wrapper.py",
      "chunk_hash": "c2fe0a97c7384d78c75451ef4b2b4c5e7e7d25f9d4b9dd3e80790f8d1217d2d1",
      "chunk_index": 0,
      "summary": "**Summary of `confluence_wrapper.py`**\n\n1. **Purpose**  \n   This code defines a `ConfluenceWrapper` class that acts as a unified client interface for interacting with Confluence, leveraging environment-based configuration for authentication and providing a consistent API for business logic layers.\n\n2. **Technical Details**  \n   - Uses a wrapper design pattern to encapsulate the underlying `ConfluenceClient`.  \n   - Lazy initialization of the client based on environment variables.  \n   - Employs Python\u2019s `logging` module for operational insights.  \n   - Uses type hints (`Optional`, `Dict`, `Any`, `List`) for better code clarity and static analysis.  \n   - The `_initialize` method checks for required environment variables and conditionally imports and instantiates the client.  \n   - Asynchronous method usage is implied (e.g., `await wrapper.get_page(...)`), suggesting the underlying client supports async operations.\n\n3. **Business Logic**  \n   Provides a simplified, consistent interface to interact with Confluence pages and resources, abstracting away authentication and client configuration details. This enables business applications to retrieve or manipulate Confluence content without managing connection details or credentials directly.\n\n4. **Dependencies**  \n   - `shared.config.settings`: For accessing environment-based configuration values.  \n   - `shared.clients.confluence_client.ConfluenceClient`: The actual client used to communicate with Confluence APIs.  \n   - Python standard libraries: `logging`, `typing`.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:41.292373",
      "status": "summarized"
    },
    "confluence_wrapper.py:chunk_2": {
      "chunk_id": "confluence_wrapper.py:chunk_2",
      "file_path": "shared\\clients\\wrappers\\confluence_wrapper.py",
      "chunk_hash": "7ad16b0f22655a2ab948deb6662dc14c521beb5dd189639d198f354baa4fad46",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines a wrapper class for interacting with a Confluence client, providing asynchronous methods to get and create Confluence pages based on environment configuration.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to interact with the Confluence API client.  \n- Encapsulates the Confluence client instance (`_env_client`) and exposes a simplified interface.  \n- Uses Python properties (`@property`) to expose configuration status and active provider information.  \n- Conditional logic to check if the client is configured before making API calls.\n\n3. **Business Logic**:  \nEnables seamless integration with Confluence for content management by abstracting the client initialization and providing methods to retrieve and create pages. This supports business workflows that require automated documentation or content updates in Confluence.\n\n4. **Dependencies**:  \n- An underlying Confluence client class (not shown) that implements `get_page` and `create_page` asynchronously.  \n- A logger instance for logging warnings, info, and errors.\n\n5. **Configuration**:  \n- Relies on environment-based configuration to initialize the Confluence client (`_env_client`).  \n- If environment variables or settings for the Confluence client are missing or invalid, the client is not initialized (`_env_client` is None).  \n- The active provider is set based on successful client initialization.\n\n6. **Error Handling**:  \n- Catches exceptions during client initialization and logs a warning with the",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:49.785700",
      "status": "summarized"
    },
    "confluence_wrapper.py:chunk_4": {
      "chunk_id": "confluence_wrapper.py:chunk_4",
      "file_path": "shared\\clients\\wrappers\\confluence_wrapper.py",
      "chunk_hash": "ebf66d06dbca3d5b8f96dcdd919ceb0a27185329d9ae49b9a1dec4229ded9d91",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code defines asynchronous wrapper methods to interact with a Confluence service client, enabling operations such as updating pages, searching pages, adding labels, and testing connectivity.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially I/O-bound operations with Confluence APIs.  \n- Delegates actual API calls to an underlying client instance (`self._env_client`), following a wrapper or proxy design pattern.  \n- Returns boolean flags or lists/dictionaries to indicate success or provide data results.  \n- Uses Python type hints for method signatures to improve code clarity and type checking.\n\n3. **Business Logic**:  \nFacilitates integration with Confluence to programmatically manage content (pages and labels) and perform searches, supporting business workflows that require automated documentation updates, content tagging, and retrieval within Confluence.\n\n4. **Dependencies**:  \n- An internal or external Confluence client instance (`self._env_client`) which implements the actual API calls.  \n- `logger` for error logging (likely Python\u2019s standard logging module or a configured logger).  \n- Python standard typing modules (`List`, `Dict`, `Any`, `Optional`) for type annotations.\n\n5. **Configuration**:  \n- The presence and configuration of `self._env_client` is critical; it likely depends on environment-specific setup or dependency injection to provide a configured Confluence client.  \n- No explicit environment variables or config files are shown here",
      "embedding_id": null,
      "created_at": "2025-10-22T20:04:57.444972",
      "status": "summarized"
    },
    "confluence_wrapper.py:chunk_6": {
      "chunk_id": "confluence_wrapper.py:chunk_6",
      "file_path": "shared\\clients\\wrappers\\confluence_wrapper.py",
      "chunk_hash": "0c308748cbc1cbc30e9a53612e71fc890852a22b3c656dd87045878729c5e35e",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code provides a lazy-initialized singleton wrapper instance for interacting with Confluence spaces, although the actual method to retrieve all Confluence spaces is currently unimplemented.\n\n2. **Technical Details**:  \n- Implements a singleton pattern via a module-level private variable `_confluence_wrapper_instance` and a factory function `get_confluence_wrapper()` that initializes the `ConfluenceWrapper` instance on first use (lazy initialization).  \n- Uses a property for backward compatibility that delegates to the singleton getter.  \n- Contains a stub method `get_spaces` that checks for an environment client (`_env_client`) and logs a warning if called, returning `None` in all cases.\n\n3. **Business Logic**:  \nIntended to provide a unified interface to retrieve Confluence spaces, which would be useful for applications needing to integrate or synchronize with Confluence content repositories. However, the core retrieval functionality is not yet implemented, indicating this is a placeholder or scaffold for future development.\n\n4. **Dependencies**:  \n- Presumably depends on a `ConfluenceWrapper` class defined elsewhere in the codebase.  \n- Uses a `logger` object for logging warnings (likely from Python\u2019s standard `logging` module or a custom logger).  \n- No direct external libraries or Confluence API calls are shown in this snippet.\n\n5. **Configuration**:  \n- Checks for an internal flag or attribute `_env_client` to determine client type, suggesting environment-specific",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:03.525062",
      "status": "summarized"
    },
    "jira_wrapper.py:chunk_0": {
      "chunk_id": "jira_wrapper.py:chunk_0",
      "file_path": "shared\\clients\\wrappers\\jira_wrapper.py",
      "chunk_hash": "b051ce7c34f01a4123a93dfb059d636dd4845634e10673229e4d10c8c677a083",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a `JiraWrapper` class that acts as a unified client for interacting with Jira. It abstracts the authentication and client initialization logic, allowing seamless switching between different Jira integration providers based on environment configuration.\n\n2. **Technical Details**:  \n- Uses a wrapper/facade design pattern to encapsulate multiple Jira client implementations behind a single interface.  \n- Lazy initialization of the underlying Jira client based on environment variables.  \n- Conditional import and instantiation of the Jira client depending on configuration presence.  \n- Uses Python\u2019s `logging` module for internal logging.  \n- Type hints (`Optional`, `Dict`, `Any`, `List`) are used for better code clarity and static analysis.\n\n3. **Business Logic**:  \nSolves the problem of managing Jira API integrations in a flexible way, enabling the application to authenticate and communicate with Jira either via environment-based credentials or alternative providers (originally Replit, now removed). This allows business logic to remain agnostic of the underlying Jira integration details, simplifying maintenance and provider switching.\n\n4. **Dependencies**:  \n- `shared.config.settings`: Configuration management, presumably loading environment variables or config files.  \n- `shared.clients.jira_client.JiraClient`: The primary Jira API client used when environment variables are set.  \n- Python standard libraries: `logging`, `typing`.\n\n5. **Configuration**:  \nRelies on the following environment variables or settings:  \n- `jira_url`",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:11.106414",
      "status": "summarized"
    },
    "jira_wrapper.py:chunk_2": {
      "chunk_id": "jira_wrapper.py:chunk_2",
      "file_path": "shared\\clients\\wrappers\\jira_wrapper.py",
      "chunk_hash": "6f912f8d9093366621669091a3c44111d7e6bf8af0c9699d4e2aa8fab282b6e3",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code defines a Jira client wrapper that abstracts interaction with Jira's API, primarily supporting an environment-variable-based configuration. It provides asynchronous methods to fetch individual Jira issues and search for issues using JQL queries.\n\n2. **Technical Details**:  \n- Uses an object-oriented design with properties and async methods.  \n- Supports multiple providers conceptually (ENV-based and Replit connector), though only ENV-based client is currently implemented.  \n- Uses asynchronous methods (`async def`) for I/O-bound operations, likely to integrate with async frameworks.  \n- Employs logging for informational and error messages.  \n- Uses Optional typing hints and returns dictionaries representing Jira issues.\n\n3. **Business Logic**:  \nEnables business applications to programmatically access Jira issue data for tracking, reporting, or automation purposes without directly managing Jira API details or authentication. This abstraction simplifies integration with Jira in environments where credentials are provided via environment variables.\n\n4. **Dependencies**:  \n- A Jira client library (not shown but implied by `_env_client.get_issue()` calls).  \n- Python standard logging module (`logger`).  \n- Python typing module for type hints (`Optional`, `Dict`, `List`, `Any`).  \n- Possibly an async event loop or framework to run async methods.\n\n5. **Configuration**:  \n- Relies on environment variables: `JIRA_URL`, `JIRA_EMAIL`, and `JIRA_API_TOKEN` to configure the Jira client.  \n- No",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:17.810699",
      "status": "summarized"
    },
    "jira_wrapper.py:chunk_4": {
      "chunk_id": "jira_wrapper.py:chunk_4",
      "file_path": "shared\\clients\\wrappers\\jira_wrapper.py",
      "chunk_hash": "7a11cafaad0dde1b7adda957793280b0710186a21a5f1426b5ba6ef751c5012f",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Python code provides an asynchronous wrapper around a Jira client to perform common Jira operations such as searching issues, creating issues, adding comments, and transitioning issue statuses.\n\n2. **Technical Details**:  \n- Uses asynchronous methods (`async def`) to enable non-blocking calls to Jira operations.  \n- Delegates actual Jira API interactions to an internal client instance (`self._env_client`).  \n- Implements conditional logic to check for the presence of a configured Jira client before performing operations.  \n- Uses standard Python typing hints (`Optional`, `List[str]`) for method signatures.  \n- Logging is used to report missing Jira client configuration.\n\n3. **Business Logic**:  \nFacilitates integration with Jira issue tracking by abstracting Jira API calls, enabling automated issue management workflows such as issue creation, commenting, searching, and status transitions. This supports business processes like bug tracking, task management, and project tracking.\n\n4. **Dependencies**:  \n- An internal Jira client instance (`self._env_client`) which presumably wraps Jira REST API calls.  \n- Python `logging` module for error reporting.  \n- Python `typing` module for type annotations.  \n- The snippet references a removed \"Replit client,\" indicating prior support for multiple Jira clients.\n\n5. **Configuration**:  \n- The Jira client (`self._env_client`) is expected to be configured externally, likely via environment variables or dependency injection.  \n- No explicit environment variables or config files",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:23.036912",
      "status": "summarized"
    },
    "jira_wrapper.py:chunk_6": {
      "chunk_id": "jira_wrapper.py:chunk_6",
      "file_path": "shared\\clients\\wrappers\\jira_wrapper.py",
      "chunk_hash": "6ee91fc95df13216ee0b4130ec8f60b1bf6b8507503d3827df78dace31d4981b",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code provides a lazy-initialized singleton wrapper for interacting with a Jira client, enabling issue transitions through a Jira provider. It ensures that the JiraWrapper instance is created only when first needed.\n\n2. **Technical Details**:  \n- Implements the Singleton design pattern via a module-level private variable `_jira_wrapper_instance` and a factory function `get_jira_wrapper()` for lazy initialization.  \n- Uses a property `jira_wrapper` for backward compatibility, exposing the JiraWrapper instance in a legacy-compatible manner.  \n- The snippet shows a conditional call to `self._env_client.transition_issue(issue_key, transition_name)` to perform issue transitions, with a fallback error log and a `False` return if no Jira provider is configured.\n\n3. **Business Logic**:  \nFacilitates automated transitions of Jira issues within a workflow, supporting business processes that rely on Jira for issue tracking and lifecycle management. It abstracts Jira client interactions to simplify integration and maintain consistent usage across the codebase.\n\n4. **Dependencies**:  \n- Assumes existence of a `JiraWrapper` class and an `_env_client` attribute within it that handles Jira API calls.  \n- Uses a `logger` for error logging.  \n- Likely depends on an underlying Jira Python client or REST API wrapper (not shown in the snippet).\n\n5. **Configuration**:  \n- The Jira provider configuration is implied but not explicitly shown; it likely depends on environment variables or config files",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:27.737382",
      "status": "summarized"
    },
    "input_router.py:chunk_0": {
      "chunk_id": "input_router.py:chunk_0",
      "file_path": "shared\\routing\\input_router.py",
      "chunk_hash": "5b8afe355faa95e2e89fbc5152e9a94d16a4e6628724d8508c31788a2641fb27",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis module defines an `InputRouter` class that routes user inputs, either text or voice, to the appropriate processing pipeline, converting voice inputs to text when necessary.\n\n2. **Technical Details**  \n- Uses an `Enum` (`InputType`) to clearly distinguish input types (`TEXT`, `VOICE`, `UNKNOWN`).  \n- The `InputRouter` class optionally integrates with an Azure Speech Service instance for speech-to-text conversion.  \n- The main method `route` is asynchronous (`async`), indicating it likely performs I/O-bound operations such as calling external speech recognition services.  \n- Input is expected as a dictionary with keys `\"type\"`, `\"content\"`, and optional `\"metadata\"`.  \n- The output is a dictionary containing the normalized input type, processed text, original input, detected language (for voice), and any error messages.\n\n3. **Business Logic**  \nThis code abstracts the complexity of handling different input modalities (voice or text) and normalizes them into a unified text representation. This enables downstream components to process user inputs uniformly, improving user experience in applications like chatbots, virtual assistants, or voice-enabled interfaces.\n\n4. **Dependencies**  \n- Python standard libraries: `typing` for type hints, `logging` for logging, and `enum` for enumerations.  \n- Optional integration with Azure Speech Service (not explicitly imported here but passed as a dependency).\n\n5. **Configuration**  \n- No explicit environment variables or config files",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:32.132454",
      "status": "summarized"
    },
    "input_router.py:chunk_2": {
      "chunk_id": "input_router.py:chunk_2",
      "file_path": "shared\\routing\\input_router.py",
      "chunk_hash": "a48827d242711688579194547a54a0c3c865fcc189813907dfefc0a29f76e675",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of an input routing module that detects the type of user input (voice or text) and processes it accordingly, specifically converting voice inputs to text using Azure Speech-to-Text services.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially long-running I/O operations such as speech transcription.  \n- Implements an input type detection mechanism (`_detect_input_type`) to differentiate between voice and text inputs.  \n- Uses a dictionary-based data structure for input and output, encapsulating input type, original data, transcribed text, and error messages.  \n- Encapsulates voice processing logic in a private method `_process_voice_input`, which interacts with an external speech service.  \n- Logging is used for error reporting.\n\n3. **Business Logic**:  \nThe code supports a multi-modal input system where users can provide either voice or text inputs. It enables voice inputs to be transcribed into text, facilitating downstream text-based processing such as natural language understanding or command execution, thus enhancing user experience and accessibility.\n\n4. **Dependencies**:  \n- Azure Speech-to-Text service (implied by the comment and `self.speech_service` usage).  \n- A logging framework (`logger`).  \n- Custom or external `InputType` enumeration or class to represent input categories.  \n- Python's asynchronous features (`async/await`).\n\n5. **Configuration**:  \n- The presence",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:37.505324",
      "status": "summarized"
    },
    "input_router.py:chunk_4": {
      "chunk_id": "input_router.py:chunk_4",
      "file_path": "shared\\routing\\input_router.py",
      "chunk_hash": "86917e35fd23e15dd483eff103f5a13e6930ea20ddb3a6d1fe34b1c0ada89c14",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet transcribes voice input audio data into text using the Azure Speech Service, detects the spoken language, and returns a structured response containing the transcription results or error details.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to call an external speech-to-text service.  \n- Invokes a method `transcribe_audio` on a `speech_service` object, passing raw audio data and format.  \n- Returns a dictionary with keys such as `input_type`, `text`, `language`, `original`, and optionally `error`.  \n- Logging is used extensively for success and error reporting.  \n- Uses an `InputType` enum or constant to tag the input as voice.  \n- Exception handling wraps the transcription call to catch and log any runtime errors.\n\n3. **Business Logic**:  \nEnables voice input processing by converting spoken audio into text, facilitating voice-driven user interactions or commands in an application. It supports multi-language detection to enhance user experience and downstream processing based on language context.\n\n4. **Dependencies**:  \n- Azure Speech Service SDK or a custom wrapper (`self.speech_service.transcribe_audio`).  \n- Logging module (`logger`).  \n- `InputType` enum or constant for input classification.\n\n5. **Configuration**:  \n- Likely requires Azure Speech Service credentials and region configuration (not shown in snippet).  \n- Audio format and data are inputs, possibly configured elsewhere in the application.",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:43.706419",
      "status": "summarized"
    },
    "input_router.py:chunk_6": {
      "chunk_id": "input_router.py:chunk_6",
      "file_path": "shared\\routing\\input_router.py",
      "chunk_hash": "7b6c02c3144ff3456dcc913eb2ae980ced005d2716aeb323094af4227552ce9d",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code asynchronously processes text input data by extracting and validating the text content, logging relevant information, and returning a structured dictionary indicating the input type and content. It also includes a partial method to detect the input type from the provided data.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for non-blocking input processing.  \n- Input data is handled as a dictionary (`Dict[str, Any]`), leveraging Python\u2019s typing for clarity.  \n- Implements basic validation by checking for the presence of the \"content\" key and its non-empty value.  \n- Uses structured logging (`logger.info`, `logger.error`) to track processing status and errors.  \n- Returns a consistent dictionary structure containing the input type (likely an enum `InputType`), the processed text, the original input, and error messages if applicable.  \n- The `_detect_input_type` method (partially shown) suggests a design pattern for input type detection based on a \"type\" string field.\n\n3. **Business Logic**:  \nThe code is designed to handle and normalize user input in text form, ensuring that empty or invalid inputs are flagged and logged. This supports business workflows that rely on clean, validated textual input, such as chatbots, voice assistants, or any system requiring text input processing.\n\n4. **Dependencies**:  \n- `InputType`: An enum or class defining input types (e.g., TEXT, VOICE).",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:49.224679",
      "status": "summarized"
    },
    "input_router.py:chunk_8": {
      "chunk_id": "input_router.py:chunk_8",
      "file_path": "shared\\routing\\input_router.py",
      "chunk_hash": "4ee64f04dc2576a6add0cd3e616c230e96ffe61ed853f13b985856e04d3d42d3",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet determines the type of input data (voice or text) based on a string identifier or by inspecting the input data content, returning an appropriate `InputType` enum value.\n\n2. **Technical Details**:  \n- Uses conditional checks on a string (`input_type_str`) and dictionary keys (`input_data.get(...)`) to classify input.  \n- Implements a simple heuristic for auto-detection: presence of \"audio\" substring or a \"format\" key implies voice input; presence of a string-type \"content\" implies text input.  \n- Returns values from an `InputType` enum, presumably defined elsewhere, with possible values like `VOICE`, `TEXT`, and `UNKNOWN`.\n\n3. **Business Logic**:  \nEnables the system to correctly identify and route different types of user inputs (voice or text), which is critical for processing them with appropriate downstream services such as speech recognition or text analysis.\n\n4. **Dependencies**:  \n- Relies on an `InputType` enum, likely defined in the same module or imported.  \n- Uses standard Python data structures (strings, dictionaries).  \n- No external libraries or services are directly referenced in this snippet.\n\n5. **Configuration**:  \n- No explicit environment variables or configuration files are referenced here.  \n- Behavior depends on the format of `input_type_str` and structure of `input_data` passed to this logic.\n\n6. **Error Handling**:  \n- No",
      "embedding_id": null,
      "created_at": "2025-10-22T20:05:58.010948",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_0": {
      "chunk_id": "github_query_detector.py:chunk_0",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "d7db1c0413a27cfb49393ec6c5437344550c692b72a0f599d9261f54c0f55821",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module defines a `GitHubQueryDetector` class designed to analyze user queries and determine if they are related to GitHub repositories, code, or require GitHub-specific context.\n\n2. **Technical Details**  \n- Uses keyword-based detection with categorized confidence levels (`high_confidence`, `medium_confidence`, `low_confidence`) to identify GitHub-related queries.  \n- Employs regular expressions with word boundary patterns (`WORD_BOUNDARY_KEYWORDS`) to avoid false positives when matching short or common words like \"git\".  \n- The design encapsulates detection logic within a class, likely allowing instantiation and method calls to analyze arbitrary text inputs.  \n- Uses Python\u2019s built-in `logging` module for internal event or error reporting.\n\n3. **Business Logic**  \nThe code addresses the need to filter or route user queries that pertain to GitHub-related topics, enabling downstream systems (e.g., chatbots, search engines, or support tools) to provide contextually relevant responses or trigger GitHub-specific workflows.\n\n4. **Dependencies**  \n- Standard Python libraries: `re` for regex operations, `logging` for diagnostics, and `typing` for type annotations (`Optional`, `Dict`, `Any`).  \n- No external third-party libraries or services are referenced in the provided snippet.\n\n5. **Configuration**  \n- No explicit environment variables or external configuration files are referenced.  \n- Keyword lists and regex patterns are hardcoded as class-level constants",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:03.852282",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_2": {
      "chunk_id": "github_query_detector.py:chunk_2",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "0d335c70913e43d9ebe477b73b577b392b46b6a4d73339d1e2ae0737eb4c0ab7",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a utility designed to detect whether a given user query is related to GitHub or version control topics by matching specific keywords and repository name patterns using regular expressions.\n\n2. **Technical Details**:  \n- Uses regular expressions with word boundaries (`\\b`) to accurately match keywords like \"pr\", \"api\", \"code\", \"function\", etc., avoiding false positives from substrings within other words.  \n- Defines multiple regex patterns to detect repository names in various formats, including shorthand (`repo owner/repo`), `owner/repo` format, and full GitHub URLs.  \n- Implements a class method `is_github_related` that converts the input query to lowercase and iterates over predefined keyword patterns to check for matches.  \n- The design follows a class-based approach with class-level constants (`WORD_BOUNDARY_KEYWORDS`, `REPO_PATTERNS`) for easy reuse and maintainability.\n\n3. **Business Logic**:  \nThe code addresses the need to identify whether a user's textual query pertains to GitHub or version control topics, enabling downstream systems (e.g., chatbots, search engines, or analytics tools) to route, filter, or prioritize queries related to software development repositories and workflows.\n\n4. **Dependencies**:  \n- Python standard library only, specifically the `re` module for regular expression matching (implied but not shown in the snippet).  \n- No external services or third-party libraries are referenced",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:11.678149",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_4": {
      "chunk_id": "github_query_detector.py:chunk_4",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "5e8b0bd9dbbd97537472fb9ded83bc92899c15f77f17505030ce2fb1e2535270",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a method that detects whether a given text query is related to GitHub by analyzing the presence of specific keywords and patterns. It returns a boolean indicating if the query is likely GitHub-related.\n\n2. **Technical Details**:  \n- Uses regular expressions (`re.search`) with case-insensitive matching to detect keyword patterns and repository naming conventions within the query.  \n- Checks multiple confidence levels of keywords categorized as `high_confidence`, `medium_confidence`, and `low_confidence` stored in class-level dictionaries or lists (`cls.GITHUB_KEYWORDS`).  \n- Combines keyword presence logic (e.g., requiring both medium and low confidence keywords) to increase detection accuracy.  \n- Logging is used extensively to record detection results and reasons.\n\n3. **Business Logic**:  \nThe method aims to classify user queries or input text as GitHub-related or not, which can be critical for routing queries, triggering GitHub-specific workflows, or filtering content in applications that interact with GitHub data or services.\n\n4. **Dependencies**:  \n- Python standard library `re` module for regex operations.  \n- A `logger` instance for informational logging (likely from Python\u2019s `logging` module or a custom logger).  \n- Class-level constants or variables: `GITHUB_KEYWORDS` and `REPO_PATTERNS` which hold keyword lists and regex patterns respectively.\n\n5. **Configuration**:  \n- The keywords",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:16.949547",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_6": {
      "chunk_id": "github_query_detector.py:chunk_6",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "114bea3047a66391b43ac680778da48550216420684fd6647b4583a1a1fc3f40",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis method `extract_context` analyzes a user query string to detect and extract GitHub-related context such as repository references, relevant keywords, and query type classification.\n\n2. **Technical Details**:  \n- Uses regular expressions with word boundary matching to identify repository names and keywords within the query text.  \n- Iterates over predefined regex patterns (`REPO_PATTERNS`) to find repository references.  \n- Uses a dictionary (`WORD_BOUNDARY_KEYWORDS`) mapping keywords to regex patterns to detect relevant keywords in a case-insensitive manner.  \n- Returns a dictionary containing extracted context fields: a boolean flag for GitHub relevance, repository name, list of keywords, and a default query type string.  \n- Employs class-level constants and methods (`cls.is_github_related`) indicating this is a class method, likely part of a utility or detector class.\n\n3. **Business Logic**:  \nEnables downstream components to understand if and how a user query relates to GitHub repositories, facilitating targeted semantic search or other GitHub-specific processing by extracting structured metadata from free-text queries.\n\n4. **Dependencies**:  \n- Python standard library: `re` for regex operations.  \n- Presumably a logging module (`logger`) for info-level logging.  \n- Class-level constants and methods (`REPO_PATTERNS`, `WORD_BOUNDARY_KEYWORDS`, `is_github_related`) defined elsewhere in the same class/module.\n\n5. **Configuration**:  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:24.120515",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_8": {
      "chunk_id": "github_query_detector.py:chunk_8",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "09bd1a646416fef743a4cb692682b685cc9d547e0aad10eb6d8e5b82aa6c8ddc",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet analyzes a user query string to detect GitHub-related keywords and classify the query into one of several predefined types (semantic_search, code_search, or file_explanation) based on the presence of keywords and context such as repository information.\n\n2. **Technical Details**:  \n- Iterates over a class-level dictionary `GITHUB_KEYWORDS` mapping categories to keyword lists, collecting all keywords found in the lowercased query string.  \n- Uses regular expressions with case-insensitive matching (`re.IGNORECASE`) to detect specific terms like \"code\", \"function\", \"class\", etc.  \n- Determines the query type by checking if the query is repository-specific (`context['repository']` present) and then applying keyword-based heuristics to assign one of three query types.  \n- Uses list comprehensions and `any()` for efficient keyword presence checks.  \n- The `context` dictionary is updated in place with detected keywords and the inferred query type.\n\n3. **Business Logic**:  \nThis logic supports a system that interprets user queries related to GitHub repositories or codebases, enabling differentiated handling such as searching code, explaining files, or performing semantic searches. This classification helps downstream components route queries to appropriate processing pipelines or search engines, improving relevance and user experience.\n\n4. **Dependencies**:  \n- Python standard library module `re` for regular expressions.  \n- Assumes existence of a class attribute `GITHUB_KEYWORDS",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:27.943963",
      "status": "summarized"
    },
    "github_query_detector.py:chunk_10": {
      "chunk_id": "github_query_detector.py:chunk_10",
      "file_path": "shared\\utils\\github_query_detector.py",
      "chunk_hash": "2539643e9dc654f676ef58a73fcec7874a76715c09a295d4e55de3552cd3843c",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis code provides utility functions to detect whether a given query string is related to GitHub and to extract contextual information about the GitHub-related query.\n\n2. **Technical Details**:  \n- The code defines two helper functions: `is_github_query` and `get_github_context`.  \n- These functions act as wrappers around static methods of a `GitHubQueryDetector` class (not shown here), which presumably implement the logic for detecting GitHub relevance and extracting context.  \n- The `get_github_context` function returns a dictionary containing details such as query type, repository name, and keywords, which are logged for monitoring.\n\n3. **Business Logic**:  \n- The code supports identifying and parsing queries that relate to GitHub repositories or issues, enabling downstream processes (e.g., search, analytics, or automation) to handle GitHub-specific requests appropriately.  \n- This helps in routing queries, enriching user interactions, or triggering GitHub-related workflows.\n\n4. **Dependencies**:  \n- Relies on a `GitHubQueryDetector` class/module which encapsulates the core detection and extraction logic.  \n- Uses a `logger` instance for logging informational messages.  \n- Uses Python standard typing (`Dict`, `Any`) for type hints.\n\n5. **Configuration**:  \n- No explicit configuration or environment variables are shown in this snippet.  \n- The behavior might depend on the internal configuration of `GitHubQueryDetector` or logging setup",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:32.309703",
      "status": "summarized"
    },
    "language_detector.py:chunk_0": {
      "chunk_id": "language_detector.py:chunk_0",
      "file_path": "shared\\utils\\language_detector.py",
      "chunk_hash": "01c6dfcca9611a42e6e6e25de1875515e2ec8198d27c4903721be10f18786d09",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis Python module provides a utility class `LanguageDetector` to identify whether a given text input is in English or Hindi. It is designed to support multilingual responses in applications like Voice Assistants and Chat systems.\n\n2. **Technical Details**:  \n- Uses Unicode character range checks specifically for the Devanagari script (Unicode range 0x0900 to 0x097F) to detect Hindi characters.  \n- Maintains predefined lists of common Hindi and English words to assist in language detection.  \n- Implements a `detect` method that analyzes input text for presence of Hindi script characters or common words to determine the language.  \n- Uses Python type hinting with `Literal` for strict language code return types (`\"en\"` or `\"hi\"`).  \n- The class reads configuration flags (`language_detection_enabled`, `default_language`) from a shared settings module to control behavior.\n\n3. **Business Logic**:  \nEnables the application to dynamically detect the language of user inputs, facilitating appropriate multilingual responses. This is critical for user experience in voice assistants and chatbots serving bilingual or multilingual audiences, ensuring responses are contextually relevant and linguistically accurate.\n\n4. **Dependencies**:  \n- Standard Python libraries: `re` for regex operations, `typing` for type annotations.  \n- Internal module: `shared.config.settings` for configuration parameters.\n\n5. **Configuration**:  \n- `language_detection_enabled`: A boolean flag to enable or disable",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:36.464901",
      "status": "summarized"
    },
    "language_detector.py:chunk_2": {
      "chunk_id": "language_detector.py:chunk_2",
      "file_path": "shared\\utils\\language_detector.py",
      "chunk_hash": "f54720f743ec2469a4530bbbf1de18c071b6915b8588ace2f9a142f6f4f4fee2",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a language detection utility that determines whether a given text is primarily Hindi or English based on character and word analysis.\n\n2. **Technical Details**:  \n- The code counts Devanagari script characters by checking Unicode code points within a predefined range (`DEVANAGARI_RANGE`).  \n- It calculates the percentage of Devanagari characters relative to the total non-whitespace characters.  \n- If the percentage exceeds 30%, the text is classified as Hindi (\"hi\").  \n- Otherwise, it counts occurrences of predefined Hindi and English words (`HINDI_WORDS` and `ENGLISH_WORDS`) within the text.  \n- The language is decided based on which word count is higher; if English words are found but Hindi words are not dominant, it returns English (\"en\").  \n- If none of these conditions are met, it falls back to a default language (`default_language`).  \n- The method shown is part of a class and is likely complemented by other methods such as `detect_with_confidence`.\n\n3. **Business Logic**:  \nThis code addresses the business need to automatically detect the language of user-generated or input text, enabling language-specific processing such as localization, content filtering, or analytics in applications targeting bilingual (Hindi-English) audiences.\n\n4. **Dependencies**:  \n- No explicit external libraries are shown in this snippet.  \n- It relies on class-level constants or attributes: `DEV",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:42.802264",
      "status": "summarized"
    },
    "language_detector.py:chunk_4": {
      "chunk_id": "language_detector.py:chunk_4",
      "file_path": "shared\\utils\\language_detector.py",
      "chunk_hash": "a73358241a34f7ab577a9a79f04f9d632630d501e60d8162272c846a49f02d95",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a language detection utility that analyzes input text to determine its language (specifically detecting Hindi) along with a confidence score.\n\n2. **Technical Details**:  \n- The detection logic primarily relies on character-level analysis and keyword matching.  \n- It calculates the percentage of Devanagari script characters (Unicode range) in the input text to identify Hindi text with high confidence.  \n- It also counts occurrences of predefined Hindi and English words within the text to further inform the language detection.  \n- The method returns a tuple containing a language code (e.g., `\"hi\"` for Hindi) and a confidence score between 0 and 1.  \n- Uses list comprehensions and generator expressions for counting characters and word matches efficiently.\n\n3. **Business Logic**:  \n- The code addresses the need for automatic language identification in user-generated content or text inputs, enabling downstream processes like localization, content filtering, or language-specific processing.  \n- It prioritizes Hindi detection by leveraging script-specific character counts and keyword presence, which is critical for applications targeting multilingual Indian audiences.\n\n4. **Dependencies**:  \n- No explicit external libraries are shown in the snippet.  \n- Relies on class-level attributes or constants such as `self.enabled`, `self.default_language`, `self.DEVANAGARI_RANGE`, `self.HINDI_WORDS`, and `self.ENGLISH_WORDS`, which are presumably defined elsewhere in the",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:49.005536",
      "status": "summarized"
    },
    "language_detector.py:chunk_6": {
      "chunk_id": "language_detector.py:chunk_6",
      "file_path": "shared\\utils\\language_detector.py",
      "chunk_hash": "3c0ffaea254869f7f710e5a259ccd059398117812a95177b1ecc47929a8adeef",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a language detection utility that determines whether a given text is primarily Hindi or English and provides corresponding instructions for language-specific responses in a large language model (LLM) prompt.\n\n2. **Technical Details**:  \n- The detection logic compares counts of Hindi and English words (`hindi_word_count`, `english_word_count`) relative to total matched words (`total_word_matches`).  \n- It calculates confidence scores as ratios of word counts to total matches.  \n- If word counts are inconclusive, it falls back to checking the percentage of Devanagari script characters (`devanagari_percentage`) to assign a medium confidence Hindi label.  \n- Defaults to English with low confidence if no strong indicators are found.  \n- Uses a dictionary mapping language codes (`\"en\"`, `\"hi\"`) to prompt instructions for LLM responses.  \n- The code snippet shows partial methods, including `get_language_instruction` and a stub for `get_language_name`.\n\n3. **Business Logic**:  \n- Enables language-aware processing by detecting whether input text is Hindi or English, which is critical for tailoring responses in multilingual applications such as chatbots, virtual assistants, or content localization tools.  \n- Provides confidence scores to quantify detection certainty, allowing downstream components to handle ambiguous cases appropriately.  \n- Supplies language-specific instructions to guide LLMs in generating responses in the correct language and style, enhancing user experience.\n\n4. **Dependencies",
      "embedding_id": null,
      "created_at": "2025-10-22T20:06:55.813934",
      "status": "summarized"
    },
    "language_detector.py:chunk_8": {
      "chunk_id": "language_detector.py:chunk_8",
      "file_path": "shared\\utils\\language_detector.py",
      "chunk_hash": "469715a10857f4ce48b6ccc91c5dbb8673775c34bdbfa54ee619aa2fa27e6ed5",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code provides utility functions to detect the language of a given text input, optionally returning a confidence score, and to retrieve language-specific instructions for a language model response.\n\n2. **Technical Details**:  \n- Uses a singleton/global instance of a `LanguageDetector` class (not fully shown here) to perform language detection.  \n- Provides convenience wrapper functions (`detect_language`, `detect_language_with_confidence`, `get_language_instruction`) that delegate calls to the global `_language_detector` instance.  \n- A small dictionary maps language codes (e.g., \"en\", \"hi\") to their full language names, with a default fallback to \"English\".  \n- The design follows a simple facade pattern to abstract the underlying language detection logic behind easy-to-use functions.\n\n3. **Business Logic**:  \nEnables applications to automatically identify the language of user-generated or external text content, which can be used to tailor responses, workflows, or UI elements based on language. The language-specific instruction retrieval supports generating localized or language-aware outputs from large language models (LLMs).\n\n4. **Dependencies**:  \n- Relies on a `LanguageDetector` class defined elsewhere in the codebase.  \n- Uses Python standard typing hints (`Tuple`, `LanguageCode` assumed to be a type alias or enum).  \n- No explicit external libraries or services are shown in this snippet.\n\n5. **Configuration**:  \n- No environment variables or external configuration files are referenced",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:01.763607",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_0": {
      "chunk_id": "qdrant_provider.py:chunk_0",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "7d1ebb0dfdf1494cf87a1c133854d96ba4a58297f706284a969a1674273b8640",
      "chunk_index": 0,
      "summary": "**Summary of `shared\\vector_db\\providers\\qdrant_provider.py`**\n\n---\n\n1. **Purpose**  \n   This module implements a provider class `QdrantProvider` that interfaces with the Qdrant vector database, enabling persistent storage and retrieval of vector embeddings for use in similarity search applications.\n\n2. **Technical Details**  \n   - Uses the `QdrantClient` from the official `qdrant-client` Python SDK to connect and interact with the Qdrant vector database.  \n   - The provider class inherits from a base class `VectorDBProvider`, suggesting a polymorphic design pattern for interchangeable vector DB backends.  \n   - Initialization involves establishing a client connection and verifying connectivity by fetching existing collections.  \n   - Uses type annotations extensively for clarity and maintainability.  \n   - Logging is integrated for operational observability.\n\n3. **Business Logic**  \n   The provider abstracts the complexity of managing vector data storage and retrieval, enabling business applications (e.g., search engines, recommendation systems, NLP pipelines) to perform efficient similarity searches on high-dimensional vector data with persistence guarantees.\n\n4. **Dependencies**  \n   - `qdrant-client`: Official Python client for Qdrant vector database operations.  \n   - Standard Python libraries: `logging`, `uuid`, `typing`, `datetime`.  \n   - Internal modules: `..base` providing `VectorDBProvider`, `VectorSearchResult`, and `DocumentMetadata` abstractions.\n\n5. **",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:08.708885",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_2": {
      "chunk_id": "qdrant_provider.py:chunk_2",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "0f1df9d7d2cb23ab083a5766f91de50b1863398e7d83964195c44dbcd56ce875",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis Python code snippet is part of a provider module that manages collections in a Qdrant vector database. It primarily handles checking for existing collections and creating new collections with specified vector dimensions and cosine similarity distance.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) for non-blocking operations.  \n- Interacts with Qdrant client API to fetch existing collections and create new ones.  \n- Utilizes `VectorParams` and `Distance.COSINE` to configure vector storage and similarity metric.  \n- Implements basic control flow to check for collection existence before creation.  \n- Uses structured logging for operational insights.\n\n3. **Business Logic**:  \nEnables the application to manage vector collections dynamically, supporting use cases such as semantic search, recommendation systems, or any AI-driven feature that relies on vector similarity search. Ensures collections are not duplicated and are created with appropriate configuration.\n\n4. **Dependencies**:  \n- Qdrant Python client library (implied by usage of `self.client`, `VectorParams`, `Distance`).  \n- Python `logging` module for logging operations.  \n- Asyncio or an async framework to support asynchronous method execution.\n\n5. **Configuration**:  \n- The Qdrant client (`self.client`) must be initialized and connected prior to these operations.  \n- Collection name and vector dimension are passed as method parameters.  \n- Distance metric is hardcoded to cosine similarity.  \n- No explicit",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:13.202208",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_4": {
      "chunk_id": "qdrant_provider.py:chunk_4",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "8223d81f4541d6c95418a7454ebd3a63f80bafe8ab11f0b886c22d8bdef9dea3",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code snippet defines a private method `_metadata_to_payload` that converts a `DocumentMetadata` object into a dictionary payload formatted for storage in a Qdrant vector database collection. It serializes metadata fields, including optional ones, into a structure suitable for indexing and retrieval.\n\n2. **Technical Details**:  \n- The method takes a `DocumentMetadata` instance as input and constructs a Python dictionary (`payload`) with key-value pairs representing metadata attributes.  \n- Mandatory fields (`doc_id`, `source`, `content_type`) are always included.  \n- Optional fields (e.g., `repo_name`, `file_path`, `commit_sha`, `language`, `author`, `created_at`, `updated_at`, `tags`) are conditionally added if present.  \n- Date/time fields (`created_at`, `updated_at`) are converted to ISO 8601 string format via `.isoformat()`.  \n- The `tags` list is serialized into a single comma-separated string for storage.  \n- The method returns the constructed dictionary, which can be used as a payload for Qdrant's collection documents.\n\n3. **Business Logic**:  \nThis method supports the business need to store rich, structured metadata alongside vector embeddings in Qdrant, enabling enhanced search, filtering, and retrieval of documents based on various attributes like source, repository, language, author, and timestamps. It facilitates traceability and contextual querying in applications such as code search, document",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:19.840335",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_6": {
      "chunk_id": "qdrant_provider.py:chunk_6",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "26bfbbd479d8a7407706db428cd2d783ab3823aa87795addb92f30f9df03f454",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis code snippet is part of a provider module that interfaces with the Qdrant vector database. It converts raw payload data from Qdrant into a structured `DocumentMetadata` object and provides an asynchronous method to add documents along with their embeddings and metadata to a specified Qdrant collection.\n\n2. **Technical Details**:  \n- The `_payload_to_metadata` method maps a dictionary payload to a `DocumentMetadata` dataclass, handling optional fields and parsing ISO-formatted datetime strings.  \n- The `add_documents` method is asynchronous, indicating integration with async I/O operations, likely to interact with Qdrant\u2019s async client API.  \n- Uses Python typing hints (`Dict`, `List`, `Any`) for clarity and type safety.  \n- The `tags` field is parsed from a comma-separated string into a list.  \n- Defensive programming is applied by checking if the Qdrant client is initialized before proceeding.\n\n3. **Business Logic**:  \nThis code supports the ingestion and organization of document data into a vector search engine (Qdrant), enabling efficient semantic search or similarity queries over documents. It facilitates storing metadata alongside vector embeddings, which is critical for filtering and contextualizing search results in applications like code search, document retrieval, or knowledge management.\n\n4. **Dependencies**:  \n- `Qdrant` vector database client (implied by `self.client` and context).  \n- `DocumentMetadata` dataclass or model",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:25.216456",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_8": {
      "chunk_id": "qdrant_provider.py:chunk_8",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "a918f7c65c02aead6a720c2e09c231f91da5b724dcb2d8a9662c59cc5bc80541",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a Qdrant vector database provider that handles adding documents with their embeddings and metadata into a Qdrant collection and performs similarity searches on stored vectors.\n\n2. **Technical Details**:  \n- Uses a loop to iterate over documents, embeddings, and metadata simultaneously.  \n- Converts metadata into a payload dictionary and appends the document content.  \n- Creates `PointStruct` objects with a unique UUID as the point ID, the embedding vector, and the payload.  \n- Uses batch upsert operation (`self.client.upsert`) to insert multiple points into a specified Qdrant collection.  \n- Implements asynchronous search method (partially shown) to query the vector database using an embedding vector and optional metadata filters.  \n- Logging is used for success and error reporting.\n\n3. **Business Logic**:  \nEnables storage and retrieval of documents based on vector similarity, facilitating use cases like semantic search, recommendation systems, or any application requiring fast similarity search over large document corpora.\n\n4. **Dependencies**:  \n- Qdrant client library (implied by `self.client.upsert` and `PointStruct`).  \n- `uuid` module for generating unique IDs.  \n- Python standard logging module (`logger`).  \n- Typing hints like `List`, `Optional`, and `Dict`.\n\n5. **Configuration**:  \n- Collection name is passed as a parameter, implying dynamic collection management.  \n-",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:31.908842",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_10": {
      "chunk_id": "qdrant_provider.py:chunk_10",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "3792ac55ce8fb8e3c196fc63e4d61392df036b85061753cd4f00e76e442bf6b7",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet performs a vector similarity search on a Qdrant vector database collection, optionally applying metadata-based filtering, and returns structured search results with associated metadata.\n\n2. **Technical Details**:  \n- Constructs a query filter using Qdrant\u2019s `FieldCondition` and `MatchValue` classes based on provided metadata key-value pairs.  \n- Uses the Qdrant client\u2019s `search` method to find the top K closest vectors to the input query embedding within a specified collection.  \n- Retrieves both payload (metadata) and vectors for each search hit.  \n- Converts raw payload data into a structured metadata format via a helper method `_payload_to_metadata`.  \n- Uses a list to accumulate results, likely wrapping each hit into a `VectorSearchResult` or similar data structure (not fully shown).\n\n3. **Business Logic**:  \nEnables semantic search or similarity search functionality over stored vector embeddings, filtered by metadata criteria. This supports use cases like recommendation systems, content retrieval, or any application requiring fast, filtered vector searches.\n\n4. **Dependencies**:  \n- Qdrant client SDK for Python (providing `search`, `FieldCondition`, `MatchValue`, `Filter`).  \n- A logging framework (e.g., Python\u2019s `logging` module) for warning messages.  \n- Internal helper methods/classes such as `_payload_to_metadata` and `VectorSearchResult`.\n\n5. **Configuration**:  \n- The Qdr",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:39.792487",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_12": {
      "chunk_id": "qdrant_provider.py:chunk_12",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "d98fca33ba77a8d6d6d40877aec6d1579394fe32a2517c762d8041c51d6d6480",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code snippet processes search results from a vector database query, extracting and normalizing embedding vectors from search hits, constructing structured search result objects, and returning a list of these results.\n\n2. **Technical Details**:  \n- It handles the conversion of vector data from the search hit into a list of floats, accommodating both list and other iterable types.  \n- Uses a list comprehension to ensure each element in the vector is a float, with special handling if elements themselves are lists.  \n- Constructs instances of a `VectorSearchResult` data structure (likely a class or dataclass) containing document ID, content, metadata, score, and embedding vector.  \n- Logging is used to record the number of results found or errors encountered.  \n- The code is wrapped in a try-except block to catch and handle exceptions during vector extraction and result construction.\n\n3. **Business Logic**:  \nThe code supports a vector search feature, enabling retrieval of documents based on similarity in vector space (e.g., semantic search). This is critical for applications like recommendation systems, semantic document retrieval, or AI-powered search engines.\n\n4. **Dependencies**:  \n- Likely depends on a vector database client (Qdrant, inferred from file path) that returns search hits with vector data.  \n- Uses a `VectorSearchResult` class or dataclass for structured results.  \n- Uses a logger for info and error messages.  \n- Python standard libraries for typing (`",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:45.238242",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_14": {
      "chunk_id": "qdrant_provider.py:chunk_14",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "de95d893234807c8d601bf5707c7d261a627c3e933c2983e5291c5eb3c72da44",
      "chunk_index": 14,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code provides functionality to delete specific documents by their IDs and to clear all documents from a collection in a Qdrant vector database.\n\n2. **Technical Details**:  \n- Uses the Qdrant client SDK to interact with the vector database.  \n- Deletes documents by applying a filter on the `doc_id` field using `FieldCondition` and `MatchValue` within a `Filter` object.  \n- Iterates over a list of document IDs to delete them one by one.  \n- Contains an asynchronous method stub (`clear_collection`) intended to clear all documents from a collection.  \n- Uses structured logging for success and error messages.\n\n3. **Business Logic**:  \nEnables management of vector data by allowing selective deletion of documents or complete clearing of collections, supporting data lifecycle management and cleanup operations in applications relying on vector search or similarity.\n\n4. **Dependencies**:  \n- Qdrant Python client library (for `client.delete`, `Filter`, `FieldCondition`, `MatchValue`).  \n- A logging framework (likely Python\u2019s standard `logging` module or a wrapper) for logging errors and info messages.\n\n5. **Configuration**:  \n- Requires an initialized Qdrant client instance (`self.client`).  \n- Collection names are passed as method parameters, implying dynamic targeting of collections.  \n- No explicit environment variables or config files shown in the snippet, but client initialization likely depends on external configuration.\n\n6. **",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:52.656429",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_16": {
      "chunk_id": "qdrant_provider.py:chunk_16",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "375df5518e1224059b1e2e57cf7e15dd8cbaf9f245dfad440702e0b5a2a2b59a",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet is part of a provider class interfacing with a Qdrant vector database. It primarily handles clearing (deleting) all documents from a specified collection and retrieving collection statistics.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) for non-blocking I/O operations.  \n- Retrieves collection statistics via `get_collection_stats` to determine the number of documents before deletion.  \n- Deletes all points/documents in a collection by calling `self.client.delete` with an empty filter (`Filter(must=[])`), which matches all documents.  \n- Uses structured logging to provide informative messages about the operation status.  \n- Exception handling wraps the deletion process to catch and log any errors.\n\n3. **Business Logic**:  \nThis code supports the business need to manage vector data collections by allowing complete clearing of a collection\u2019s contents. This can be used in scenarios such as resetting datasets, cleaning up stale or obsolete data, or preparing collections for fresh data ingestion.\n\n4. **Dependencies**:  \n- `self.client`: A Qdrant client instance responsible for interacting with the Qdrant vector database.  \n- `Filter`: Likely a class or data structure from the Qdrant client SDK used to specify deletion filters.  \n- `logger`: A logging utility for info and error messages.  \n- Python's `asyncio` for asynchronous execution.\n\n5. **Configuration**:  \n- The code",
      "embedding_id": null,
      "created_at": "2025-10-22T20:07:58.020602",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_18": {
      "chunk_id": "qdrant_provider.py:chunk_18",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "5384e91a80cc351763909d81cd329270d29661b6448cc5a9a2ef416999119572",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a Qdrant vector database provider implementation. It retrieves metadata and statistics about a specific vector collection and performs a health check on the Qdrant client connection.\n\n2. **Technical Details**:  \n- Uses the Qdrant client API to fetch collection information (`get_collection`).  \n- Extracts vector dimension by inspecting the collection configuration, supporting both single-vector and multi-vector setups.  \n- Returns a dictionary summarizing collection name, point count, vector dimension, provider name, and collection status.  \n- Implements asynchronous health check method to verify client connectivity.  \n- Uses Python exception handling to catch and log errors during metadata retrieval.\n\n3. **Business Logic**:  \nEnables the application to monitor and manage vector collections stored in Qdrant, which is critical for vector search or similarity search functionalities. By exposing collection stats and health status, it supports operational reliability and system monitoring.\n\n4. **Dependencies**:  \n- Qdrant client library (implied by `self.client.get_collection`).  \n- Python standard logging module (`logger.error`).  \n- Asyncio for asynchronous method (`async def health_check`).\n\n5. **Configuration**:  \n- Collection name is passed as a parameter to the method.  \n- Default vector dimension is set to 768 if not explicitly found in the collection config.  \n- Assumes `self.client` is pre-configured and connected to a Qdrant instance.",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:04.105921",
      "status": "summarized"
    },
    "qdrant_provider.py:chunk_20": {
      "chunk_id": "qdrant_provider.py:chunk_20",
      "file_path": "shared\\vector_db\\providers\\qdrant_provider.py",
      "chunk_hash": "28d8a46b3579d52eaff1c3ed2b00b1675192a7562a63cae03f2b82bdaf2174c2",
      "chunk_index": 20,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet performs a simple health check on a Qdrant vector database client by attempting to retrieve the list of collections, returning `True` if successful and `False` otherwise.\n\n2. **Technical Details**:  \n- Uses a try-except block to handle potential exceptions during the call to `self.client.get_collections()`.  \n- The method relies on the Qdrant client\u2019s API to fetch collections metadata, which likely involves an HTTP or gRPC request to the Qdrant service.  \n- Logging is used to record errors when the health check fails.\n\n3. **Business Logic**:  \nEnsures that the Qdrant vector database service is reachable and operational before proceeding with vector search or storage operations, thereby preventing downstream failures in applications relying on vector similarity search.\n\n4. **Dependencies**:  \n- `self.client`: An instance of the Qdrant client SDK, which interfaces with the Qdrant vector database.  \n- `logger`: A logging utility for error reporting.  \n- Qdrant service running and accessible.\n\n5. **Configuration**:  \n- The Qdrant client configuration (e.g., host, port, API key) is assumed to be set up elsewhere in the application.  \n- No explicit environment variables or config files are referenced in this snippet.\n\n6. **Error Handling**:  \n- Catches all exceptions (`Exception`) that may arise from the `get_collections()` call",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:08.627941",
      "status": "summarized"
    },
    "api_client.py:chunk_0": {
      "chunk_id": "api_client.py:chunk_0",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "640f3f2064f3d312bdf3be718e13ede73216afa3fd73b0d1eebc392ee4b0cc00",
      "chunk_index": 0,
      "summary": "1. **Purpose**  \nThis Python module defines an `APIClient` class designed to interact with an AI Dev Agent API, primarily to test language model (LLM) providers by sending prompts and receiving responses.\n\n2. **Technical Details**  \n- Uses the `requests` library to perform HTTP POST requests.  \n- Constructs the base URL dynamically based on environment variables or passed parameters.  \n- Implements a method `test_llm` that sends a prompt and provider name as query parameters to a specific API endpoint (`/api/test/llm`).  \n- Uses type hints (`Dict[str, Any]`, `Optional[str]`) for method signatures.  \n- Includes nested try-except blocks for HTTP response validation and JSON parsing (though the JSON parsing code is incomplete in the snippet).\n\n3. **Business Logic**  \nEnables integration and testing of different LLM providers by sending prompts to an AI Dev Agent API, facilitating evaluation or validation of AI model responses in development or production environments.\n\n4. **Dependencies**  \n- External Python library: `requests` for HTTP communication.  \n- Standard libraries: `os` for environment variable access, `typing` for type annotations.\n\n5. **Configuration**  \n- Environment variables used:  \n  - `REPL_SLUG` and `REPL_OWNER` to construct a Replit-based URL.  \n  - `PORT` to specify a local server port (default 8501).  \n  - `API_BASE_URL` as an",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:14.564254",
      "status": "summarized"
    },
    "api_client.py:chunk_2": {
      "chunk_id": "api_client.py:chunk_2",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "a4093cd926441956707e82f8da16a20b7ed07203f0feb550987c60572e6e6a29",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `ui\\api_client.py`**\n\n1. **Purpose**  \n   The code handles errors related to HTTP API requests and JSON response parsing. It aims to catch and manage issues such as invalid JSON responses, request timeouts, connection errors, and unexpected response formats from the API server.\n\n2. **Exception Types**  \n   - `ValueError`: Raised when `response.json()` fails due to invalid JSON content.  \n   - `requests.exceptions.Timeout`: Raised when the HTTP request exceeds the specified timeout duration.  \n   - `requests.exceptions.ConnectionError`: Raised when the client cannot establish a connection to the API server.  \n   - Generic `Exception`: Catches any other unforeseen errors during the request or response processing.\n\n3. **Recovery Strategy**  \n   The strategy is primarily to catch exceptions and return a structured error dictionary indicating failure (`\"success\": False`) along with an error message. There is no retry mechanism implemented; instead, the function fails fast and reports the error back to the caller for further handling.\n\n4. **Logging**  \n   There is no explicit logging or monitoring in the provided code snippet. Errors are returned as part of the response dictionary but are not logged to a file, console, or external monitoring system.\n\n5. **User Impact**  \n   End users receive a consistent error response structure indicating failure and an error message. This allows the UI or calling code to display meaningful error messages or take corrective action. However, users may experience",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:19.573316",
      "status": "summarized"
    },
    "api_client.py:chunk_4": {
      "chunk_id": "api_client.py:chunk_4",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "6e877d4f0f0a2f2f7956f5dc02ad478f1d9a60dbd26246f1730f5a386b8c8055",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines three methods to test the integration status of Jira, Confluence, and Grafana services by making HTTP POST requests to corresponding API endpoints and returning the JSON response.\n\n2. **Technical Details**:  \n- Each method uses the `requests.post` function to send HTTP POST requests with optional query parameters (`project_key` for Jira, `space_key` for Confluence).  \n- The methods expect JSON responses and parse them using `response.json()`.  \n- A 10-second timeout is set for each request to avoid hanging calls.  \n- Basic exception handling is implemented to catch all exceptions and return a standardized error dictionary.\n\n3. **Business Logic**:  \nThese methods enable the application to verify connectivity and configuration correctness of external tools (Jira, Confluence, Grafana) that are likely part of the organization's software ecosystem, ensuring integrations are functioning before further operations.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- Assumes `self.base_url` is defined elsewhere in the class or module, representing the base API URL for integration tests.\n\n5. **Configuration**:  \n- `self.base_url` must be configured to point to the appropriate backend service handling the integration tests.  \n- Timeout is hardcoded to 10 seconds but could be externalized for flexibility.\n\n6. **Error Handling**:  \n- Catches all exceptions generically (`except Exception as e`).  \n- On error,",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:26.743374",
      "status": "summarized"
    },
    "api_client.py:chunk_6": {
      "chunk_id": "api_client.py:chunk_6",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "decfc737e84cfe8df5a883d0362b2c08e6d29c054f56ae04472017233f0ab4ac",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis Python code defines client methods to interact with a remote API for testing various code-related functionalities such as context resolution, code analysis, and test generation.\n\n2. **Technical Details**:  \n- Uses HTTP POST requests to communicate with API endpoints.  \n- Parameters are passed as URL query parameters (`params` in `requests.post`).  \n- Responses are expected in JSON format and parsed accordingly.  \n- Each method returns a dictionary representing the JSON response or an error dictionary on failure.  \n- Basic try-except blocks handle exceptions during HTTP calls.\n\n3. **Business Logic**:  \nThe code supports automated testing workflows by enabling:  \n- Resolution of contextual information related to issues in code repositories.  \n- Analysis of code snippets within a given context.  \n- Generation of test cases for provided source code in specified programming languages.  \nThis facilitates integration with tools that automate code quality assurance and test creation.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- Assumes `self.base_url` is defined elsewhere in the class to specify the API server address.\n\n5. **Configuration**:  \n- `self.base_url` must be configured to point to the target API server.  \n- Timeout for HTTP requests is set to 30 seconds.  \n- No explicit environment variables or config files shown in this snippet.\n\n6. **Error Handling**:  \n- Catches all exceptions generically (`Exception`).  \n- Returns a dictionary with",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:32.568569",
      "status": "summarized"
    },
    "api_client.py:chunk_8": {
      "chunk_id": "api_client.py:chunk_8",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "51f33a410ff61e2ac81821241f898c349b835ec5fbeda236af52de22d4bb5c16",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines client-side API methods to interact with a backend service for issue analysis and documentation orchestration, enabling automated processing and management of software issues and related documentation.\n\n2. **Technical Details**:  \n- Uses HTTP POST requests via the `requests` library to communicate with RESTful API endpoints.  \n- Methods serialize input parameters into JSON payloads for API consumption.  \n- Returns parsed JSON responses as Python dictionaries.  \n- Employs try-except blocks to catch all exceptions during HTTP calls and returns structured error information.  \n- Uses optional and default parameters to provide flexible API method signatures.\n\n3. **Business Logic**:  \n- Automates the analysis of software issues by sending issue metadata (issue ID, source, repository, flags for PR creation and documentation publishing, Confluence space) to a backend analysis service.  \n- Supports orchestration of documentation generation and management, likely to streamline developer workflows and improve documentation quality and availability.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- Python standard typing module for type hints (`Optional`, `Dict`, `Any`).  \n- Backend API service accessible via `self.base_url`.\n\n5. **Configuration**:  \n- `self.base_url` is a configurable base URL for the backend API, presumably set during client initialization or via environment/configuration files (not shown in snippet).  \n- Timeout values for HTTP requests are hardcoded (30s for some calls",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:40.076099",
      "status": "summarized"
    },
    "api_client.py:chunk_10": {
      "chunk_id": "api_client.py:chunk_10",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "09f40c66533440712b8ae1ee83edf6a42e06c2f49d0cf38ec0f1d3c8ea7c7719",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python method orchestrates a complete documentation workflow by sending a structured request to a backend API endpoint, enabling automated documentation generation, publishing to Confluence, and optionally creating Jira tickets.\n\n2. **Technical Details**:  \n- Constructs a JSON payload with parameters controlling documentation generation and publishing options.  \n- Uses an HTTP POST request via the `requests` library to communicate with a RESTful API endpoint (`/api/docs/orchestrate`).  \n- Returns the JSON response from the API or an error dictionary in case of exceptions.  \n- The method signature suggests it is part of a class (likely an API client) that holds a `base_url` attribute.\n\n3. **Business Logic**:  \n- Automates the documentation process for code repositories, including committing generated docs to GitHub, publishing to Confluence spaces, and creating Jira tickets for tracking or issue management.  \n- Supports integration with Atlassian tools (Confluence and Jira), streamlining documentation workflows and project management.\n\n4. **Dependencies**:  \n- `requests` library for HTTP communication.  \n- External services: GitHub (for commits), Confluence (for publishing), Jira (for ticket creation).  \n- The method relies on a backend API service accessible at `self.base_url`.\n\n5. **Configuration**:  \n- `self.base_url` must be configured to point to the backend API server.  \n- Parameters like `confluence_space_key`, `confluence_parent",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:47.037429",
      "status": "summarized"
    },
    "api_client.py:chunk_12": {
      "chunk_id": "api_client.py:chunk_12",
      "file_path": "ui\\api_client.py",
      "chunk_hash": "ee1ce68316a9ce9e4842aad7b9cfdde0587f030aaa2c1c1dd34d5bccc332cf3c",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis code defines a method to check the health status of an external API by sending an HTTP GET request to its `/health` endpoint and returning the parsed JSON response.\n\n2. **Technical Details**:  \n- Uses the `requests` library to perform an HTTP GET request with a 5-second timeout.  \n- Parses the response as JSON and returns it directly.  \n- Implements a try-except block to catch any exceptions during the request or JSON parsing, returning a fallback dictionary indicating an unhealthy status.\n\n3. **Business Logic**:  \nIt provides a mechanism to programmatically verify the availability and health of a dependent API service, which is critical for monitoring system dependencies and ensuring reliability in business workflows.\n\n4. **Dependencies**:  \n- External Python library: `requests` for HTTP communication.  \n- Assumes `self.base_url` is defined elsewhere in the class or module, representing the base URL of the target API.\n\n5. **Configuration**:  \n- `self.base_url` must be configured, likely via environment variables, configuration files, or constructor parameters to specify the API endpoint.  \n- The timeout value is hardcoded as 5 seconds.\n\n6. **Error Handling**:  \n- Catches all exceptions (`Exception`) broadly, including network errors, timeouts, and JSON decoding errors.  \n- Returns a dictionary with `\"status\": \"unhealthy\"` and an `\"error\"` message string describing the exception.\n\n7. **API/",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:51.844376",
      "status": "summarized"
    },
    "UserController.java:chunk_0": {
      "chunk_id": "UserController.java:chunk_0",
      "file_path": "code-intelligence\\examples\\UserController.java",
      "chunk_hash": "96ed89f8dd5bbf253d96dff846300eed83afeeda5f85ed8153b85d1ef7553932",
      "chunk_index": 0,
      "summary": "**Summary of Error Handling in UserController.java**\n\n1. **Purpose**:  \n   The error handling in this code is designed to manage errors related to user retrieval operations, specifically when a user with a given ID cannot be found in the system. It ensures that the API responds with appropriate HTTP status codes reflecting the error condition.\n\n2. **Exception Types**:  \n   - `UserNotFoundException`: This is a custom exception thrown by the `UserService` when a user with the specified ID does not exist.\n\n3. **Recovery Strategy**:  \n   - The controller catches the `UserNotFoundException` and prevents the exception from propagating further. Instead of retrying or attempting recovery, it translates the exception into an HTTP 404 Not Found response, signaling to the client that the requested resource is unavailable.\n\n4. **Logging**:  \n   - The provided code snippet does not show any explicit logging or monitoring of the exception. There is no evidence of error logs or integration with monitoring tools within this method.\n\n5. **User Impact**:  \n   - End users receive a clear and standard HTTP 404 Not Found response when requesting a user that does not exist. This informs clients that the resource is unavailable without exposing internal server errors or stack traces.\n\n6. **Fallback**:  \n   - There is no fallback data or default user returned. The system gracefully degrades by returning a 404 status, which is the expected behavior for a missing resource in RESTful APIs",
      "embedding_id": null,
      "created_at": "2025-10-22T20:08:58.752582",
      "status": "summarized"
    },
    "UserController.java:chunk_2": {
      "chunk_id": "UserController.java:chunk_2",
      "file_path": "code-intelligence\\examples\\UserController.java",
      "chunk_hash": "7d0e2428cc6716097e04e3878fe207ffb552c851c44778ed8f4d641a28692ebe",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling in `UserController.java`**\n\n1. **Purpose**  \n   The error handling code manages exceptions arising during user-related operations such as fetching, creating, and listing users. It aims to provide appropriate HTTP responses for common failure scenarios like resource not found, validation errors, and duplicate entries.\n\n2. **Exception Types**  \n   - `Exception` (generic catch-all for unexpected errors)  \n   - `DuplicateEmailException` (specific to user creation when email uniqueness is violated)  \n   - `ValidationException` (declared in Javadoc for input validation failures, though not explicitly caught in the shown code)\n\n3. **Recovery Strategy**  \n   - For generic exceptions, the controller returns HTTP 500 Internal Server Error without retrying or alternative processing.  \n   - For `DuplicateEmailException`, it returns HTTP 400 Bad Request, signaling client-side input issues without retry.  \n   - Validation errors are expected to be handled by Spring\u2019s validation framework (triggered by `@Valid`), likely resulting in automatic 400 responses.  \n   - No explicit retry or fallback mechanisms are implemented; the controller relies on client correction or upstream error handling.\n\n4. **Logging**  \n   - The provided code snippet does not include any logging statements for exceptions or errors.  \n   - Absence of logging means errors are not recorded at this layer, potentially limiting observability and troubleshooting capabilities.\n\n5. **User Impact**  \n   - Users receive standard HTTP status codes",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:04.044885",
      "status": "summarized"
    },
    "UserController.java:chunk_4": {
      "chunk_id": "UserController.java:chunk_4",
      "file_path": "code-intelligence\\examples\\UserController.java",
      "chunk_hash": "1baf75b3431dd557510f4b446da735043c1acc1c585661428b18a0a62ad54751",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis Java Spring controller code snippet provides an HTTP DELETE endpoint to remove a user by their ID. It returns a 204 No Content response upon successful deletion.\n\n2. **Technical Details**:  \n- Uses Spring MVC annotations such as `@DeleteMapping` to map HTTP DELETE requests to the `deleteUser` method.  \n- The method accepts a path variable `id` of type `Long` to identify the user to delete.  \n- The controller delegates the deletion operation to a `userService` component, following the service layer pattern.  \n- Returns a `ResponseEntity<Void>` with HTTP status 204 to indicate successful deletion without a response body.\n\n3. **Business Logic**:  \nEnables administrative users to delete user accounts from the system, supporting user lifecycle management and compliance with business rules around user data removal.\n\n4. **Dependencies**:  \n- Spring Framework (Spring MVC for REST controller and Spring Security for role-based access control).  \n- `userService` component, likely a service class managing user data persistence and business rules.\n\n5. **Configuration**:  \n- Security roles and access control are configured externally via Spring Security, requiring admin privileges to invoke this endpoint.  \n- No explicit environment variables or config files are shown in this snippet, but typical configurations would include security settings and service bean definitions.\n\n6. **Error Handling**:  \n- The snippet does not explicitly handle exceptions; error handling is likely managed globally or within `user",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:10.827633",
      "status": "summarized"
    },
    "sample_code.py:chunk_0": {
      "chunk_id": "sample_code.py:chunk_0",
      "file_path": "code-intelligence\\examples\\sample_code.py",
      "chunk_hash": "67b475eea0f0d2cd7c08038159c5aefab018e65d8098d44fde3d43fb9d0982b6",
      "chunk_index": 0,
      "summary": "Summary:\n\n1. **Purpose**:  \n   The error handling in this code is designed to manage issues arising during asynchronous user profile retrieval, particularly focusing on cache access and database operations. It aims to handle cases where user data is not found or when underlying system errors occur, ensuring the service can respond appropriately.\n\n2. **Exception Types**:  \n   While the provided snippet does not show explicit exception catching code, the docstring indicates that `HTTPException` from FastAPI is raised to signal errors such as \"user not found\" or database-related failures. This implies handling of exceptions related to cache misses, database connectivity, or query failures.\n\n3. **Recovery Strategy**:  \n   The strategy involves first attempting to retrieve user data from a cache (likely Redis) to reduce database load and latency. If the cache retrieval fails or data is not found, the system presumably falls back to querying the database asynchronously. Errors during these steps result in raising HTTP exceptions rather than silent failures or retries, indicating a fail-fast approach rather than automatic retries.\n\n4. **Logging**:  \n   The snippet does not explicitly show logging statements. However, given the raising of HTTP exceptions, it is likely that higher-level middleware or FastAPI\u2019s exception handlers log these errors for monitoring and alerting. No direct logging or monitoring code is visible in the provided code.\n\n5. **User Impact**:  \n   When errors occur (e.g., user not found or database errors), the service raises HTTP exceptions that translate",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:16.386994",
      "status": "summarized"
    },
    "sample_code.py:chunk_2": {
      "chunk_id": "sample_code.py:chunk_2",
      "file_path": "code-intelligence\\examples\\sample_code.py",
      "chunk_hash": "2e496c10de80796be827f5952576b498ef44fee04500e6b27aa249d0bf455c9a",
      "chunk_index": 2,
      "summary": "**Summary of Error Handling Code in `sample_code.py`**\n\n1. **Purpose**  \n   This code segment handles errors occurring during user data retrieval from a database and caching layer. It ensures that failures in database queries or cache operations are translated into appropriate HTTP responses for an API endpoint, maintaining robustness and clear client communication.\n\n2. **Exception Types**  \n   - `HTTPException`: Explicitly raised for known HTTP error conditions (e.g., user not found).  \n   - `ConnectionError`: Captures failures related to database connectivity issues.  \n   - `Exception`: Catches all other unexpected errors that may arise during execution.\n\n3. **Recovery Strategy**  \n   - For `HTTPException`, the error is re-raised immediately, allowing upstream handlers or middleware to process it.  \n   - For `ConnectionError`, the code converts the error into a 503 Service Unavailable HTTP response, signaling temporary backend unavailability without retry logic shown here.  \n   - For generic exceptions, it raises a 500 Internal Server Error with the exception message, indicating an unhandled or unexpected failure.  \n   There is no explicit retry or fallback mechanism implemented in this snippet.\n\n4. **Logging**  \n   - The provided code does not include any logging statements or integration with monitoring tools.  \n   - Errors are only transformed into HTTP exceptions without recording diagnostic information, which may limit observability.\n\n5. **User Impact**  \n   - If the user is not found, the client receives a",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:22.850623",
      "status": "summarized"
    },
    "postcss.config.js:chunk_0": {
      "chunk_id": "postcss.config.js:chunk_0",
      "file_path": "frontend\\postcss.config.js",
      "chunk_hash": "190c877db466995bf1482f4a16abd06e04a89ede3119341e2a86ff96e1737b27",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code configures PostCSS to use the Tailwind CSS framework and Autoprefixer plugin for processing CSS files in a frontend project.\n\n2. **Technical Details**:  \n- Exports a default configuration object for PostCSS.  \n- Uses a plugins object to specify PostCSS plugins: `tailwindcss` (for utility-first CSS generation) and `autoprefixer` (for adding vendor prefixes automatically).  \n- No complex algorithms or data structures; a simple declarative configuration pattern.\n\n3. **Business Logic**:  \nEnables streamlined and maintainable styling by integrating Tailwind CSS for rapid UI development and Autoprefixer to ensure cross-browser CSS compatibility, improving frontend development efficiency and user experience.\n\n4. **Dependencies**:  \n- `tailwindcss`: A utility-first CSS framework.  \n- `autoprefixer`: A PostCSS plugin to parse CSS and add vendor prefixes.  \n- PostCSS itself (implied as the processor running this config).\n\n5. **Configuration**:  \n- No environment variables or external config files referenced here.  \n- This file (`postcss.config.js`) is the main configuration for PostCSS plugins in the build process.\n\n6. **Error Handling**:  \n- No explicit error handling in this configuration file.  \n- Errors related to plugin loading or CSS processing would be handled by PostCSS or the build tool (e.g., webpack, Vite).\n\n7. **API/Interface",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:31.497476",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_0": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "ad3d180268b4493dd2d39f04af9f038c2fdc1b0e09122fa909e20813002074f1",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component, `ConfigurationPanel`, provides a user interface for managing and saving various service configuration settings such as GitHub, Jira, Confluence, Grafana, and Azure OpenAI keys.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`) to manage local state for configuration fields and save status.  \n- Implements controlled input handling via `handleChange` to update state dynamically based on field name and value.  \n- Includes a reusable subcomponent `ConfigSection` for grouping related configuration inputs with icons and titles.  \n- Uses a simple save mechanism (`handleSave`) that logs the current config to the console and toggles a saved indicator with a 3-second timeout.\n\n3. **Business Logic**:  \nEnables users (likely administrators or developers) to input and persist credentials and URLs for multiple third-party integrations, facilitating centralized configuration management for the application\u2019s external service connections.\n\n4. **Dependencies**:  \n- React (for component and state management)  \n- `lucide-react` icon library for UI icons (Settings, Database, Key, Cloud, Save)\n\n5. **Configuration**:  \n- Configuration fields include tokens, URLs, usernames, and API keys for services like GitHub, Jira, Confluence, Grafana, Together, and Azure OpenAI.  \n- These are stored in component state and presumably intended to be saved or sent to a backend (though backend integration is not shown in this snippet",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:37.352932",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_2": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "8146401a8336182689505eae586093df17aba5e72f2ec6605dadb301ce01c0b9",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component renders a configuration panel UI for an application, allowing users to input and save integration and API credential settings through labeled input fields.\n\n2. **Technical Details**:  \n- Uses React functional components with TypeScript for type safety.  \n- Defines a reusable `InputField` component that accepts props such as `label`, `value`, `onChange`, `placeholder`, and an optional `type` (defaulting to `'text'`).  \n- Utilizes controlled components pattern where input values are managed via React state and updated through callbacks.  \n- Employs Tailwind CSS utility classes for styling and layout (e.g., grid, flexbox, spacing).  \n- Conditional styling and text rendering on the save button based on a `saved` boolean state.  \n- The layout includes a header section and a grid-based form layout for configuration sections.\n\n3. **Business Logic**:  \nEnables users to configure application integrations (e.g., GitHub) and API credentials through a user-friendly interface, facilitating secure and customizable connection setups necessary for the app\u2019s operation.\n\n4. **Dependencies**:  \n- React and React DOM for UI rendering.  \n- TypeScript for static typing.  \n- Tailwind CSS for styling.  \n- Icon components such as `Save` and `Database` (likely from an icon library or custom SVG components).  \n- Possibly other internal components like `ConfigSection` and `InputField` (the snippet shows usage",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:43.357175",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_4": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "ffedee41bd0d5568e203abda87444d5bd49cbbdb7875032f44351a0a32b48570",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders configuration input fields for integrating with GitHub and Jira services, allowing users to input credentials and connection details securely.\n\n2. **Technical Details**:  \n- Uses controlled components (`InputField`) bound to a `config` state object.  \n- Employs event handlers (`handleChange`) to update configuration state dynamically based on user input.  \n- Organizes inputs into logical sections (`ConfigSection`) with titles and icons for better UI clarity.  \n- Sensitive fields like tokens use `type=\"password\"` to mask input.\n\n3. **Business Logic**:  \nEnables users to configure authentication and connection parameters for GitHub and Jira integrations, facilitating automated interactions such as issue tracking, repository management, or CI/CD workflows within the application.\n\n4. **Dependencies**:  \n- React (for component structure and state management).  \n- Custom components: `InputField` for input controls, `ConfigSection` for grouping inputs, and an icon component (`Key`) for UI enhancement.  \n- Likely relies on external services: GitHub API and Jira API for backend integration.\n\n5. **Configuration**:  \n- Inputs correspond to environment-specific credentials/settings:  \n  - GitHub: Personal Access Token (`githubToken`), Repository Owner (`githubOwner`).  \n  - Jira: URL (`jiraUrl`), Username/Email (`jiraUsername`), API Token (`jiraApiToken`).  \n- These values are expected to be stored",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:50.720433",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_6": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "a2494dbd95775a387a478d3ef588ef4a8d056584684ede78e19b6d13f4b96bf5",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component code snippet renders a configuration panel UI that allows users to input and update connection settings for Confluence and Grafana services.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX to define UI sections (`ConfigSection`) and input fields (`InputField`).  \n- State management is implied via `config` object and `handleChange` callback to update configuration values dynamically.  \n- Input fields include text and password types, with placeholders guiding user input.  \n- Icons (`Database`, `Cloud`) visually distinguish configuration sections.\n\n3. **Business Logic**:  \nEnables users to configure integration settings for Confluence (a collaboration/wiki platform) and Grafana (a monitoring/visualization tool), facilitating seamless connectivity and data exchange between the application and these external services.\n\n4. **Dependencies**:  \n- React library for UI rendering.  \n- Custom components: `ConfigSection`, `InputField`.  \n- Icon components: `Database`, `Cloud` (likely from an icon library or internal assets).\n\n5. **Configuration**:  \n- User-provided values for:  \n  - Confluence URL, username/email, and API token.  \n  - Grafana URL and API key.  \n- These settings are likely stored in application state or persisted externally for use in API calls.\n\n6. **Error Handling**:  \n- Not explicitly shown in the snippet; no validation or error feedback mechanisms are present here.  \n- Pres",
      "embedding_id": null,
      "created_at": "2025-10-22T20:09:54.470804",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_8": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "f2e08492818ad61e0451063a7ed1abb2d616a738f965872d87dc39e617d6996d",
      "chunk_index": 8,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component code snippet renders a configuration panel UI that allows users to input and manage API keys and endpoints for various AI providers, including Together AI and Azure OpenAI, as well as a Grafana API key.\n\n2. **Technical Details**:  \n- Utilizes React functional components and JSX for UI rendering.  \n- Employs controlled input fields (`InputField` components) bound to a `config` state object.  \n- Uses event handlers (`handleChange`) to update configuration state on user input.  \n- Organizes inputs into logical sections (`ConfigSection` components) with titles and icons for better UX.\n\n3. **Business Logic**:  \nEnables users to securely configure API credentials and endpoints for integrating AI services and Grafana monitoring within the application, facilitating seamless connectivity to external AI providers and monitoring tools.\n\n4. **Dependencies**:  \n- React library for UI components.  \n- Custom components: `ConfigSection`, `InputField`.  \n- Icon components such as `Settings` and `Cloud` (likely from an icon library or internal assets).  \n- External AI services: Together AI, Azure OpenAI, and Grafana APIs.\n\n5. **Configuration**:  \n- API keys and endpoints are stored in a `config` object, likely managed via React state or context.  \n- Sensitive inputs use `type=\"password\"` to mask API keys.  \n- Placeholders guide users on expected input formats (e.g.,",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:00.384158",
      "status": "summarized"
    },
    "ConfigurationPanel.tsx:chunk_10": {
      "chunk_id": "ConfigurationPanel.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\ConfigurationPanel.tsx",
      "chunk_hash": "0b7aa5c7cc171c2b9d04b03ab4e612052da37c666221a15059359426c2dd8277",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component snippet renders a UI panel section displaying a configuration note to users, informing them about secure credential storage and the need to restart the application after saving environment variable changes.\n\n2. **Technical Details**:  \n- Uses JSX to define UI elements with Tailwind CSS utility classes for styling (e.g., `flex-1`, `font-semibold`, `text-blue-900`).  \n- The component structure is simple and purely presentational, with no state management or event handling shown in the snippet.  \n- The snippet is part of a larger React component, likely using functional component syntax.\n\n3. **Business Logic**:  \n- Provides users with important information regarding the security of credentials and operational instructions to ensure environment variable changes are applied correctly.  \n- Helps prevent misconfiguration or user errors by clearly communicating the need to restart the application after saving.\n\n4. **Dependencies**:  \n- React (implied by JSX and component export).  \n- Tailwind CSS for styling (inferred from class names).  \n- No external services or modules are directly referenced in this snippet.\n\n5. **Configuration**:  \n- Mentions environment variables as part of the configuration process, indicating that the application relies on environment variables for credentials or settings.  \n- No direct configuration code is present, but the note implies environment variables are updated elsewhere in the application.\n\n6. **Error Handling**:  \n- No explicit error handling or exception management is present in",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:06.369061",
      "status": "summarized"
    },
    "FullAnalysisPanel.tsx:chunk_0": {
      "chunk_id": "FullAnalysisPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx",
      "chunk_hash": "3662d24d14d61a5cf4f98a24977ae0534a2403ae14635e92cbc9cfe90bb2f67e",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component provides a user interface panel for performing a full analysis of an issue from a specified source (defaulting to GitHub). It allows users to input parameters and triggers an asynchronous API call to analyze the issue, displaying the results or errors accordingly.\n\n2. **Technical Details**:  \n- Utilizes React hooks (`useState`) for managing component state such as input values, loading status, and API results.  \n- Implements an asynchronous function `handleAnalyze` that calls an external API client method `analyze` with parameters derived from the component state.  \n- Conditional logic is applied to include the `repository` parameter only when the source is GitHub.  \n- Uses JSX for rendering UI elements, including icons from the `lucide-react` library for visual cues.\n\n3. **Business Logic**:  \nEnables users to perform a comprehensive analysis of issues (e.g., bug reports or feature requests) from different sources, primarily GitHub repositories. This supports workflows such as issue triaging, quality assessment, or automated reporting within a software development or project management context.\n\n4. **Dependencies**:  \n- `react` for UI and state management.  \n- `lucide-react` for SVG icon components (`BarChart3`, `Loader2`, `CheckCircle`, `XCircle`).  \n- A custom `apiClient` service module responsible for making backend API calls.  \n- Type definitions imported for `Source` from the project",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:11.444758",
      "status": "summarized"
    },
    "FullAnalysisPanel.tsx:chunk_2": {
      "chunk_id": "FullAnalysisPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx",
      "chunk_hash": "7b047f66ba2995c5dec013aa0e48402fbb9763d0dcb0e417a9aaebcfa5800c58",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a form panel allowing users to select a data source (GitHub, Jira, or Grafana), input an issue ID, and conditionally input a GitHub repository name when the source is GitHub.\n\n2. **Technical Details**:  \n- Utilizes React functional component patterns with state hooks (`source`, `issueId`, `repository`) managed via `setSource`, `setIssueId`, and `setRepository` callbacks.  \n- Conditional rendering is used to display the repository input field only when the selected source is GitHub.  \n- Controlled form inputs ensure the component state reflects the current user input.  \n- Uses standard HTML form elements (`select`, `input`) styled with Tailwind CSS utility classes (`input-field`, `block`, `text-sm`, etc.).\n\n3. **Business Logic**:  \nEnables users to specify the origin of an issue or ticket (from GitHub, Jira, or Grafana) and provide relevant identifiers to fetch or analyze data related to that issue, supporting integrations with multiple issue tracking or monitoring platforms.\n\n4. **Dependencies**:  \n- React for component and state management.  \n- Tailwind CSS for styling.  \n- Likely TypeScript given the type assertion (`as Source`).  \n- No explicit external API calls or services shown in this snippet, but the inputs imply integration with GitHub, Jira, and Grafana APIs elsewhere.\n\n5. **Configuration**:  \nNo environment",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:18.985995",
      "status": "summarized"
    },
    "FullAnalysisPanel.tsx:chunk_4": {
      "chunk_id": "FullAnalysisPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx",
      "chunk_hash": "8f446239fdea676fd2d64ef7c0e7917bc52f9f224ae5586123b54632655ab247",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a user interface panel that allows users to input an issue identifier and trigger an analysis process, displaying loading states and the result status (success or failure) upon completion.\n\n2. **Technical Details**:  \n- Utilizes React functional components with JSX for UI rendering.  \n- Conditional rendering is used to toggle button states and display different icons/text based on loading status (`isLoading`) and analysis result (`result.success`).  \n- Uses state variables like `issueId`, `isLoading`, and `result` to manage user input, asynchronous operation state, and analysis outcome respectively.  \n- UI elements include buttons with event handlers (`onClick={handleAnalyze}`) and input fields with validation (`disabled={isLoading || !issueId.trim()}`).  \n- Icons such as `Loader2`, `BarChart3`, `CheckCircle`, and `XCircle` are used for visual feedback.\n\n3. **Business Logic**:  \nEnables users to analyze a specific issue (likely from a repository or project management system) by entering an identifier and triggering an analysis workflow. It provides immediate feedback on the analysis progress and outcome, facilitating decision-making or further actions based on the analysis results.\n\n4. **Dependencies**:  \n- React for UI components and state management.  \n- Icon components (`Loader2`, `BarChart3`, `CheckCircle`, `XCircle`), likely from an icon library such as `lucide-react",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:23.552764",
      "status": "summarized"
    },
    "FullAnalysisPanel.tsx:chunk_6": {
      "chunk_id": "FullAnalysisPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\FullAnalysisPanel.tsx",
      "chunk_hash": "136e91078fafe44bee95685235e32fa695c11449abcf2d09fe156ddb8462ccfe",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React functional component snippet renders the results of an AI-driven analysis process, displaying either a success message with detailed JSON output of the analysis or an error message if the analysis failed.\n\n2. **Technical Details**:  \n- Uses conditional rendering to display different UI blocks based on the presence of `result.analysis` or `result.error`.  \n- JSON.stringify is used to format the analysis object for readable display inside a `<pre>` tag.  \n- Tailwind CSS utility classes are applied for styling (background colors, borders, padding, text colors).  \n- The component appears to be part of a larger React component tree, likely receiving `result` as a prop or from state.\n\n3. **Business Logic**:  \nThe component supports a business workflow where an AI system analyzes issues, enriches context, and generates fixes with tests. It provides users with immediate feedback on the success or failure of this automated analysis, helping developers or stakeholders understand the AI output or diagnose errors.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Possibly other React ecosystem libraries not shown here (state management, API calls) but not explicit in this snippet.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration likely occurs elsewhere in the app.\n\n6. **Error Handling**:  \n- Displays error messages stored in `result.error` inside a styled red alert box",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:28.532304",
      "status": "summarized"
    },
    "GitHubTestPanel.tsx:chunk_0": {
      "chunk_id": "GitHubTestPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx",
      "chunk_hash": "4473986fbc7e5fdd33ecea628c4775d8810852233179d09fa9f90cac5b5fdcbf",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component provides a UI panel that allows users to input a GitHub repository identifier (in \"owner/repo\" format) and test connectivity or integration with that repository via an API call.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`) to manage component state for repository input, loading status, and test results.  \n- Implements an asynchronous function `handleTest` to call an external API client method `testGitHub` with the repository string.  \n- Uses conditional rendering and state updates to reflect loading state and display success or error results.  \n- UI elements include icons from `lucide-react` and standard form controls styled with utility CSS classes (likely Tailwind CSS).\n\n3. **Business Logic**:  \nEnables users (likely developers or administrators) to verify that a specified GitHub repository can be accessed or integrated with the backend system, facilitating troubleshooting or validation of repository configurations.\n\n4. **Dependencies**:  \n- `react` for component and state management.  \n- `lucide-react` for SVG icon components (Github, Loader2, CheckCircle, XCircle).  \n- `apiClient` from a local service module (`../../services/api`) which abstracts API communication.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet. The `apiClient` likely depends on external configuration (e.g., base URLs, authentication tokens) managed elsewhere in the application",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:35.142588",
      "status": "summarized"
    },
    "GitHubTestPanel.tsx:chunk_2": {
      "chunk_id": "GitHubTestPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx",
      "chunk_hash": "efc81eccd6d3be0250dc7161ea0738bba1e316719eddfd8219121db95ed59fbb",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis React component provides a user interface panel for testing GitHub repository integration by allowing users to input a repository name and trigger a test action, displaying success or error results accordingly.\n\n2. **Technical Details**:  \n- Uses React functional components with hooks (`useState`) for managing state such as `repository`, `isLoading`, and `result`.  \n- Controlled input field bound to `repository` state with an `onChange` handler updating the state.  \n- A button triggers the `handleTest` function, which presumably performs the GitHub integration test asynchronously.  \n- Conditional rendering is used to show loading indicators (`Loader2` spinner), success (`CheckCircle` icon), or error (`XCircle` icon) states.  \n- CSS classes (e.g., `btn-primary`, `input-field`) are used for styling and layout.\n\n3. **Business Logic**:  \nEnables users (likely developers or admins) to verify that a specified GitHub repository is correctly integrated with the application, ensuring that repository connections are valid before proceeding with further operations such as CI/CD, code analysis, or deployment.\n\n4. **Dependencies**:  \n- React library for UI components and state management.  \n- Icon components (`Loader2`, `Github`, `CheckCircle`, `XCircle`) likely imported from an icon library such as `lucide-react` or similar.  \n- CSS framework or custom styles for layout and design.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:40.257271",
      "status": "summarized"
    },
    "GitHubTestPanel.tsx:chunk_4": {
      "chunk_id": "GitHubTestPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx",
      "chunk_hash": "1a34bfbce66367d471127a43128fee33935e08fd2e95bfd614ef836d38fc2ae2",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a panel displaying GitHub repository information, including the repository name, its default branch, and a list of recent issues (up to 5).\n\n2. **Technical Details**:  \n- Uses JSX to conditionally render UI elements based on the presence of data in the `result` object.  \n- Data structures involved include an object (`result`) with properties like `repository` (string), `default_branch` (string), and `issues` (array).  \n- The `issues` array is sliced to limit the display to the first 5 issues, and mapped to generate individual issue cards.  \n- Tailwind CSS classes are used for styling and layout.\n\n3. **Business Logic**:  \nProvides a concise summary view of a GitHub repository\u2019s key metadata and recent activity, enabling users to quickly assess repository status and outstanding issues, which is useful for project management, monitoring, or integration dashboards.\n\n4. **Dependencies**:  \n- React (JSX syntax) for component rendering.  \n- Tailwind CSS for styling.  \n- The code snippet implies upstream data fetching logic (not shown) that populates the `result` object, likely from GitHub\u2019s REST or GraphQL API.\n\n5. **Configuration**:  \nNo explicit configuration or environment variables are shown in this snippet. However, the component likely depends on external configuration for API access tokens or endpoints elsewhere in the application.\n\n6. **Error Handling**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:45.594012",
      "status": "summarized"
    },
    "GitHubTestPanel.tsx:chunk_6": {
      "chunk_id": "GitHubTestPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\GitHubTestPanel.tsx",
      "chunk_hash": "0da60cccb75d99c5ac3e267ce2e7a8d6914292f6c98f47293f9e832511e77bb6",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component, `GitHubTestPanel`, renders a UI panel that displays the result of a GitHub-related test operation, showing either success details or error messages.\n\n2. **Technical Details**:  \n- Utilizes conditional rendering to display different UI blocks based on the presence of an error in the `result` object.  \n- Uses JSX with Tailwind CSS classes for styling (e.g., `bg-red-50`, `border-red-200`, `rounded-lg`, `p-4`).  \n- The component likely receives a `result` prop or state containing the outcome of a GitHub test operation.  \n- The error message is displayed inside a styled `<p>` tag when `result.error` exists.\n\n3. **Business Logic**:  \nProvides immediate visual feedback to users or developers about the success or failure of GitHub integration tests, helping diagnose connection or authentication issues with GitHub services.\n\n4. **Dependencies**:  \n- React (functional components and JSX)  \n- Tailwind CSS for styling  \n- Possibly other internal components or hooks (not shown in the snippet)\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration related to GitHub testing likely exists elsewhere in the application.\n\n6. **Error Handling**:  \n- Handles error cases by checking if `result.error` exists and displaying the error message in a styled alert box.  \n- No explicit try",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:51.974539",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_0": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "9b1651c77278d3bec232264926de794cebbbc9d265be6c4f719ad53e1e6f76f9",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component, `IntegrationsPanel`, provides a user interface to test and display the connection status of various third-party integrations such as GitHub, Jira, Confluence, Grafana, and Azure. It allows users to input configuration (e.g., GitHub repo) and triggers API calls to verify integration connectivity.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`) to manage local component state for input values, test results, loading states, and connection status.  \n- Defines a `TestResult` interface to standardize the shape of integration test responses, including success status, optional data, and error messages.  \n- Implements asynchronous functions (e.g., `testGitHub`) that invoke API client methods to test integrations, updating state based on the response.  \n- Loading states are managed via a single state object with boolean flags per integration to control UI feedback during async operations.  \n- UI icons from `lucide-react` (e.g., `Loader2`, `CheckCircle`, `XCircle`) are used to visually indicate loading, success, or failure states.\n\n3. **Business Logic**:  \nThe component addresses the business need to verify and monitor the connectivity and configuration correctness of multiple third-party services integrated into the platform. This ensures that integrations are properly set up, which is critical for downstream workflows relying on these external systems.\n\n4. **Dependencies**:  \n- `react`: For building the component and",
      "embedding_id": null,
      "created_at": "2025-10-22T20:10:56.831715",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_2": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "7670ca835e8e187aedf0aba0a7746b91e59e266baf37c1716501b24a0471cf90",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code defines asynchronous functions within a React component to test connectivity and retrieve data from external integrations\u2014specifically Jira, Confluence, and GitHub\u2014updating the UI state based on the success or failure of these tests.\n\n2. **Technical Details**:  \n- Uses React hooks (`setLoadingStates`, `setJiraResult`, `setConfluenceResult`) to manage component state.  \n- Implements async/await pattern for asynchronous API calls via `apiClient`.  \n- Uses try/catch/finally blocks to handle asynchronous operations and ensure loading states are reset.  \n- State updates are done immutably using functional updates (`prev => ({ ...prev, key: value })`).  \n- Error handling distinguishes between JavaScript `Error` instances and generic failures.\n\n3. **Business Logic**:  \nEnables users or administrators to verify the connectivity and configuration status of third-party integrations (Jira, Confluence, GitHub) within the application, facilitating troubleshooting and ensuring integrations are correctly set up for project management and collaboration workflows.\n\n4. **Dependencies**:  \n- `apiClient`: an abstraction for making API calls to backend services that test the integrations.  \n- React (likely React 16.8+ for hooks).  \n- Possibly TypeScript (inferred from `.tsx` extension).\n\n5. **Configuration**:  \nNot explicitly shown in the snippet, but likely relies on environment variables or config files for API endpoints and authentication credentials",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:04.590913",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_4": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "425a2c6246bf9962dc520610a6a7b3c05ab341b1472ef9ba98d77439c1ba19bb",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis code defines asynchronous functions within a React component to test connectivity and integration status with external services (Grafana and Azure), updating UI state based on the results.\n\n2. **Technical Details**:  \n- Uses React state hooks (`setLoadingStates`, `setGrafanaResult`, `setAzureResult`, `setAzureConnected`) to manage loading indicators and test results.  \n- Implements asynchronous calls with `async/await` to external APIs: a custom `apiClient.testGrafana()` method and a REST fetch call to `/api/azure/test-connection`.  \n- Uses try-catch-finally blocks for robust error handling and to ensure loading states are reset.  \n- State updates use functional updates (`prev => ({ ...prev, key: value })`) to safely merge new loading states without overwriting others.\n\n3. **Business Logic**:  \nEnables users or the system to verify the connectivity and configuration status of integrations with Grafana and Azure services, which is critical for ensuring these external tools are properly connected and operational within the application ecosystem.\n\n4. **Dependencies**:  \n- `apiClient` module for interacting with Grafana API.  \n- Browser `fetch` API for making HTTP requests to backend Azure test endpoint.  \n- React for state management.\n\n5. **Configuration**:  \n- The Azure test endpoint is hardcoded as `/api/azure/test-connection`, implying backend routing configuration.  \n- No explicit environment variables or config",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:13.950379",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_6": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "db9b0341786fba025fbb00187f36c1b86986929e5b5d52c8ca6abefb49fc8517",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component code defines UI elements and logic for managing integration tests within an integrations panel, specifically allowing users to test or skip Azure AI integration and input related configuration data.\n\n2. **Technical Details**:  \n- Uses React functional components and hooks (e.g., `useState` implied by `setAzureResult`).  \n- Defines a reusable `IntegrationCard` component with props for title, description, icon, test action, loading state, test results, and optional input handling.  \n- The `skipAzure` function updates state to mark the Azure integration as skipped with a success message.  \n- UI layout uses Tailwind CSS classes for styling and flexbox for alignment.  \n- Input handling is done via controlled components, with callbacks for input changes.\n\n3. **Business Logic**:  \nEnables users to configure and validate third-party integrations (like Azure AI) within the application, providing feedback on test results or allowing them to skip integration setup, facilitating flexible onboarding or configuration workflows.\n\n4. **Dependencies**:  \n- React (functional components, hooks)  \n- Tailwind CSS for styling  \n- Likely internal state management (e.g., React `useState`)  \n- No explicit external API calls shown in the snippet, but integration testing implies backend communication elsewhere.\n\n5. **Configuration**:  \n- No explicit environment variables or config files shown in this snippet.  \n- Input fields suggest dynamic user-provided configuration (e.g., API keys",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:19.836253",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_8": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "f48b6ad7ccd8c7f596e7263bbadf6265a8dda5154d48afd0d6b3ad93a80ac451",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component snippet renders a user interface for testing an integration connection, displaying a button to trigger the test, a loading state during the test, and the result of the connection attempt with success or failure feedback.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX for UI rendering.  \n- Conditional rendering based on `isLoading` and `result` state variables.  \n- Displays different icons (`Loader2`, `CheckCircle`, `XCircle`) depending on the state.  \n- Uses Tailwind CSS utility classes for styling.  \n- Handles asynchronous operation indicated by `onTest` callback and loading state.  \n- Checks if `result.data` is an array to conditionally render the count of items found.\n\n3. **Business Logic**:  \nEnables users to verify connectivity or configuration of an external integration by testing the connection and providing immediate visual feedback on success or failure, helping ensure integrations are correctly set up before use.\n\n4. **Dependencies**:  \n- React for UI components.  \n- Tailwind CSS for styling.  \n- Icon components (`Loader2`, `CheckCircle`, `XCircle`) likely from a UI icon library (e.g., Heroicons or similar).  \n- Presumably an external integration API or service is called within `onTest` (not shown).\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet; configuration likely occurs elsewhere for integration endpoints or",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:27.800315",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_10": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "19eedbb0c0effab1c5a33a772bab5a90d384f577c3803c354175456bfbc30447",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis React component code snippet renders UI panels for testing integrations with external services like GitHub and Jira. It displays connection test results, including repository details or error messages, and provides input fields for user interaction.\n\n2. **Technical Details**:  \n- Uses React functional components with JSX for UI rendering.  \n- Conditional rendering based on the `result` object to display success or error states.  \n- Utilizes a reusable `IntegrationCard` component to encapsulate integration-specific UI and logic.  \n- State management for loading indicators (`loadingStates.github`), input values (`githubRepo`), and test results (`githubResult`).  \n- Displays nested data such as repository name, default branch, and issue count from the API response.\n\n3. **Business Logic**:  \nEnables users to verify connectivity and configuration of third-party integrations (e.g., GitHub, Jira) within the application, ensuring that API connections are valid and repositories or projects are accessible before further operations.\n\n4. **Dependencies**:  \n- React (likely with hooks for state management).  \n- Custom components like `IntegrationCard`.  \n- External APIs for GitHub and Jira (implied by the integration context).  \n- CSS classes suggest use of a utility-first CSS framework such as Tailwind CSS.\n\n5. **Configuration**:  \n- Input placeholders like `\"owner/repo\"` indicate user-provided configuration for repository identification.  \n- No explicit environment variables or config files shown in the",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:32.967777",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_12": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "c089938a2b6c487f90c2740dbb9f93b19af99ac1da48880988c3f955f92ee8c9",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis React component code snippet renders a panel with multiple integration cards, each allowing users to test API connections to various third-party services such as Jira, Confluence, Grafana, and Azure AI.\n\n2. **Technical Details**:  \n- Uses React functional components and JSX for UI rendering.  \n- Each integration is represented by an `IntegrationCard` component with props for title, description, icon, test callback (`onTest`), loading state, and test result.  \n- Conditional rendering is used for the Azure AI card to show different UI elements based on connection and test result states.  \n- UI styling leverages utility-first CSS classes (likely Tailwind CSS) for layout and design.\n\n3. **Business Logic**:  \nEnables users (likely administrators or developers) to verify connectivity and integration status with key external services critical for business workflows, such as issue tracking (Jira), documentation (Confluence), monitoring (Grafana), and AI capabilities (Azure AI). This helps ensure smooth interoperability and early detection of integration issues.\n\n4. **Dependencies**:  \n- React library for component rendering.  \n- Possibly Tailwind CSS for styling (inferred from class names).  \n- IntegrationCard component (custom or imported) encapsulates the UI and logic for each integration test card.  \n- External APIs/services: Jira, Confluence, Grafana, Azure AI.\n\n5. **Configuration**:  \n- The snippet does not explicitly show environment variables or",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:38.314908",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_14": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_14",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "2a6d5e3de5e530aacb37d37cb6690a1a9976878dab25f07e182183c12ec8aee8",
      "chunk_index": 14,
      "summary": "1. **Purpose**:  \nThis React component snippet manages the UI for connecting to Azure AI services within an integrations panel. It provides buttons to initiate the connection, display loading states, allow skipping the connection, and show the connection result status.\n\n2. **Technical Details**:  \n- Uses conditional rendering to toggle button states and display feedback (loading spinner, success, or error icons).  \n- Utilizes React state variables (`loadingStates.azure`, `azureResult`) to control UI behavior.  \n- Employs JSX fragments and Tailwind CSS classes for styling and layout.  \n- Icons (`Loader2`, `CheckCircle`, `XCircle`) are used to visually indicate status.  \n- Event handlers like `onClick={skipAzure}` handle user interactions.\n\n3. **Business Logic**:  \nEnables users to connect their Azure AI account to the application or skip this step, facilitating integration with Azure AI services. This supports onboarding or configuration workflows where Azure AI connectivity is optional but recommended.\n\n4. **Dependencies**:  \n- React for component structure and state management.  \n- Tailwind CSS for styling.  \n- Icon components (`Loader2`, `CheckCircle`, `XCircle`), likely from a UI icon library such as Heroicons or similar.  \n- Presumably, Azure SDK or API calls are handled elsewhere, as this snippet focuses on UI.\n\n5. **Configuration**:  \nNo explicit environment variables or config files are shown in this snippet. However, integration with Azure",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:42.559603",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_16": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_16",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "083455ecd398d554128c2bf13cbfa47993cebfee64aa6ae2c19734977deb2cec",
      "chunk_index": 16,
      "summary": "1. **Purpose**:  \nThis React component snippet renders the status and details of an Azure AI integration connection, displaying success messages with available services or error messages if the connection fails.\n\n2. **Technical Details**:  \n- Uses conditional rendering based on the `azureResult` object's properties (`success`, `data`, `error`).  \n- Renders UI elements with Tailwind CSS classes for styling (e.g., `bg-green-50`, `border-green-200`).  \n- Iterates over an array of services (`azureResult.data.services`) using `map` to dynamically generate a list of available Azure AI services.  \n- Uses JSX syntax within a TypeScript React functional component context.\n\n3. **Business Logic**:  \nProvides users with feedback on the status of their Azure AI integration, informing them if the connection was successful, listing available AI services, or showing error messages to guide troubleshooting or next steps (e.g., connecting later from Provider Settings).\n\n4. **Dependencies**:  \n- React (JSX, component rendering)  \n- Tailwind CSS for styling  \n- Likely depends on a higher-level state or props providing `azureResult` (not shown in snippet) which contains the connection status and data.\n\n5. **Configuration**:  \n- No explicit environment variables or config files are referenced in this snippet.  \n- Presumably, the `azureResult` data is fetched/configured elsewhere, possibly involving Azure credentials or API endpoints configured in environment variables or app settings",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:49.919535",
      "status": "summarized"
    },
    "IntegrationsPanel.tsx:chunk_18": {
      "chunk_id": "IntegrationsPanel.tsx:chunk_18",
      "file_path": "frontend\\src\\components\\Panels\\IntegrationsPanel.tsx",
      "chunk_hash": "1c7184a73e5ac5e2891629ddcf0e04e8b318cd1b887b61187ed504f3b4ef16e6",
      "chunk_index": 18,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React functional component, `IntegrationsPanel`, renders a user interface panel that includes an option to skip Azure integration and continue without it. It provides a button labeled \"Skip and continue without Azure\" which triggers a handler when clicked.\n\n2. **Technical Details**:  \n- Implemented as a React functional component using JSX.  \n- Uses event handling via the `onClick` attribute to invoke the `skipAzure` function.  \n- Utilizes Tailwind CSS utility classes for styling (`mt-2`, `text-xs`, `text-gray-600`, `hover:text-gray-900`, `underline`).  \n- Conditional rendering is implied by the nested JSX structure (not fully visible in the snippet).\n\n3. **Business Logic**:  \nEnables users to bypass Azure integration setup within the application workflow, allowing them to proceed without configuring Azure services. This supports flexibility in onboarding or configuration processes where Azure integration is optional.\n\n4. **Dependencies**:  \n- React library for component creation and rendering.  \n- Tailwind CSS for styling.  \n- Presumably other internal modules or hooks (e.g., the `skipAzure` handler) defined elsewhere in the codebase.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. Configuration related to Azure integration or feature toggles might be managed elsewhere.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. Error management",
      "embedding_id": null,
      "created_at": "2025-10-22T20:11:54.890313",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_0": {
      "chunk_id": "BackendActivityStream.tsx:chunk_0",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "6155dfe270898878963d015c1dd91eebecc6306a9a8c948a60d7902bc34a1e3a",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis React functional component, `BackendActivityStream`, streams backend orchestration activity logs in real-time based on a user-provided message and optional template, displaying progress and status updates to the frontend.\n\n2. **Technical Details**:  \n- Uses React hooks (`useState`, `useEffect`) to manage component state and lifecycle.  \n- Defines TypeScript interfaces for strong typing of activity logs and component props.  \n- Implements an asynchronous function inside `useEffect` to POST data to a backend streaming API endpoint (`/api/orchestration/stream`).  \n- Maintains streaming state (`isStreaming`), accumulated activity logs (`activities`), and error state (`error`).  \n- Uses JSON for request payload serialization and expects a streaming response (though the snippet cuts off before response handling).  \n- UI icons imported from `lucide-react` suggest visual status indicators for activity steps.\n\n3. **Business Logic**:  \nEnables real-time monitoring and visualization of backend orchestration workflows or task executions triggered by a user message, facilitating transparency and feedback during potentially long-running backend processes.\n\n4. **Dependencies**:  \n- React (hooks) for UI and state management.  \n- `lucide-react` for SVG icon components representing activity statuses.  \n- Backend API endpoint at `/api/orchestration/stream` for streaming orchestration data.\n\n5. **Configuration**:  \n- The component accepts props to configure:  \n  - `message`: the input",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:00.800235",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_2": {
      "chunk_id": "BackendActivityStream.tsx:chunk_2",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "37401adfc390c5251b9334845729d7b6eb3c5ce285e9d3624bc0700d4490e6b8",
      "chunk_index": 2,
      "summary": "**Summary of `BackendActivityStream.tsx` snippet**\n\n1. **Purpose**  \nThis code establishes and processes a Server-Sent Events (SSE) stream from a backend endpoint, incrementally receiving and parsing streamed JSON data to update frontend state and notify consumers upon completion or error.\n\n2. **Technical Details**  \n- Uses the Fetch API to connect to a streaming HTTP response (`response.body.getReader()`), reading data chunks asynchronously via a `ReadableStreamDefaultReader`.  \n- Decodes binary chunks to text using `TextDecoder`.  \n- Parses the stream line-by-line, filtering lines starting with `\"data: \"` per SSE protocol.  \n- Parses JSON payloads and distinguishes between partial activity updates and a final result (`parsed.type === 'final_result'`).  \n- Updates React state with new activities (`setActivities`) or triggers completion callback (`onComplete`).  \n- Uses async/await for asynchronous flow control inside a continuous `while(true)` loop until stream ends (`done === true`).  \n- Implements error handling with try/catch around JSON parsing and the entire streaming process.\n\n3. **Business Logic**  \nEnables real-time streaming of backend-generated activity data (e.g., logs, events, or task progress) to the frontend UI, allowing dynamic updates and final result notification without polling. This supports interactive user experiences such as live progress tracking or incremental data display.\n\n4. **Dependencies**  \n- Browser Fetch API and Streams API (native web APIs).  \n- React hooks",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:07.511755",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_4": {
      "chunk_id": "BackendActivityStream.tsx:chunk_4",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "37a63a53027ab022b2d40f288142e7744ab96a495f3c8ac82e78b41dd13b8942",
      "chunk_index": 4,
      "summary": "1. **Purpose**:  \nThis React component code provides utility functions to visually represent the status of backend activities with icons, format step names into human-readable strings, and extract key details from activity metadata for display in a frontend activity stream.\n\n2. **Technical Details**:  \n- `getStatusIcon(status: string)`: Uses a switch-case statement to map status strings to corresponding React icon components with specific styling and animations.  \n- `formatStepName(step: string)`: Transforms camelCase or snake_case step identifiers into properly capitalized, spaced words using regex replacements and string manipulation.  \n- `formatDetails(details: Record<string, any>)`: Iterates over a details object to selectively extract and format important fields into an array of descriptive strings for UI display.\n\n3. **Business Logic**:  \nThe code supports a user interface feature that tracks and displays the progress and results of backend processes or workflows, helping users quickly understand the current state, step names, and relevant metadata of backend activities.\n\n4. **Dependencies**:  \n- React components for icons: `Loader2`, `CheckCircle2`, `XCircle`, `AlertCircle`, `Clock` (likely imported from an icon library such as `lucide-react` or similar).  \n- React JSX syntax for rendering UI elements.\n\n5. **Configuration**:  \nNo explicit environment variables or external configuration settings are referenced or required by this snippet.\n\n6. **Error Handling**:  \nNo explicit error handling is implemented",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:12.439535",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_6": {
      "chunk_id": "BackendActivityStream.tsx:chunk_6",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "ec1358a0f60e3ee29aa0376e188dfee793c060215379755be31229339a2f17b7",
      "chunk_index": 6,
      "summary": "1. **Purpose**:  \nThis React component snippet processes and formats backend activity details into a human-readable string and conditionally renders UI elements to display streaming errors or hide the component when no activities are present.\n\n2. **Technical Details**:  \n- Uses conditional checks on a `details` object to build an array (`important`) of formatted strings representing various backend activity metrics.  \n- Joins the array elements with a separator (`\u2022`) to produce a summary string.  \n- Implements conditional rendering based on error presence and streaming state.  \n- Uses JSX to render styled error messages with icons (e.g., `<XCircle />`).  \n- Checks for empty activity lists and streaming status to decide whether to render content or return `null`.\n\n3. **Business Logic**:  \nThe code provides a concise summary of backend activity stream details such as task counts, cache hits, errors, and references, enabling users or developers to quickly understand the status and results of backend operations. It also clearly communicates streaming errors to improve troubleshooting and user experience.\n\n4. **Dependencies**:  \n- React (JSX syntax) for UI rendering.  \n- An icon component `<XCircle />` likely imported from an icon library (e.g., Heroicons or similar).  \n- Styling classes suggest use of Tailwind CSS or a similar utility-first CSS framework.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are referenced in this snippet.\n\n6. **Error Handling**:  \n- Detect",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:17.676735",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_8": {
      "chunk_id": "BackendActivityStream.tsx:chunk_8",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "cdc462cce814bf0e0ac0cd4c8f5374107d6da67a5e5629970c1a040f05690636",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis React component renders a styled activity stream UI panel displaying backend activities with real-time status updates and visual indicators for different activity states.\n\n2. **Technical Details**:  \n- Uses React functional component with JSX for UI rendering.  \n- Maps over an `activities` array to dynamically generate activity entries.  \n- Conditional rendering applies different CSS classes based on activity status (`running`, `started`, `completed`, `failed`) to visually differentiate states.  \n- Uses Tailwind CSS utility classes for styling and layout.  \n- Displays a loading spinner (`Loader2` icon) and \"Processing...\" text when `isStreaming` flag is true.  \n- Uses icons (`Play`, `Loader2`) likely imported as React components or SVGs.\n\n3. **Business Logic**:  \nProvides a real-time visual representation of backend processes or jobs, helping users monitor backend system activity status and progress, which is critical for operational transparency and troubleshooting.\n\n4. **Dependencies**:  \n- React (JSX, functional components)  \n- Tailwind CSS for styling  \n- Icon components (`Play`, `Loader2`) possibly from a UI icon library or custom components\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet. The component relies on props or context for `activities` and `isStreaming` state.\n\n6. **Error Handling**:  \nNo explicit error handling or exception management is present in this UI rendering code. It",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:22.607305",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_10": {
      "chunk_id": "BackendActivityStream.tsx:chunk_10",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "4e6aa9c7b558ba1e30b9a8ac4085b5ae6aabcd34bb7dcbdb173ee7dd2989416d",
      "chunk_index": 10,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis React component snippet renders a list of backend activity stream entries, displaying status icons, step names, timestamps, and detailed messages including error information for failed activities.\n\n2. **Technical Details**:  \n- Uses JSX to dynamically render UI elements based on the `activities` array.  \n- Conditional rendering is applied to show details only if present and errors specifically when the status is 'failed'.  \n- Utilizes utility functions such as `getStatusIcon()`, `formatStepName()`, and `formatDetails()` to transform raw data into user-friendly UI elements.  \n- Employs Tailwind CSS classes for styling and layout (e.g., flexbox, spacing, colors).  \n- Date formatting is done via JavaScript's `Date` object and `toLocaleTimeString()` for timestamp display.\n\n3. **Business Logic**:  \nThe component provides real-time visibility into backend process steps and their statuses, enabling users or administrators to monitor workflow progress and quickly identify failures with detailed error messages.\n\n4. **Dependencies**:  \n- React (JSX syntax)  \n- Tailwind CSS for styling  \n- Presumably internal utility functions (`getStatusIcon`, `formatStepName`, `formatDetails`) defined elsewhere in the codebase.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are visible in this snippet; styling and behavior are controlled via component props and utility functions.\n\n6. **Error Handling**:  \n- Displays",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:27.847278",
      "status": "summarized"
    },
    "BackendActivityStream.tsx:chunk_12": {
      "chunk_id": "BackendActivityStream.tsx:chunk_12",
      "file_path": "frontend\\src\\components\\Shared\\BackendActivityStream.tsx",
      "chunk_hash": "9e036b8f9670a691acf53a839276b3c1b0819a70fc8ff863fdee26c7ca9e70b5",
      "chunk_index": 12,
      "summary": "1. **Purpose**:  \nThis React component renders a backend activity stream UI, displaying a loading indicator while connecting to the backend and summarizing the status of backend activities once loaded.\n\n2. **Technical Details**:  \n- Uses React functional component syntax with JSX for rendering.  \n- Conditional rendering based on the presence of `activities` and connection/loading state.  \n- Filters the `activities` array to count completed and failed steps using array `.filter()` method.  \n- Utilizes Tailwind CSS classes for styling and layout.  \n- Includes an animated spinner icon (`Loader2` component) to indicate loading state.\n\n3. **Business Logic**:  \nThe component provides users with real-time feedback on backend process steps, showing how many steps have been completed or failed, which helps in monitoring backend workflows or jobs.\n\n4. **Dependencies**:  \n- React (functional components and JSX).  \n- `Loader2` icon/component, likely from an icon library or custom component.  \n- Tailwind CSS for styling.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration settings are evident in this snippet. The component likely receives `activities` and connection state as props or from context.\n\n6. **Error Handling**:  \nNo explicit error handling is present in this snippet. Failed activities are visually counted and displayed but no error UI or retry logic is shown.\n\n7. **API/Interface**:  \n- The component exports a default React component named `BackendActivityStream`.",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:32.467172",
      "status": "summarized"
    },
    "vite-env.d.ts:chunk_0": {
      "chunk_id": "vite-env.d.ts:chunk_0",
      "file_path": "frontend\\src\\vite-env.d.ts",
      "chunk_hash": "312d8bc5fc5603b4af3c6ce16cbef1adb20c07e1345ba56ff5eac6a6b67e0666",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis TypeScript declaration file extends the Vite build tool's environment typing by defining the shape of the `import.meta.env` object, enabling type-safe access to environment flags such as development, production, and server-side rendering modes.\n\n2. **Technical Details**:  \n- Uses TypeScript's declaration merging to augment the global `ImportMeta` interface.  \n- Defines a readonly `ImportMetaEnv` interface with boolean flags: `DEV`, `PROD`, and `SSR`.  \n- Leverages triple-slash directive `/// <reference types=\"vite/client\" />` to include Vite's client types.\n\n3. **Business Logic**:  \nFacilitates environment-specific behavior in the frontend application by providing strongly typed access to build and runtime environment flags, which can be used to conditionally enable features, logging, or optimizations depending on whether the app is running in development, production, or server-side rendering mode.\n\n4. **Dependencies**:  \n- Depends on Vite's type definitions (`vite/client`) for base environment typings.  \n- No runtime dependencies; purely a compile-time type declaration.\n\n5. **Configuration**:  \n- Relies on Vite's environment variables system, where `DEV`, `PROD`, and `SSR` are automatically injected boolean flags based on the build context.  \n- No explicit config files here, but these flags are controlled by Vite's build and serve commands.\n\n6. **Error Handling**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:39.203343",
      "status": "summarized"
    },
    "tailwind.config.js:chunk_0": {
      "chunk_id": "tailwind.config.js:chunk_0",
      "file_path": "frontend\\tailwind.config.js",
      "chunk_hash": "199f0f2b086d084a1b1e62479cf25f4192e10cb4d78dbeaaaf24dcd5e759a7a0",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines the Tailwind CSS configuration for a frontend project, specifying which files Tailwind should scan for class names and extending the default theme with a custom primary color palette.\n\n2. **Technical Details**:  \n- Uses Tailwind CSS configuration format with TypeScript type hinting for editor support.  \n- Specifies `content` paths to enable Tailwind\u2019s Just-In-Time (JIT) compiler to purge unused styles by scanning HTML and JS/TS/JSX/TSX files.  \n- Extends the default theme by adding a custom `primary` color scale with shades from 50 to 900, enabling consistent use of brand colors throughout the UI.  \n- No plugins are added, keeping the configuration minimal.\n\n3. **Business Logic**:  \nProvides a consistent and customizable design system foundation by defining brand-specific colors, which helps maintain UI consistency and supports branding requirements in the frontend application.\n\n4. **Dependencies**:  \n- Depends on the `tailwindcss` package for styling and configuration.  \n- Implicitly relies on the project structure where source files are located under `./src` and the main HTML file is `index.html`.\n\n5. **Configuration**:  \n- The `content` array configures Tailwind to scan specific files for class names to generate CSS.  \n- The `theme.extend.colors.primary` object defines the custom color palette.  \n- No environment variables or external config files are referenced.\n\n6. **",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:45.114848",
      "status": "summarized"
    },
    "vite.config.ts:chunk_0": {
      "chunk_id": "vite.config.ts:chunk_0",
      "file_path": "frontend\\vite.config.ts",
      "chunk_hash": "a77921bfecff625a428a1889f7fa65f223487d4b68a32e1233682b7f1ca64ad9",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code configures the Vite development server for a React frontend application, setting up plugins, server behavior, hot module replacement (HMR), file watching, and API request proxying.\n\n2. **Technical Details**:  \n- Uses `defineConfig` from Vite to create a strongly-typed configuration object.  \n- Integrates the official React plugin for Vite to enable React-specific optimizations and JSX support.  \n- Configures the development server to listen on all network interfaces (`0.0.0.0`) at port 5000 with strict port binding (fails if port is unavailable).  \n- Enables HMR with a client port explicitly set to 443, likely to support secure WebSocket connections.  \n- Uses polling-based file watching with a 1000ms interval to detect file changes, improving reliability on certain file systems or network drives.  \n- Sets up a proxy so that requests to `/api` are forwarded to a backend server running locally on port 8000, with origin headers modified accordingly.\n\n3. **Business Logic**:  \nFacilitates a smooth and efficient frontend development experience for a React-based web application by enabling live reloads, seamless API integration during development, and network accessibility for testing on multiple devices or environments.\n\n4. **Dependencies**:  \n- `vite`: Modern frontend build tool and development server.  \n- `@vitejs/plugin-react`: Official React plugin for Vite enabling JSX and React",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:51.828730",
      "status": "summarized"
    },
    "example_usage.py:chunk_0": {
      "chunk_id": "example_usage.py:chunk_0",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "3cc6b92531ddbe61d5b3dfbe99f393fa355cb812cdaee8df8b3831873e2753da",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis code defines a FastAPI router that exposes an endpoint to process messages through a modular orchestration pipeline, enabling integration of complex workflows driven by message inputs.\n\n2. **Technical Details**:  \n- Uses FastAPI for REST API creation with dependency injection (`Depends`) for service management and LLM (Large Language Model) factory provisioning.  \n- Defines Pydantic models (`MessageRequest` and `MessageResponse`) for request validation and response serialization.  \n- Implements an asynchronous POST endpoint `/api/orchestration/process` that accepts structured message requests and returns structured responses.  \n- The orchestration pipeline is abstracted behind the `OrchestrationFacade` (imported but not shown in snippet), suggesting a facade design pattern to encapsulate complex subsystem interactions.\n\n3. **Business Logic**:  \nEnables clients to submit messages (e.g., commands or queries related to software issues or tasks) that are processed through a customizable orchestration pipeline. This supports business workflows such as automated issue analysis, task execution, or data enrichment based on templates and optional parameters, improving operational automation and decision-making.\n\n4. **Dependencies**:  \n- **FastAPI**: Web framework for API routing and dependency injection.  \n- **Pydantic**: Data validation and settings management.  \n- **orchestration.facade.OrchestrationFacade**: Core orchestration logic handler (not detailed here).  \n- **shared.services.manager.ServiceManager**: Service management dependency",
      "embedding_id": null,
      "created_at": "2025-10-22T20:12:57.138288",
      "status": "summarized"
    },
    "example_usage.py:chunk_2": {
      "chunk_id": "example_usage.py:chunk_2",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "35a2f6a2f52c755f49060ed81d5896c7ed39eabb5fb6df64950371bd58673cd7",
      "chunk_index": 2,
      "summary": "1. **Purpose**:  \nThis code snippet asynchronously processes an input message through an orchestration facade, which parses and enriches the message based on a specified template and options, then serializes the processed result into a structured dictionary format suitable for further use or transmission.\n\n2. **Technical Details**:  \n- Utilizes an asynchronous method `process_message` on the `OrchestrationFacade` class, indicating async/await concurrency model.  \n- The facade pattern is employed via `OrchestrationFacade` to abstract complex interactions between the `service_manager` and `llm_factory`.  \n- The result contains nested data structures: a parsed message object with references (each having type, raw text, normalized value, and metadata), and an enriched context with multiple context items.  \n- Serialization converts domain objects (likely custom classes with attributes) into plain Python dictionaries with primitive types and lists, facilitating JSON serialization or API response formatting.\n\n3. **Business Logic**:  \nThe code supports a business workflow where incoming textual messages are parsed, referenced entities extracted, and contextual information enriched\u2014likely for applications such as automated customer support, knowledge extraction, or intelligent message handling. The use of templates and enrichment options suggests customizable processing pipelines tailored to different business scenarios.\n\n4. **Dependencies**:  \n- `OrchestrationFacade` class, which internally depends on `service_manager` (likely managing various backend services) and `llm_factory` (a factory for large language model instances or similar AI",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:04.186133",
      "status": "summarized"
    },
    "example_usage.py:chunk_4": {
      "chunk_id": "example_usage.py:chunk_4",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "9aad8e2c15b79799a5af48c41df3b6ba1df5fab7b144af9913aa9bff5695098d",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines an asynchronous API endpoint `/parse-only` that accepts a message string, processes it through an orchestration facade to perform parsing (the first step in a multi-step pipeline), and returns a structured response containing parsed context, formatted prompts, task results, and metadata.\n\n2. **Technical Details**:  \n- Uses FastAPI's dependency injection (`Depends()`) for service management.  \n- Implements an asynchronous POST endpoint handler (`async def parse_only`).  \n- Utilizes an orchestration facade pattern (`OrchestrationFacade`) to encapsulate the parsing logic.  \n- Processes complex nested data structures including lists of context items and tasks, serializing them into dictionaries for JSON response.  \n- Returns a custom response object (`MessageResponse`) indicating success or failure with detailed data or error messages.\n\n3. **Business Logic**:  \nThe code supports a business workflow that requires parsing user messages to extract enriched contextual information, generate formatted prompts, and track task execution results. This is likely part of a larger system for automated message processing, AI orchestration, or conversational AI pipelines.\n\n4. **Dependencies**:  \n- FastAPI framework for API routing and dependency injection.  \n- Custom modules/classes: `OrchestrationFacade`, `ServiceManager`, `MessageResponse`.  \n- Asynchronous programming with `async/await`.\n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are shown in the snippet. However, the use",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:12.398399",
      "status": "summarized"
    },
    "example_usage.py:chunk_6": {
      "chunk_id": "example_usage.py:chunk_6",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "4ddea7380fffd5a83149eae06bad85a7d5dd0cde4d1f709c37c42387adbf2db0",
      "chunk_index": 6,
      "summary": "1. **Purpose**  \nThis code snippet provides an example usage of an orchestration service pipeline and exposes a health check endpoint to verify the operational status of various submodules within the orchestration layer.\n\n2. **Technical Details**  \n- Implements an asynchronous FastAPI GET endpoint `/health` that returns the status of multiple internal modules.  \n- Defines a class `DirectUsageExample` demonstrating direct, programmatic invocation of the orchestration pipeline without using the API layer.  \n- Uses a service manager (`ServiceManager`) to coordinate service calls and process messages through a pipeline, returning structured results including original and cleaned messages and references.  \n- Utilizes Python async/await syntax for asynchronous operations.  \n- Data structures include dictionaries for JSON responses and list comprehensions to transform reference objects into serializable dictionaries.\n\n3. **Business Logic**  \nThe code supports a business need to process and enrich messages through a multi-stage pipeline (parsing, context enrichment, prompt building, agent interaction) and provide operational health visibility of these components. This enables reliable message processing workflows and system monitoring for uptime and diagnostics.\n\n4. **Dependencies**  \n- `shared.services.manager.ServiceManager`: Core orchestration service manager coordinating pipeline stages.  \n- FastAPI framework (implied by use of `@router.get` and async endpoints).  \n- Python standard libraries for async programming and exception handling.\n\n5. **Configuration**  \nNo explicit environment variables or configuration files are shown in this snippet. Configuration is likely managed elsewhere for",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:19.197689",
      "status": "summarized"
    },
    "example_usage.py:chunk_8": {
      "chunk_id": "example_usage.py:chunk_8",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "e3252c49ccbd1dc45632fa5044793c2cb65fd701813f0e9a21673ff7f064b794",
      "chunk_index": 8,
      "summary": "1. **Purpose**:  \nThis Python code demonstrates usage examples of an orchestration facade to process, parse, enrich, and build prompts from input messages asynchronously, showcasing both an all-in-one and a step-by-step pipeline approach.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to handle potentially I/O-bound operations efficiently.  \n- Employs a facade design pattern (`OrchestrationFacade`) to abstract and simplify interactions with underlying services.  \n- The code processes messages by parsing references, enriching context, and optionally executing tasks based on templates.  \n- Data structures involved include dictionaries (e.g., `result` with keys like `'parsed_message'` and `'metadata'`) and objects with attributes such as `references` and `context_items`.\n\n3. **Business Logic**:  \nThe code supports automated analysis and processing of textual messages (e.g., bug reports or issue references), extracting actionable references, enriching them with contextual data, and optionally executing related tasks. This facilitates streamlined issue tracking, documentation updates, or task automation workflows in project management or software development contexts.\n\n4. **Dependencies**:  \n- Internal module: `shared.services.manager.ServiceManager` for service orchestration.  \n- `OrchestrationFacade` class (presumably from the same or related module) encapsulates the orchestration logic.  \n- No explicit external third-party libraries shown, but asynchronous support implies Python 3.7+.\n\n5. **Configuration**:",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:25.041875",
      "status": "summarized"
    },
    "example_usage.py:chunk_10": {
      "chunk_id": "example_usage.py:chunk_10",
      "file_path": "orchestration\\example_usage.py",
      "chunk_hash": "cb09c104156c75a332080074c8148607274074c25d09c041c00471548a440268",
      "chunk_index": 10,
      "summary": "**Summary of `orchestration/example_usage.py`:**\n\n1. **Purpose**  \nThis script demonstrates example usages of an orchestration system that manages and executes asynchronous tasks related to code analysis and security review using customizable templates.\n\n2. **Technical Details**  \n- Uses asynchronous programming (`async/await`) to handle task execution without blocking.  \n- Defines tasks via the `AgentTask` data model, uniquely identified by UUIDs.  \n- Implements a facade pattern (`OrchestrationFacade`) to abstract complex orchestration logic and provide a simplified interface for task execution and template management.  \n- Supports dynamic addition of custom templates for task processing, enabling flexible message handling based on different contexts (e.g., security review).  \n- Uses structured task objects with fields like `task_id`, `task_type`, `description`, and `context` to encapsulate task metadata and payload.\n\n3. **Business Logic**  \nEnables automated orchestration of code analysis workflows, including vulnerability scanning and security reviews, facilitating faster and more consistent code quality assurance. The custom template feature allows tailoring the analysis to specific business needs such as security compliance.\n\n4. **Dependencies**  \n- `orchestration.shared.models.AgentTask`: Data model for defining tasks.  \n- `shared.services.manager.ServiceManager`: Service manager likely responsible for managing service lifecycles or dependencies.  \n- `OrchestrationFacade`: Core orchestration interface (import implied but not shown).  \n- Standard Python libraries: `uuid` for unique",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:30.492104",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_0": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_0",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "5b205e2d05e82aba8d07531981170aace36cb89a9cc560d578c36e39d169c5d9",
      "chunk_index": 0,
      "summary": "1. **Purpose**:  \nThis module provides an enhanced summarization service leveraging Azure OpenAI to improve the quality, clarity, and formatting of responses for chat and voice assistant applications.\n\n2. **Technical Details**:  \n- Implements a class `AzureEnhancedSummarizer` that uses a resilient orchestrator pattern (`ResilientLLMOrchestrator`) to interact with Azure OpenAI services.  \n- The class encapsulates logic for context-aware summarization, formatting improvements, multilingual support, and enhanced code explanation.  \n- Uses asynchronous programming (`async def enhance_response`) to handle potentially long-running API calls efficiently.  \n- Logging is integrated for observability and debugging.\n\n3. **Business Logic**:  \n- Enhances user experience by providing clearer, better-structured, and contextually relevant responses in conversational AI scenarios.  \n- Supports multilingual and technical content, making it suitable for diverse user bases and technical domains.  \n- Helps maintain high-quality interactions in chatbots and voice assistants, potentially increasing user satisfaction and engagement.\n\n4. **Dependencies**:  \n- `ResilientLLMOrchestrator` from `shared.llm_providers.resilient_orchestrator` for robust interaction with LLM APIs.  \n- `settings` from `shared.config` for configuration management.  \n- Standard Python libraries: `logging`, `typing.Optional`.\n\n5. **Configuration**:  \n- Controlled by configuration flags `settings.llm_provider` and `settings.chat_provider` to enable",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:37.269400",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_2": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_2",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "ef8eeb48342ea5611a0c8fde69f9c0e08a64dcc240f1f2837ddfd94c1ba5b51f",
      "chunk_index": 2,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis asynchronous Python method enhances a given textual response by leveraging an Azure Large Language Model (LLM) to improve the quality, clarity, and formatting of the response based on optional context and specified response type.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async/await`) to call Azure LLM services without blocking.  \n- Constructs a prompt dynamically via a helper method `_build_enhancement_prompt` that incorporates the original response, optional context, and response type.  \n- Retrieves an LLM provider configured for chat completions via `self.llm.get_provider_for_role(\"chat\")`.  \n- Sends a chat completion request to the Azure LLM with the constructed prompt wrapped as a message.  \n- Uses logging extensively to trace the enhancement process and response lengths.\n\n3. **Business Logic**:  \nImproves the quality of automated responses (e.g., chatbot replies, generated content) by refining them with Azure\u2019s advanced language models, thus enhancing user experience and communication effectiveness across different response types (general, code, technical, voice).\n\n4. **Dependencies**:  \n- Azure Large Language Model service (Azure OpenAI or similar).  \n- An LLM abstraction layer (`self.llm`) that manages providers and roles.  \n- Python `logging` module for info-level logs.  \n- Possibly `asyncio` for asynchronous execution.  \n- Optional typing (`Optional[str]`) for input parameters.\n\n5. **Configuration**",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:42.049317",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_4": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_4",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "e3b8b214f656d09f0bb680390e799e7c714ed75bfbb5df9e60f0f57d7eaa019d",
      "chunk_index": 4,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a module designed to enhance or improve technical text responses by applying structured formatting, clearer explanations, and better presentation. It uses an AI-based approach to refine an original response into a more polished and readable output.\n\n2. **Technical Details**:  \n- The code constructs a prompt dynamically based on the type of response and optional context to guide the enhancement process.  \n- It interacts with a language model (likely via an API call) using a conversational format with system and user roles to generate the enhanced text.  \n- Logging is used to track success and failure of the enhancement process.  \n- The enhancement prompt includes instructions to add headings, sections, inline comments for code, and markdown formatting improvements.\n\n3. **Business Logic**:  \nThe code addresses the business need for improving the quality and clarity of automatically generated technical responses, such as summaries or explanations, which can be critical for user comprehension and satisfaction in applications like documentation tools, chatbots, or automated report generators.\n\n4. **Dependencies**:  \n- An AI language model API (e.g., OpenAI GPT or Azure OpenAI) for text generation.  \n- A logging framework for operational insights.  \n- Python standard libraries for exception handling and typing (e.g., `Optional`).\n\n5. **Configuration**:  \n- The enhancement process uses parameters such as `temperature=0.3` to control the creativity of the AI output.  \n- The",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:48.962568",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_6": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_6",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "95ed7b5bfdfdf3b6ad966f98994508f383587f40b82af7e0d00b8f8e20455b06",
      "chunk_index": 6,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a method that generates a prompt string to enhance a given response based on the specified response type and optional context. It tailors instructions for improving clarity, technical accuracy, or conversational style in summarization or explanation tasks.\n\n2. **Technical Details**:  \n- Uses conditional branching (`if-elif-else`) to select type-specific instructions for enhancing the response.  \n- Constructs a multi-line formatted string (`prompt`) combining base instructions, type-specific guidance, optional context, and the original response.  \n- The method appears asynchronous (`async def enhance_code_section` is partially shown), suggesting integration with async workflows.  \n- The snippet is part of a larger class or module focused on enhancing or summarizing code or text responses.\n\n3. **Business Logic**:  \n- Supports automated enhancement of textual or code responses to improve communication quality in different modes (code clarity, voice interaction, technical accuracy).  \n- Enables adaptable summarization or explanation generation tailored to user needs or output channels, improving user experience in documentation, code review, or voice assistant contexts.\n\n4. **Dependencies**:  \n- The snippet itself does not explicitly import or use external libraries, but the async method signature implies use of Python\u2019s `asyncio` or similar async frameworks.  \n- Likely part of a larger system that may depend on Azure services or NLP models (inferred from file path `azure_enhanced_summarizer.py`).",
      "embedding_id": null,
      "created_at": "2025-10-22T20:13:54.954003",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_8": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_8",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "921151649e4d2313870cad2dd8c107afc79f6820c1303668fe628e14ee58fbb0",
      "chunk_index": 8,
      "summary": "**Summary of `azure_enhanced_summarizer.py` snippet**\n\n1. **Purpose**  \nThis asynchronous method enhances given code snippets by adding helpful inline comments and explanations to improve readability without altering the original logic.\n\n2. **Technical Details**  \n- Uses prompt engineering to create a natural language prompt instructing an LLM (Large Language Model) to add comments to code.  \n- Interacts asynchronously with an LLM provider via a `chat_completion` API call, passing a user role message with a temperature setting for controlled randomness.  \n- Returns the enhanced code wrapped in language-specific markdown code blocks.  \n- Conditional execution based on an `enabled` flag to optionally bypass enhancement.\n\n3. **Business Logic**  \nImproves developer productivity and code maintainability by automatically generating clearer, well-commented code snippets. This can be used in documentation generation, code review tools, or educational platforms to help users understand complex code sections.\n\n4. **Dependencies**  \n- An LLM interface (`self.llm`) with a method `get_provider_for_role(\"chat\")` that returns a provider supporting `chat_completion`.  \n- Logging via a `logger` instance for info-level messages.  \n- Python async/await syntax indicating asynchronous I/O operations.\n\n5. **Configuration**  \n- Controlled by an `enabled` boolean attribute to toggle enhancement functionality.  \n- Temperature parameter (0.2) set in the LLM call to balance creativity and determinism.  \n- No explicit environment variables",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:01.817577",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_10": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_10",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "ae5d681010ff14a86f71cd02dc548d8f415c9f8ed75997bb3e6e9cbd4e235816",
      "chunk_index": 10,
      "summary": "1. **Purpose**:  \nThis asynchronous Python method `summarize_for_voice` generates a concise, conversational summary of a given text optimized for voice output, with a configurable maximum character length.\n\n2. **Technical Details**:  \n- Uses prompt engineering to instruct a language model to create a voice-friendly summary.  \n- Employs asynchronous programming (`async def`) to handle potentially long-running I/O-bound operations without blocking.  \n- Interacts with a language model provider via a chat completion API, passing a structured prompt message.  \n- Implements a simple truncation fallback when summarization is disabled.  \n- Uses string formatting to dynamically build the prompt with instructions and input text.\n\n3. **Business Logic**:  \nEnables the generation of voice-optimized summaries that are concise and natural sounding, improving user experience in voice-based applications such as virtual assistants, audiobooks, or accessibility tools where spoken summaries are needed.\n\n4. **Dependencies**:  \n- A logging utility (`logger`) for info and error messages.  \n- An LLM (Large Language Model) interface accessible via `self.llm.get_provider_for_role(\"chat\")` which supports asynchronous chat completions.  \n- The code snippet implies an external LLM service or API is used to generate the summary.\n\n5. **Configuration**:  \n- A boolean flag `self.enabled` controls whether to use the LLM summarization or fallback to truncation.  \n- `max_length` parameter controls the maximum length of the",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:08.277646",
      "status": "summarized"
    },
    "azure_enhanced_summarizer.py:chunk_12": {
      "chunk_id": "azure_enhanced_summarizer.py:chunk_12",
      "file_path": "orchestration\\summary_layer\\azure_enhanced_summarizer.py",
      "chunk_hash": "eb303fcd0181abca8ac3568f88f300c11d23bd277cf5d9722b03b4854c31229c",
      "chunk_index": 12,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis code snippet is part of a method that generates a summarized voice-friendly text output, ensuring the summary does not exceed a specified maximum length. It logs the success or failure of the summarization process and returns a truncated fallback summary on error.\n\n2. **Technical Details**:  \n- The code truncates the generated summary to a maximum character length (`max_length`), appending an ellipsis (\"...\") if truncation occurs.  \n- It uses logging to record the success (`logger.info`) or failure (`logger.error`) of the summarization operation.  \n- Exception handling is implemented to catch any errors during summarization and provide a fallback summary by truncating the original text.  \n- The snippet ends with the instantiation of a global singleton-like instance `azure_enhanced_summarizer` of the `AzureEnhancedSummarizer` class.\n\n3. **Business Logic**:  \nThe code addresses the need to produce concise, voice-optimized summaries that fit within length constraints, likely for applications such as voice assistants, audio content generation, or accessibility tools where text length impacts user experience.\n\n4. **Dependencies**:  \n- A logger instance (`logger`) is used for logging events.  \n- The class `AzureEnhancedSummarizer` is defined elsewhere in the module or package.  \n- The summarization logic (not fully shown) presumably depends on Azure Cognitive Services or related Azure SDKs, suggested by the class name.\n\n5",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:14.076394",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_1": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_1",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "049562591c44ff8cc3ba81143bf519a3e6484cabd2f94863a09b5877f488741e",
      "chunk_index": 1,
      "summary": "1. **Purpose**  \nThis deprecated Python module provides a service to index the contents of GitHub repositories into a vector database by embedding repository data for efficient semantic search and retrieval. It is retained solely for backward compatibility and will be removed in future releases.\n\n2. **Technical Details**  \n- Utilizes an orchestrator (`CodeIntelligenceOrchestrator`) to asynchronously embed repository content into a vector collection.  \n- Defines a `RepositoryIndexer` class that integrates three main components: a vector database provider (`VectorDBProvider`), an embedding generation service (`EmbeddingService`), and optionally a GitHub API client (`GitHubWrapper`).  \n- Employs standard Python typing for method signatures and logging for operational insights.  \n- Uses hashing (`hashlib`) and timestamps (`datetime`) likely for metadata management and deduplication (implied by imports).  \n- The design follows a service-oriented pattern encapsulating repository indexing logic within a dedicated class.\n\n3. **Business Logic**  \nEnables semantic indexing of GitHub repository content to support advanced code search, knowledge discovery, or AI-driven code intelligence applications. This facilitates developers or automated systems to query codebases more effectively by embedding code semantics into vector representations stored in a specialized database.\n\n4. **Dependencies**  \n- `code-intelligence.orchestrator` module for orchestrating embedding workflows.  \n- Standard Python libraries: `logging`, `typing`, `datetime`, `hashlib`.  \n- Internal modules: `VectorDBProvider` and `",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:19.737970",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_3": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_3",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "498d02abf28f6f7a5ff7377b4ad74ca10ea6af87a78e14483580e38c7e8a1588",
      "chunk_index": 3,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code defines an asynchronous method to index the contents of a GitHub repository into a vector database, enabling semantic search or similarity queries on the repository data.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to handle potentially long-running I/O operations such as network calls to GitHub and embedding services.  \n- Relies on dependency injection for `vector_db`, `embedding_service`, and `github_client` to abstract storage, embedding generation, and GitHub API interactions.  \n- Logs detailed progress and configuration information using a logger.  \n- Returns a dictionary summarizing the success or failure of the indexing operation, including error messages.\n\n3. **Business Logic**:  \nThe code supports the business need to transform code repositories into vector representations for advanced search, recommendation, or analysis features, facilitating enhanced developer productivity or code intelligence platforms.\n\n4. **Dependencies**:  \n- A GitHub client for repository access (likely a wrapper around GitHub REST or GraphQL API).  \n- An embedding service to convert code/text into vector embeddings (could be a machine learning model or external API).  \n- A vector database to store and query embeddings.  \n- A logging framework for operational visibility.\n\n5. **Configuration**:  \n- Parameters such as repository owner, name, branch, and vector DB collection name are configurable via method arguments.  \n- The presence of the GitHub client and embedding service is expected to be configured externally",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:24.200564",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_5": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_5",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "d724eeafe4f64a9036421add2d469df7cf90f9617cb7725b24d4ab2f0ef2d1ed",
      "chunk_index": 5,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet performs a health check on an embedding service and attempts to fetch a GitHub repository tree if the embedding service is available and connected.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) for non-blocking calls to external services.  \n- Retrieves health status from an embedding service via `self.embedding_service.health_check()`.  \n- Logs detailed status information about the embedding service including connection status, provider, model, and dimension.  \n- Attempts to fetch a repository tree from GitHub asynchronously via `self._get_repository_tree(owner, repo, branch)`.  \n- Uses structured logging with emoji-enhanced messages for clarity and debugging.  \n\n3. **Business Logic**:  \nEnsures that the embedding service, which likely provides vector embeddings for repository content, is operational before proceeding to index or analyze the repository structure. This is critical for workflows that depend on embedding vectors for search, recommendation, or analysis of code repositories.\n\n4. **Dependencies**:  \n- An embedding service accessible via `self.embedding_service` with a `health_check()` async method.  \n- GitHub API or an abstraction thereof accessed through `self._get_repository_tree()`.  \n- A logging framework (`logger`) for recording operational status and errors.  \n\n5. **Configuration**:  \n- Repository owner, repository name, and branch are passed as parameters (likely method arguments).  \n- Embedding service configuration (provider, model, dimension)",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:29.851599",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_7": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_7",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "11bef60ceebae2d6abbf761c1118457701e5967b5fb591e899659b22f00dcebb",
      "chunk_index": 7,
      "summary": "1. **Purpose**:  \nThis snippet is part of a deprecated repository indexer service that retrieves a repository's file tree, filters files relevant for indexing (such as code, documentation, markdown), and processes these files by fetching their content to create searchable documents.\n\n2. **Technical Details**:  \n- Retrieves a list (`tree`) representing the repository's file structure.  \n- Uses filtering logic (`_filter_indexable_files`) to select files based on type (likely by file extension).  \n- Iterates over filtered files, logging progress every 10 files or on the first file.  \n- Collects documents and metadata in lists for further processing.  \n- Uses structured logging with emoji-enhanced messages for clarity and monitoring.\n\n3. **Business Logic**:  \nEnables efficient indexing of repository contents to support search, analytics, or documentation generation features by focusing only on relevant file types, thereby optimizing resource usage and improving the quality of indexed data.\n\n4. **Dependencies**:  \n- A logger instance (`logger`) for structured logging.  \n- Internal method `_filter_indexable_files` for filtering logic.  \n- Presumably interacts with a repository API or service to fetch the file tree and file contents (not shown in snippet).\n\n5. **Configuration**:  \nNot explicitly shown in the snippet, but likely depends on:  \n- Repository access credentials or tokens.  \n- Configuration for which file types are considered indexable.  \n- Possibly environment variables or config files defining repository endpoints or",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:36.083368",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_9": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_9",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "3bdf2fe3345b2e57f97dcb0862f76bc2f82af367cb0c59806f46bd1ec5ee56a2",
      "chunk_index": 9,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet processes a batch of files to extract documents and metadata, then generates vector embeddings for those documents using an external embedding service.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to handle potentially I/O-bound operations such as file processing and embedding generation.  \n- Collects processed documents and their metadata into lists (`documents`, `metadatas`).  \n- Uses timestamps (`datetime.now()`) to measure the duration of the embedding generation step.  \n- Employs logging for progress and diagnostic information.  \n- Embeddings are generated in batch via a method `generate_embeddings_batch` on an embedding service object, which abstracts the embedding provider details.\n\n3. **Business Logic**:  \nThe code supports indexing repository content by converting raw files into vector representations, enabling efficient semantic search or similarity queries over repository data. It filters out files that fail processing and ensures only valid documents are embedded and indexed.\n\n4. **Dependencies**:  \n- An asynchronous embedding service (`self.embedding_service`) that provides:  \n  - `provider_name` (embedding provider identifier)  \n  - `embedding_model` (model name/version)  \n  - `get_dimension()` (embedding vector size)  \n  - `generate_embeddings_batch()` (batch embedding generation method)  \n- Python standard libraries: `datetime` for timing, and a `logger` for logging.  \n- The method `_process_file` (likely internal) for file content extraction",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:45.808859",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_11": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_11",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "a904ec3ca38d9be0588a63aecda24e793ce43d2bba01058bf44ad5e6b6b652b7",
      "chunk_index": 11,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet logs the timing and progress of generating embeddings for a set of documents and subsequently adds these documents along with their embeddings to a vector database for indexing.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`await`) to interact with a vector database service.  \n- Measures elapsed time for embedding generation and database insertion using `datetime.now()`.  \n- Logs detailed progress and performance metrics (total duration, average time per document).  \n- Calls a method `add_documents` on a `vector_db` object, passing collections, documents, embeddings, and metadata.  \n- Returns a success response dictionary including repository and branch info upon successful indexing.\n\n3. **Business Logic**:  \nThe code supports the business need to index documents from a code repository (identified by `owner/repo` and `branch`) into a vector database, enabling efficient semantic search or similarity queries over the repository\u2019s content.\n\n4. **Dependencies**:  \n- `logger`: a logging utility for info-level messages.  \n- `datetime` module for timing.  \n- An asynchronous vector database client/service (`self.vector_db`) with an `add_documents` method.  \n- Implicitly depends on prior embedding generation logic (not shown here).\n\n5. **Configuration**:  \n- Collection name (`collection_name`) is dynamically specified, likely configured per repository or project.  \n- Repository identifiers (`owner`, `repo`, `branch`) are inputs to the indexing",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:49.895895",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_13": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_13",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "6ca721b090298ef0f0dca44d003fd39b37b1ea83b4e545a1faba886271b78336",
      "chunk_index": 13,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis Python code snippet is part of a deprecated repository indexer service that asynchronously retrieves a GitHub repository's file tree and attempts to index documents into a vector database.\n\n2. **Technical Details**:  \n- Uses asynchronous programming (`async def`) to fetch repository data from GitHub.  \n- Interacts with a GitHub client abstraction (`self.github_client`) to retrieve the repository tree recursively.  \n- Returns structured dictionaries indicating success or failure states when adding documents to a vector database.  \n- Uses logging extensively for info, warning, and error messages.  \n- Data structures involved include lists of dictionaries representing file tree items and dictionaries for response payloads.\n\n3. **Business Logic**:  \nThe code supports the business need to index source code repositories by extracting their file structure and storing relevant documents in a vector database, enabling efficient search and retrieval of repository content for downstream applications such as code search, analysis, or recommendation systems.\n\n4. **Dependencies**:  \n- A GitHub client module or service (`self.github_client`) that provides asynchronous API calls to GitHub.  \n- A vector database client/service (implied but not shown in snippet) for document storage.  \n- Python standard logging module (`logger`).  \n- Python typing for type hints (`Optional`, `List`, `Dict`, `Any`).\n\n5. **Configuration**:  \n- Requires configuration of the GitHub client instance (`self.github_client`) before use.  \n- Lik",
      "embedding_id": null,
      "created_at": "2025-10-22T20:14:56.731378",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_15": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_15",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "5c5c3961e81092e1fa47e6274d9e88f4c3e58e160b94c4f3931f54e44f5ad381",
      "chunk_index": 15,
      "summary": "1. **Purpose**:  \nThis Python code is part of a deprecated repository indexer service designed to filter and process files from a repository tree for the purpose of indexing relevant source code and documentation files.\n\n2. **Technical Details**:  \n- The `_filter_indexable_files` method filters a list of file metadata dictionaries (`tree`) to retain only files with specific extensions deemed indexable.  \n- It uses a predefined set of file extensions representing common programming languages and documentation formats.  \n- The method iterates over each item, checks if it is a file (`type == 'blob'`), extracts the file extension, and includes it if it matches the allowed set.  \n- The `_process_file` method (partially shown) is asynchronous and intended to handle the processing of a single file, likely involving reading file content and generating metadata for indexing.  \n- Exception handling is implemented to log errors with stack traces and return `None` on failure.\n\n3. **Business Logic**:  \nThe code supports a business need to index source code and documentation files from code repositories, enabling features such as search, code analysis, or knowledge discovery within an organization\u2019s codebase.\n\n4. **Dependencies**:  \n- Uses Python standard libraries such as `logging` (implied by `logger.error`).  \n- Relies on asynchronous programming constructs (`async def`).  \n- Uses type hints from `typing` (e.g., `List`, `Dict`, `Any`, `Optional`).",
      "embedding_id": null,
      "created_at": "2025-10-22T20:15:02.571712",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_17": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_17",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "6d8d78c5a107436c43957925174acf53cfcce17289e157793d7f1f70ea34478e",
      "chunk_index": 17,
      "summary": "1. **Purpose**:  \nThis asynchronous Python code snippet fetches the content of a specific file from a GitHub repository, performs validation checks on the file size and content, and generates a unique document ID for indexing purposes.\n\n2. **Technical Details**:  \n- Uses asynchronous calls (`await`) to fetch file content from GitHub via a client abstraction (`self.github_client`).  \n- Validates file content by checking for existence, size limits (skips files > 500KB), and emptiness.  \n- Generates a unique document identifier by hashing a concatenated string of repository owner, name, branch, and file path using SHA-256, truncated to 16 hex characters.  \n- Uses logging at different severity levels (`error`, `warning`, `debug`) to track processing states and issues.\n\n3. **Business Logic**:  \nThe code supports a repository indexing service that selectively processes files from GitHub repositories to build or update a searchable vector database. It ensures only relevant, manageable-sized, and non-empty files are indexed, optimizing storage and search quality.\n\n4. **Dependencies**:  \n- `self.github_client`: An external or internal GitHub API client abstraction responsible for fetching file content.  \n- `hashlib`: Python standard library for SHA-256 hashing.  \n- `logger`: A logging utility for error and status reporting.\n\n5. **Configuration**:  \n- Requires a properly configured GitHub client instance (`self.github_client`) to interact with GitHub APIs",
      "embedding_id": null,
      "created_at": "2025-10-22T20:15:07.320367",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_19": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_19",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "bd357855f2be8b15da4ea5fd57d64aa09f98266cf8ae5e3ad676a19db452d5d3",
      "chunk_index": 19,
      "summary": "1. **Purpose**:  \nThis code snippet processes source code files from a repository by detecting their programming language based on file extension, creating associated metadata, and returning the file content along with this metadata for further indexing or storage.\n\n2. **Technical Details**:  \n- Uses a private method `_detect_language` that maps file extensions to programming language names via a dictionary (`extension_map`).  \n- Constructs a `DocumentMetadata` object containing identifiers, source information, language, content type, and timestamps.  \n- Employs exception handling to catch and log errors during file processing.  \n- Uses Python's `datetime.now()` to timestamp metadata creation and updates.  \n- Logging is used for both successful processing (`logger.debug`) and errors (`logger.error`).\n\n3. **Business Logic**:  \nThe code supports a repository indexing system that categorizes files by language and metadata, enabling efficient search, retrieval, or analysis of code files from GitHub repositories. This facilitates features like language-specific search, version tracking (via commit SHA), and source attribution.\n\n4. **Dependencies**:  \n- `DocumentMetadata` class or data structure (likely a custom or domain-specific model).  \n- `datetime` module for timestamps.  \n- `logger` for logging debug and error messages.  \n- Possibly other parts of the system for file reading and repository interaction (not shown).  \n\n5. **Configuration**:  \nNo explicit environment variables or configuration files are referenced in the snippet. The language detection relies",
      "embedding_id": null,
      "created_at": "2025-10-22T20:15:15.787737",
      "status": "summarized"
    },
    "repository_indexer.deprecated.py:chunk_21": {
      "chunk_id": "repository_indexer.deprecated.py:chunk_21",
      "file_path": "shared\\vector_db\\services\\repository_indexer.deprecated.py",
      "chunk_hash": "e5506656be0b73d7b1ef0bed6549fb4b063486e92ad2ef5ddfa9543393b61367",
      "chunk_index": 21,
      "summary": "Summary:\n\n1. **Purpose**:  \nThis snippet maps a file extension extracted from a given file path to a corresponding programming language identifier string.\n\n2. **Technical Details**:  \n- Uses a dictionary (`extension_map`) to associate file extensions (e.g., `.cs`, `.rb`) with language names (e.g., `csharp`, `ruby`).  \n- Extracts the file extension by splitting the file path on the period character and prepending a dot to the last segment.  \n- Performs a case-insensitive lookup by converting the extension to lowercase before querying the dictionary.\n\n3. **Business Logic**:  \nEnables the system to identify the programming language of source code files based on their extensions, which is essential for language-specific processing such as syntax highlighting, indexing, or analysis in a vector database or code search context.\n\n4. **Dependencies**:  \nNo external libraries or modules are used in this snippet; it relies solely on built-in Python string operations and dictionary data structures.\n\n5. **Configuration**:  \nNo environment variables or external configuration influence this code; the mapping is hardcoded within the dictionary.\n\n6. **Error Handling**:  \nNo explicit error handling is present. If the file path lacks an extension or the extension is not in the map, the function returns `None` implicitly.\n\n7. **API/Interface**:  \nThis code appears to be part of a function (not fully shown) that takes a `file_path` string as input and",
      "embedding_id": null,
      "created_at": "2025-10-22T20:15:20.927065",
      "status": "summarized"
    }
  },
  "stats": {
    "total_files": 207,
    "completed_files": 207,
    "total_chunks": 922,
    "completed_chunks": 0,
    "failed_chunks": 0,
    "cache_hit_rate": 0.0
  }
}