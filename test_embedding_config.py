#!/usr/bin/env python3
"""
Test script to show current embedding configuration
"""

import asyncio
import sys
import os

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from shared.llm import llm_client
from shared.vector_db.embedding_service import EmbeddingService

async def test_embedding_config():
    """Test current embedding configuration"""
    
    print("üß† EMBEDDING CONFIGURATION TEST\n" + "="*50)
    
    # Test unified LLM client
    print("1Ô∏è‚É£ **Unified LLM Client Embeddings**")
    provider_info = llm_client.get_provider_info()
    print(f"   ‚Ä¢ Provider: {provider_info.get('provider', 'Unknown')}")
    print(f"   ‚Ä¢ Enhanced Features: {provider_info.get('enhanced_features', False)}")
    
    if hasattr(llm_client.provider, 'embeddings_model'):
        print(f"   ‚Ä¢ Embeddings Model: {llm_client.provider.embeddings_model}")
    
    # Test embeddings generation
    try:
        test_text = "This is a test for embedding generation"
        embeddings = await llm_client.generate_embeddings([test_text])
        
        if embeddings and len(embeddings) > 0:
            print(f"   ‚Ä¢ ‚úÖ Embeddings Generated: {len(embeddings[0])} dimensions")
            print(f"   ‚Ä¢ Sample values: {embeddings[0][:5]}...")
        else:
            print("   ‚Ä¢ ‚ùå No embeddings generated")
            
    except Exception as e:
        print(f"   ‚Ä¢ ‚ùå Error: {e}")
    
    print("\n2Ô∏è‚É£ **Vector DB Embedding Service**")
    
    # Test embedding service
    embedding_service = EmbeddingService()
    
    try:
        embedding = await embedding_service.generate_embedding(test_text)
        print(f"   ‚Ä¢ ‚úÖ Embedding Generated: {len(embedding)} dimensions")
        print(f"   ‚Ä¢ Sample values: {embedding[:5]}...")
        
        # Check if it's using hash fallback (all values would be similar pattern)
        if len(set(str(x)[:6] for x in embedding[:10])) == 1:
            print("   ‚Ä¢ ‚ö†Ô∏è  Using hash-based fallback (not LLM embeddings)")
        else:
            print("   ‚Ä¢ ‚úÖ Using LLM-generated embeddings")
            
    except Exception as e:
        print(f"   ‚Ä¢ ‚ùå Error: {e}")
    
    print("\n3Ô∏è‚É£ **Configuration Summary**")
    print(f"   ‚Ä¢ Default Provider: {os.getenv('LLM_PROVIDER', 'azure')}")
    print(f"   ‚Ä¢ Azure Embeddings Model: {os.getenv('AZURE_OPENAI_EMBEDDINGS_MODEL', 'text-embedding-ada-002')}")
    print(f"   ‚Ä¢ Together API Available: {'‚úÖ' if os.getenv('TOGETHER_API_KEY') else '‚ùå'}")
    print(f"   ‚Ä¢ Azure API Available: {'‚úÖ' if os.getenv('AZURE_OPENAI_API_KEY') else '‚ùå'}")

if __name__ == "__main__":
    asyncio.run(test_embedding_config())